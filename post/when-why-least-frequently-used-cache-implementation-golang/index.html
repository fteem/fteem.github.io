<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang | Ilija Eftimov ⚡️</title><meta name=keywords content="lfu"><meta name=description content="Over the years, people involved in computer science and engineering have worked really hard on optimisations of various natures. Given that we live in a world with limited resources, humanity has always worked on ways to optimise the costs and speed literally everything.
In software engineering, I would argue, the most popular approach to performance improvement is caching. While there are various applications of caching, depending on the area of software engineering, the idea behind caching is quite simple: store data that is often needed/used in fast structure/storage so it can be retrieved very fast."><meta name=author content="Ilija"><link rel=canonical href=https://ieftimov.com/post/when-why-least-frequently-used-cache-implementation-golang/><link href=/assets/css/stylesheet.min.css rel="preload stylesheet" as=style><link rel=icon href=https://ieftimov.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ieftimov.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ieftimov.com/favicon-32x32.png><link rel=apple-touch-icon href=https://ieftimov.com/apple-touch-icon.png><link rel=mask-icon href=https://ieftimov.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.83.1"><script async defer data-domain=ieftimov.com src=https://plausible.io/js/plausible.js></script><link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel=stylesheet><meta property="og:title" content="When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang"><meta property="og:description" content="Over the years, people involved in computer science and engineering have worked really hard on optimisations of various natures. Given that we live in a world with limited resources, humanity has always worked on ways to optimise the costs and speed literally everything.
In software engineering, I would argue, the most popular approach to performance improvement is caching. While there are various applications of caching, depending on the area of software engineering, the idea behind caching is quite simple: store data that is often needed/used in fast structure/storage so it can be retrieved very fast."><meta property="og:type" content="article"><meta property="og:url" content="https://ieftimov.com/post/when-why-least-frequently-used-cache-implementation-golang/"><meta property="og:image" content="https://ieftimov.com/cards/when-why-least-frequently-used-cache-implementation-golang.png"><meta property="article:published_time" content="2019-02-27T00:00:00+00:00"><meta property="article:modified_time" content="2019-02-27T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://ieftimov.com/cards/when-why-least-frequently-used-cache-implementation-golang.png"><meta name=twitter:title content="When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang"><meta name=twitter:description content="Over the years, people involved in computer science and engineering have worked really hard on optimisations of various natures. Given that we live in a world with limited resources, humanity has always worked on ways to optimise the costs and speed literally everything.
In software engineering, I would argue, the most popular approach to performance improvement is caching. While there are various applications of caching, depending on the area of software engineering, the idea behind caching is quite simple: store data that is often needed/used in fast structure/storage so it can be retrieved very fast."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ieftimov.com/posts/"},{"@type":"ListItem","position":2,"name":"When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang","item":"https://ieftimov.com/post/when-why-least-frequently-used-cache-implementation-golang/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang","name":"When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang","description":"Over the years, people involved in computer science and engineering have worked really hard on optimisations of various natures. Given that we live in a world with limited …","keywords":["lfu"],"articleBody":"Over the years, people involved in computer science and engineering have worked really hard on optimisations of various natures. Given that we live in a world with limited resources, humanity has always worked on ways to optimise the costs and speed literally everything.\nIn software engineering, I would argue, the most popular approach to performance improvement is caching. While there are various applications of caching, depending on the area of software engineering, the idea behind caching is quite simple: store data that is often needed/used in fast structure/storage so it can be retrieved very fast.\nIn fact, caches have to be fast along two dimensions:\n Ensuring that as many of the requests for files go to it (cache hit), not over the network or to main memory (cache miss); The overhead of using it should be small: testing membership and deciding when to replace a file should be as fast as possible.  In this article we will focus on the second part: taking a specific implementation approach to Least Frequently Used cache and making its membership test and eviction algorithms performant. Also, we’ll also cover the basics and explore where such a caching scheme can be useful.\nThe basics LFU is a caching algorithm in which the Least Frequently Used item in the cache is removed whenever the cache’s capacity limit is reached. This means that for every item in our cache we have to keep track of how frequently it is used. Once the capacity is exceeded of the cache, an eviction algorithm will be run which has to pick and expire (remove) items from the cache.\nIf you have ever implemented an LFU cache you’ve probably looked into using a min-heap data structure because it handles insertion, deletion, and update in logarithmic time complexity. In this article, we will look at another approach to implementing it.\nBut before we go into the implementation, let’s see in what cases LFU is better than the alternatives.\nWhere LFU shines Imagine an asset cache on a CDN, where the assets are cached based on the usage patterns. So, when users request some images for the web page they are requesting, this CDN will add it to its cache for other users to get it even faster.\nFor example, one such image (asset) is the logo of the website. Can you imagine how many times a day Google’s logo is requested across all of their products? I’d really like to find that number out, but for now, we can probably agree that the number is HUGE.\nSuch asset caches are the perfect use-case for LFU caches. An LFU cache eviction algorithm will never evict frequently accessed assets. In fact, in such a cache Google’s logo will be cached virtually forever. In contrast, if there are any images that are going to be accessed due to a new landing page of a new product that’s on front page of Reddit, Slashdot \u0026 Hackernews, once the hype-storm passes the assets will be evicted faster because the access frequency will drop dramatically, although in the past few days they have been accessed many times.\nAs you might already be noticing, this approach to cache eviction is very efficient in cases where the access patterns of the cached objects do not change often. While LRU caches will evict the assets that would not be accessed recently, the LFU eviction approach would evict the assets that are not needed any more after the hype has settled.\nImplementing an LFU cache Now, let’s get to the meat of it. As we said before, instead of looking at a min-heap as a possible data structure that would back our LFU cache, we’re going to look at a better approach.\nIn fact, in 2010, a group of researchers Prof. Ketan Shah, Anirban Mitra \u0026 Dhruv Matani published a paper titled “An O(1) algorithm for implementing the LFU cache eviction scheme” (you can check it here) in which they explain an implementation of an LFU cache that has a runtime complexity of O(1) for all of its operations, which include insertion, access and deletion (eviction).\nHere, I’ll show you how we can implement this cache and walk you through the implementation.\nThe data structure(s) Nope, it’s not going to be some sort of a Frankenstein red-black tree. It’s, in fact, two doubly-linked lists and a hash table. Yes, that’s all.\nTo be able to understand the fundamentals of this implementation of LFU, let’s look at the linked list and hash table as graphics. Before we look at the actual graphics, we need to understand how the hash table and linked lists will be used.\nThe hash table will store all of the items with a key that is processed through a hashing algorithm (for our purpose we can keep it simple) and the value will be the actual item:\nThe linked lists are a bit more complicated. The first one will be the “frequency list”, which will have all of the frequencies of access. Each of the nodes in this list will have an item list, which will contain all of the items that have been accessed with the corresponding frequency. Additionally, each of the items in the item list will have a pointer to their ancestor in the frequency list:\nIf we look at our graphical example above, we can notice that the items A, B, C and D have been accessed 1 time. The items E and F have been accessed 4 times and so on. The blue lines are the pointers that each of the items in the item lists has to their ancestor in the frequency list.\nSo, what would happen if item E gets accessed one more time? Let’s go through the steps:\n Retrieving the item from the hash table is easy (and scales well, O(1)) We would access the item’s frequencyParent pointer, from which we can check what is the next frequency in the list If the new frequency is present (e.g. 8), we will push it as the first item of the item list under frequency node 8. If the new frequency is not present, we will create the frequency node 8 and will add E to its item list  That’s it. Retrieving the item and refreshing the frequency of the item is O(1). Before we go into implementing the access algorithm, let’s first establish the basic types that we would need to make this work.\nTypes As we said earlier, we need to model the types required that will be the backbone of our cache.\nThe first struct will be the CacheItem. This will be the actual item that will be stored in the cache:\n1 2 3 4 5  type CacheItem struct { key string // Key of entry \tvalue interface{} // Value of item \tfrequencyParent *list.Element // Pointer to parent in cacheList }   It contains the key by which we can look it up in the hash table, the value which is the actual cached item and a frequencyParent pointer to the pointer in the frequency list.\nThe next struct is the FrequencyItem, which represents each of the items in the frequency list. It contains a set of entries which will be a set of CacheItem pointers. We will use a map to store it so we can treat it as a set, which contains only unique items:\n1 2 3 4  type FrequencyItem struct { entries map[*CacheItem]byte // Set of entries \tfreq int // Access frequency }   The last struct that we will need to have a smooth running cache is, well, the Cache itself:\n1 2 3 4 5 6  type Cache struct { bykey map[string]*CacheItem // Hashmap containing *CacheItems for O(1) access \tfreqs *list.List // Linked list of frequencies \tcapacity int // Max number of items \tsize int // Current size of cache }   The Cache will contain the hashmap, called bykey (the naming comes from the paper linked above), the frequency list called freqs, the maximum capacity of the cache called capacity and the size of the cache which represents the count of items cached at any given moment.\nNew, set \u0026 get Let’s look at the first three functions needed to make our cache work. The first one is a little constructor function:\n1 2 3 4 5 6 7 8 9  func New() *Cache { cache := new(Cache) cache.bykey = make(map[string]*CacheItem) cache.freqs = list.New() cache.size = 0 cache.capacity = 100 return \u0026c }   The constructor New will create a new Cache struct and will set all the defaults to it. In case you’re wondering how list.New() works: for the frequency list, we will use Go’s container/list package, which contains a neat linked-list implementation. You can check its documentation for more details.\nThe second function, which will be implemented on the Cache, is the Set function:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  func (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value // Increment item access frequency here \t} else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ // Eviction, if needed \t// Increment item access frequency \t} }   The function will take the cache key and the actual value/item to be cached as arguments. Then, it checks if the item is already cached or not. If it is cached, it will just update the value on the item. Otherwise, it will create a new CacheItem which will encapsulate the actual value, it will set the key, it will add the item to the bykey hashtable and it will increment the size of the cache.\nNow, in both logical branches I have added some comments for the missing pieces:\n Cache will have to know how to increment the access frequency for aCacheItem, but we are yet to implement that; Cache will have to know how to evict an item based on the access frequency if the size reaches the capacity.  We will keep these comments in until we implement the increment and evict functions.\nThe third function that Cache will receive is Get - accessing the item by the key from the hashtable and returning it:\n1 2 3 4 5 6 7 8  func (cache *Cache) Get(key string) interface{} { if e, ok := cache.bykey[key]; ok { // Increment acess frequency here \treturn e.value } return nil }   There’s no magic here as well - we check if the bykey hashtable contains a value with the key argument and we return it if present. Otherwise, we return nil. Here, just like in Set, we will leave the placeholder comment where we have to add the frequency increment function call once we implement it.\nUpdating the access frequency As we already saw, with every access action to the cache we have to update the access frequency of the accessed item.\nLet’s look at the steps that our Increment function would have to take. First, for the item to be expired we will have to decide if this item is already a part of the hash table and the frequency list or not. If it is, we will have to find out its new frequency value and its next frequency position (node) in the frequency list.\nSecond, we will have to figure out if for the new frequency there’s already a node in the frequency list or not. If there is one, we will have to add the item to its list of entries and assign its new access frequency (which is the current access frequency + 1). If there’s none, we will have to create a new frequency node in the frequency list (and set all of its sane defaults) and then add the item to its list of entries\nThird, once we have a FrequencyParent detected, our function will have to set the new parent to the item that’s being incremented and add it to the parent’s list of entries.\nAs the final step, the increment function will remove the item from the entries of the old frequency node (frequencyParent).\nHere’s the code in Golang:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  func (cache *Cache) increment(item *CacheItem) { currentFrequency := item.frequencyParent var nextFrequencyAmount int var nextFrequency *list.Element if currentFrequency == nil { nextFrequencyAmount = 1 nextFrequency = cache.freqs.Front() } else { nextFrequencyAmount = currentFrequency.Value.(*FrequencyItem).freq + 1 nextFrequency = currentFrequency.Next() } if nextFrequency == nil || nextFrequency.Value.(*FrequencyItem).freq != nextFrequencyAmount { newFrequencyItem := new(FrequencyItem) newFrequencyItem.freq = nextFrequencyAmount newFrequencyItem.entries = make(map[*CacheItem]byte) if currentFrequency == nil { nextFrequency = cache.freqs.PushFront(newFrequencyItem) } else { nextFrequency = cache.freqs.InsertAfter(newFrequencyItem, currentFrequency) } } item.frequencyParent = nextFrequency nextFrequency.Value.(*FrequencyItem).entries[item] = 1 if currentFrequency != nil { cache.remove(currentFrequency, item) } }   Let’s refer back to our original diagram of the frequency and entries lists and walk through incrementing the E item.\nThe first steps that our increment function will take are to allocate a pointer to node 4 (the frequencyParent) and its value (which is 4). Since node 4 is present in the list, it will find the next node in the frequency list, which in our case is node 7.\nOnce it figures out that the new frequency for the E node should be 5 and not 7, it will append a new frequency node in the list, between nodes 4 and 7:\nOnce the 5 node is added to the list, the function will set the defaults needed for the node to function properly. Then it will set E’s pointer to the new frequencyParent (the 5 node):\nAs the last step it will take the item, which has a *CacheItem type, and will add it to the entries list while deleting it from the entries list from the previous frequencyParent:\nLet’s look at what are the steps to remove a CacheItem from a FrequencyItem’s entries list.\nRemoving entries Once we know the node in the list from which we want to remove it, we can just remove the item from the entries list and also completely remove the FrequencyItem from the frequency list if the entries become empty:\n1 2 3 4 5 6 7  func (cache *Cache) Remove(listItem *list.Element, item *CacheItem) { frequencyItem := listItem.Value.(*FrequencyItem) delete(frequencyItem.entries, item) if len(frequencyItem.entries) == 0 { cache.freqs.Remove(listItem) } }   Eviction The last piece of the puzzle is eviction, or in other words, removing the least frequently used items once the cache reaches its maximum capacity.\nWe have to know how many items we want to evict. Usually, our cache would have a low and high bound, so when the high bound is reached we will remove items until the low bound. In our case, we will evict an arbitrary number of items, that the Evict function will take as an argument.\nThe function will start to “walk through” the frequency list from the beginning towards the end. Since the frequency list is in ascending order, it will start to remove the entries from the first frequency node onwards, until it removes as many items as the arbitrary number passed in.\nIf a frequency node contains no entries due to eviction, the Evict function will have to remove the frequency node from the frequency list as well. It will do that by invoking the Remove function. That way, the eviction will not leave any garbage behind.\nHere’s the code of what we described above:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  func (cache *Cache) Evict(count int) { for i := 0; i if item := cache.freqs.Front(); item != nil { for entry, _ := range item.Value.(*FrequencyItem).entries { if i delete(cache.bykey, entry.key) cache.Remove(item, entry) cache.size-- i++ } } } } }   Back to Set and Get At the beginning of this article we implemented the Set and Get functions. One thing that we didn’t have available back then is the Evict and increment functions, so we can use them accordingly. Let’s add their invocation.\nIncrementing access frequency In the Get function, if we find an item in the bykey hash table, we need to increment it’s access frequency before we proceed to return its value:\n1 2 3 4 5 6 7 8  func (cache *Cache) Get(key string) interface{} { if e, ok := cache.bykey[key]; ok { cache.increment(e) return e.value } return nil }   With this change, the Cache will increment the frequency of that particular item before we return it. But, are we forgetting something? Also, the Set function makes access to the cached items when it actually caches them. This means that when an item is cached it will immediately be added to the frequency list, under the node with value 1:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  func (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value cache.increment(item) } else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ // Eviction, if needed  cache.increment(item) } }   Eviction after addition The Set function allows users of our LFU Cache to cache more items in it. A key component of any cache is that it should know how to evict items (free up space) when new items are added to the cache. For an LFU cache, the least frequently used items need to be removed when the cache is at capacity.\nLet’s first add a function that will return a bool if the cache has reached its maximum capacity:\n1 2 3  func (cache *Cache) atCapacity() bool { return cache.size = cache.capacity }   The function is simple: checks if the current size of the Cache is bigger or equals than the capacity.\nNow, let’s put this into use in the Set function. Once we have a new item set in the cache, we have to check if the cache has reached its capacity and then evict a number of items from it.\nFor simplicity, we will remove only 10 items every time we reach max capacity:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  func (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value cache.increment(item) } else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ if cache.atCapacity() { cache.Evict(10) } cache.increment(item) } }   With this change, if at any point adding an item reaches the capacity of the cache, the cache will evict the least frequently used items.\nIf you would like to see the whole code for this article, you can check out this gist.\nComments on scaling and time complexity LFU is an interesting eviction scheme, especially when compared to LRU, in my opinion, due to its unconventional nature. While its application is limited, the algorithm and the backing data structures explained in the paper used in this article are fascinating due to the scaling ability of the approach.\nIf we revisit the paper that we mentioned at the beginning of the article, we will see that while LFU is not news, but it was traditionally implemented using a min-heap, which has a logarithmic time for insert, lookup and deletion. Interestingly in this paper, the authors explain that the approach they propose has an O(1) time complexity for each of the operations (insertion, lookup and deletion) because the operations are based on a hash table. Additionally, the linked lists do not add any time complexity because we do not traverse the lists at any point - we merely add or remove a node in them if needed (which is an O(1) operation).\nIn closing In this article, we went through the basics of LFU caches. We established what are the most important performance metrics (hit to miss ratio, membership \u0026 eviction speed). We saw that while it’s not the most widely used caching scheme, it sure can be very performant in some use cases.\nThen we went on to implement it, using an approach that scales quite well in terms of time complexity. We saw the complexities of implementing the eviction and frequency incrementation algorithms. In the end, we explored some more how the approach we used to implement it scales.\nIf you would like to read more on the topic, here are a couple of links that will enrich your knowledge of LFU caches and caching in general:\n “An O(1) algorithm for implementing the LFU cache eviction scheme” - Prof. Ketan Shah, Anirban Mitra, Dhruv Matani “Caching in theory and practice” - Pavel Panchekha “LFU (Least Frequently Used) Cache Implementation”  Geeks for Geeks    Liked this article? You can buy me a coffee. Or simply subscribe to my newsletter and get my fresh posts in your inbox. It's short and sweet, going out monthly to over 1,000 subscribers.  ","wordCount":"3493","inLanguage":"en","datePublished":"2019-02-27T00:00:00Z","dateModified":"2019-02-27T00:00:00Z","author":{"@type":"Person","name":"Ilija"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ieftimov.com/post/when-why-least-frequently-used-cache-implementation-golang/"},"publisher":{"@type":"Organization","name":"Ilija Eftimov ⚡️","logo":{"@type":"ImageObject","url":"https://ieftimov.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://ieftimov.com/ accesskey=h title="Ilija Eftimov ⚡️ (Alt + H)">Ilija Eftimov ⚡️</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://ieftimov.com/ title=About><span>About</span></a></li><li><a href=https://ieftimov.com/posts title=Writing><span>Writing</span></a></li><li><a href=https://ieftimov.com/newsletter title=Newsletter><span>Newsletter</span></a></li><li><a href=https://forms.gle/orfXK5jh1LRaiFzo8 title="Suggest a topic"><span>Suggest a topic</span></a></li><li><a href=https://www.buymeacoffee.com/ieftimov title="Buy me a ☕"><span>Buy me a ☕</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang</h1><div class=post-meta>February 27, 2019&nbsp;·&nbsp;17 min&nbsp;·&nbsp;Ilija</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#the-basics aria-label="The basics">The basics</a><ul><li><a href=#where-lfu-shines aria-label="Where LFU shines">Where LFU shines</a></li></ul></li><li><a href=#implementing-an-lfu-cache aria-label="Implementing an LFU cache">Implementing an LFU cache</a><ul><li><a href=#the-data-structures aria-label="The data structure(s)">The data structure(s)</a></li><li><a href=#types aria-label=Types>Types</a></li><li><a href=#new-set--get aria-label="New, set &amp;amp; get">New, set & get</a></li><li><a href=#updating-the-access-frequency aria-label="Updating the access frequency">Updating the access frequency</a></li><li><a href=#removing-entries aria-label="Removing entries">Removing entries</a></li><li><a href=#eviction aria-label=Eviction>Eviction</a></li><li><a href=#back-to-set-and-get aria-label="Back to Set and Get">Back to Set and Get</a><ul><li><a href=#incrementing-access-frequency aria-label="Incrementing access frequency">Incrementing access frequency</a></li><li><a href=#eviction-after-addition aria-label="Eviction after addition">Eviction after addition</a></li></ul></li></ul></li><li><a href=#comments-on-scaling-and-time-complexity aria-label="Comments on scaling and time complexity">Comments on scaling and time complexity</a></li><li><a href=#in-closing aria-label="In closing">In closing</a></li></ul></div></details></div><div class=post-content><p>Over the years, people involved in computer science and engineering have worked
really hard on optimisations of various natures. Given that we live in a world
with limited resources, humanity has always worked on ways to optimise the
costs and speed literally everything.</p><p>In software engineering, I would argue, the most popular approach to
performance improvement is caching. While there are various applications of
caching, depending on the area of software engineering, the idea behind caching
is quite simple: store data that is often needed/used in fast structure/storage
so it can be retrieved very fast.</p><p>In fact, caches have to be fast along two dimensions:</p><ol><li>Ensuring that as many of the requests for files go to it (cache hit), not
over the network or to main memory (cache miss);</li><li>The overhead of using it should be small: testing membership and deciding
when to replace a file should be as fast as possible.</li></ol><p>In this article we will focus on the second part: taking a specific
implementation approach to Least Frequently Used cache and making its
membership test and eviction algorithms performant. Also, we&rsquo;ll also cover the
basics and explore where such a caching scheme can be useful.</p><h2 id=the-basics>The basics<a hidden class=anchor aria-hidden=true href=#the-basics>#</a></h2><p>LFU is a caching algorithm in which the Least Frequently Used item in the cache
is removed whenever the cache&rsquo;s capacity limit is reached. This means that for
every item in our cache we have to keep track of how frequently it is used.
Once the capacity is exceeded of the cache, an eviction algorithm will be run
which has to pick and expire (remove) items from the cache.</p><p>If you have ever implemented an LFU cache you&rsquo;ve probably looked into using a
min-heap data structure because it handles insertion, deletion, and update in
logarithmic time complexity. In this article, we will look at another approach
to implementing it.</p><p>But before we go into the implementation, let&rsquo;s see in what cases LFU is better
than the alternatives.</p><h3 id=where-lfu-shines>Where LFU shines<a hidden class=anchor aria-hidden=true href=#where-lfu-shines>#</a></h3><p>Imagine an asset cache on a CDN, where the assets are cached based on the usage
patterns. So, when users request some images for the web page they are
requesting, this CDN will add it to its cache for other users to get it even
faster.</p><p>For example, one such image (asset) is the logo of the website. Can you imagine
how many times a day Google&rsquo;s logo is requested across all of their products?
I&rsquo;d really like to find that number out, but for now, we can probably agree
that the number is <strong>HUGE</strong>.</p><p>Such asset caches are the perfect use-case for LFU caches. An LFU cache
eviction algorithm will never evict frequently accessed assets. In fact, in
such a cache Google&rsquo;s logo will be cached virtually forever. In contrast, if
there are any images that are going to be accessed due to a new landing page of
a new product that&rsquo;s on front page of Reddit, Slashdot & Hackernews, once the
hype-storm passes the assets will be evicted faster because the access
frequency will drop dramatically, although in the past few days they have been
accessed many times.</p><p>As you might already be noticing, this approach to cache eviction is very
efficient in cases where the access patterns of the cached objects do not
change often. While LRU caches will evict the assets that would not be accessed
recently, the LFU eviction approach would evict the assets that are not needed
any more after the hype has settled.</p><h2 id=implementing-an-lfu-cache>Implementing an LFU cache<a hidden class=anchor aria-hidden=true href=#implementing-an-lfu-cache>#</a></h2><p>Now, let&rsquo;s get to the meat of it. As we said before, instead of looking at a
min-heap as a possible data structure that would back our LFU cache, we&rsquo;re
going to look at a better approach.</p><p>In fact, in 2010, a group of researchers Prof. Ketan Shah, Anirban Mitra &
Dhruv Matani published a paper titled &ldquo;An O(1) algorithm for implementing the
LFU cache eviction scheme&rdquo; (you can check it
<a href=http://dhruvbird.com/lfu.pdf>here</a>) in which they explain an implementation
of an LFU cache that has a runtime complexity of <code>O(1)</code> for all of its
operations, which include insertion, access and deletion (eviction).</p><p>Here, I&rsquo;ll show you how we can implement this cache and walk you through the
implementation.</p><h3 id=the-data-structures>The data structure(s)<a hidden class=anchor aria-hidden=true href=#the-data-structures>#</a></h3><p>Nope, it&rsquo;s not going to be some sort of a Frankenstein red-black tree. It&rsquo;s, in
fact, two doubly-linked lists and a hash table. Yes, that&rsquo;s all.</p><p>To be able to understand the fundamentals of this implementation of LFU, let&rsquo;s
look at the linked list and hash table as graphics. Before we look at the
actual graphics, we need to understand how the hash table and linked lists will
be used.</p><p>The hash table will store all of the items with a key that is processed through
a hashing algorithm (for our purpose we can keep it simple) and the value will
be the actual item:</p><p><img src=/golang-lfu-cache/lfu-backbone-hashtable.png alt></p><p>The linked lists are a bit more complicated. The first one will be the
&ldquo;frequency list&rdquo;, which will have all of the frequencies of access. Each of the
nodes in this list will have an item list, which will contain all of the items
that have been accessed with the corresponding frequency. Additionally, each of
the items in the item list will have a pointer to their ancestor in the
frequency list:</p><p><img src=/golang-lfu-cache/lfu-backbone-linked-lists.png alt></p><p>If we look at our graphical example above, we can notice that the items <code>A</code>,
<code>B</code>, <code>C</code> and <code>D</code> have been accessed 1 time. The items <code>E</code> and <code>F</code> have been
accessed 4 times and so on. The blue lines are the pointers that each of the
items in the item lists has to their ancestor in the frequency list.</p><p>So, what would happen if item <code>E</code> gets accessed one more time? Let&rsquo;s go through
the steps:</p><ol><li>Retrieving the item from the hash table is easy (and scales well, <code>O(1)</code>)</li><li>We would access the item&rsquo;s <code>frequencyParent</code> pointer, from which we can
check what is the next frequency in the list</li><li>If the new frequency is present (e.g. <code>8</code>), we will push it as the first
item of the item list under frequency node <code>8</code>.</li><li>If the new frequency is not present, we will create the frequency node <code>8</code>
and will add <code>E</code> to its item list</li></ol><p>That&rsquo;s it. Retrieving the item and refreshing the frequency of the item is
<code>O(1)</code>. Before we go into implementing the access algorithm, let&rsquo;s first
establish the basic types that we would need to make this work.</p><h3 id=types>Types<a hidden class=anchor aria-hidden=true href=#types>#</a></h3><p>As we said earlier, we need to model the types required that will be the
backbone of our cache.</p><p>The first <code>struct</code> will be the <code>CacheItem</code>. This will be the actual item that
will be stored in the cache:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">5
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>type</span> CacheItem <span style=color:#0087ff>struct</span> {
	key      	<span style=color:#af0000>string</span>        <span style=color:#4e4e4e>// Key of entry
</span><span style=color:#4e4e4e></span>	value    	<span style=color:#0087ff>interface</span>{}   <span style=color:#4e4e4e>// Value of item
</span><span style=color:#4e4e4e></span>	frequencyParent *list.Element <span style=color:#4e4e4e>// Pointer to parent in cacheList
</span><span style=color:#4e4e4e></span>}</code></pre></td></tr></table></div></div><p>It contains the <code>key</code> by which we can look it up in the hash table, the <code>value</code>
which is the actual cached item and a <code>frequencyParent</code> pointer to the pointer
in the frequency list.</p><p>The next <code>struct</code> is the <code>FrequencyItem</code>, which represents each of the items in
the frequency list. It contains a set of entries which will be a set of
<code>CacheItem</code> pointers. We will use a <code>map</code> to store it so we can treat it as a
set, which contains only unique items:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>type</span> FrequencyItem <span style=color:#0087ff>struct</span> {
	entries <span style=color:#0087ff>map</span>[*CacheItem]<span style=color:#af0000>byte</span> <span style=color:#4e4e4e>// Set of entries
</span><span style=color:#4e4e4e></span>	freq    <span style=color:#af0000>int</span>                  <span style=color:#4e4e4e>// Access frequency
</span><span style=color:#4e4e4e></span>}</code></pre></td></tr></table></div></div><p>The last <code>struct</code> that we will need to have a smooth running cache is, well, the
<code>Cache</code> itself:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">6
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>type</span> Cache <span style=color:#0087ff>struct</span> {
	bykey       <span style=color:#0087ff>map</span>[<span style=color:#af0000>string</span>]*CacheItem <span style=color:#4e4e4e>// Hashmap containing *CacheItems for O(1) access
</span><span style=color:#4e4e4e></span>	freqs       *list.List            <span style=color:#4e4e4e>// Linked list of frequencies
</span><span style=color:#4e4e4e></span>	capacity    <span style=color:#af0000>int</span>                   <span style=color:#4e4e4e>// Max number of items
</span><span style=color:#4e4e4e></span>	size        <span style=color:#af0000>int</span>                   <span style=color:#4e4e4e>// Current size of cache
</span><span style=color:#4e4e4e></span>}</code></pre></td></tr></table></div></div><p>The <code>Cache</code> will contain the hashmap, called <code>bykey</code> (the naming comes from the
paper linked above), the frequency list called <code>freqs</code>, the maximum capacity of
the cache called <code>capacity</code> and the <code>size</code> of the cache which represents the
count of items cached at any given moment.</p><h3 id=new-set--get>New, set & get<a hidden class=anchor aria-hidden=true href=#new-set--get>#</a></h3><p>Let&rsquo;s look at the first three functions needed to make our cache work. The first
one is a little constructor function:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">7
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">8
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">9
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> <span style=color:#0087ff>New</span>() *Cache {
	cache := <span style=color:#0087ff>new</span>(Cache)
	cache.bykey = <span style=color:#0087ff>make</span>(<span style=color:#0087ff>map</span>[<span style=color:#af0000>string</span>]*CacheItem)
	cache.freqs = list.<span style=color:#0087ff>New</span>()
	cache.size = <span style=color:#00afaf>0</span>
	cache.capacity = <span style=color:#00afaf>100</span>

	<span style=color:#5f8700>return</span> &amp;c
}</code></pre></td></tr></table></div></div><p>The constructor <code>New</code> will create a new <code>Cache</code> struct and will set all the
defaults to it. In case you&rsquo;re wondering how <code>list.New()</code> works: for the
frequency list, we will use Go&rsquo;s <code>container/list</code> package, which contains a neat
linked-list implementation. You can check
<a href=https://golang.org/pkg/container/list/>its documentation</a> for more details.</p><p>The second function, which will be implemented on the <code>Cache</code>, is the <code>Set</code>
function:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 7
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 8
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 9
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">10
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">11
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">12
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">13
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>Set</span>(key <span style=color:#af0000>string</span>, value <span style=color:#0087ff>interface</span>{}) {
	<span style=color:#5f8700>if</span> item, ok := cache.bykey[key]; ok {
		item.value = value
		<span style=color:#4e4e4e>// Increment item access frequency here
</span><span style=color:#4e4e4e></span>	} <span style=color:#5f8700>else</span> {
		item := <span style=color:#0087ff>new</span>(CacheItem)
		item.key = key
		item.value = value
		cache.bykey[key] = item
		cache.size++
		<span style=color:#4e4e4e>// Eviction, if needed
</span><span style=color:#4e4e4e></span>		<span style=color:#4e4e4e>// Increment item access frequency
</span><span style=color:#4e4e4e></span>	}
}</code></pre></td></tr></table></div></div><p>The function will take the cache key and the actual value/item to be cached as
arguments. Then, it checks if the item is already cached or not. If it is cached,
it will just update the value on the item. Otherwise, it will create a new
<code>CacheItem</code> which will encapsulate the actual value, it will set the <code>key</code>,
it will add the item to the <code>bykey</code> hashtable and it will increment the <code>size</code>
of the cache.</p><p>Now, in both logical branches I have added some comments for the missing pieces:</p><ol><li><code>Cache</code> will have to know how to increment the access frequency for
a<code>CacheItem</code>, but we are yet to implement that;</li><li><code>Cache</code> will have to know how to evict an item based on the access frequency
if the <code>size</code> reaches the <code>capacity</code>.</li></ol><p>We will keep these comments in until we implement the <code>increment</code> and <code>evict</code>
functions.</p><p>The third function that <code>Cache</code> will receive is <code>Get</code> - accessing the item by
the key from the hashtable and returning it:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">7
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>Get</span>(key <span style=color:#af0000>string</span>) <span style=color:#0087ff>interface</span>{} {
	<span style=color:#5f8700>if</span> e, ok := cache.bykey[key]; ok {
		<span style=color:#4e4e4e>// Increment acess frequency here
</span><span style=color:#4e4e4e></span>		<span style=color:#5f8700>return</span> e.value
	}

	<span style=color:#5f8700>return</span> <span style=color:#d75f00>nil</span>
}</code></pre></td></tr></table></div></div><p>There&rsquo;s no magic here as well - we check if the <code>bykey</code> hashtable contains a
value with the <code>key</code> argument and we return it if present. Otherwise, we return
<code>nil</code>. Here, just like in <code>Set</code>, we will leave the placeholder comment where we
have to add the frequency increment function call once we implement it.</p><h3 id=updating-the-access-frequency>Updating the access frequency<a hidden class=anchor aria-hidden=true href=#updating-the-access-frequency>#</a></h3><p>As we already saw, with every <strong>access</strong> action to the cache we have to update
the access frequency of the accessed item.</p><p>Let&rsquo;s look at the steps that our <code>Increment</code> function would have to take.
First, for the item to be expired we will have to decide if this item is already
a part of the hash table and the frequency list or not. If it is, we will have
to find out its new frequency value and its next frequency position (node) in
the frequency list.</p><p>Second, we will have to figure out if for the new frequency there&rsquo;s already a
node in the frequency list or not. If there is one, we will have to add the item
to its list of <code>entries</code> and assign its new access frequency
(which is the current access frequency + 1). If there&rsquo;s none, we will have to
create a new frequency node in the frequency list (and set all of its sane
defaults) and then add the item to its list of <code>entries</code></p><p>Third, once we have a <code>FrequencyParent</code> detected, our function will have to set
the new parent to the <code>item</code> that&rsquo;s being incremented and add it to the parent&rsquo;s
list of <code>entries</code>.</p><p>As the final step, the <code>increment</code> function will remove the item from the
<code>entries</code> of the old frequency node (<code>frequencyParent</code>).</p><p>Here&rsquo;s the code in Golang:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 7
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 8
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 9
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">10
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">11
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">12
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">13
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">14
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">15
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">16
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">17
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">18
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">19
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">20
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">21
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">22
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">23
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">24
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">25
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">26
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">27
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">28
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">29
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">30
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>increment</span>(item *CacheItem) {
	currentFrequency := item.frequencyParent
	<span style=color:#0087ff>var</span> nextFrequencyAmount <span style=color:#af0000>int</span>
	<span style=color:#0087ff>var</span> nextFrequency *list.Element

	<span style=color:#5f8700>if</span> currentFrequency == <span style=color:#d75f00>nil</span> {
		nextFrequencyAmount = <span style=color:#00afaf>1</span>
		nextFrequency = cache.freqs.<span style=color:#0087ff>Front</span>()
	} <span style=color:#5f8700>else</span> {
		nextFrequencyAmount = currentFrequency.Value.(*FrequencyItem).freq + <span style=color:#00afaf>1</span>
		nextFrequency = currentFrequency.<span style=color:#0087ff>Next</span>()
	}

	<span style=color:#5f8700>if</span> nextFrequency == <span style=color:#d75f00>nil</span> || nextFrequency.Value.(*FrequencyItem).freq != nextFrequencyAmount {
		newFrequencyItem := <span style=color:#0087ff>new</span>(FrequencyItem)
		newFrequencyItem.freq = nextFrequencyAmount
		newFrequencyItem.entries = <span style=color:#0087ff>make</span>(<span style=color:#0087ff>map</span>[*CacheItem]<span style=color:#af0000>byte</span>)
		<span style=color:#5f8700>if</span> currentFrequency == <span style=color:#d75f00>nil</span> {
			nextFrequency = cache.freqs.<span style=color:#0087ff>PushFront</span>(newFrequencyItem)
		} <span style=color:#5f8700>else</span> {
			nextFrequency = cache.freqs.<span style=color:#0087ff>InsertAfter</span>(newFrequencyItem, currentFrequency)
		}
	}

	item.frequencyParent = nextFrequency
	nextFrequency.Value.(*FrequencyItem).entries[item] = <span style=color:#00afaf>1</span>
	<span style=color:#5f8700>if</span> currentFrequency != <span style=color:#d75f00>nil</span> {
		cache.<span style=color:#0087ff>remove</span>(currentFrequency, item)
	}
}</code></pre></td></tr></table></div></div><p>Let&rsquo;s refer back to our original diagram of the frequency and entries lists and
walk through incrementing the <code>E</code> item.</p><p><img src=/golang-lfu-cache/e-cached-item.png alt></p><p>The first steps that our <code>increment</code> function will take are to allocate a
pointer to node <code>4</code> (the <code>frequencyParent</code>) and its <code>value</code> (which is <code>4</code>).
Since node <code>4</code> is present in the list, it will find the next node in the
frequency list, which in our case is node <code>7</code>.</p><p>Once it figures out that the new frequency for the <code>E</code> node should be <code>5</code> and not
<code>7</code>, it will append a new frequency node in the list, between nodes <code>4</code> and <code>7</code>:</p><p><img src=/golang-lfu-cache/new-frequency-insertion.png alt></p><p>Once the <code>5</code> node is added to the list, the function will set the defaults needed
for the node to function properly. Then it will set <code>E</code>&rsquo;s pointer to the new
<code>frequencyParent</code> (the <code>5</code> node):</p><p><img src=/golang-lfu-cache/e-parent-frequency-pointer.png alt></p><p>As the last step it will take the <code>item</code>, which has a <code>*CacheItem</code> type, and
will add it to the <code>entries</code> list while deleting it from the <code>entries</code> list from
the previous <code>frequencyParent</code>:</p><p><img src=/golang-lfu-cache/new-frequency-entry-insertion.png alt></p><p>Let&rsquo;s look at what are the steps to remove a <code>CacheItem</code> from a <code>FrequencyItem</code>&rsquo;s
<code>entries</code> list.</p><h3 id=removing-entries>Removing entries<a hidden class=anchor aria-hidden=true href=#removing-entries>#</a></h3><p>Once we know the node in the list from which we want to remove it, we can just
remove the item from the <code>entries</code> list and also completely remove the
<code>FrequencyItem</code> from the frequency list if the <code>entries</code> become empty:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">7
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>Remove</span>(listItem *list.Element, item *CacheItem) {
	frequencyItem := listItem.Value.(*FrequencyItem)
	<span style=color:#0087ff>delete</span>(frequencyItem.entries, item)
	<span style=color:#5f8700>if</span> <span style=color:#0087ff>len</span>(frequencyItem.entries) == <span style=color:#00afaf>0</span> {
		cache.freqs.<span style=color:#0087ff>Remove</span>(listItem)
	}
}</code></pre></td></tr></table></div></div><h3 id=eviction>Eviction<a hidden class=anchor aria-hidden=true href=#eviction>#</a></h3><p>The last piece of the puzzle is eviction, or in other words, removing the least
frequently used items once the cache reaches its maximum capacity.</p><p>We have to know how many items we want to evict. Usually, our cache would have
a low and high bound, so when the high bound is reached we will remove items
until the low bound. In our case, we will evict an arbitrary number of items,
that the <code>Evict</code> function will take as an argument.</p><p>The function will start to &ldquo;walk through&rdquo; the frequency list from the beginning
towards the end. Since the frequency list is in ascending order, it will start
to remove the <code>entries</code> from the first frequency node onwards, until it removes
as many items as the arbitrary number passed in.</p><p>If a frequency node contains no <code>entries</code> due to eviction, the <code>Evict</code> function
will have to remove the frequency node from the frequency list as well. It will
do that by invoking the <code>Remove</code> function. That way, the eviction will not
leave any garbage behind.</p><p>Here&rsquo;s the code of what we described above:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 7
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 8
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 9
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">10
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">11
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">12
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">13
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>Evict</span>(count <span style=color:#af0000>int</span>) {
	<span style=color:#5f8700>for</span> i := <span style=color:#00afaf>0</span>; i &lt; count; {
		<span style=color:#5f8700>if</span> item := cache.freqs.<span style=color:#0087ff>Front</span>(); item != <span style=color:#d75f00>nil</span> {
			<span style=color:#5f8700>for</span> entry, _ := <span style=color:#5f8700>range</span> item.Value.(*FrequencyItem).entries {
				<span style=color:#5f8700>if</span> i &lt; count {
					<span style=color:#0087ff>delete</span>(cache.bykey, entry.key)
					cache.<span style=color:#0087ff>Remove</span>(item, entry)
					cache.size--
					i++
				}
			}
		}
	}
}</code></pre></td></tr></table></div></div><h3 id=back-to-set-and-get>Back to Set and Get<a hidden class=anchor aria-hidden=true href=#back-to-set-and-get>#</a></h3><p>At the beginning of this article we implemented the <code>Set</code> and <code>Get</code> functions.
One thing that we didn&rsquo;t have available back then is the <code>Evict</code> and <code>increment</code>
functions, so we can use them accordingly. Let&rsquo;s add their invocation.</p><h4 id=incrementing-access-frequency>Incrementing access frequency<a hidden class=anchor aria-hidden=true href=#incrementing-access-frequency>#</a></h4><p>In the <code>Get</code> function, if we find an item in the <code>bykey</code> hash table, we need
to increment it&rsquo;s access frequency before we proceed to return its <code>value</code>:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">7
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>Get</span>(key <span style=color:#af0000>string</span>) <span style=color:#0087ff>interface</span>{} {
	<span style=color:#5f8700>if</span> e, ok := cache.bykey[key]; ok {
		cache.<span style=color:#0087ff>increment</span>(e)
		<span style=color:#5f8700>return</span> e.value
	}

	<span style=color:#5f8700>return</span> <span style=color:#d75f00>nil</span>
}</code></pre></td></tr></table></div></div><p>With this change, the <code>Cache</code> will increment the frequency of that particular
item before we return it. But, are we forgetting something? Also, the <code>Set</code>
function makes access to the cached items when it actually caches them. This
means that when an item is cached it will immediately be added to the frequency
list, under the node with value <code>1</code>:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 7
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 8
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 9
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">10
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">11
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">12
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">13
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>Set</span>(key <span style=color:#af0000>string</span>, value <span style=color:#0087ff>interface</span>{}) {
	<span style=color:#5f8700>if</span> item, ok := cache.bykey[key]; ok {
		item.value = value
                cache.<span style=color:#0087ff>increment</span>(item)
	} <span style=color:#5f8700>else</span> {
		item := <span style=color:#0087ff>new</span>(CacheItem)
		item.key = key
		item.value = value
		cache.bykey[key] = item
		cache.size++
		<span style=color:#4e4e4e>// Eviction, if needed
</span><span style=color:#4e4e4e></span>                cache.<span style=color:#0087ff>increment</span>(item)
	}
}</code></pre></td></tr></table></div></div><h4 id=eviction-after-addition>Eviction after addition<a hidden class=anchor aria-hidden=true href=#eviction-after-addition>#</a></h4><p>The <code>Set</code> function allows users of our LFU <code>Cache</code> to cache more items in it.
A key component of any cache is that it should know how to evict items (free up
space) when new items are added to the cache. For an LFU cache, the least
frequently used items need to be removed when the cache is at capacity.</p><p>Let&rsquo;s first add a function that will return a <code>bool</code> if the cache has reached
its maximum capacity:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">3
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>atCapacity</span>() <span style=color:#af0000>bool</span> {
	<span style=color:#5f8700>return</span> cache.size &gt;= cache.capacity
}</code></pre></td></tr></table></div></div><p>The function is simple: checks if the current <code>size</code> of the <code>Cache</code> is bigger
or equals than the <code>capacity</code>.</p><p>Now, let&rsquo;s put this into use in the <code>Set</code> function. Once we have a new item set
in the cache, we have to check if the cache has reached its capacity and then
evict a number of items from it.</p><p>For simplicity, we will remove only 10 items every time we reach max capacity:</p><div class=highlight><div style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 1
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 2
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 3
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 4
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 5
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 6
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 7
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 8
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545"> 9
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">10
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">11
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">12
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">13
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">14
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">15
</span><span style="margin-right:.4em;padding:0 .4em;color:#454545">16
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=color:#8a8a8a;background-color:#1c1c1c;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#0087ff>func</span> (cache *Cache) <span style=color:#0087ff>Set</span>(key <span style=color:#af0000>string</span>, value <span style=color:#0087ff>interface</span>{}) {
	<span style=color:#5f8700>if</span> item, ok := cache.bykey[key]; ok {
		item.value = value
		cache.<span style=color:#0087ff>increment</span>(item)
	} <span style=color:#5f8700>else</span> {
		item := <span style=color:#0087ff>new</span>(CacheItem)
		item.key = key
		item.value = value
		cache.bykey[key] = item
		cache.size++
		<span style=color:#5f8700>if</span> cache.<span style=color:#0087ff>atCapacity</span>() {
			cache.<span style=color:#0087ff>Evict</span>(<span style=color:#00afaf>10</span>)
		}
		cache.<span style=color:#0087ff>increment</span>(item)
	}
}</code></pre></td></tr></table></div></div><p>With this change, if at any point adding an item reaches the capacity of the
cache, the cache will evict the least frequently used items.</p><p>If you would like to see the whole code for this article, you can check out
<a href=https://gist.github.com/fteem/ff1ef56f4ee83700f052b308e2fc6ba6>this gist</a>.</p><h2 id=comments-on-scaling-and-time-complexity>Comments on scaling and time complexity<a hidden class=anchor aria-hidden=true href=#comments-on-scaling-and-time-complexity>#</a></h2><p>LFU is an interesting eviction scheme, especially when compared to LRU, in my
opinion, due to its unconventional nature. While its application is limited,
the algorithm and the backing data structures explained in the paper used in
this article are fascinating due to the scaling ability of the approach.</p><p>If we revisit <a href=http://dhruvbird.com/lfu.pdf>the paper</a> that we mentioned at
the beginning of the article, we will see that while LFU is not news, but it
was traditionally implemented using a min-heap, which has a logarithmic time
for insert, lookup and deletion. Interestingly in this paper, the authors
explain that the approach they propose has an <code>O(1)</code> time complexity for each
of the operations (insertion, lookup and deletion) because the operations are
based on a hash table. Additionally, the linked lists do not add any time
complexity because we do not traverse the lists at any point - we merely add or
remove a node in them if needed (which is an O(1) operation).</p><h2 id=in-closing>In closing<a hidden class=anchor aria-hidden=true href=#in-closing>#</a></h2><p>In this article, we went through the basics of LFU caches. We established what
are the most important performance metrics (hit to miss ratio, membership &
eviction speed). We saw that while it&rsquo;s not the most widely used caching
scheme, it sure can be very performant in some use cases.</p><p>Then we went on to implement it, using an approach that scales quite well in
terms of time complexity. We saw the complexities of implementing the eviction
and frequency incrementation algorithms. In the end, we explored some more how
the approach we used to implement it scales.</p><p>If you would like to read more on the topic, here are a couple of links that
will enrich your knowledge of LFU caches and caching in general:</p><ul><li><a href=http://dhruvbird.com/lfu.pdf>&ldquo;An O(1) algorithm for implementing the LFU cache eviction
scheme&rdquo;</a> - Prof. Ketan Shah, Anirban Mitra,
Dhruv Matani</li><li><a href=https://blogs.dropbox.com/tech/2012/10/caching-in-theory-and-practice/>&ldquo;Caching in theory and practice&rdquo;</a> -
Pavel Panchekha</li><li><a href=https://www.geeksforgeeks.org/lfu-least-frequently-used-cache-implementation/>&ldquo;LFU (Least Frequently Used) Cache
Implementation&rdquo;</a><ul><li>Geeks for Geeks</li></ul></li></ul><section class=subscribe><b>Liked this article?</b>
You can <a href=https://www.buymeacoffee.com/ieftimov>buy me a coffee</a>.
Or simply <a href=/newsletter>subscribe to my
newsletter</a> and get my fresh posts in your inbox. It's short and sweet,
going out monthly to over 1,000 subscribers.</section></div><footer class=post-footer><ul class=post-tags><li><a href=https://ieftimov.com/tags/lfu/>lfu</a></li></ul><nav class=paginav><a class=prev href=https://ieftimov.com/post/spotify-recently-played-least-recently-used-cache-golang/><span class=title>« Prev Page</span><br><span>Barebones model of Spotify's 'Recently Played' screen using a Least Recently Used (LRU) cache in Golang</span></a>
<a class=next href=https://ieftimov.com/post/golang-datastructures-trees/><span class=title>Next Page »</span><br><span>Golang Datastructures: Trees</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang on twitter" href="https://twitter.com/intent/tweet/?text=When%20and%20Why%20to%20use%20a%20Least%20Frequently%20Used%20%28LFU%29%20cache%20with%20an%20implementation%20in%20Golang&url=https%3a%2f%2fieftimov.com%2fpost%2fwhen-why-least-frequently-used-cache-implementation-golang%2f&hashtags=lfu"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fieftimov.com%2fpost%2fwhen-why-least-frequently-used-cache-implementation-golang%2f&title=When%20and%20Why%20to%20use%20a%20Least%20Frequently%20Used%20%28LFU%29%20cache%20with%20an%20implementation%20in%20Golang&summary=When%20and%20Why%20to%20use%20a%20Least%20Frequently%20Used%20%28LFU%29%20cache%20with%20an%20implementation%20in%20Golang&source=https%3a%2f%2fieftimov.com%2fpost%2fwhen-why-least-frequently-used-cache-implementation-golang%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fieftimov.com%2fpost%2fwhen-why-least-frequently-used-cache-implementation-golang%2f&title=When%20and%20Why%20to%20use%20a%20Least%20Frequently%20Used%20%28LFU%29%20cache%20with%20an%20implementation%20in%20Golang"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fieftimov.com%2fpost%2fwhen-why-least-frequently-used-cache-implementation-golang%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang on whatsapp" href="https://api.whatsapp.com/send?text=When%20and%20Why%20to%20use%20a%20Least%20Frequently%20Used%20%28LFU%29%20cache%20with%20an%20implementation%20in%20Golang%20-%20https%3a%2f%2fieftimov.com%2fpost%2fwhen-why-least-frequently-used-cache-implementation-golang%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang on telegram" href="https://telegram.me/share/url?text=When%20and%20Why%20to%20use%20a%20Least%20Frequently%20Used%20%28LFU%29%20cache%20with%20an%20implementation%20in%20Golang&url=https%3a%2f%2fieftimov.com%2fpost%2fwhen-why-least-frequently-used-cache-implementation-golang%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>Copyright 2021 © Ilija Eftimov</span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})});var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>