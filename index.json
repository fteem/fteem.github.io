[{"content":"Docker Compose + local development = ❤️ If you’re like me, you like a simple Docker Compose setup for your local project setup. It makes bringing up and tearing down different Docker containers easy with a single command. Especially if your application requires additional backing services, like a data store, a Docker Compose setup for local development makes it very easy to spin them all up in one go.\nAnother reason why I like Docker Compose because I am a bit of a purist when it comes to Dockerfiles – I believe that there should be only one Dockerfile for your service, and it should work for all environments. Nope, none of the Dockerfile.dev \u0026amp; Dockerfile.prod shenanigans. Why? Because I want my services to require only one set of dependencies, regardless of the deployment environment.\nFollowing that idea, Docker Compose uses the project\u0026rsquo;s Dockerfile and orchestrates all backing services via a simple YAML file. And the cherry on top: I can check-in docker-compose.yml version control, and everyone in my organization can reap the benefits.\nOK, OK, you know I like Docker Compose for local development. But, sometimes, it can be not very pleasant. For example, it doesn’t want to start a process or a server in a container because it never cleaned up its PID file.\nWhen running docker-compose up, you might have seen one of these error messages (or a variation):\nhttpd (pid 1) already running ERROR: Pidfile (celerybeat.pid) already exists. A server is already running. Check /usr/src/app/tmp/pids/server.pid. Seems familiar? Let\u0026rsquo;s work with a Rails application to reproduce the issue and fix it in four different ways.\nWhile this article uses a Rails application as an example to showcase the issue with stray PID files when using Docker Compose, the solution provided below is language- and framework-agnostic.\nIn other words, one can use the approaches showcased below with any programming language or framework, as long as the application is containerized.\n Dockerizing the app Let\u0026rsquo;s look at the Dockerfile of a simple Rails application, that uses no backing services. The Dockerfile will use the ruby:3.0.2-alpine3.14 image as base:\nFROMruby:3.0.2-alpine3.14 WORKDIR/app # Install runtime dependencies RUN apk add --no-cache \\  shared-mime-info \\  tzdata \\  sqlite-libs # Install the project dependencies COPY Gemfile* /app # Bundle build dependencies RUN apk add --no-cache --virtual build-dependencies \\  build-base \\  sqlite-dev \\  \u0026amp;\u0026amp; bundle install \\  \u0026amp;\u0026amp; rm -rf /usr/local/bundle/cache/*.gem \\  \u0026amp;\u0026amp; find /usr/local/bundle/gems/ -name \u0026#34;*.[co]\u0026#34; -delete \\  \u0026amp;\u0026amp; apk del --no-network build-dependencies COPY . . ENTRYPOINT [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;] CMD [\u0026#34;bundle exec rails s -b 0.0.0.0 -p $SERVER_PORT\u0026#34;] In the Dockerfile, we first set the working directory (WORKDIR) and then install a mix of build and runtime dependencies. Next, we copy the Gemfile and Gemfile.lock files to download and compile the bundle in the next step. But before we run bundle, we install some build tooling so Docker can build and install the gems.\nLastly, we COPY all project files to the image and run the Rails server using the rails s command. We COPY all files because we want all the project files to be inside the container to run. If we fail to copy a required file, the application will fail to boot, rendering our Docker image useless.\nTo run this container, we first need to build its image:\n$ docker build -t jarjar:latest . [+] Building 14.9s (11/11) FINISHED =\u0026gt; [internal] load build definition from Dockerfile 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 622B 0.0s =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; [internal] load metadata for docker.io/library/ruby:3.0.2-alpine3.14 0.6s =\u0026gt; [1/6] FROM docker.io/library/ruby:3.0.2-alpine3.14@sha256:5bb06d7e3853903b9e9480b647b2d99ca289f9511 0.0s =\u0026gt; [internal] load build context 0.0s =\u0026gt; =\u0026gt; transferring context: 18.47kB 0.0s =\u0026gt; CACHED [2/6] WORKDIR /app 0.0s =\u0026gt; CACHED [3/6] RUN apk add --no-cache shared-mime-info tzdata sqlite-libs 0.0s =\u0026gt; CACHED [4/6] COPY Gemfile* /app 0.0s =\u0026gt; [5/6] RUN apk add --no-cache --virtual build-dependencies build-base sqlite-dev \u0026amp;\u0026amp; bundle in 13.6s =\u0026gt; [6/6] COPY . . 0.0s =\u0026gt; exporting to image 0.5s =\u0026gt; =\u0026gt; exporting layers 0.5s =\u0026gt; =\u0026gt; writing image sha256:c24befc2a0ce11f5550672e4f7aa64a5f6d8169609d173c35d039bf459bce757 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/jarjar:latest 0.0s After the image is built, we can create a container:\n$ docker run --env SERVER_PORT=3000 -p 3000:3000 jarjar:latest =\u0026gt; Booting Puma =\u0026gt; Rails 6.1.4.1 application starting in development =\u0026gt; Run `bin/rails server --help` for more startup options Puma starting in single mode... * Puma version: 5.5.2 (ruby 3.0.2-p107) (\u0026#34;Zawgyi\u0026#34;) * Min threads: 5 * Max threads: 5 * Environment: development * PID: 1 * Listening on http://0.0.0.0:3000 Use Ctrl-C to stop Voilá! Our container is off to the races!\nBecause we map the container port 3000 to the host machine\u0026rsquo;s port 3000, we can curl the Rails application from our host machine. Fortunately, we will get an HTTP 200:\n$ curl -X GET -I localhost:3000 HTTP/1.1 200 OK X-Frame-Options: SAMEORIGIN X-XSS-Protection: 1; mode=block X-Content-Type-Options: nosniff X-Download-Options: noopen X-Permitted-Cross-Domain-Policies: none Referrer-Policy: strict-origin-when-cross-origin Content-Type: text/html; charset=utf-8 Vary: Accept Cache-Control: no-store, must-revalidate, private, max-age=0 Content-Security-Policy: script-src \u0026#39;unsafe-inline\u0026#39;; style-src \u0026#39;unsafe-inline\u0026#39; X-Request-Id: a4befe81-30be-4859-b757-feac45f90b08 X-Runtime: 0.312531 X-MiniProfiler-Original-Cache-Control: max-age=0, private, must-revalidate X-MiniProfiler-Ids: 8hq1e1quzqh4uacc9xb8 Set-Cookie: __profilin=p%3Dt; path=/; HttpOnly; SameSite=Lax Content-Length: 400499 Now, instead of running our application with the complicated docker run command, let\u0026rsquo;s throw in a Docker Compose file and make our lifes easier:\nversion: \u0026#39;3.8\u0026#39; services: http: build: . image: jarjar environment: SERVER_PORT: ${SERVER_PORT} ports: - ${SERVER_PORT}:${SERVER_PORT} # Set to 4000 in .env file volumes: - .:/app The file sets up the required environment variables, ports and volumes for the Rails application. To build our image now, we can use docker-compose build:\n$ docker-compose build Building http [+] Building 0.7s (11/11) FINISHED =\u0026gt; [internal] load build definition from Dockerfile 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 622B 0.0s =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; [internal] load metadata for docker.io/library/ruby:3.0.2-alpine3.14 0.6s =\u0026gt; [1/6] FROM docker.io/library/ruby:3.0.2-alpine3.14@sha256:5bb06d7e3853903b9e9480b647b2d99ca289f9511 0.0s =\u0026gt; [internal] load build context 0.0s =\u0026gt; =\u0026gt; transferring context: 32.32kB 0.0s =\u0026gt; CACHED [2/6] WORKDIR /app 0.0s =\u0026gt; CACHED [3/6] RUN apk add --no-cache shared-mime-info tzdata sqlite-libs 0.0s =\u0026gt; CACHED [4/6] COPY Gemfile* /app 0.0s =\u0026gt; CACHED [5/6] RUN apk add --no-cache --virtual build-dependencies build-base sqlite-dev \u0026amp;\u0026amp; bun 0.0s =\u0026gt; CACHED [6/6] COPY . . 0.0s =\u0026gt; exporting to image 0.0s =\u0026gt; =\u0026gt; exporting layers 0.0s =\u0026gt; =\u0026gt; writing image sha256:c24befc2a0ce11f5550672e4f7aa64a5f6d8169609d173c35d039bf459bce757 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/jarjar 0.0s Now that we have the image built, we can run the service:\n$ docker-compose up Starting jarjar_http_1 ... done Attaching to jarjar_http_1 http_1 | =\u0026gt; Booting Puma http_1 | =\u0026gt; Rails 6.1.4.1 application starting in development http_1 | =\u0026gt; Run `bin/rails server --help` for more startup options http_1 | Puma starting in single mode... http_1 | * Puma version: 5.5.2 (ruby 3.0.2-p107) (\u0026#34;Zawgyi\u0026#34;) http_1 | * Min threads: 5 http_1 | * Max threads: 5 http_1 | * Environment: development http_1 | * PID: 1 http_1 | * Listening on http://0.0.0.0:4000 http_1 | Use Ctrl-C to stop We have our service running using Docker Compose! Let\u0026rsquo;s curl it, again:\n$ curl -X GET -I localhost:4000 HTTP/1.1 200 OK X-Frame-Options: SAMEORIGIN X-XSS-Protection: 1; mode=block X-Content-Type-Options: nosniff X-Download-Options: noopen X-Permitted-Cross-Domain-Policies: none Referrer-Policy: strict-origin-when-cross-origin Content-Type: text/html; charset=utf-8 Vary: Accept Cache-Control: no-store, must-revalidate, private, max-age=0 Content-Security-Policy: script-src \u0026#39;unsafe-inline\u0026#39;; style-src \u0026#39;unsafe-inline\u0026#39; X-Request-Id: d7a72b16-9630-4e4c-9e9e-8781c8207b52 X-Runtime: 0.020082 X-MiniProfiler-Original-Cache-Control: max-age=0, private, must-revalidate X-MiniProfiler-Ids: dvwfody0av0h45hub5bw,pp70s0op22fdolh4u8zt,hdpxqj8kohhs6r3jf7xp,c080m80j1zfarr0b4qxw Set-Cookie: __profilin=p%3Dt; path=/; HttpOnly; SameSite=Lax Content-Length: 400562 We get an HTTP 200. If we bring down the container and up again, we\u0026rsquo;ll run into a familiar problem:\n$ docker-compose up Starting jarjar_http_1 ... done [...] http_1 | =\u0026gt; Booting Puma http_1 | =\u0026gt; Rails 6.1.4.1 application starting in development http_1 | =\u0026gt; Run `bin/rails server --help` for more startup options http_1 | Exiting http_1 | A server is already running. Check /app/tmp/pids/server.pid. jarjar_http_1 exited with code 1 Apparently we have a stray PID file, and our server can\u0026rsquo;t boot.\nStray PID files The default web server for Rails, Puma, creates a PID file. A PID, shorthand for Process ID, is a file that contains only the ID of the server process on the operating system. So, if we boot our server container, we attach to it and open the PID file; we will see that the file contains only the PID number in it:\n/app # cat tmp/pids/server.pid 1 Before I got to this section, I had no idea why PID files were useful. However, after consulting an excellent StackOverflow answer (that I recommend reading thoroughly), it appears that we can use PID files for:\n as a signal to other processes and users of the system that that particular program is running, or at least started successfully allows one to write a script to check if a particular process is running and issue a plain kill command (e.g., if one wants to end it) it is a cheap way for a program to see if any of its previous instances did not exit successfully  That last point hits close to home - Puma’s PID file is still present before the container shuts down, and, when booting, Rails thinks there’s already another server running.\nOne thing that threw me off with the stray PID file is that containers and their file systems are supposed to be ephemeral. Once you stop them – they\u0026rsquo;re gone for good. What I found out is that Docker Compose reuses containers whose configurations have not changed:\n Compose caches the configuration used to create a container. When you restart a service that has not changed, Compose re-uses the existing containers. Re-using containers means that you can make changes to your environment very quickly.\n This is a neat feature of Compose, but it means that Compose does not destroy the container that contains the stray PID file. Actually, Compose reuses it. And it’s the reason why the lost PID file is detected, and Puma cannot start when using Docker Compose.\nThere are several ways to force Docker Compose to recreate the containers, but from a workflow perspective, we want docker-compose up to just do the trick. There\u0026rsquo;s always docker-compose up --force-recreate, but from a developer experience perspective, that seems\u0026hellip; hacky.\nIf container reuse is a feature of Docker Compose, then the solution to our stray PID files must lie with Puma. In other words, how can we make Puma clean up its mess before exiting?\nCleaning up the mess For Puma to clean up its PID file, it has to receive the proper interrupt signal (SIGINT) when we press Ctrl-C so it can act upon it. But when we press Ctrl-C, even though we think we are interrupting Puma, we are not.\nInspect this output, carefully:\n$ docker-compose up Recreating jarjar_http_1 ... done Attaching to jarjar_http_1 http_1 | =\u0026gt; Booting Puma http_1 | =\u0026gt; Rails 6.1.4.1 application starting in development http_1 | =\u0026gt; Run `bin/rails server --help` for more startup options http_1 | Puma starting in single mode... http_1 | * Puma version: 5.5.2 (ruby 3.0.2-p107) (\u0026#34;Zawgyi\u0026#34;) http_1 | * Min threads: 5 http_1 | * Max threads: 5 http_1 | * Environment: development http_1 | * PID: 1 http_1 | * Listening on http://0.0.0.0:4000 http_1 | Use Ctrl-C to stop From STDOUT we see Puma saying Use Ctrl-C to stop, but when we press Ctrl-C we interrupt Docker Compose (its up command), not Puma. This is because upon pressing Ctrl-C we rely on Docker Compose to send that same SIGINT to the Puma process, but that is not how Compose works.\nThe fact that Docker Compose does not \u0026ldquo;bubble up\u0026rdquo; the SIGINT to Puma means that the Puma process is abruptly killed by the container shutting down, and Puma can\u0026rsquo;t clean up its PID file.\nSo, how can we make sure we remove the PID file?\nAttempt no. 1: Remove PID before Puma boot The most straightforward way is to remove the PID file before we kick-off the Puma server. It can be done by modifying the CMD of the Dockerfile:\nCMD [\u0026#34;rm -f tmp/pids/server.pid \u0026amp;\u0026amp; bundle exec rails s -b 0.0.0.0 -p $SERVER_PORT\u0026#34;] The Internet is riddled with variations of this approach. From Reddit threads, to many different Stack Overflow answers, \u0026ldquo;just remove the PID file\u0026rdquo; seems to be the default workaround for this problem.\nBefore I comment on this approach, let\u0026rsquo;s look at a similar but better approach.\nAttempt no. 2: Use an entrypoint script This solution is suggested by Docker Compose\u0026rsquo;s documentation on Rails \u0026amp; Postgres:\n \u0026hellip;provide an entrypoint script to fix a Rails-specific issue that prevents the server from restarting when a certain server.pid file pre-exists. This script will be executed every time the container gets started.\n The entrypoint.sh script, as taken from the documentation:\n#!/bin/bash  # Stops the execution of a script in case of error set -e # Remove a potentially pre-existing server.pid for Rails. rm -f /myapp/tmp/pids/server.pid # Then exec the container\u0026#39;s main process (what\u0026#39;s set as CMD in the Dockerfile). exec \u0026#34;$@\u0026#34; This script will work in unison with the Dockerfile, which will have to make the script executable and run it as an ENTRYPOINT:\n[...] # Add a script to be executed every time the container starts. COPY entrypoint.sh /usr/bin/ RUN chmod +x /usr/bin/entrypoint.sh ENTRYPOINT [\u0026#34;entrypoint.sh\u0026#34;] CMD [\u0026#34;bundle exec rails s -b 0.0.0.0 -p $SERVER_PORT\u0026#34;] While the above solutions work and the second is even officially recommended by Compose, I do not like them for three reasons:\n Any code we write, such as the script, will need to be checked in source control and maintained The solution pollutes the Dockerfile due to a shortcoming of docker-compose up The solution adds accidental complexity in the Dockerfile for any non-local environment (e.g. cloud). In other words, if we deploy our application to a cloud provider, we wouldn\u0026rsquo;t use Docker Compose, but we will still end up carrying the entrypoint script to the cloud.  For the above reasons, let\u0026rsquo;s take a step deeper and see if there\u0026rsquo;s a better/more self-contained solution.\nOverriding Puma\u0026rsquo;s PID file When deploying your application to the cloud, it is critical to keep the Dockerfile minimal, containing only the absolute essentials. If you have seen bloated Dockerfiles, or even worse, a proliferation of Dockerfiles in a project, you know what I am talking about.\nTo keep the Dockerfile minimal, we must make tradeoffs: any potential local setup complexity will end up in the docker-compose.yml file.\nPuma allows us to set the PID file path from the command line using the -p toggle. Unfortunately, this will add complexity to our Dockerfile:\nCMD [\u0026#34;bundle exec rails s -b 0.0.0.0 -p $SERVER_PORT -P /some/path/server.pid\u0026#34;] This is a no-go, as we want to stick to the defaults in any other (cloud) environment. The good news is that since 2019, Rails has supported setting the PID file path using an environment variable, allowing us to set the PIDFILE environment variable, and Rails will use it transparently.\nOK, now that we have a way to transparently set the PID file path, what should its value be? Unix operating systems have one place where all bits go to die: /dev/null.\nAttempt no. 3: Send the PID file to /dev/null This is easily achieved by adding a single line in the docker-compose.yml:\nversion: \u0026#39;3.8\u0026#39; services: http: build: . image: jarjar environment: SERVER_PORT: ${SERVER_PORT} + PIDFILE: /dev/null  ports: - ${SERVER_PORT}:${SERVER_PORT} volumes: - .:/app It will work as expected if we test this out: docker-compose up can be ran and interrupted (using Ctrl-C) without problems.\nBut, by setting the PID file path to /dev/null we lose all valuable aspects of PID files: we can\u0026rsquo;t check whether a process is running or whether a previous instance has failed.\nCan we do better? Could we place the PID file in an ephemeral location that would be present for the duration of the container life, but it would evaporate after Compose takes the container down?\nSolution: Use tmpfs Docker ships with tmpfs mounts as a storage option that works only on containers running Linux. When we create a container with a tmpfs mount, the container can create files outside the container’s writable layer.\nAs opposed to volumes and bind mounts, a tmpfs mount is temporary and persists in the host memory. So when the container stops, the tmpfs mount is removed, and all files in it will be gone. tmpfs mounts seem like the perfect ephemeral storage for our problem.\nTo add a tmpfs path in our Compose file and to store the PID file in that path, we need to make the following changes:\nversion: \u0026#39;3.8\u0026#39; services: http: build: . image: jarjar environment: SERVER_PORT: ${SERVER_PORT} - PIDFILE: /dev/null + PIDFILE: /tmp/pids/server.pid  ports: - ${SERVER_PORT}:${SERVER_PORT} volumes: - .:/app + tmpfs: + - /tmp/pids/ Docker Compose will create a path and mount it in the host’s memory when we run docker-compose up. This will allow us to set the PID file in that ephemeral path, /tmp/pids in our example, and use the PID file during the duration of the container. When the container is torn down, we lose the temporary mount in the void with all PID files in it.\nLet\u0026rsquo;s give this a shot and see if we can run docker-compose up and interrupt it ad infinitum.\nFirst run:\n$ docker-compose up Creating jarjar_http_1 ... done [...] http_1 | =\u0026gt; Booting Puma http_1 | =\u0026gt; Rails 6.1.4.1 application starting in development http_1 | =\u0026gt; Run `bin/rails server --help` for more startup options http_1 | Puma starting in single mode... http_1 | * Puma version: 5.5.2 (ruby 3.0.2-p107) (\u0026#34;Zawgyi\u0026#34;) http_1 | * Min threads: 5 http_1 | * Max threads: 5 http_1 | * Environment: development http_1 | * PID: 1 http_1 | * Listening on http://0.0.0.0:4000 http_1 | Use Ctrl-C to stop ^CGracefully stopping... (press Ctrl+C again to force) Killing jarjar_http_1 ... done Looking good! Next run:\n$ docker-compose up Starting jarjar_http_1 ... done [...] http_1 | =\u0026gt; Booting Puma http_1 | =\u0026gt; Rails 6.1.4.1 application starting in development http_1 | =\u0026gt; Run `bin/rails server --help` for more startup options http_1 | Puma starting in single mode... http_1 | * Puma version: 5.5.2 (ruby 3.0.2-p107) (\u0026#34;Zawgyi\u0026#34;) http_1 | * Min threads: 5 http_1 | * Max threads: 5 http_1 | * Environment: development http_1 | * PID: 1 http_1 | * Listening on http://0.0.0.0:4000 http_1 | Use Ctrl-C to stop Works as advertised!\nUsing a tmpfs mount, we can leave our Dockerfile unscathed without additional entrypoints scripts or dependencies. Instead, we are using a native Docker solution that has been around for a while, with just two extra lines in our Docker Compose file.\nAnd maybe the best part is that our solution is stack agnostic. It will work with any process that creates a PID file, whether a web server (such as Puma) or another program. The tmpfs approach requires only the program to set a custom path for the PID file – that\u0026rsquo;s all!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/docker-compose-stray-pids-rails-beyond/","summary":"Docker Compose + local development = ❤️ If you’re like me, you like a simple Docker Compose setup for your local project setup. It makes bringing up and tearing down different Docker containers easy with a single command. Especially if your application requires additional backing services, like a data store, a Docker Compose setup for local development makes it very easy to spin them all up in one go.\nAnother reason why I like Docker Compose because I am a bit of a purist when it comes to Dockerfiles – I believe that there should be only one Dockerfile for your service, and it should work for all environments.","title":"Docker Compose, stray PID files, Rails and beyond"},{"content":"HTTP caching 101 Every browser implements its own in-memory caching. The information about the cache size per browser is spotty, but there\u0026rsquo;s one thing for sure: the cache sizes vary. The great thing is that browsers are smart nowadays – they manage their caches opaquely for us, the end-users.\nThere are a few ways to put these caches to use. But it all starts with HTTP caching directives (or headers). The two HTTP response headers used for specifying freshness (another word for should something be cached) are Cache-Control and Expires:\n Expires sets an explicit date and time when the content expires; Cache-Control specifies how long the browser can cache the content relative to the fetch time  In cases when the request has both headers specified, Cache-Control takes precedence.\nAnother way to put the browser caches to use is by using conditional requests and revalidation. We use the Last-modified and ETag (Entity Tag) response headers for that purpose:\n Last-modified is a timestamp that specifies when the backend last changed the object. ETag is a unique identifier for the content as a string. The server decides its format, but usually, it’s some form of a hash.  As we advance, we will explore caching by using conditional GET requests. In-depth!\n  Conditional HTTP requests Conditional requests are HTTP requests that include headers that indicate a certain precondition. When said headers are present, the HTTP server must check the condition. The server must perform the check before executing the HTTP method against the target resource. The result of the request can be different based on the result of the check of the precondition.\nAt the core of the conditional HTTP requests are validators. Validators are metadata the user-agent and the server use to discern if a resource is stale or not. The revalidation mechanisms implemented by the HTTP server check if the resource stored on the server matches a specific version that the user-agent has cached. The HTTP server performs the check (validation) based on the validators (metadata) sent by the user-agent.\nValidators fall in two categories:\n timestamp of last modification of the resource - the Last-Modified header unique string representing the resource version - the ETag (entity tag) header  Validator types Both validators, Last-Modified and ETag, allow two types of validation: weak and strong. Depending on the case, the complexity of implementing the validation can vary.\nStrong validators Strong validators are metadata that changes its value whenever the representational data of the resource changes. The representational data is the data format that would be observable in the payload body of an HTTP 200 OK response to GET /resource/:id.\nI know that\u0026rsquo;s loaded, so let me explain through an oversimplified example. Imagine we have a user resource served by GET /users/:id. For example, the response body of GET /users/1 would be:\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jane\u0026#34;, \u0026#34;age\u0026#34;: 30 } A strong validator in this particular case can be an ETag composed based on the user\u0026rsquo;s id, name, and age attributes. In Ruby, the MD5 hash of these three values would be:\n\u0026gt;\u0026gt; Digest::MD5.hexdigest(\u0026#34;1-Jane-30\u0026#34;) =\u0026gt; \u0026#34;fb324ab8bda9e1cbb47c2a001fa36349\u0026#34; If any of the attributes of the user change, given that our ETag is supposed to be a strong validator, we would like the ETag value to change. For example, after Jane\u0026rsquo;s birthday, the age will increase to 31. The new ETag would be:\n\u0026gt;\u0026gt; Digest::MD5.hexdigest(\u0026#34;1-Jane-31\u0026#34;) =\u0026gt; \u0026#34;f78e2fe80b589cd55a2fef324e877d34\u0026#34; But also the change in the representational data of the resource is observable by GET-ing it from the server, e.g., GET /users/1:\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jane\u0026#34;, \u0026#34;age\u0026#34;: 31 } This means that the metadata sent in the ETag changed because it is also observable by the user-agent in the data of the resource itself – not a magical field in the server\u0026rsquo;s database that the user-agent won\u0026rsquo;t know about.\nThere are scenarios, such as content negotiation, in which strong validators can change. The bottom line is: the origin server should only change the validator’s value when it is necessary to invalidate the cached responses in caches and other user-agents.\nHTTP uses strong validation by default, but it provides a way for clients to specify when they use weak validation. Clients can prepend ETags with the W/ string, denoting that the server should perform a weak validation.\nWeak validators A weak validator is metadata that might not change for every change to the representation data. It\u0026rsquo;s the opposite of the strong validators – even if the representation data changes, the HTTP server considers the change not worth busting the cached representation in the user-agents and other proxies/caches.\nBuilding on the example from above, let\u0026rsquo;s imagine that the representation of the user is as follows:\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jane\u0026#34;, \u0026#34;age\u0026#34;: 31, \u0026#34;position\u0026#34;: \u0026#34;Software Engineer\u0026#34; } If this user is promoted, from Software Engineer to Senior Software Engineer, a strong validator would be updated, causing user-agents and proxies to invalidate their caches. But what about weak validators?\nIt depends. The validator\u0026rsquo;s weakness might stem from how the product uses the data or the context in which it resides. For example, say we have an endpoint as part of an employee directory within a company. In that context, the change of age (i.e. birthday) might not be the reason to invalidate a resource. Invalidation in such an event will bust the caches, and we will incur a performance penalty for a non-essential change.\nIf that is the case, the ETag will not take all attributes from the representation into account – only the relevant ones, hence being a weak ETag. For example:\n\u0026gt;\u0026gt; etag = Digest::MD5.hexdigest(\u0026#34;1-Jane-Software-Engineer\u0026#34;) =\u0026gt; \u0026#34;d18968bf453b0208dbbbcb5bd72af3e1\u0026#34; But a change of position (a.k.a. promotion) is relevant information that should cause the resource to be revalidated by caches.\nIn other words, an origin server should change a weak entity tag whenever it considers prior representations to be unacceptable as a substitute for the current representation.\nRevalidating weak ETags  Imagine Jane getting a promotion and then still seeing their old title in the employees' directory, even though they worked so hard to get the promotion. Soul-crushing. And all that because of a weak ETag. So choose your validators wisely!\nDeeper into the validators Let\u0026rsquo;s look at the format of Last-Modified and ETag, how to generate them, how to perform the comparison, and when to use them.\nLast-modified As we already established, the Last-Modified response header is a timestamp that indicates when the origin server believes the selected resource was last modified while handling the request.\nFor example, if the origin server serves a request to GET /users/1 at Date: 2021-05-05 12:00:00, then the Last-Modified header will be set to a timestamp that the server knows the user with an ID of 1 was last updated. When the origin server responds to a GET /users/1, even a second later in time (at Date: 2021-05-05 12:00:01), the server can potentially return a different Last-Modified as in the meantime the underlying entity might be updated.\nSetting the Last-Modified In the wild, the Last-Modified header on the response is rarely generated based on a single resource. When set on web pages, the Last-Modified header will be set based on all the different resources that are rendered on the page.\nTherefore the most straightforward way to generating the Last-Modified header is to take the most recent time that the server has changed any of those resources. An additional angle to consider is if all resources rendered on the page are worth busting the cache.\nFor example, a page that renders TV shows for watching, with a list of recommended shows in the footer, could set the Last-Modified to the most recent time server updated the TV show entity. When the recommendations in the footer change, the origin server can still keep the Last-Modified tied to the show update time, as the recommendations are secondary to the page.\n  When the TV show gets a new season, this is an event when the server should update the Last-Modified header, as we would like all users to see that we have added a new season.\nBut if the recommendations keep people watching and discovering new shows, then more recent (and better), recommendations should also be taken into account when setting the Last-Modified header.\nETag ETag is an opaque validator - as we already mentioned, the server generates the entity tags, but how it generates them is unknown to the user-agent. In fact, from the user-agent perspective, the approach to generating the ETag is irrelevant. It\u0026rsquo;s only crucial that the ETag is changed once the resource representation changes, so the user-agent can revalidate when the change happens.\nThe main principle to generating and sending an ETag is always to create one where the server can reliably and consistently determine the changes on the underlying resource. Proper usage of ETags will substantially reduce HTTP network traffic and can be a significant factor in improving service scalability and reliability.\nComparing ETags ETags opaqueness forced their inventors to add a weakness denominator: the W/ prefix. For example, the same ETag header will be differently handled by the user-agent, based on the weakness indicator:\n# Weak ETag ETag: \u0026#34;W/3cb377-13f27-5c0c816db0d40\u0026#34; # Strong ETag ETag: \u0026#34;3cb377-13f27-5c0c816db0d40\u0026#34; Although they contain the same value, these two headers are different due to the weakness indicator. Looking at the example above, we can see that strong is the default, or in other words, an ETag is weak only if the weak indicator (W/) is present.\nA comparison table on weak and strong ETags looks like this:\n   ETag 1 ETag 2 Strong Comparison Weak Comparison     W/\u0026quot;Foo\u0026quot; W/\u0026quot;Foo\u0026quot; No match Match   W/\u0026quot;Foo\u0026quot; W/\u0026quot;Bar\u0026quot; No match No match   W/\u0026quot;Foo\u0026quot; \u0026quot;Foo\u0026quot; No match Match   \u0026quot;Foo\u0026quot; \u0026quot;Foo\u0026quot; Match Match    Conditional requests semantics and mechanisms Now that we understand the validator headers and their intricacies let\u0026rsquo;s look at the precondition and header semantics.\nThere are five headers used for communicating preconditions between the user-agent and the servers:\n If-Match If-None-Match If-Modified-Since If-Unmodified-Since If-Range  In this article, we are looking at only conditional reads, or conditional GETs, as a way of caching content at the user-agent. That\u0026rsquo;s why, out of the five headers above, we will look only at the 2nd and 3rd: If-None-Match and If-Modified-Since. The other three are used for conditional requests but of a different kind that we will look into in another article.\nBefore we continue investigating the two headers, let\u0026rsquo;s first familiarize ourselves with the example application that we\u0026rsquo;ll be using.\nFamiliarizing with our application We will begin this exploration by looking at a sample application. For my comfort, we will use a Ruby on Rails application. Yet, the concepts discussed can be transferred to any web framework or language, as long as it can speak HTTP.\nThe application that we will be using to demonstrate these concepts is the \u0026ldquo;Sample app\u0026rdquo; built as part of the most popular Ruby on Rails book - Ruby on Rails Tutorial by Michael Hartl. The complete source code is available on Github.\nThe sample application is a Twitter clone. It is a multi-tenant application where users can create microposts. The application\u0026rsquo;s root path (/) points to the timeline of the logged-in user, which the StaticPagesController#home action renders:\nclass StaticPagesController \u0026lt; ApplicationController def home if logged_in? @feed_items = current_user.feed.paginate(page: params[:page]) end end end Below you can see what the microposts feed looks like:\n  Let\u0026rsquo;s use this action and explore the various ways we can implement conditional HTTP requests.\nConditional requests using ETags and If-None-Match As mentioned in RFC-7232, the implementation of ETags is left to the server itself. That\u0026rsquo;s why there is no single implementation of ETags. It is every server for itself.\nThe case for using conditional requests, in this case, is: when a user is logged in, we would like not to send bytes over the network as long as there are no new @feed_items on the page.\nWhy? Think about this: we open the page, get the latest microposts from the people we follow and read them. That\u0026rsquo;s it. The next time we refresh the page, if there are no new microposts on the page, our browser already has all the data in its cache, so there\u0026rsquo;s no need to fetch new bytes from the server.\nIn such cases, we want to skip (most of) the network traffic and get an HTTP 304 Not modified from the server. As stated in section 4.1 of RFC-7232:\n The 304 (Not Modified) status code indicates that a conditional GET or HEAD request has been received and would have resulted in a 200 (OK) response if it were not for the fact that the condition evaluated to false. In other words, there is no need for the server to transfer a representation of the target resource because the request indicates that the client, which made the request conditional, already has a valid representation; the server is therefore redirecting the client to make use of that stored representation as if it were the payload of a 200 (OK) response.\n This excerpt is packed, but the main point is: the client made the request conditional (using a header), the server evaluated the condition and decided that the client has the fresh content by returning an HTTP 304.\n  In our example, having the latest @feed_items means that there\u0026rsquo;s nothing new to be returned by the server, so the server informs the client that the cached @feed_items are still valid to be used by returning HTTP 304.\nNow, how can we practically do that?\nA manual approach As we mentioned before, the ETag is a string that differentiates between multiple representations of the same resource. It means that if the @feed_items collection changes, the ETag must also change. In addition, two identical @feed_items collections must have the same ETags.\nKnowing all of this, our ETag has to consider the id and the content of the Micropost (the @feed_items collection contains multiple Micropost objects). If the id or content changes on any Micropost, we want the ETag to change. When the ETag changes, the client will fail the revalidation condition, and the server will respond with the latest data.\nTherefore, the ETag of the @feed_items collection will consist of all ETags of each Micropost in the collection. The implementation would look like this:\n# app/models/micropost.rb def my_etag [id, Digest::MD5.hexdigest(content)].join(\u0026#39;-\u0026#39;) end If we run this method against a micropost:\n\u0026gt;\u0026gt; m = Micropost.last =\u0026gt; #\u0026lt;Micropost id: 1, content: \u0026#34;Soluta dolorem aspernatur doloremque vel.\u0026#34;, user_id: 1, created_at:... \u0026gt;\u0026gt; m.id =\u0026gt; 1 \u0026gt;\u0026gt; m.content =\u0026gt; \u0026#34;Soluta dolorem aspernatur doloremque vel.\u0026#34; \u0026gt;\u0026gt; m.my_etag =\u0026gt; \u0026#34;1-3268ba55dd9915c975821eda93eb22dc\u0026#34; We concatenate the MD5 hash of the content and the id to form an ETag for the micropost.\nUsually, we generate the ETag using an MD5 hash of the resource, allowing us to use a single string value, with 32 hexadecimal digits, instead of long arbitrary strings.\nThe MD5 hash will also change if any of the parameters used to generate it get changed.\n Now, back to our controller:\n# app/controllers/static_pages_controller.rb def home if logged_in? @feed_items = current_user.feed.paginate(page: params[:page]) my_etag = @feed_items.map(\u0026amp;:my_etag).join(\u0026#39;-\u0026#39;) if my_etag != request.headers[\u0026#39;If-None-Match\u0026#39;] response.set_header(\u0026#39;ETag\u0026#39;, my_etag) else head :not_modified end end end We generate my_etag for the @feed_items collection by joining all the Micropost#my_etag outputs for each micropost in the collection. Then, we take the If-None-Match header from the request and compare it with the my_etag value. If the two are the same, that means that the browser already has the latest @feed_items in its cache, and there\u0026rsquo;s no point for the server to return it again. Instead, it returns a response with HTTP 304 status and no body.\nIf the two values differ, then we set the response header ETag to that new value, and we return the whole response.\nBut why the If-None-Match header? As described in section 3.2 of RFC-7232:\n The \u0026ldquo;If-None-Match\u0026rdquo; header field makes the request method conditional on a recipient cache or origin server either not having any current representation of the target resource, or having a selected representation with an entity-tag that does not match any of those listed in the field-value.\n In other words, the client sends the ETag value in the If-None-Match header, and our server decides whether that\u0026rsquo;s the valid representation of the content to be served. If it is valid, then the server will return an HTTP 304 to the client.\nIf we send a request to the page again, we will see the following output:\n  Our (massive!) custom ETag is present. While such a long header is not practical, it still works. If we rerun the same request, by refreshing the page, we will see the server responding with an HTTP 304:\n  That happened because our browser sent the ETag value as part of the If-none-match header:\n  Voila! We implemented our conditional requests using Rails. Before we go on, there\u0026rsquo;s one thing I\u0026rsquo;d like to point out – avoid custom implementations. Our implementation is problematic, as it does not consider the differences between strong and weak validators.\nThere\u0026rsquo;s a better way to do it – using the built-in helpers by the web framework or a library for the respective language/framework.\nUsing helpers Similar to most web frameworks, Rails provides helpers to deal with conditional GET requests. In our particular case, we can substitute all of the custom code we wrote with a single method call: fresh_when.\nHere\u0026rsquo;s the new version of our controller action:\n# app/controllers/static_pages_controller.rb def home if logged_in? @feed_items = current_user.feed.paginate(page: params[:page]) fresh_when(etag: @feed_items) end end Internally fresh_when will do what our custom code did before, and a bit more.\nIf we inspect the method\u0026rsquo;s source code, we will see that fresh_when can handle both strong and weak ETags and the Last-modified header (which we will look into soon).\nIn our code snippet above, we explicitly set the etag to be set by fresh_when based on the @feed_items collection.\nBut how Rails know how to calculate the ETag? Well, internally fresh_when calls the ActionDispatch::Http::Cache::Request#fresh? method, which handles the ETag validation. It taps into the If-None-Match value of the request object and the ETag header value of the response and compares the two.\nIf we test out the new code, we will see a very similar behavior as before:\n  The server set the ETag response header to a string, prepending it with W/ denoting a weak ETag. The server will exhibit the same behavior on the next request: an empty response body with the HTTP 304 Not Modified status.\n  Conditional requests using Last-modified and If-Modified-Since As we mentioned before, the Last-modified header contains a timestamp specifying when the server last changed the object. If we continue to use the same example with @feed_items, we are running into an interesting problem: from all the @feed_items in the collection, we have to return only a single last modified date. What object\u0026rsquo;s last modified date should we pick then?\nThe easiest way to do it is to find the largest last updated date from all the objects in the collection. Neatly, most Rails models have a updated_at attribute updated when the record in the database is changed – perfect for us to use it as the last updated date.\nIf your framework or application does not have the updated_at attribute (or similar), you need to figure out another way to deduce when each record was last updated. We can find the last updated timestamp through an audit trail or another field in the database.\nStill, I recommend adding a updated_at field as it is a neat way to solve the problem.\n In the example application, that would look like:\nlast_modified = @feed_items.map(\u0026amp;:updated_at).max.httpdate Knowing all this, let\u0026rsquo;s implement this manually and then using fresh_when.\nA manual approach Validating the If-Modified-Since is a comparison between two DateTime objects: the last_modified and the if_modified_since. We want to compare the two and return an HTTP 304 if the last_modified is more recent (larger) than the if_modified_since.\nIf the client does not send the If-Modified-Since header, we need to make sure we return it to the client to send it on the subsequent request.\nAll of that, in code:\n# app/controllers/static_pages_controller.rb def home if logged_in? @feed_items = current_user.feed.paginate(page: params[:page]) last_modified = @feed_items.map(\u0026amp;:updated_at).max.httpdate if request.headers.key?(\u0026#39;If-Modified-Since\u0026#39;) if_modified_since = DateTime.parse(request.headers[\u0026#39;If-Modified-Since\u0026#39;]).httpdate head :not_modified if if_modified_since \u0026gt;= last_modified end response.set_header(\u0026#39;Last-Modified\u0026#39;, last_modified) end end If we give this a shot in the browser, we will see that on the first request-response cycle, we will get the Last-Modified header set:\n  Following the spec, on the subsequent request, the browser will send the If-Modified-Since condition header, which will cause the server to make the comparison of the two dates. Once it determines that the dates are the same, it will return an HTTP 304:\n  If we were to update any of the @feed_items or create a new item, the last_modified date would be changed, and the conditional validation will fail, resulting in an HTTP 200 instead of an HTTP 304.\nEven though this implementation works fine, let\u0026rsquo;s see how we can do that with fresh_when.\nUsing fresh_when Similar to before, finding the last_modified stays in the code. But all the other logic goes away:\n# app/controllers/static_pages_controller.rb def home if logged_in? @feed_items = current_user.feed.paginate(page: params[:page]) last_modified = @feed_items.map(\u0026amp;:updated_at).max fresh_when(last_modified: last_modified) end end That\u0026rsquo;s all! We substituted that logic with a single line of fresh_when. If we rerun the same tests, the behavior will stay identical:\n  In the first request-response cycle, we got the Last-Modified header set on the response.\nAnd similar to before, on the following request, the browser will send the If-Modified-Since condition header, which will cause the server to make the comparison of the two dates. Once it determines that the dates are the same, it will return an HTTP 304:\n  As you can see, both the manual and the built-in solutions work identically. Revalidating requests using Last-Modified and If-Modified-Since is a powerful mechanism of speeding up our applications by not sending (useless) bytes over the network.\nOutro We began our exploration of conditional requests by looking at the specification. We familiarized ourselves with validators, conditions,and how they work. We then went on to explore how we can implement conditional HTTP requests with some header comparisons. Our Last-Modified implementation works as well as the built-in framework one!\nWe saw how implementing such optimizations can improve the performance of our web applications. We all know the fastest requests are the ones that are never sent. But as the title of this article says: the second-fastest are the ones that need no response body!\nWhile there are more details that we could explore here, this covers the whole topic of conditional GET requests. We could further explore conditional requests for static files (such as assets) in combination with Content Delivery Networks (or popularly called CDNs). But that is a topic for another article.\nAnd, as always, I hope you all learned something.\nFurther reading  RFC-7232 HTTP conditional requests on MDN Conditional View Processing in Django ActionController::ConditionalGet in Rails ETag and Conditionals Package in Laravel  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/conditional-http-get-fastest-requests-need-no-response-body/","summary":"HTTP caching 101 Every browser implements its own in-memory caching. The information about the cache size per browser is spotty, but there\u0026rsquo;s one thing for sure: the cache sizes vary. The great thing is that browsers are smart nowadays – they manage their caches opaquely for us, the end-users.\nThere are a few ways to put these caches to use. But it all starts with HTTP caching directives (or headers). The two HTTP response headers used for specifying freshness (another word for should something be cached) are Cache-Control and Expires:","title":"Conditional HTTP GET: The fastest requests need no response body"},{"content":"The error in your browser\u0026rsquo;s console  No \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; header is present on the requested resource.\n  Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at https://example.com/\n  Access to fetch at \u0026lsquo;https://example.com\u0026rsquo; from origin \u0026lsquo;http://localhost:3000\u0026rsquo; has been blocked by CORS policy.\n I am sure you\u0026rsquo;ve seen one of these errors, or a variation, in your browser\u0026rsquo;s console. If you have not – don\u0026rsquo;t fret, you soon will. There are enough CORS errors for all developers out there.\nThese popping-up during development can be annoying. But in fact, CORS is an incredibly useful mechanism in a world of misconfigured web servers, hostile actors on the web and organizations pushing the web standards ahead.\nBut let\u0026rsquo;s go back the beginning\u0026hellip;\nIn the beginning was the first subresource A subresource is an HTML element that is requested to be embedded into the document, or executed in its context. In the year of 1993, the first subresource \u0026lt;img\u0026gt; was introduced. By introducing \u0026lt;img\u0026gt;, the web got prettier. And more complex.\nBack to 1993  You see, if your browser would render a page with an \u0026lt;img\u0026gt; on it, it would actually have to go fetch that subresource from an origin. When a browser fetches said subresource from an origin that does not reside on the same scheme, fully qualified hostname or port – that\u0026rsquo;s a cross-origin request.\nOrigins \u0026amp; cross-origin An origin is identified by a triple: scheme, fully qualified hostname and port. For example, http://example.com and https://example.com are different origins – the first uses http scheme and the second https. Also, the default http port is 80, while the https is 443. Therefore, in this example, the two origins differ by scheme and port, although the host is the same (example.com).\nYou get the idea – if any of the three items in the triple are different, then the origin is different.\nAs an exercise if we run a comparison of the https://blog.example.com/posts/foo.html origin against other origins, we would get the following results:\n   URL Result Reason     https://blog.example.com/posts/bar.html Same Only the path differs   https://blog.example.com/contact.html Same Only the path differs   http://blog.example.com/posts/bar.html Different Different protocol   https://blog.example.com:8080/posts/bar.html Different Different port (https:// is port 443 by default)   https://example.com/posts/bar.html Different Different host    A cross-origin request means, for example, a resource (i.e. page) such as http://example.com/posts/bar.html that would try to render a subresource from the https://example.com origin (note the scheme change!).\nThe many dangers of cross-origin requests Now that we defined what same- and cross-origin is, let\u0026rsquo;s see what is the big deal.\nWhen we introduced \u0026lt;img\u0026gt; to the web, we opened the floodgates. Soon after the web got \u0026lt;script\u0026gt;, \u0026lt;frame\u0026gt;, \u0026lt;video\u0026gt;, \u0026lt;audio\u0026gt;, \u0026lt;iframe\u0026gt;, \u0026lt;link\u0026gt;, \u0026lt;form\u0026gt; and so on. These subresources can be fetched by the browser after loading the page, therefore they can all be same- or cross-origin requests.\nLet\u0026rsquo;s travel to an imaginary world where CORS does not exist and web browsers allow all sorts of cross-origin requests.\nImagine I got a page on my website evil.com with a \u0026lt;script\u0026gt;. On the surface it looks like a simple page, where you read some useful information. But in the \u0026lt;script\u0026gt;, I have specially crafted code that will send a specially-crafted request to bank\u0026rsquo;s DELETE /account endpoint. Once you load the page, the JavaScript is executed and an AJAX call hits the bank\u0026rsquo;s API.\nPuff, your account is gone. 🌬  Mind-blowing – imagine while reading some information on a web page, you get an email from your bank that you\u0026rsquo;ve successfully deleted your account. I know I know\u0026hellip; if it was THAT easy to do anything with a bank\u0026rsquo;s. I digress.\nFor my evil \u0026lt;script\u0026gt; to work, as part of the request your browser would also have to send your credentials (cookies) from the bank\u0026rsquo;s website. That\u0026rsquo;s how the bank\u0026rsquo;s servers would identify you and know which account to delete.\nLet\u0026rsquo;s look at a different, not-so-evil scenario.\nI want to detect folks that work for Awesome Corp, whose internal website is on intra.awesome-corp.com. On my website, dangerous.com I got an \u0026lt;img src=\u0026quot;https://intra.awesome-corp.com/avatars/john-doe.png\u0026quot;\u0026gt;.\nFor users that do not have a session active with intra.awesome-corp.com, the avatar won\u0026rsquo;t render – it will produce an error. But, if you\u0026rsquo;re logged in the intranet of Awesome Corp., once you open my dangerous.com website I\u0026rsquo;ll know that you have access.\nThat means that I will be able to derive some information about you. While it\u0026rsquo;s definitely harder for me to craft an attack, the knowledge that you have access to Awesome Corp. is still a potential attack vector.\nLeaking info to 3rd parties 💦  While these two are overly-simplistic examples, it is this kind of threats that have made the same-origin policy \u0026amp; CORS necessary. These are all different dangers of cross-origin requests. Some have been mitigated, others can\u0026rsquo;t be mitigated – they\u0026rsquo;re rooted in the nature of the web. But for the plethora of attack vectors that have been squashed – it\u0026rsquo;s because of CORS.\nBut before CORS, there was the same-origin policy.\nSame-origin policy The same-origin policy prevents cross-origin attacks by blocking read access to resources loaded from a different origin. This policy still allows some tags, like \u0026lt;img\u0026gt;, to embeds resources from a different origin.\nThe same-origin policy was introduced by Netscape Navigator 2.02 in 1995, originally intended to protect cross-origin access to the DOM.\nEven though same-origin policy implementations are not required to follow an exact specification, all modern browsers implement some form of it. The principles of the policy are described in RFC6454 of the Internet Engineering Task Force (IETF).\nThe implementation of the same-origin policy is defined with this ruleset:\n   Tags Cross-origin Note     \u0026lt;iframe\u0026gt; Embedding permitted Depends on X-Frame-Options   \u0026lt;link\u0026gt; Embedding permitted Proper Content-Type might be required   \u0026lt;form\u0026gt; Writing permitted Cross-origin writes are common   \u0026lt;img\u0026gt; Embedding permitted Cross-origin reading via JavaScript and loading it in a \u0026lt;canvas\u0026gt; is forbidden   \u0026lt;audio\u0026gt; / \u0026lt;video\u0026gt; Embedding permitted    \u0026lt;script\u0026gt; Embedding permitted Access to certain APIs might be forbidden    Same-origin policy solves many challenges, but it is pretty restrictive. In the age of single-page applications and media-heavy websites, same-origin does not leave a lot of room for relaxation of or fine-tuning of these rules.\nCORS was born with the goals to relax the same-origin policy and to fine-tune cross-origin access.\nEnter CORS So far we covered what is an origin, how it\u0026rsquo;s defined, what the drawbacks of cross-origin requests are and the same-origin policy that browsers implement.\nNow it\u0026rsquo;s time to familiarize ourselves with Cross Origin Resource Sharing (CORS). CORS is a mechanism that allows control of access to subresources on a web page over a network. The mechanism classifies three different categories of subresource access:\n Cross-origin writes Cross-origin embeds Cross-origin reads  Before we go on to explain each of these categories, it\u0026rsquo;s important to realize that although your browser (by default) might allow a certain type of cross-origin request, that does not mean that said request will be accepted by the server.\nCross-origin writes are links, redirects, and form submissions. With CORS active in your browser, these are all allowed. There is also a thing called preflight request that fine-tunes cross-origin writes, so while some writes might be permitted by default it doesn\u0026rsquo;t mean they can go through in practice. We\u0026rsquo;ll look into that a bit later.\nCross-origin embeds are subresources loaded via: \u0026lt;script\u0026gt;, \u0026lt;link\u0026gt;, \u0026lt;img\u0026gt;, \u0026lt;video\u0026gt;, \u0026lt;audio\u0026gt;, \u0026lt;object\u0026gt;, \u0026lt;embed\u0026gt;, \u0026lt;iframe\u0026gt; and more. These are all allowed by default. \u0026lt;iframe\u0026gt; is a special one – as it\u0026rsquo;s purpose is to literally load a different page inside the frame, its cross-origin framing can be controlled by using the X-Frame-options header.\nWhen it comes to \u0026lt;img\u0026gt; and the other embeddable subresources – it\u0026rsquo;s in their nature to trigger cross-origin requests. That\u0026rsquo;s why in CORS differentiates between cross-origin embeds and cross-origin reads, and treats them differently.\nCross-origin reads are subresources loaded via AJAX / fetch calls. These are by default blocked in your browser. There\u0026rsquo;s the workaround of embedding such subresources in a page, but such tricks are handled by another policy present in modern browsers.\nIf your browser is up to date, all of these heuristics are already implemented in it.\nCross-origin writes Cross-origin writes can be the very problematic. Let\u0026rsquo;s look into an example and see CORS in action.\nFirst, we\u0026rsquo;ll have a simple Crystal (using Kemal) HTTP server:\nrequire \u0026#34;kemal\u0026#34; port = ENV[\u0026#34;PORT\u0026#34;].to_i || 4000 get \u0026#34;/\u0026#34; do \u0026#34;Hello world!\u0026#34; end get \u0026#34;/greet\u0026#34; do \u0026#34;Hey!\u0026#34; end post \u0026#34;/greet\u0026#34; do |env| name = env.params.json[\u0026#34;name\u0026#34;].as(String) \u0026#34;Hello, #{name}!\u0026#34; end Kemal.config.port = port Kemal.run It simply takes a request at the /greet path, with a name in the request body, and returns a Hello #{name}!. To run this tiny Crystal server, we can boot it with:\n$ crystal run server.cr This will boot the server and listen on localhost:4000. If we navigate to localhost:4000 in our browser, we will be presented a simple \u0026ldquo;Hello World\u0026rdquo; page:\nHello, world! 🌍  Now that we know our server is running, let\u0026rsquo;s execute a POST /greet to the server listening on localhost:4000, from the console of our browser page. We can do that by using fetch:\nfetch( \u0026#39;http://localhost:4000/greet\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify({ name: \u0026#39;Ilija\u0026#39;}) } ).then(resp =\u0026gt; resp.text()).then(console.log) Once we run it, we will see the greeting come back from the server:\nHi there! 👋  This was a POST request, but it was not cross-origin. We sent the request from the browser where http://localhost:4000 (the origin) was rendered, to that same origin.\nNow, let\u0026rsquo;s try the same request, but cross-origin. We will open https://google.com and try to send that same request from that tab in our browser:\nHello, CORS! 💣  We managed to get the famous CORS error. Although our Crystal server can fulfil the request, our browser is protecting us from ourselves. It is basically telling us that a website that we have opened wants to make changes to another website as ourselves.\nIn the first example, where we sent the request to http://localhost:4000/greet from the tab that rendered http://localhost:4000, our browser looks at that request and lets it through because it appears that our website is calling our server (which is fine). But in the second example where our website (https://google.com) wants to write to http://localhost:4000, then our browser flags that request and does not let it go through.\nPreflight requests If we look deeper in our developer console, in the Network tab in particular, we will in fact notice two requests in place of the one that we sent:\nTwo outbound requests as seen in the Network panel  What is interesting to notice is that the first request has a HTTP method of OPTIONS, while the second has POST.\nIf we explore the OPTIONS request we will see that this is a request that has been sent by our browser prior to sending our POST request:\nLooking into the OPTIONS request 🔍  What is interesting is that even though the response to the OPTIONS request was a HTTP 200, it was still marked as red in the request list. Why?\nThis is the preflight request that modern browsers do. A preflight request is performed for requests which CORS deems as complex. The criteria for complex request is:\n A request that uses methods other than GET, POST, or HEAD A request that includes headers other than Accept, Accept-Language or Content-Language A request that has a Content-Type header value other than application/x-www-form-urlencoded, multipart/form-data, or text/plain  Therefore in the above example, although we send a POST request, the browser considers our request complex due to the Content-Type: application/json header.\nIf we would change our server to handle text/plain content (instead of JSON), we can work around the need for a preflight request:\nrequire \u0026#34;kemal\u0026#34; get \u0026#34;/\u0026#34; do \u0026#34;Hello world!\u0026#34; end get \u0026#34;/greet\u0026#34; do \u0026#34;Hey!\u0026#34; end post \u0026#34;/greet\u0026#34; do |env| body = env.request.body name = \u0026#34;there\u0026#34; name = body.gets.as(String) if !body.nil? \u0026#34;Hello, #{name}!\u0026#34; end Kemal.config.port = 4000 Kemal.run Now, when we can send our request with the Content-type: text/plain header:\nfetch( \u0026#39;http://localhost:4000/greet\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }, body: \u0026#39;Ilija\u0026#39; } ) .then(resp =\u0026gt; resp.text()) .then(console.log) Now, while the preflight request will not be sent, the CORS policy of the browser will keep on blocking:\nCORS standing strong  But because we have crafted a request which does not classify as complex, our browser actually won\u0026rsquo;t block the request:\nRequest went through ➡️  Simply put: our server is misconfigured to accept text/plain cross-origin requests, without any other protection in place, and our browser can\u0026rsquo;t do much about that. But still, it does the next best thing – it does not expose our opened page / tab to the response of that request. Therefore in this case, CORS does not block the request - it blocks the response.\nThe CORS policy of our browser considers this effectively a cross-origin read, because although the request is sent as POST, the Content-type header value makes it essentially the same as a GET. And cross-origin reads are blocked by default, hence the blocked response we are seeing in our network tab.\nWorking around preflight requests like in the example above is not recommended. In fact, if you expect that your server will have to gracefully handle preflight requests, it should implement the OPTIONS endpoints and return the correct headers.\nWhen implementing the OPTIONS endpoint, you need to know that the preflight request of the browser looks for three headers in particular that can be present on the response:\n Access-Control-Allow-Methods – it indicates which methods are supported by the response’s URL for the purposes of the CORS protocol. Access-Control-Allow-Headers - it indicates which headers are supported by the response’s URL for the purposes of the CORS protocol. Access-Control-Max-Age - it indicates the number of seconds (5 by default) the information provided by the Access-Control-Allow-Methods and Access-Control-Allow-Headers headers can be cached.  Let\u0026rsquo;s go back to our previous example where we sent a complex request:\nfetch( \u0026#39;http://localhost:4000/greet\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify({ name: \u0026#39;Ilija\u0026#39;}) } ).then(resp =\u0026gt; resp.text()).then(console.log) We already confirmed that when we send this request, our browser will check with the server if it can perform the cross-origin request. To get this request working in a cross-origin environment, we have to first add the OPTIONS /greet endpoint to our server. In its response header, the new endpoint will have to inform the browser that the request to POST /greet, with Content-type: application/json header, from the origin https://www.google.com, can be accepted.\nWe\u0026rsquo;ll do this by using the Access-Control-Allow-* headers:\noptions \u0026#34;/greet\u0026#34; do |env| # Allow `POST /greet`... env.response.headers[\u0026#34;Access-Control-Allow-Methods\u0026#34;] = \u0026#34;POST\u0026#34; # ...with `Content-type` header in the request... env.response.headers[\u0026#34;Access-Control-Allow-Headers\u0026#34;] = \u0026#34;Content-type\u0026#34; # ...from https://www.google.com origin. env.response.headers[\u0026#34;Access-Control-Allow-Origin\u0026#34;] = \u0026#34;https://www.google.com\u0026#34; end If we boot our server and send the request:\nStill blocked? 🤔  Our request remains blocked. Even though our OPTIONS /greet endpoint did allow the request, we are still seeing the error message. In our network tab there\u0026rsquo;s something interesting going on:\nOPTIONS is green! 🎉  The request to the OPTIONS /greet endpoint was a success! But the POST /greet call still failed. If we take a peek in the internals of the POST /greet request we will see a familiar sight:\nPOST is green too? 😲  In fact, the request did succeed – the server returned a HTTP 200. The preflight request did work – the browser did make the POST request instead of blocking it. But the response of the POST request did not contain any CORS headers, so even though the browser did make the request, it blocked any response processing.\nTo allow the browser also process the response from the POST /greet request, we need to add a CORS header to the POST endpoint as well:\npost \u0026#34;/greet\u0026#34; do |env| name = env.params.json[\u0026#34;name\u0026#34;].as(String) env.response.headers[\u0026#34;Access-Control-Allow-Origin\u0026#34;] = \u0026#34;https://www.google.com\u0026#34; \u0026#34;Hello, #{name}!\u0026#34; end By adding the Access-Control-Allow-Origin header response header, we tell the browser that a tab that has https://www.google.com open can also access the response payload.\nIf we give this another shot:\nPOST works!  We will see that POST /greet did get us a response, without any errors. If we take a peek in the Network tab, we\u0026rsquo;ll see that both requests are green:\nOPTIONS \u0026amp; POST in action! 💪  By using proper response headers on our preflight endpoint OPTIONS /greet, we unlocked our server\u0026rsquo;s POST /greet endpoint to be accessed across different origin. On top of that, by providing a correct CORS response header on the response of the POST /greet endpoint, we freed the browser to process the response without any blocking.\nCross-origin reads As we mentioned before, cross-origin reads are blocked by default. That\u0026rsquo;s on purpose - we wouldn\u0026rsquo;t want to load other resources from other origins in the scope of our origin.\nSay, we have a GET /greet action in our Crystal server:\nget \u0026#34;/greet\u0026#34; do \u0026#34;Hey!\u0026#34; end From our tab that has www.google.com rendered, if we try to fetch the GET /greet endpoint we will get blocked by CORS:\nCORS blocking 🙅  If we look deeper in the request, we will found out something interesting:\nA successful GET 🎉  In fact, just like before, our browser did let the request through – we got a HTTP 200 back. But it did not expose our opened page / tab to the response of that request. Again, in this case CORS does not block the request - it blocks the response.\nJust like with cross-origin writes, we can relax CORS and make it available for cross-origin reading - by adding the Access-Control-Allow-Origin header:\nget \u0026#34;/greet\u0026#34; do |env| env.response.headers[\u0026#34;Access-Control-Allow-Origin\u0026#34;] = \u0026#34;https://www.google.com\u0026#34; \u0026#34;Hey!\u0026#34; end When the browser gets the response back from the server, it will look at the Access-Control-Allow-Origin header and will decide based on its value if it can let the page read the response. Given that the value in this case is https://www.google.com which is the page that we use in our example the outcome will be a success:\nA successful cross-origin GET 🎉  This is how the browser shields us from cross-origin reads and respects the server directives that are sent via the headers.\nFine-tuning CORS As we already saw in previous examples, to relax the CORS policy of our website, we can set the Access-Control-Allow-Origin of our /greet action to the https://www.google.com value:\npost \u0026#34;/greet\u0026#34; do |env| body = env.request.body name = \u0026#34;there\u0026#34; name = body.gets.as(String) if !body.nil? env.response.headers[\u0026#34;Access-Control-Allow-Origin\u0026#34;] = \u0026#34;https://www.google.com\u0026#34; \u0026#34;Hello, #{name}!\u0026#34; end This will allow the https://www.google.com origin to call our server, and our browser will feel fine about that. Having the Access-Control-Allow-Origin in place, we can try to execute the fetch call again:\nSuccess! 🎉  This made it work! With the new CORS policy, we can call our /greet action from our tab that has https://www.google.com rendered. Alternatively, we could also set the header value to *, which would tell the browser that the server can be called from any origin.\nSuch a configuration has to be carefully considered. Yet, putting relaxed CORS headers is almost always safe. One rule of thumb is: if you open the URL in an incognito tab, and you are happy with the information you are exposing, then you can set a permissive (*) CORS policy on said URL.\nAnother way to fine-tune CORS on our website is to use the Access-Control-Allow-Credentials response header. Access-Control-Allow-Credentials instructs browsers whether to expose the response to the frontend JavaScript code when the request\u0026rsquo;s credentials mode is include.\nThe request\u0026rsquo;s credentials mode comes from the introduction of the Fetch API, which has its roots back the original XMLHttpRequest objects:\nvar client = new XMLHttpRequest() client.open(\u0026#34;GET\u0026#34;, \u0026#34;./\u0026#34;) client.withCredentials = true With the introduction of fetch, the withCredentials option was transformed into an optional argument to the fetch call:\nfetch(\u0026#34;./\u0026#34;, { credentials: \u0026#34;include\u0026#34; }).then(/* ... */) The available options for the credentials options are omit, same-origin and include. The different modes are available so developers can fine-tune the outbound request, whereas the response from the server will inform the browser how to behave when credentials are sent with the request (via the Access-Control-Allow-Credentials header).\nThe Fetch API spec contains a well-written and thorough breakdown of the interplay of CORS and the fetch Web API, and the security mechanisms put in place by browsers.\nSome best practices Before we wrap it up, let\u0026rsquo;s cover some best practices when it comes to Cross Origin Resource Sharing (CORS).\nFree for all A common example is if you own a website that displays content for the public, that is not behind paywalls, or requiring authentication or authorization – you should be able to set Access-Control-Allow-Origin: * to its resources.\nThe * value is a good choice in cases when:\n No authentication or authorization is required The resource should be accessible to a wide range of users without restrictions The origins \u0026amp; clients that will access the resource is of great variety, you don\u0026rsquo;t have knowledge of it or you simply don\u0026rsquo;t care  A dangerous prospect of such configuration is when it comes to content served on private networks (i.e. behind firewall or VPN). When you are connected via a VPN, you have access to the files on the company\u0026rsquo;s network:\nOversimplification of VPNs  Now, if an attacker hosts as website dangerous.com, which contains a link to a file within the VPN, they can (in theory) create a script on their website that can access that file:\nFile leak  While such an attack is hard and requires a lot of knowledge about the VPN and the files stored within it, it is a potential attack vector that we must be aware of.\nKeeping it in the family Continuing with the example from above, imagine we want to implement analytics for our website. We would like our users' browsers to send us data about the experience and behavior of our users on our website.\nA common way to do this is to send that data periodically using asynchronous requests using JavaScript in the browser. On the backend we have a simple API that takes these requests from our users' browsers and stores the data on the backend for further processing.\nIn such cases, our API is public, but we don\u0026rsquo;t want any website to send data to our analytics API. In fact, we are interested only in requests that originate from browsers that have our website rendered – that is all.\n  In such cases, we want our API to set the Access-Control-Allow-Origin header to our website\u0026rsquo;s URL. That will make sure browsers never send requests to our API from other pages.\nIf users or other websites try to cram data in our analytics API, the Access-Control-Allow-Origin headers set on the resources of our API won\u0026rsquo;t let the request to go through:\n  NULL origins Another interesting case are null origins. They occur when a resource is accessed by a browser that renders a local file. For example, requests coming from some JavaScript running in a static file on your local machine have the Origin header set to null.\nIn such cases, if our servers do now allow access to resources for the null origin, then it can be a hindrance to the developer productivity. Allowing the null origin within your CORS policy has to be deliberately done, and only if the users of your website / product are developers.\nSkip cookies, if you can As we saw before with the Access-Control-Allow-Credentials, cookies are not enabled by default. To allow cross-origin sending cookies, it as easy as returning Access-Control-Allow-Credentials: true. This header will tell browsers that they are allowed to send credentials (i.e. cookies) in cross-origin requests.\nAllowing and accepting cross-origin cookies can be tricky. You could expose yourself to potential attack vectors, so enable them only when absolutely necessary.\nCross-origin cookies work best in situations when you know exactly which clients will be accessing your server. That is why the CORS semantics do not allow us to set Access-Control-Allow-Origin: * when cross-origin credentials are allowed.\nWhile the Access-Control-Allow-Origin: * and Access-Control-Allow-Credentials: true combination is technically allowed, it\u0026rsquo;s a anti-pattern and should absolutely be avoided.\nIf you would like your servers to be accessed by different clients and origins, you should probably look into building an API (with token-based authentication) instead of using cookies. But if going down the API path is not an option, then make sure you implement cross-site request forgery (CSRF) protection.\nAdditional reading I hope this (long) read gave you a good idea about CORS, how it came to be, and why it\u0026rsquo;s neccesary. Here are a few more links that I used while writing this article, or that I believe are a good read on the topic:\n Cross-Origin Resource Sharing (CORS) Access-Control-Allow-Credentials header on MDN Web Docs Authoritative guide to CORS (Cross-Origin Resource Sharing) for REST APIs The \u0026ldquo;CORS protocol\u0026rdquo; section of the Fetch API spec Same-origin policy on MDN Web Docs Quentin\u0026rsquo;s great summary of CORS on StackOverflow  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/deep-dive-cors-history-how-it-works-best-practices/","summary":"The error in your browser\u0026rsquo;s console  No \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; header is present on the requested resource.\n  Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at https://example.com/\n  Access to fetch at \u0026lsquo;https://example.com\u0026rsquo; from origin \u0026lsquo;http://localhost:3000\u0026rsquo; has been blocked by CORS policy.\n I am sure you\u0026rsquo;ve seen one of these errors, or a variation, in your browser\u0026rsquo;s console. If you have not – don\u0026rsquo;t fret, you soon will.","title":"Deep dive in CORS: History, how it works, and best practices"},{"content":"No test suite is perfect. Some test suites are missing good helper functions; others are under-configured or over-customize. Some have obsolete packages included and are left unmaintained. Folks that have experience with more mature projects will likely agree that all of the above can be found in the wild.\nOften, when we test our Go programs, need to create files. Such files can be just fixture files, or whole file trees, to set up the correct environment for the tests to run. Once the tests finish running, we have to clean them up, so they don\u0026rsquo;t linger around.\nWe should rely on the test suite\u0026rsquo;s set of helpers to provide us with a way to manage test files if they exist in the first place. Unfortunately, not all test suites have such clean-up helpers set up. Sometimes, you might find a few different implementations, instead of one obvious way to do it.\nComing up in Go v1.15, the testing package will improve the support for creating temporary test files and directories. Let\u0026rsquo;s see how we can put them to use.\nConverting PDFs to TXT files While thinking about a small program that will aid our understanding of leaking test files, I was asking myself, \u0026ldquo;What is a program that generates files?\u0026rdquo;. Because I work for a company that does a lot with documents, I thought, \u0026ldquo;let\u0026rsquo;s do something straightforward with PDFs\u0026rdquo;.\nImagine we have a program that extracts text out of PDFs. Why? Well, for one, if we want to know how long it will take us to read the PDF, we can take the number of words in a PDF and divide it by the average reading speed (which, according to Google, is 250 words per minute).\nBut to do that, we first have to take a PDF and create a TXT file with all of the sentences inside. To do that, we can use one of the many PDF parsing libraries for Go.\nHere\u0026rsquo;s the code that takes a PDF, extracts all rows of text from it, and saves them in a TXT file.\nFirst, the persist function:\nfunc persist(content []byte, w io.Writer) error { _, err := w.Write(content) if err != nil { log.Println(\u0026#34;Failed to persist contents.\u0026#34;) return err } return nil } It takes some bytes as content and persists them to a io.Writer - it can be a file, a strings.StringBuilder or a different type that implements the io.Writer interface. The argument types are generic (interfaces) by design, so the function arguments are more liberal. You will see why when we test this function.\nThe slurp function is next. It will take a pdf.Reader type, which is a type from the pdf library we use. We will slurp all of the relevant content (text) from the PDF and return a slice of bytes.\nfunc slurp(r *pdf.Reader) []byte { var bs []byte total := r.NumPage() for i := 1; i \u0026lt;= total; i++ { p := r.Page(i) if p.V.IsNull() { continue } rows, _ := p.GetTextByRow() for _, row := range rows { for _, word := range row.Content { bs = append(bs, []byte(word.S)...) } } } return bs } By returning a slice of bytes, instead of a string, we can use a generic interface such as io.Writer (like in persist). The interface is applicable because the Write function it implements takes a slice of bytes as an argument - making the arguments of slurp and the returned values of persist compatible.\nNext, the function that ties them all together – run:\nfunc run(args []string, out io.Writer) error { log.SetOutput(out) if len(args) \u0026lt; 3 { return fmt.Errorf(\u0026#34;Expected at least 2 arguments, got %d.\u0026#34;, len(args)-1) } pdfFile, r, err := pdf.Open(args[1]) if err != nil { return err } defer pdfFile.Close() contents := slurp(r) txtFile, err := os.Create(args[2]) if err != nil { return err } defer txtFile.Close() err = persist(contents, txtFile) if err != nil { return err } return nil } run\u0026rsquo;s role is to check the arguments received from main and the io.Writer to where it should send all of its output. Then it opens the PDF file for reading and passes the file reference to the slurp function.\nOnce slurp returns the contents of the file, which is just a slice of bytes run will create a new file for writing, called txtFile. Once it opens the file, it will send the contents and the txtFile to persist as arguments.\nAs we already saw above, persist will save the contents to the file and return any potential errors. If no errors are returned, run successfully exits.\nLastly, the straightforward main function:\nfunc main() { if err := run(os.Args, os.Stdout); err != nil { log.Fatal(err) } } Locally, I have a simple PDF with some text inside that I\u0026rsquo;ve found online. Its contents, according to the author, are popular interview questions. We will run the above program with any PDF, and as long as it finds some text inside it will save it to an output file.\nHere it is in action:\n$ go run main.go input.pdf out.txt $ cat out.txt 50 Common Interview Questions and Answers1. Tell me about yourself: The most often asked question in interviews. ... That\u0026rsquo;s really it. Our program took the contents from input.pdf and stored them in out.txt. Let\u0026rsquo;s see how we can test this program.\nTesting persist The persist function does not do much. In fact it just invokes the Write function of the io.Writer instance. Since we are using a file, that is part of the standard library, we do not need to test it. But, given that there\u0026rsquo;s some error handling, which is a custom implementation, we can add some tests to strive to get to that full test coverage.\nTestPersist, in all of its glory:\nfunc TestPersist(t *testing.T) { tt := []struct { name string content []byte out func() (io.ReadWriter, error) }{ { name: \u0026#34;WithNoContent\u0026#34;, content: []byte{}, out: func() (io.ReadWriter, error) { return os.Create(\u0026#34;empty.txt\u0026#34;) }, }, { name: \u0026#34;WithContent\u0026#34;, content: []byte{}, out: func() (io.ReadWriter, error) { return os.Create(\u0026#34;not-empty.txt\u0026#34;) }, }, } for _, tc := range tt { t.Run(tc.name, func(t *testing.T) { f, err := tc.out() if err != nil { t.Fatalf(\u0026#34;Cannot create output file: %s\u0026#34;, err) } err = persist(tc.content, f) if err != nil { t.Fatalf(\u0026#34;Cannot persits to output file: %s\u0026#34;, err) } b := []byte{} if _, err = io.ReadFull(f, b); err != nil { t.Fatalf(\u0026#34;Cannot read test output file: %s\u0026#34;, err) } if !bytes.Equal(b, tc.content) { t.Errorf(\u0026#34;Persisted content is different than saved content.\u0026#34;) } }) } } Each of the test cases, part of the table-driven tests, contains the name of the test case, the content that it will persist, and the out function, which will create the output file.\nIn the test itself, we create a subtest for each of the test cases, which will try to write the content to a file, and then it will read all of the content back from the file. If the persisted content and the test case content are the same, then the test successfully passes.\nIf we run the tests, this is the output we will see:\n$ go test -v -run TestPersist === RUN TestPersist === RUN TestPersist/WithNoContent === RUN TestPersist/WithContent --- PASS: TestPersist (0.00s) --- PASS: TestPersist/WithNoContent (0.00s) --- PASS: TestPersist/WithContent (0.00s) PASS ok github.com/fteem/go-playground/testing-in-go-leak-test-files\t0.250s We ran the two test cases where we try to persist a file with no content and some content. Both of them passed, and we can move on!\nTesting slurp The slurp function is more involved. It requires two different test files – two dummy PDFs with some content and no content (empty). Then, by passing the two different files to slurp, we can test if extracting the text from the PDF works as intended.\nThis is the test:\nfunc TestSlurp(t *testing.T) { tt := []struct { name string pdfPath string size int }{ { name: \u0026#34;PDFWithContent\u0026#34;, pdfPath: \u0026#34;testdata/content.pdf\u0026#34;, size: 11463, }, { name: \u0026#34;PDFWithoutContent\u0026#34;, pdfPath: \u0026#34;testdata/empty.pdf\u0026#34;, size: 0, }, } for _, tc := range tt { t.Run(tc.name, func(t *testing.T) { pdfFile, r, err := pdf.Open(tc.pdfPath) if err != nil { t.Fatalf(\u0026#34;Couldn\u0026#39;t open PDF %s, error: %s\u0026#34;, tc.pdfPath, err) } defer pdfFile.Close() contents := slurp(r) if len(contents) != tc.size { t.Errorf(\u0026#34;Expected contents to be %d bytes, got %d\u0026#34;, tc.size, len(contents)) } }) } } Each of the test cases from the table-driven tests will have a pdfPath, which is an actual PDF file on disk. For each of the test cases, a subtest will be run, which will open the PDF using the ledongthuc/pdf library. We will then pass the reference to the PDF file to the slurp function, expecting the contents to be returned by slurp.\nOnce it returns the content, we simply compare the size - the number of bytes that are expected (tc.size), comparing it against the len(contents), which is the size of the bytes returned. If the sizes match, we assume that the content is correct, and the test will pass.\nHere\u0026rsquo;s the test in action:\n$ go test -v -run TestSlurp === RUN TestSlurp === RUN TestSlurp/PDFWithContent === RUN TestSlurp/PDFWithoutContent --- PASS: TestSlurp (0.03s) --- PASS: TestSlurp/PDFWithContent (0.03s) --- PASS: TestSlurp/PDFWithoutContent (0.00s) PASS ok github.com/fteem/go-playground/testing-in-go-leak-test-files\t0.253s Testing run The run function is what glues everything together. It validates the arguments, then opens the PDF for reading, slurps all of the contents using slurp, and lastly saves all of the text content to the TXT file using persist.\nHere\u0026rsquo;s the test:\nfunc TestRun(t *testing.T) { tt := []struct { name string input string output string }{ { name: \u0026#34;WithValidArguments\u0026#34;, input: \u0026#34;testdata/input.pdf\u0026#34;, output: \u0026#34;testdata/output.txt\u0026#34;, }, { name: \u0026#34;WithEmptyInput\u0026#34;, input: \u0026#34;testdata/empty.pdf\u0026#34;, output: \u0026#34;testdata/output.txt\u0026#34;, }, } for _, tc := range tt { t.Run(tc.name, func(t *testing.T) { err := run([]string{\u0026#34;foo\u0026#34;, tc.input, tc.output}, os.Stdout) if err != nil { t.Fatalf(\u0026#34;Expected no error, got: %s\u0026#34;, err) } if _, err := os.Stat(tc.output); os.IsNotExist(err) { t.Errorf(\u0026#34;Expected persisted file at %s, did not find it: %s\u0026#34;, tc.output, err) } }) } } In TestRun, we check if, for each of the test PDFs we provide, the run function crates the corresponding TXT file. In TestRun, we do not care about the actual contents – we can assume that the rest of the unit tests covers that part of the functionality.\nThen, for each test case, we use os.Stat, which will return an error if the file does not exist. If the file does exist, we consider the run function as properly functioning and mark the test as passed.\nHere\u0026rsquo;s the test in action:\n$ go test -v -run TestRun === RUN TestRun === RUN TestRun/WithValidArguments === RUN TestRun/WithEmptyInput --- PASS: TestRun (0.03s) --- PASS: TestRun/WithValidArguments (0.03s) --- PASS: TestRun/WithEmptyInput (0.00s) PASS ok github.com/fteem/go-playground/testing-in-go-leak-test-files\t0.106s Another test we can also run is to test the returned errors. We will create another function called TestRunErrors, which will cover the potential errors returned by run. Here\u0026rsquo;s the test function:\nfunc TestRunErrors(t *testing.T) { tt := []struct { name string input string output string }{ { name: \u0026#34;WithoutArguments\u0026#34;, input: \u0026#34;\u0026#34;, output: \u0026#34;\u0026#34;, }, { name: \u0026#34;WithoutOneArgument\u0026#34;, input: \u0026#34;testdata/input.pdf\u0026#34;, output: \u0026#34;\u0026#34;, }, { name: \u0026#34;WithNonexistentInput\u0026#34;, input: \u0026#34;testdata/nonexistent.pdf\u0026#34;, output: \u0026#34;testdata/output.txt\u0026#34;, }, } for _, tc := range tt { t.Run(tc.name, func(t *testing.T) { err := run([]string{\u0026#34;foo\u0026#34;, tc.input, tc.output}, os.Stdout) if err == nil { t.Fatalf(\u0026#34;Expected an error, did not get one.\u0026#34;) } }) } } The TestRunErrors is similar to TestRun, with having the focus on the returned errors. It checks that for each of the bad inputs the run function receives, that it returns an error. We could take this a step further by implementing sentinel errors and asserting on them, but this will do just fine this article.\nHere\u0026rsquo;s the TestRunErrors function in action:\n$ go test -v -run TestRunErrors === RUN TestRunErrors === RUN TestRunErrors/WithoutArguments === RUN TestRunErrors/WithoutOneArgument === RUN TestRunErrors/WithNonexistentInput --- PASS: TestRunErrors (0.02s) --- PASS: TestRunErrors/WithoutArguments (0.00s) --- PASS: TestRunErrors/WithoutOneArgument (0.02s) --- PASS: TestRunErrors/WithNonexistentInput (0.00s) PASS ok github.com/fteem/go-playground/testing-in-go-leak-test-files\t0.140sbash Cleaning up after our test If you were following along, you should notice that test files are created in your project\u0026rsquo;s directory. The files stay there because we never clean up the output files that our program creates when the tests run.\nStarting from Go v1.15, there will be a nice way to do this: TB.TempDir(). To clean up the test files, we can use TB.TempDir as a parent directory wherever we are passing the output file path. Once the tests pass, Go will automatically get rid of this directory, without us having to do any clean-up.\nFirst, let\u0026rsquo;s see how we can change the TestPersist function to clean up the empty.txt and non-empty.txt files it creates:\nfunc TestPersist(t *testing.T) { tt := []struct { name string content []byte out func() (io.ReadWriter, error) }{ { name: \u0026#34;WithNoContent\u0026#34;, content: []byte{}, out: func() (io.ReadWriter, error) { return os.Create(filepath.Join(t.TempDir(), \u0026#34;empty.txt\u0026#34;)) }, }, { name: \u0026#34;WithContent\u0026#34;, content: []byte{}, out: func() (io.ReadWriter, error) { return os.Create(filepath.Join(t.TempDir(), \u0026#34;not-empty.txt\u0026#34;)) }, }, } for _, tc := range tt { // Snipped... \t} } The only notable change is to use filepath.Join with t.TempDir() and the file name as arguments. This combo will compose a valid temporary path, that Go will remove once the tests finish. Given that at the time of writing this, Go 1.15 is still not out, we can use the gotip tool to run Go\u0026rsquo;s latest master version:\n$ gotip test -v -run TestPersist === RUN TestPersist === RUN TestPersist/WithNoContent === RUN TestPersist/WithContent --- PASS: TestPersist (0.00s) --- PASS: TestPersist/WithNoContent (0.00s) --- PASS: TestPersist/WithContent (0.00s) PASS ok github.com/fteem/go-playground/testing-in-go-leak-test-files\t0.048s If we inspect the project root, we will see that no new files are being created. The output files are cleaned up after the tests have finished running.\nThe gotip tool compiles and runs the go command from the development tree. Using the gotip command, instead of the normal go command, will run the latest version of the language, as seen in the main Git trunk.\nYou can see its documentation for more details.\n Next, we can do the same change to the TestRun function:\nfunc TestRun(t *testing.T) { tt := []struct { name string input string output string }{ { name: \u0026#34;WithValidArguments\u0026#34;, input: \u0026#34;testdata/input.pdf\u0026#34;, output: filepath.Join(t.TempDir(), \u0026#34;output.txt\u0026#34;), }, { name: \u0026#34;WithEmptyInput\u0026#34;, input: \u0026#34;testdata/empty.pdf\u0026#34;, output: filepath.Join(t.TempDir(), \u0026#34;output.txt\u0026#34;), }, } for _, tc := range tt { // Same as before... \t} } In the TestRun function, we use the same trick - we use the T.TempDir function to concatenate the path of the output file. Running the test the same way, we can see T.TempDir once more in action:\n$ gotip test -v -run TestRun === RUN TestRun === RUN TestRun/WithValidArguments === RUN TestRun/WithEmptyInput --- PASS: TestRun (0.03s) --- PASS: TestRun/WithValidArguments (0.03s) --- PASS: TestRun/WithEmptyInput (0.00s) === RUN TestRunErrors === RUN TestRunErrors/WithoutArguments === RUN TestRunErrors/WithoutOneArgument === RUN TestRunErrors/WithNonexistentInput --- PASS: TestRunErrors (0.02s) --- PASS: TestRunErrors/WithoutArguments (0.00s) --- PASS: TestRunErrors/WithoutOneArgument (0.02s) --- PASS: TestRunErrors/WithNonexistentInput (0.00s) PASS ok github.com/fteem/go-playground/testing-in-go-leak-test-files\t0.265s If you want to check out the motivation and the discussion around this addition to the new Go version 1.15, you can head over to the original proposal.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-stop-leaking-files/","summary":"No test suite is perfect. Some test suites are missing good helper functions; others are under-configured or over-customize. Some have obsolete packages included and are left unmaintained. Folks that have experience with more mature projects will likely agree that all of the above can be found in the wild.\nOften, when we test our Go programs, need to create files. Such files can be just fixture files, or whole file trees, to set up the correct environment for the tests to run.","title":"Testing in Go: Stop Leaking Files"},{"content":"If you have ever worked with Ruby, or have maybe maintained a Rails application, I am sure the name Sidekiq will sound familiar. For those unfamiliar with the project, Sidekiq is a job system for Ruby. It is a wildly popular project, and the author has turned it into a successful business.\nNone of the above would be relevant if Sidekiq\u0026rsquo;s author Mike Perham, in 2014, did not write a concise and informative post titled \u0026ldquo;Don\u0026rsquo;t Daemonize your Daemons!\u0026quot;. In it, he covers four guidelines to daemonizing programs correctly:\n Log to STDOUT Shut down on SIGTERM/SIGINT Reload config on SIGHUP Provide the necessary config file for your favorite init system to control your daemon  (You can also read the whole article on his website.)\nSo I was thinking, why don\u0026rsquo;t we explore how to apply these guidelines while daemonizing a Go program?\nWebsite Observer The program in question is a simple command-line program that can monitor any website by sending periodic HTTP requests to it. If you ever heard of Datadog\u0026rsquo;s synthetic tests or Pingdom, think of our program as their little sibling.\nThe observer program will read its configuration from flags, environment variables, or a configuration file. If the configuration is not present as a flag, it will look into the ENV vars for it and then in a configuration file (if present). If nothing is found, it will use the default value or exit with an error depending on how crucial the configuration is.\nTo do this, we will use the namsral/flag package, which is a drop-in replacement for Go\u0026rsquo;s flag package, with the addition of parsing files and environment variables. Being a drop-in replacement means that using the namsral/flag package is as simple as using the flag package from the standard library.\nFirst, observer will have a config type, which will encapsulate the configuration for the website that it will observe:\nconst defaultTick = 60 * time.Second type config struct { contentType string server string statusCode int tick time.Duration url string userAgent string } func (c *config) init(args []string) error { flags := flag.NewFlagSet(args[0], flag.ExitOnError) flags.String(flag.DefaultConfigFlagname, \u0026#34;\u0026#34;, \u0026#34;Path to config file\u0026#34;) var ( statusCode = flags.Int(\u0026#34;status\u0026#34;, 200, \u0026#34;Response HTTP status code\u0026#34;) tick = flags.Duration(\u0026#34;tick\u0026#34;, defaultTick, \u0026#34;Ticking interval\u0026#34;) server = flags.String(\u0026#34;server\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Server HTTP header value\u0026#34;) contentType = flags.String(\u0026#34;content_type\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Content-Type HTTP header value\u0026#34;) userAgent = flags.String(\u0026#34;user_agent\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;User-Agent HTTP header value\u0026#34;) url = flags.String(\u0026#34;url\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Request URL\u0026#34;) ) if err := flags.Parse(args[1:]); err != nil { return err } c.statusCode = *statusCode c.tick = *tick c.server = *server c.contentType = *contentType c.userAgent = *userAgent c.url = *url return nil } The init function will take the command line arguments as input and build a FlagSet, which represents a set of defined flags. Each of the flags is listed and parsed; then, their values are assigned to the config. Additionally, having the flag.DefaultConfigFilename as a flag as well enables our observer to load the configuration from a config.conf file. The .conf file has a key=value format, with new lines after each key-value pair.\nHere\u0026rsquo;s the main function:\nfunc main() { ctx := context.Background() ctx, cancel := context.WithCancel(ctx) c := \u0026amp;config{} defer func() { cancel() }() if err := run(ctx, c); err != nil { fmt.Fprintf(os.Stderr, \u0026#34;%s\\n\u0026#34;, err) os.Exit(1) } } Following Mat Ryer\u0026rsquo;s advice, we are going to keep main very thin while keeping the main logic of the observer in the run method. main here just sets up the main context that will propagate down to the run method, and it initializes the observer config. Then it passes all of the relevant arguments to the run method.\nHere\u0026rsquo;s the run method:\nfunc run(ctx context.Context, c *config) error { c.init(os.Args) for { select { case \u0026lt;-ctx.Done(): return nil case \u0026lt;-time.Tick(c.tick): resp, err := http.Get(c.url) if err != nil { return err } if resp.StatusCode != c.statusCode { log.Printf(\u0026#34;Status code mismatch, got: %d\\n\u0026#34;, resp.StatusCode) } if s := resp.Header.Get(\u0026#34;server\u0026#34;); s != c.server { log.Printf(\u0026#34;Server header mismatch, got: %s\\n\u0026#34;, s) } if ct := resp.Header.Get(\u0026#34;content-type\u0026#34;); ct != c.contentType { log.Printf(\u0026#34;Content-Type header mismatch, got: %s\\n\u0026#34;, ct) } if ua := resp.Header.Get(\u0026#34;user-agent\u0026#34;); ua != c.userAgent { log.Printf(\u0026#34;User-Agent header mismatch, got: %s\\n\u0026#34;, ua) } } } } First, the run method initializes the config instance c, using the init method. Then, it loops infinitely until the context ctx is done. When ctx is done, it means the observer process is terminated, so it merely returns a nil and finishes with its execution.\nAlternatively, it will execute the other case every tick. By using the time.Tick channel here we run this code by receiving a signal through the channel every c.tick period. For example, if c.tick is 30 seconds, we will receive a signal every 30 seconds, meaning the code will run every 30 seconds.\nThe code itself is simple – it sends an HTTP GET request to the URL assigned to c.url. Once the response returns, the run method compares the relevant response headers and the status code with the once provided through the configuration. If any mismatch is detected, it logs the error.\nRunning the observer is relatively simple. One way is to supply a config file through the command line:\n$ ./observer -config ./config.conf 2020/04/23 19:41:54 Status code mismatch, got: 200 Alternatively, using flags:\n$ ./observer -status=500 -tick=10s -url=https://ieftimov.com -server=Cloudflare 2020/04/23 19:43:34 Status code mismatch, got: 200 2020/04/23 19:43:34 Server header mismatch, got: cloudflare 2020/04/23 19:43:34 Content-Type header mismatch, got: text/html; charset=utf-8 We can do the same using environment variables, or a combination of all three: config file, environment variables, and flags.\nNow, how can we apply the four simple rules of daemonization?\nLogging to STDOUT While daemons don\u0026rsquo;t have much to do with web services, one of the 12 factors of modern web services are treating logs as event streams. While the 12 factors in this particular case are not applicable, the guiding principle stays: the daemon itself should not manage log streams, nor it should not concern itself with writing to or managing log files. Instead, daemons should send their log stream, unbuffered, to STDOUT.\nThe service management system will capture each daemon\u0026rsquo;s stream. The init config file is what we will use to configure logging, such as where the logs should be stored or streamed.\nSo, how can we adapt the observer to log to STDOUT?\nFirst, we will add another argument to the run function, called out of type io.Writer. Then, we will invoke the log.SetOutput function passing the out as argument to it.\nfunc run(ctx context.Context, c *config, out io.Writer) error { c.init(os.Args) log.SetOutput(out) for { select { case \u0026lt;-ctx.Done(): return nil case \u0026lt;-time.Tick(c.tick): // Identical to above, removed from brewity \t} } } By doing this, we will have to pass STDOUT from the main function, but we keep our run function more testable. Using a separate run method means we can invoke it with any instance that implements the io.Writer interface. We basically couple the run method to a behavior instead of type.\nThen, we need to update the main function to pass the additional argument to the run function when invoking it. And the io.Writer will be simple os.Stdout:\nfunc main() { ctx := context.Background() ctx, cancel := context.WithCancel(ctx) c := \u0026amp;config{} defer func() { cancel() }() if err := run(ctx, c, os.Stdout); err != nil { fmt.Fprintf(os.Stderr, \u0026#34;%s\\n\u0026#34;, err) os.Exit(1) } } If we run the program again we won\u0026rsquo;t see a difference:\n$ ./observer -status=500 -tick=10s -url=https://ieftimov.com -server=Cloudflare 2020/04/23 19:43:34 Status code mismatch, got: 200 2020/04/23 19:43:34 Server header mismatch, got: cloudflare 2020/04/23 19:43:34 Content-Type header mismatch, got: text/html; charset=utf-8 Why is that? Well, the log package logs to STDERR by default, so there is no visible change of behavior there. Still, we make the dependency on an output stream explicit to the run function, which clearly states that run needs to know where to send its logs when running.\nShut down on SIGTERM/SIGINT In Go, having errors as values is very helpful to think about what will happen to our program if an error is returned. While this makes our Go programs always have some repetitive error handling, it also gives us confidence that our program will gracefully handle any error.\nTermination signals *nix operating systems (OS) employ a system of signals, which is a mechanism of the OS to ask a process to perform a particular action. There are two general types of signals: those that cause termination of a process and those that do not.\n(Refer to the full list of the POSIX-defined signals to learn more.)\nUsing these system signals, a process that has received one can choose one of the following behaviors to take place: perform the default POSIX-defined action, ignore the signal, or catch the signal with a signal handler and perform some sort of a custom action.\nSome signals that just can\u0026rsquo;t be caught or ignored; it means that the default action has to happen. For example, SIGSTOP and SIGKILL are such signals. Once a process receives any of these two signals, we just know that it will be stopped/killed by the OS.\nBut other signals are more polite. While we cannot ignore them, they give a chance to our process to clean up and go away with grace. Most of the ones on the list are of the polite kind. In this section, we will look into the SIGTERM and SIGINT signals and how we can treat them in our Go programs.\nHandling SIGTERM \u0026amp; SIGNIT The os/signal package implements access to incoming signals with the purpose of signal handling. Through the Notify function, a Go program can accept signals thorough a channel of type os.Signal.\nIn our observer\u0026rsquo;s case, we don\u0026rsquo;t have to do any cleanup once it receives a SIGTERM/SIGINT. All we have to do is to stop further execution and shut down gracefully. So, how can we achieve that?\nFirst, we need to create a channel through which we will accept these two signals:\nsignalChan := make(chan os.Signal, 1) signal.Notify(signalChan, syscall.SIGINT, syscall.SIGTERM) Once the observer process receives a SIGINT or a SIGTERM, it will proxy it through the signalChan channel. To process the signals, we would need to create a goroutine that will receive signals through the signalChan. Once it gets a signal, it will have to cancel() the context, which would stop the further execution of the run method:\ngo func() { select { case = \u0026lt;-signalChan: log.Printf(\u0026#34;Got SIGINT/SIGTERM, exiting.\u0026#34;) cancel() os.Exit(1) case \u0026lt;-ctx.Done(): log.Printf(\u0026#34;Done.\u0026#34;) os.Exit(1) } }() So, once the cancel function is executed, in the for loop of the run method the execution will stop:\nfunc run(ctx context.Context, c *config, stdout io.Writer) error { c.init(os.Args) log.SetOutput(os.Stdout) for { select { case \u0026lt;-ctx.Done(): return nil case \u0026lt;-time.Tick(c.tick): // Same as above...  } } } The last thing we need to do in the main function is to close the signalChan channel when the programs exits:\nfunc main() { // Same as above...  defer func() { signal.Stop(signalChan) cancel() }() // Same as above... } The Stop function will stop relaying incoming signals to signalChan. When Stop returns, it is guaranteed that signalChan will receive no more signals.\nLet\u0026rsquo;s run the observer program and see the signal handling in action:\n$ ./observer -config=config.conf 2020/04/26 00:14:46 Status code mismatch, got: 200 ... 2020/04/26 00:15:46 Status code mismatch, got: 200 Now, having the PID of observer, we can send any signal using the kill command line tool:\n$ kill -SIGINT 37212 By executing the kill command, we will send a SIGINT to the observer process. This will force observer to wrap up the execution, log a line to STDOUT and exit:\n$ ./observer -config=config.conf 2020/04/26 00:29:22 Status code mismatch, got: 200 2020/04/26 00:29:22 Got SIGINT/SIGTERM, exiting. exit status 1 We can try the same exercise with SIGTERM as well:\n› kill -SIGTERM 37827 Causes observer to exit with the same behavior:\n$ ./observer -config=config.conf 2020/04/26 00:33:42 Status code mismatch, got: 200 2020/04/26 00:33:44 Got SIGINT/SIGTERM, exiting. exit status 1 Reload config on SIGHUP Now that we know how to handle signals, we need to add another signal to the mix - SIGHUP. To do that, we can just add syscall.SIGHUP to the signal.Notify call:\nsignalChan := make(chan os.Signal, 1) signal.Notify(signalChan, syscall.SIGINT, syscall.SIGTERM, syscall.SIGHUP) Now that we have SIGHUP covered, in the goroutine that handles the signals, once a SIGHUP is received, it should re-run the config.init method. By doing that, we will reload the configuration of the observer, loading any changes in the configuration:\ngo func() { select { case s := \u0026lt;-signalChan: switch s { case syscall.SIGINT, syscall.SIGTERM: log.Printf(\u0026#34;Got SIGINT/SIGTERM, exiting.\u0026#34;) cancel() os.Exit(1) case syscall.SIGHUP: log.Printf(\u0026#34;Got SIGHUP, reloading.\u0026#34;) c.init(os.Args) } case \u0026lt;-ctx.Done(): log.Printf(\u0026#34;Done.\u0026#34;) os.Exit(1) } }() The change is relatively small. By using a switch construct, detect the received signal. If it\u0026rsquo;s a SIGHUP, we invoke c.init(os.Args). Otherwise, we cancel() the context and os.Exit the program.\nWe can test this using the same trick from before:\n$ kill -SIGHUP 38761 Will cause the observer to reload:\n$ ./observer -config=config.conf 2020/04/26 01:15:40 Status code mismatch, got: 200 2020/04/26 01:15:44 Got SIGHUP, reloading. This looks nice. Let\u0026rsquo;s shut down the server now by sending a SIGTERM:\n$ kill -SIGTERM 38761 In case you\u0026rsquo;re following along, you will find out that the observer is still running; this is a bug – the goroutine that was receiving signals exited because the select construct completed once it received the SIGHUP.\nTo make the goroutine accept signals without exiting, we need to make the goroutine run infinitely – using a for loop:\ngo func() { for { select { case s := \u0026lt;-signalChan: switch s { case syscall.SIGINT, syscall.SIGTERM: log.Printf(\u0026#34;Got SIGINT/SIGTERM, exiting.\u0026#34;) cancel() os.Exit(1) case syscall.SIGHUP: log.Printf(\u0026#34;Got SIGHUP, reloading.\u0026#34;) c.init(os.Args) } case \u0026lt;-ctx.Done(): log.Printf(\u0026#34;Done.\u0026#34;) os.Exit(1) } } }() By wrapping the whole goroutine in a for loop, we will make sure that it will not exit, except when a SIGINT/SIGTERM is received, or if the context is done. By having this endless goroutine, we also can send multiple SIGHUPs to the observer, and it will process them correctly.\nLet\u0026rsquo;s send two SIGHUPs, to perform two reloads, and SIGTERM to shut down the observer:\n$ kill -SIGHUP 38960 $ kill -SIGHUP 38960 $ kill -SIGTERM 38960 And the observer output:\n$ ./observer -config=config.conf 2020/04/26 01:25:02 Status code mismatch, got: 200 2020/04/26 01:25:03 Got SIGHUP, reloading. 2020/04/26 01:25:05 Got SIGHUP, reloading. 2020/04/26 01:25:08 Got SIGINT/SIGTERM, exiting. And that\u0026rsquo;s it. The observer now knows how to log to STDOUT, gracefully exit when it receives SIGINT or SIGTERM and reloads the configuration when it receives a SIGHUP.\nProvide the necessary config file for your favorite init system to control your daemon Now, given that computer of choice is a MacBook, I will explain here how you can create a config file for launchd – macOS\u0026rsquo;s service management framework for starting, stopping and managing daemons, applications, processes, and scripts. In macOS, the system runs daemons, while the users run programs as agents. So, we will turn our observer into an agent.\nIn the past, I have written about creating and managing macOS agents, so if you would like to more about this topic, you can head read that as well. Still, let\u0026rsquo;s see a minimal launchd configuration for observer:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.ieftimov.observer\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;KeepAlive\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/usr/local/bin/observer\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;-config\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;/etc/observer.conf\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;key\u0026gt;StandardOutPath\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;/tmp/observer.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardErrorPath\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;/tmp/observer.error.log\u0026lt;/string\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; The configuration is relatively straightforward, here are all of the pieces in order:\n The Label identifies the job and has to be unique for the launchd instance. Think of it as a unique name for the given agent. RunAtLoad means launchd will start the job as soon as it loads it. KeepAlive tells launchd to keep the agent running no matter what. ProgramArguments provides command-line options to the agent command. In our case, this will create the following command: /usr/local/bin/observer -config /etc/observer.conf. StandardOutPath and StandardErrorPath are the paths to where launchd will write the respective output. In our case, we write these to the tmp directory. An alternative would be to add the log files to /var/log, but that requires granting write access of the agent to /var/log.  To make sure we can run the agent, we have to also supply the configuration file observer.conf in the /etc directory. On my machine, its contents are as follows:\nstatus=500 tick=30s url=https://ieftimov.com server=cloudflare content_type=text/html; charset=utf-8 user_agent= After placing the observer.conf file in /etc, for the agent to work, we have to place its .plist file in ~/Library/LaunchAgents, and load it with:\n$ launchctl load ~/Library/LaunchAgents/com.ieftimov.observer.plist Now, if we would tail -f the log files in /tmp we will see its outputs there:\n$ tail -f /tmp/observer.* ==\u0026gt; /tmp/observer.error.log \u0026lt;== ==\u0026gt; /tmp/observer.log \u0026lt;== 2020/05/02 11:49:03 Status code mismatch, got: 200 Voila! The agent is running and its logging output to STDOUT, while launchd is redirecting that output to a log file.\nIf we would like to run the observer on GNU/Linux, we cannot use this launchd configuration.\nIn Linux-land, systemd is widespread and popular. If you are interested in a deeper explanation of systemd units and unit files, Digital Ocean\u0026rsquo;s blog has an article on \u0026ldquo;Understanding Systemd Units and Unit Files\u0026rdquo; by Justin Ellingwood. I recommend reading it! And keep in mind, the community\u0026rsquo;s opinion on systemd is pretty divided.\nThere are a bunch of other alternatives, but my knowledge of GNU/Linux init systems is minimal. Therefore, I will stop right here and ask for your help: if you would like to contribute a Linux init system configuration to this article, drop the link to a gist/repo in the comments, and I will include it in this article.\nOf course, with proper attribution.\nYou can see the final implementation of the observer here.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/four-steps-daemonize-your-golang-programs/","summary":"If you have ever worked with Ruby, or have maybe maintained a Rails application, I am sure the name Sidekiq will sound familiar. For those unfamiliar with the project, Sidekiq is a job system for Ruby. It is a wildly popular project, and the author has turned it into a successful business.\nNone of the above would be relevant if Sidekiq\u0026rsquo;s author Mike Perham, in 2014, did not write a concise and informative post titled \u0026ldquo;Don\u0026rsquo;t Daemonize your Daemons!","title":"Four Steps to Daemonize Your Go Programs"},{"content":"Some of my newsletter subscribers have asked me a few times what is the easiest way to think about byte slices, or using Go\u0026rsquo;s syntax: []byte. Folks that have experience with low-level languages, where working with bytes is widespread, usually do not have challenges comprehending what []byte means and how to use it.\nBut, if you come from a dynamic or a high-level language background, although everything we do ends up being a bunch of bytes, higher-level languages hide such details from us. Coming from a Ruby background, I sympathize with the folks that find this challenging.\nInspired by the conversations I had with these readers, I decided to try to help out. So, without beating around the bush – let\u0026rsquo;s explore how we can build a simple TCP-based application protocol. And thoroughly understand bytes in the process.\nStanding on shoulders of giants The protocol that we will be implementing will work on top of TCP, because:\n TCP is high level enough, so we don\u0026rsquo;t have to worry about too many low-level connection details Go has excellent TCP support through the net package The interfaces that the net packages provide allow us to play with bytes (and slices of bytes) TCP provides certain guarantees when it comes to data transfer, so we are left with less to worry about Standing on the shoulders of giants is more uncomplicated than reinventing the wheel  Now, because protocol design is no small feat, we will be implementing a very tiny and toyish protocol. I am by no means a protocol designer, so what we are going to be working on here is merely an example. But, if you have any experience with protocols, please do not hesitate to drop me a comment (or a message) and let me know what I got wrong.\nEnter SLCK Let us imagine that Slack, the omnipresent collaboration and communication app, wants to turn their chat design into an open internet protocol. Being an open internet protocol would allow anyone to create a Slack-compliant server by implementing the SLCK protocol and build their version of Slack.\nIn theory, having an open protocol would allow Slack to become distributed, with people hosting their Slack servers. If people would host their SLCK servers, the servers will communicate with a cluster (or inter-server) protocol. With a cluster protocol (between servers) and a client protocol (between client and server), two SLCK servers will have the ability to communicate between themselves and with clients.\nBut, a cluster protocol is not what we will explore here, as it is significantly more challenging to implement. That\u0026rsquo;s why we will focus only on the client SLCK protocol.\nNow, to make the client SLCK protocol production-ready would be a massive effort, and it is beyond what an article can cover. But, I believe that it\u0026rsquo;s a great example through which we can learn more about working with bytes.\nWithout further ado, let\u0026rsquo;s talk about SLCK.\nSLCK design SLCK is a text-based wire protocol, meaning that the data that travels on the wire is not binary, but just ASCII text. The advantage of text-based protocols is that a client can practically open a TCP connection to a server that implements the protocol and talk to it by sending ASCII characters.\nClients can connect to and communicate with a SLCK server through a TCP socket, using a set of commands and conventions that we will define next.\nProtocol conventions SLCK follows a few simple but important conventions:\n It has TLV (type-length-value) format It has a control line \u0026amp; a content line It uses carriage return (\\r\\n) as delimiter It contains a fixed list of subjects (tags) representing actions And as already mentioned, it uses ASCII encoded text on the wire  Or, if we put all of these conventions in combination, a SLCK message would look like:\nMSG #general 11\\r\\nHello World So, why an ASCII-encoded text-based wire protocol? Well, the advantage of such protocols is that once the specification (usually called spec) of the protocol is public, anyone can write an implementation. Thus, such a protocol can be the backbone on top of which an ecosystem can be born.\nMore practically, having a simple protocol makes it easy to work with it. We do not need fancy clients to talk to a server that implements SLCK. A connection through telnet would suffice, and the messages sent to the server can be written by anyone that understands the protocol specification, just by hand.\nProtocol commands (subjects and options) SLCK has a few different commands:\n   ID Sent by Description     REG Client Register as client   JOIN Client Join a channel   LEAVE Client Leave a channel   MSG Both Send or receive a message to/from entity (channel or user)   CHNS Client List available channels   USRS Client List users   OK Server Command acknowledgement   ERR Server Error    Let\u0026rsquo;s explore each of them:\nREG When a client connects to a server, they can register as a client using the REG command. It takes an identifier as an argument, which is the client\u0026rsquo;s username.\nSyntax:\nREG \u0026lt;handle\u0026gt; where:\n handle: name of the user  JOIN When a client connects to a server, they can join a channel using the JOIN command. It takes an identifier as an argument, which is the channel ID.\nSyntax:\nJOIN \u0026lt;channel-id\u0026gt; where:\n channel-id: ID of the channel  LEAVE Once a user has joined a channel, they can leave the channel using the LEAVE command, with the channel ID as argument.\nSyntax:\nLEAVE \u0026lt;channel-id\u0026gt; where:\n channel-id: ID of the channel  Example 1: to leave the #general channel, the client can send:\nLEAVE #general MSG To send a message to a channel or a user, the client can use the MSG command, with the channel or user identifier as argument, followed with the body length and the body itself.\nSyntax:\nMSG \u0026lt;entity-id\u0026gt; \u0026lt;length\u0026gt;\\r\\n[payload] where:\n entity-id: the ID of the channel or user length: payload length payload: the message body  Example 1: send a Hello everyone! message to the #general channel:\nMSG #general 16\\r\\nHello everyone! Example 2: send a Hello! message to @jane:\nMSG @jane 4\\r\\nHey! CHNS To list all available channels, the client can send the CHNS message. The server will reply with the list of available channels.\nSyntax:\nCHNS USRS To list all users, the client can send the USRS message. The server will reply with the list of available users.\nSyntax:\nUSRS OK/ERR When the server receives a command, it can reply with OK or ERR.\nOK does not have any text after that, think of it as an HTTP 204.\nERR \u0026lt;error-message\u0026gt; is the format of the errors returned by the server to the client. No protocol errors result in the server closing the connection. That means that although an ERR has been returned, the server is still maintaining the connection with the client.\nExample 1: Protocol error due to bad username selected during registration:\nERR Username must begin with @ Example 2: Protocol error due to bad channel ID sent with JOIN:\nERR Channel ID must begin with # Implementing a server Now that we have the basics of the SLCK protocol in place, we can move on to the implementation. There are many ways to create the server, but as long as it implements the SLCK protocol correctly, the clients will not care about what happens under the hood of the server.\nIn continuation, I will explain my approach to building the SLCK TCP server, and while we are on it, we will learn lots about bytes and slices of bytes.\n(If you would like to jump ahead, the full code of the SLCK protocol server implementation can be found in this repo.)\nServer design The server design will have four different parts: a client (user), a channel (chat room), a command (from the client to the server), and a hub - the server that manages it all.\nLet\u0026rsquo;s take it from the most straightforward piece towards the most complicated.\nCommands Commands are what flows from the clients to the hub. Each received command from the user, such as REG, MSG, and the others, has to be appropriately parsed, validated, and handled.\nEach command is of type command. The type definition is as follows:\ntype command struct { id ID recipient string sender string body []byte } The four attributes of the type, including their explanation:\n id - the identification of the command, which can be one of the protocol commands. recipient - who/what is the receiver of the command. It can be a @user or a #channel. sender - the sender of the command, which is the @username of a user. body - the body of the command sent by the sender to the receiver.  The flow of commands will be: a client receives the wire-protocol message, parses it, and turns it in a command, that the client sends to the hub.\nAdditionally, the command also uses a type ID, which is an int type alias. We use ID so we can control the valid command types using a constants and an iota:\ntype ID int const ( REG ID = iota JOIN LEAVE MSG CHNS USRS ) Although the clients have to work with the raw strings that they receive from the network, internally in the server, we map the wire commands to their constant counterparts. This way, we establish strict control of all the command types, enforced by Go\u0026rsquo;s compiler. Using this approach, we assure that the id will always be a valid command type.\nChannels Channels in the SLCK protocol lingo are just chat rooms. It\u0026rsquo;s worth mentioning they have nothing in common with Go channels, except the name.\nA channel is just a type with two attributes:\ntype channel struct { name string clients map[*client]bool } The name of the channel is just a string that contains the unique name of the channel. The clients map is a set of *clients that are part of the channel at a given time. Having the list of clients available allows us to easily broadcast messages to all clients in the channel, such as:\nfunc (c *channel) broadcast(s string, m []byte) { msg := append([]byte(s), \u0026#34;: \u0026#34;...) msg = append(msg, m...) msg = append(msg, \u0026#39;\\n\u0026#39;) for cl := range c.clients { cl.conn.Write(msg) } } Which brings us to the client itself.\nClient A client is a wrapper around the TCP connection. It encapsulates all the functionality around accepting messages from the TCP connection, parsing the messages, validating their structure and content, and sending them for further processing and handling to the hub.\nLet\u0026rsquo;s look closer into the client type:\ntype client struct { conn net.Conn outbound chan\u0026lt;- command register chan\u0026lt;- *client deregister chan\u0026lt;- *client username string } The four attributes of the client type, in order:\n conn - the TCP connection itself (of type net.Conn) outbound - a send-only channel of type command. This channel will be the connection between the client and the hub, through which the client will send commands to the hub register - a send-only channel of type *client through which the client will let the hub know that it wants to register itself with the hub (a.k.a. the chat server) deregister - a send-only channel of type *client through which the client will let the hub know that the user has closed the socket, so the hub should deregister the client (by removing it from the clients map and from all channels) username - the username of the user (of type string) that is sitting behind the TCP connection  If this is a bit confusing, worry not. It will get more evident once you see the whole thing in action.\nNow, let\u0026rsquo;s move on to the client\u0026rsquo;s methods. Once we intantiate a client, it can listen for incoming messages over the TCP connection. To do that, the client has a method called read:\nfunc (c *client) read() error { for { msg, err := bufio.NewReader(c.conn).ReadBytes(\u0026#39;\\n\u0026#39;) if err == io.EOF { // Connection closed, deregister client \tc.deregister \u0026lt;- c return nil } if err != nil { return err } c.handle(msg) } } read loops endlessly using a for loop, and accepts incoming messages from the conn attribute (the TCP connection). Once the message (msg) is received, it will pass it on to the handle method, which will process it.\nIn case the err returned is io.EOF, meaning the user can closed the connection, the client will send notify the hub through the deregister channel. The hub will remove the deregistered client from the clients map and from all of the channels that the client participated in.\nHandling bytes in handle using the bytes package Because of the protocol definition, we know the structure of the commands that the chat server might receive from the user. That\u0026rsquo;s what the client\u0026rsquo;s handle method does - it get the raw messages from the socket and parses the bytes to make meaning out of them.\nfunc (c *client) handle(message []byte) { cmd := bytes.ToUpper(bytes.TrimSpace(bytes.Split(message, []byte(\u0026#34; \u0026#34;))[0])) args := bytes.TrimSpace(bytes.TrimPrefix(message, cmd)) switch string(cmd) { case \u0026#34;REG\u0026#34;: if err := c.reg(args); err != nil { c.err(err) } case \u0026#34;JOIN\u0026#34;: if err := c.join(args); err != nil { c.err(err) } case \u0026#34;LEAVE\u0026#34;: if err := c.leave(args); err != nil { c.err(err) } case \u0026#34;MSG\u0026#34;: if err := c.msg(args); err != nil { c.err(err) } case \u0026#34;CHNS\u0026#34;: c.chns() case \u0026#34;USRS\u0026#34;: c.usrs() default: c.err(fmt.Errorf(\u0026#34;Unknown command %s\u0026#34;, cmd)) } } Handling messages is where we get to see the slice of bytes ([]byte) type in action. So, what happens here? Let\u0026rsquo;s break it down.\nGiven that our SLCK protocol is a text-based wire protocol, the bytes that are flowing on the TCP connection are, in fact, plain ASCII text. Each byte (or octet, because a byte is eight bits) in the decimal number system has a value between 0 and 255 (2 to the power of 8). That means that each of the octets can contain any of the characters in the extended ASCII encoding. (Refer to this ASCII table to see all of the available characters.)\nHaving a text-based protocol allows us to easily convert each of the bytes that arrive through the TCP connection into a meaningful text. That\u0026rsquo;s why each byte in the []byte slice represents one character. Because each byte in the slice []byte is a character, converting a []byte in a string is as easy as: s := string(slice).\nAnd Go is good at handling bytes. For example, it has a bytes package which lets us work with []byte, instead of converting them into strings every time we want to work with bytes.\nGiven that all SLCK commands begin with a single word separated with space after it, we can simply take the first word from the []byte, upcase it and compare it with the valid keywords of the protocol. \u0026ldquo;But, how are we supposed to take a word from a slice of bytes?\u0026rdquo; you might ask. Since bytes are not words, we have to resort to either compare them byte-by-byte or use the built-in bytes package. To keep things simple, we will use the bytes package. (You can check this snippet to compare the two approaches.)\nIn the first line of the handle, method we take the first part of the received message, and we upcase it. Then, on the second line, we remove the first part from the rest of the message. The split allows us to have the command (cmd) and the rest of the command arguments (args) in separate variables.\ncmd := bytes.ToUpper(bytes.TrimSpace(bytes.Split(message, []byte(\u0026#34; \u0026#34;))[0])) args := bytes.TrimSpace(bytes.TrimPrefix(message, cmd)) After that, in the switch construct, we handle all of the different commands. For example, handling the REG command is done using the reg, and the err methods:\nfunc (c *client) reg(args []byte) error { u := bytes.TrimSpace(args) if u[0] != \u0026#39;@\u0026#39; { return fmt.Errorf(\u0026#34;Username must begin with @\u0026#34;) } if len(u) == 0 { return fmt.Errorf(\u0026#34;Username cannot be blank\u0026#34;) } c.username = string(u) c.register \u0026lt;- c return nil } The reg method takes the args slice, and it removes any space bytes (using bytes.TrimSpace). Given that the second argument of the REG command is the @username of the user, it checks if the passed username begins with @ and if it\u0026rsquo;s blank. Once it does that, it converts the username to a string, and it assigns it to the client (c) itself. From then on, the client has an assigned username.\nAs a second step, it sends the client itself through the register channel. This channel is read by the hub (the chat server), which will do more validation of the username before it successfully registers the client.\nfunc (c *client) err(e error) { c.conn.Write([]byte(\u0026#34;ERR \u0026#34; + e.Error() + \u0026#34;\\n\u0026#34;)) } The err func simply takes an error and sends its contents back to the user, using the underlying TCP connection of the client.\nWe will come back to the other commands and methods once we have thoroughly explored the chat server.\nThe hub The hub is the central entity that the clients connect and register with. The hub also manages the available channels (chat rooms), broadcasting messages to said channels, and relaying messages (private/direct messages) between clients.\nAll of the above functionality means that the hub is the central place of all communications, hence the name.\nFirst, let\u0026rsquo;s explore the hub type with all of its attributes:\ntype hub struct { channels map[string]*channel clients map[string]*client commands chan command deregistrations chan *client registrations chan *client } The attributes, and their explanations, in order:\n channels - a map of the channels (chat rooms), with the name of the channel as the key and the *channel as value clients - a map of the clients (connected users), with the username as the key and the *client as value commands - a channel of command that are flowing from the clients to the hub, that the hub will validate and execute deregistrations - a channel of *client through which a client deregisters itself, through which the hub will be informed that the user has closed the connection and it will clean up any references to that client registrations - a channel of *client through which new clients register themselves to the hub, through which the hub will accept the new client, validate their username and add them to the clients map  So, how does the hub function? It all begins with the run method:\nfunc (h *hub) run() { for { select { case client := \u0026lt;-h.registrations: h.register(client) case client := \u0026lt;-h.deregistrations: h.unregister(client) case cmd := \u0026lt;-h.commands: switch cmd.id { case JOIN: h.joinChannel(cmd.sender, cmd.recipient) case LEAVE: h.leaveChannel(cmd.sender, cmd.recipient) case MSG: h.message(cmd.sender, cmd.recipient, cmd.body) case USRS: h.listUsers(cmd.sender) case CHNS: h.listChannels(cmd.sender) default: // Freak out? \t} } } } When we establish a new hub instance (which we will see later), we execute the run method in a goroutine. The goroutine will run the for loop indefinitely, processing the registrations, deregistrations, and the commands channels. Messages arriving through the registrations and deregistrations channels will be handled differently from the messages that will come from the commands channel.\nrun will receive messages through the registrations channel, and it will send them to the register method for processing:\nfunc (h *hub) register(c *client) { if _, exists := h.clients[c.username]; exists { c.username = \u0026#34;\u0026#34; c.conn.Write([]byte(\u0026#34;ERR username taken\\n\u0026#34;)) } else { h.clients[c.username] = c c.conn.Write([]byte(\u0026#34;OK\\n\u0026#34;)) } } The register method will check if the hub already has a user with the given username, and it will react accordingly. If the username is taken, it will remove the username from the client and respond with an error. If the username is not taken, then it will add the client to the clients map, with the username as a key and the client reference as a value.\nrun will receive messages through the deregistrations channel, and it will send them to the deregister method for processing:\nfunc (h *hub) deregister(c *client) { if _, exists := h.clients[c.username]; exists { delete(h.clients, c.username) for _, channel := range h.channels { delete(channel.clients, c) } } } The deregister method will check if the hub already has a user with the given username. If it finds the user, it will remove it from the hub\u0026rsquo;s clients map. Also, it will go through the map of channels and it will try to remove it from each of the channel\u0026rsquo;s clients map.\nWhen it comes to handling commands, things are more different. Each of the commands, as we already established, has an id attribute. For each of the commands that we receive, we do a switch on the id attribute, which will invoke a different method. For example, to join a channel, the id must be of value JOIN, which will invoke the joinChannel function, with the command\u0026rsquo;s sender and recipient attributes.\nThe joinChannel function receives the username (u) and the channel (c) as arguments. Then, if it finds the channel, it will add the client to the channel\u0026rsquo;s clients map. Otherwise, it will first create the channel, using the newChannel constructor, and then add the client as the first client to the channel:\nfunc (h *hub) joinChannel(u string, c string) { if client, ok := h.clients[u]; ok { if channel, ok := h.channels[c]; ok { // Channel exists, join \tchannel.clients[client] = true } else { // Channel doesn\u0026#39;t exists, create and join \th.channels[c] = newChannel(c) h.channels[c].clients[client] = true } } } Now, let\u0026rsquo;s zoom out and see how a client wraps a TCP connection. Then, we will see how bytes are flowing from the user, through the client, to the hub ending up with the receiver (another channel or user).\nSending messages The core functionality to a chat server and the purpose of our SLCK protocol is sending and receiving messages. Let\u0026rsquo;s follow the flow of the bytes and see how we can implement sending messages between clients.\nThe structure of the MSG command is as follows:\nMSG \u0026lt;entity-id\u0026gt; \u0026lt;length\u0026gt;\\r\\n[payload] For example, to send a Hello! message to the #general channel:\nMSG #general 6\\r\\nHello! Or, to send a Hey! message to @jane:\nMSG @jane 4\\r\\nHey! Once the user sends the MSG command, the client\u0026rsquo;s handle method accepts it. Then, in handle we extract the message and the command, and we invoke the msg method of the client:\nfunc (c *client) handle(message []byte) { cmd := bytes.ToUpper(bytes.TrimSpace(bytes.Split(message, []byte(\u0026#34; \u0026#34;))[0])) args := bytes.TrimSpace(bytes.TrimPrefix(message, cmd)) switch string(cmd) { // Some other stuff here... \tcase \u0026#34;MSG\u0026#34;: if err := c.msg(args); err != nil { c.err(err) } // Some other stuff here... \tdefault: c.err(fmt.Errorf(\u0026#34;Unknown command %s\u0026#34;, cmd)) } } The args are passed to the msg method, which does some heavy lifting.\nfunc (c *client) msg(args []byte) error { args = bytes.TrimSpace(args) if args[0] != \u0026#39;#\u0026#39; \u0026amp;\u0026amp; args[0] != \u0026#39;@\u0026#39; { return fmt.Errorf(\u0026#34;recipient must be a channel (\u0026#39;#name\u0026#39;) or user (\u0026#39;@user\u0026#39;)\u0026#34;) } recipient := bytes.Split(args, []byte(\u0026#34; \u0026#34;))[0] if len(recipient) == 0 { return fmt.Errorf(\u0026#34;recipient must have a name\u0026#34;) } // More stuff here... } The msg method\u0026rsquo;s first step is to check if the first argument of the message begins with a @ or # – a user or a channel name. If that\u0026rsquo;s correct, we extract the recipient, which can be the username or the channel name.\nfunc (c *client) msg(args []byte) error { // The stuff from above here...  args = bytes.TrimSpace(bytes.TrimPrefix(args, recipient)) l := bytes.Split(args, DELIMITER)[0] length, err := strconv.Atoi(string(l)) if err != nil { return fmt.Errorf(\u0026#34;body length must be present\u0026#34;) } if length == 0 { return fmt.Errorf(\u0026#34;body length must be at least 1\u0026#34;) } padding := len(l) + len(DELIMITER) // Size of the body length + the delimiter \tbody := args[padding : padding+length] c.outbound \u0026lt;- command{ recipient: string(recipient[1:]), sender: c.username, body: body, id: \u0026#34;MSG\u0026#34;, } return nil } We extract the next argument after, which, according to the protocol specification, is the length of the body in bytes. Having the size of the body (the length of the bytes) as part of the command that is sent by the client allows the server to slice off the bytes it needs from the body efficiently.\nLet\u0026rsquo;s see an example:\nMSG #general 39\\r\\nHey folks, hope you are all doing well! In the handle method, we sliced off MSG, and we send the rest of the bytes to the msg method. In msg, we checked if the next argument is a channel or a username – which is correct. Then, we pick up the 39, and we store them in the l variable.\nHaving l being 39 is not enough – the slice of bytes that represent the ASCII 39 is [51 57]. The 51 and 57 bytes just mean that the two octets representing 3 and 9 in ASCII, have byte representation as 51 and 57. To make our Go code understand [51 57] like 39, we have to convert them into a string, so they become \u0026quot;39\u0026quot; and then use the strconv package to convert the string to an int:\nl := bytes.Split(args, DELIMITER)[0] length, err := strconv.Atoi(string(l)) Once we have the length of the body, we validate that it will be at least one byte. Next, we take the remaining bytes from the args, and we slice off the length amount of bytes from the args:\npadding := len(l) + len(DELIMITER) // Size of the body length + the delimiter body := args[padding : padding+length] In context of our example above:\nMSG #general 39\\r\\nHey folks, hope you are all doing well! we take the length (2) of the 39 plus the length of the \\r\\n delimiter and then take the body out of the args slice of bytes by using the \u0026ldquo;slice\u0026rdquo; operator (:). The slicing operation results in slicing all of the bytes between \\n to the end of the body, meaning the body becomes:\nHey folks, hope you are all doing well! If the length were less then 39, then the body would end up being shorter, because the user has sent the wrong body size to the server. Conversely, if we tried to slice off more than the size of the body, then the goroutine serving the hub would crash, rendering our server useless.\nGiven that body now contains the message itself, the last step of the msg method is to send the new command it received through the outbound channel to the hub:\nc.outbound \u0026lt;- command{ recipient: string(recipient[1:]), sender: c.username, body: body, id: MSG, } The command has a recipient (channel or user ID), the sender, which is the username of the message author, the body containing the body of the message, and the id that\u0026rsquo;s the identifier of the command - MSG in this case.\nThen, the hub which infinitely loops and reads from the commands channel (which is the same channel as the outbound channel of the client), will pick up the message from the client and process it in the message method:\nfunc (h *hub) message(u string, r string, m []byte) { if sender, ok := h.clients[u]; ok { switch r[0] { case \u0026#39;#\u0026#39;: if channel, ok := h.channels[r]; ok { if _, ok := channel.clients[sender]; ok { channel.broadcast(sender.username, m) } } case \u0026#39;@\u0026#39;: if user, ok := h.clients[r]; ok { user.conn.Write(append(m, \u0026#39;\\n\u0026#39;)) } } } } The message method will check if the sender username (u) is present in the list of active clients (h.clients). If the client is active, then it will check if the first byte of the message (m) is a # or a @. Based on the result of the switch, either it will broadcast the message (m) to the channel, or it will find the recipient (r) from the h.clients list and send the message through the recipient\u0026rsquo;s TCP connection.\nLet\u0026rsquo;s see this in action. I will start the server (using go run .) and open two telnet sessions with the server:\n$ telnet 127.0.0.1 8081 Trying 127.0.0.1... Connected to localhost. Escape character is \u0026#39;^]\u0026#39;. Given that SCLK is a ASCII wire protocol, it means we can just send some commands to the server right away. Let\u0026rsquo;s first register both clients. The first one will be @jane:\nREG @jane OK And the second client will be @john:\nREG @john OK In both cases the registration with the server went well, so the server replied with OK. Now, let\u0026rsquo;s make both of the clients join the #general channel. If any of the users listed the channels they would get an error:\nCHNS ERR no channels found Great, let\u0026rsquo;s make them both join #general, so the channel would be created. First @john:\nJOIN #general OK @jane righ after:\nCHNS #general JOIN #general OK Now that both are in the channel, we can also send a message from @jane to #general, and it should pop up on @john\u0026rsquo;s screen too.\nSending the message:\nMSG #general 5\\r\\nHello And in @john\u0026rsquo;s screen we can see:\njane: Hello Voilá! @john received the message. Let\u0026rsquo;s say @john would like to send @jane a direct message. He sends:\nMSG @jane 3\\r\\nHey And on @jane\u0026rsquo;s screen she will see:\n@john: Hey Tying it all together Now that we went through the client, hub, channel, and command, we need to see the last piece of the puzzle - the main function that ties it all together.\nIn the main func, we will initialize a TCP listener, through which we can accept a new TCP connection. Then, we will establish a new hub and invoke run in a separate goroutine.\nOnce the hub is running, we will infinitely loop using a for. Within the for loop, we will accept new TCP connections, wrap them in a new client and spin them off in a new goroutine.\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; ) func main() { ln, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8081\u0026#34;) if err != nil { log.Printf(\u0026#34;%v\u0026#34;, err) } hub := newHub() go hub.run() for { conn, err := ln.Accept() if err != nil { log.Printf(\u0026#34;%v\u0026#34;, err) } c := newClient( conn, hub.commands, hub.registrations, hub.deregistrations, ) go c.read() } } As a refresher, within the read function of the client, we also infinitely loop using a for and accept new incoming TCP messages:\nfunc (c *client) read() error { for { msg, err := bufio.NewReader(c.conn).ReadBytes(\u0026#39;\\n\u0026#39;) if err == io.EOF { // Connection closed, deregister client \tc.deregister \u0026lt;- c return nil } if err != nil { return err } c.handle(msg) } return nil } Having the client\u0026rsquo;s read method being run a separate goroutine allows us to spin off as many goroutines as we have connections. That leaves our main thread to accept new connections and just spin the off into goroutines. Once the goroutine is running, it will take care of itself until it crashes or the client exits.\nThe pitfall of this approach is that we have a single hub instance, which means that there\u0026rsquo;s only one goroutine that is accepting messages from what can be thousands of clients. While having a single hub instance simplifies the design, it also introduces a single point of failure. If the hub.run goroutine crashes/exits for whatever reason, the server will be rendered useless, although all of the client connections will be working fine.\nThe full code of the SLCK protocol server implementation can be found in this repo.\nNotable shortcuts Before we wrap up here, I would like to highlight a few of the shortcuts we took while building this server implementation. Cutting these corners was with a purpose - not making this long article even longer.\nFirst, we are missing resource locking when creating the channels or when a user joins/leaves a channel. If multiple people would join the same channel at the same time, it is possible to get a concurrent writes issue.\nSecond, our server does not have a graceful shutdown. A production-ready implementation would gracefully shut down all of the connections, informing the clients about the shutdown. Then, it would potentially save some state on disk before shutting down.\nAnother shortcut we took was validation of the body size in the msg method. When we are performing the slicing of the message body, we do not take into consideration if there are enough bytes in the message. If a client sends a body size larger then the body itself, we might slice off more bytes than available, which would result in a panic and a slice out of bounds error.\nIf you would like to play more with our chat server, I recommend starting with adding each of these missing functionalities to it. And drop me the link to the repo in the comments, so I can see how you pulled it off.\n Changelog:\n 2020-04-04 10:10UTC - Fixed the client type definition, which was missing the deregister channel, as pointed out by Rene C. over email.  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/understanding-bytes-golang-build-tcp-protocol/","summary":"Some of my newsletter subscribers have asked me a few times what is the easiest way to think about byte slices, or using Go\u0026rsquo;s syntax: []byte. Folks that have experience with low-level languages, where working with bytes is widespread, usually do not have challenges comprehending what []byte means and how to use it.\nBut, if you come from a dynamic or a high-level language background, although everything we do ends up being a bunch of bytes, higher-level languages hide such details from us.","title":"Understanding bytes in Go by building a TCP protocol"},{"content":"WebSockets offer duplex communication from a non-trusted source to a server that we own across a TCP socket connection. This means that, instead of continually polling the web server for updates and having to perform the whole TCP dance with each request, we can maintain a single TCP socket connection and then send and listen to messages on said connection.\nIn Go\u0026rsquo;s ecosystem there are few different implementations of the WebSocket protocol. Some libraries are pure implementation of the protocol. Others though, have chosen to build on top of the WebSocket protocol to create better abstractions for their particular use-case.\nHere\u0026rsquo;s a non-exhaustive list of Go WebSocket protocol implementations:\n x/net/websocket (from Go sub-repository packages) gorilla/websocket nhooyr/websocket gobwas/ws sacOO7/gowebsocket  In this article we will use the excellent gorilla/websocket implementation of the WebSocket protocol, from the Gorilla Web Toolkit project. You will notice that testing WebSocket is not much different from testing HTTP servers. Still, there are aspects of WebSockets that we have to take into account while testing.\nAuctions One of the businesses whose backbone is real-time communication are online auction houses. During an auction, seconds make the difference between winning or losing a collectible item that you have been wanting for so long.\nLet\u0026rsquo;s use a simple auction application powered by gorilla/websocket as an example for this article.\nFirst, we will define two very simple entities Bid and Auction that we will use in our WebSocket handlers. The Auction will receive a Bid method that we will use to place a new bid on the Auction.\nEntities Let\u0026rsquo;s look at the Auction and Bid types, in all of their glory:\ntype Bid struct { UserID int `json:\u0026#34;user_id\u0026#34;` Amount float64 `json:\u0026#34;amount\u0026#34;` } type Auction struct { ItemID int `json:\u0026#34;item_id\u0026#34;` EndTime int64 `json:\u0026#34;end_time\u0026#34;` Bids []*Bid } func NewAuction(d time.Duration, itemID int, b []*Bid) Auction { return Auction{ ItemID: itemID, EndTime: time.Now().Add(d).Unix(), Bids: b, } } Both of the types are fairly simple, encapsulating very little data. The NewAuction constructor function builds an auction with a duration, itemID and a slice of *Bids.\nBidding We will place a bid on an auction through the Bid method:\nfunc (a *Auction) Bid(amount float64, userID int) (*Bid, error) { if len(a.Bids) \u0026gt; 0 { largestBid := a.Bids[len(a.Bids)-1] if largestBid.Amount \u0026gt;= amount { return nil, fmt.Errorf(\u0026#34;amount must be larger than %.2f\u0026#34;, largestBid.Amount) } } if a.EndTime \u0026lt; time.Now().Unix() { return nil, fmt.Errorf(\u0026#34;auction already closed\u0026#34;) } bid := Bid{ Amount: amount, UserID: userID, } // Mutex lock \ta.Bids = append(a.Bids, \u0026amp;bid) // Mutex unlock  return \u0026amp;bid, nil } The Auction\u0026rsquo;s Bid method is where the bidding magic happens. It takes an amount and a userID as arguments and adds a Bid to the Auction. Also, it checks if the Auction has already closed and that the new bid amount is larger than the amount of the largest bid. If any of these conditions are not true, it will return an appropriate error to the caller.\nHaving the types and the Bid method out of the way, let\u0026rsquo;s dive into the WebSockets mechanics.\nHandling WebSockets Imagine a web frontend that can place bids on an auction in real time. With every JSON message it sends over WebSockets it will supply the identifier of the user placing the bid (UserID) and the amount (Amount) of the bid. Once the server accepts the message, it will place the bid and reply with a meaningful answer to the client.\nOn the server side, this communication will be done by a net/http Handler. It will handle all of the WebSocket intricacies, with a few notable steps:\n Upgrade the incoming HTTP connection to a WebSocket one Accept incoming messages from a client Decode bid from the inbound message Place the bid Send an outbound message with the reply to the client  Let\u0026rsquo;s write such a handler.\nFirst, let\u0026rsquo;s define the inbound and outbound message types:\ntype inbound struct { UserID int `json:\u0026#34;user_id\u0026#34;` Amount float64 `json:\u0026#34;amount\u0026#34;` } type outbound struct { Body string `json:\u0026#34;body\u0026#34;` } Both of them represent the in/outbound messages respectively, which will be the data flowing between the client and the server. The inbound message will represent a bid, while the outbound type represents a simple message with some text in its Body.\nNext, let\u0026rsquo;s define the bidsHandler, including its ServeHTTP method containing the HTTP connection upgrade:\nvar upgrader = websocket.Upgrader{} type bidsHandler struct { auction *Auction } func (bh bidsHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { upgrader.CheckOrigin = func(r *http.Request) bool { return true } ws, err := upgrader.Upgrade(w, r, nil) if err != nil { log.Println(\u0026#34;upgrade:\u0026#34;, err) return } defer ws.Close() // More to come... } First, we define a websocket.Upgrader, which takes the http.ResponseWriter and the *http.Request from the handler and upgrades the connection. Because this is just an example application, the upgrader.CheckOrigin method will only return a true bool, without checking the origin of the incoming request.\nOnce the upgrader finishes with the connection upgrade, it returns a *websocket.Conn object, stored in the ws variable. The *websocket.Conn will receive all of the incoming messages, where our handler will be reading from. Also, the handler will be writing messages to the *websocket.Conn, which will send an outbound message to the client.\nLet\u0026rsquo;s add the message loop next:\nfunc (bh bidsHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { // Code from above...  for { _, m, err := ws.ReadMessage() if err != nil { if websocket.IsUnexpectedCloseError(err, websocket.CloseGoingAway, websocket.CloseAbnormalClosure) { log.Printf(\u0026#34;error: %v\u0026#34;, err) } return } var in inbound err = json.Unmarshal(m, \u0026amp;in) if err != nil { handleError(ws, err) continue } bid, err := bh.auction.Bid(in.Amount, in.UserID) if err != nil { handleError(ws, err) continue } out, err := json.Marshal(outbound{Body: fmt.Sprintf(\u0026#34;Bid placed: %.2f\u0026#34;, bid.Amount)}) if err != nil { handleError(ws, err) continue } err = ws.WriteMessage(websocket.BinaryMessage, out) if err != nil { handleError(ws, err) continue } } } This for loop does a few things. First, it reads a new WebSocket message using ws.ReadMessage(), which returns the type of the message (binary or text), the message itself (m) and a potential error (err). Then, it checks the error if the client has closed the connection unexpectedly.\nOnce the error handling is completed and the message is retrieved, we decode it using json.Unmarshal into the in inbound message. Once in is available, we invoke bh.auction.Bid which places a bid on the auction, using the amount of the bid (in.Amount) and the ID of the bidder (in.UserID) as arguments. The Bid method returns a bid (bid) and an error (err).\nAfter the bid is placed, we use json.Marshal to convert an outbound message with the bid confirmation message encapsulated to slice of bytes ([]byte). Then we send the bytes to the client using the ws.WriteMessage method, which concludes the request-response server loop.\nWe can ignore the client side for now. Let\u0026rsquo;s now see how we can test this WebSockets handler code.\nTesting WebSockets handlers Although writing WebSocket handlers is more involved relative to ordinary HTTP handlers, testing them is simple. In fact, testing WebSockets handlers is as simple as testing HTTP handlers. This is because WebSockets are built on HTTP, so testing WebSockets is done using the same tools that testing HTTP servers is done with.\nWe will begin by adding the test setup:\nfunc TestBidsHandler(t *testing.T) { tcs := []struct { name string bids []*Bid duration time.Duration message inbound reply outbound }{ { name: \u0026#34;with good bid\u0026#34;, bids: []*Bid{}, duration: time.Hour * 1, message: inbound{UserID: 1, Amount: 10}, reply: outbound{Body: \u0026#34;Bid placed: 10.00\u0026#34;}, }, { name: \u0026#34;with bad bid\u0026#34;, bids: []*Bid{ \u0026amp;Bid{ UserID: 1, Amount: 20, }, }, duration: time.Hour * 1, message: inbound{UserID: 1, Amount: 10}, reply: outbound{Body: \u0026#34;amount must be larger than 20.00\u0026#34;}, }, { name: \u0026#34;good bid on expired auction\u0026#34;, bids: []*Bid{ \u0026amp;Bid{ UserID: 1, Amount: 20, }, }, duration: time.Hour * -1, message: inbound{UserID: 1, Amount: 30}, reply: outbound{Body: \u0026#34;auction already closed\u0026#34;}, }, } for _, tt := range tcs { t.Run(tt.name, func(t *testing.T) { a := NewAuction(tt.duration, 1, tt.bids) h := bidsHandler{\u0026amp;a} // To be added... \t}) } } First, we begin by defining the testcase type. It has a name, which is the human-readable name of the test case. Also, each testcase has a bids slice and a duration which will be used to create a test Auction with. The testcase also has an inbound message and an outbound reply - which is what the test case will send to and expect in return from the handler.\nAfter, in the TestBidsHandler we add three different test cases – one where the client wants to place a bad bid, that is lower than the largest bid, another test case where the client adds a good bid and a third one where the client bids on an expired auction.\nIn the for loop, for each of the test cases, we create a subtest which uses the NewAuction constructor to create a new test auction. We also create a bidsHandler that takes the newly created Auction as an attribute.\nLet\u0026rsquo;s finish off the subtest function: func TestBidsHandler(t *testing.T) { // Test cases and other setup from above...  for _, tt := range tcs { t.Run(tt.name, func(t *testing.T) { a := NewAuction(tt.duration, 1, tt.bids) h := bidsHandler{\u0026amp;a} s, ws := newWSServer(t, h) defer s.Close() defer ws.Close() sendMessage(t, ws, tt.message) reply := receiveWSMessage(t, ws) if reply != tt.reply { t.Fatalf(\u0026#34;Expected \u0026#39;%+v\u0026#39;, got \u0026#39;%+v\u0026#39;\u0026#34;, tt.reply, reply) } }) } }\nWe added few new functions to the subtest function body. The newWSServer will create a test server and upgrade it to a WebSocket connection, returning both the server and the WebSocket connections. Then, the sendMessage function will send the message from the test case to the test server throught the WebSocket connection. After that, through the receiveWSMessage we will retrieve the reply from the server and assert for its correctness by comparing it to the reply of the test case.\nSo, what do each of these small functions do? Let\u0026rsquo;s break them down one by one.\nfunc newWSServer(t *testing.T, h http.Handler) (*httptest.Server, *websocket.Conn) { t.Helper() s := httptest.NewServer(h) wsURL := httpToWs(t, s.URL) ws, _, err := websocket.DefaultDialer.Dial(wsURL, nil) if err != nil { t.Fatal(err) } return s, ws } The newWSServer function will use the httptest.NewServer function to mount the handler on a test HTTP server. Once that is done, it will convert the server\u0026rsquo;s URL to a WebSocket URL through the httpToWS function. (It simply replaces the http protocol to a ws, or https to wss, protocol in the URL.`)\nTo establish a WebSocket connection, we use the websocket.DefaultDialer which is a dialer with all fields set to the default values. We invoke the Dial method on the dialer, with the WebSocket server URL (wsURL) which returns the WebSocket connection.\nfunc sendMessage(t *testing.T, ws *websocket.Conn, msg inbound) { t.Helper() m, err := json.Marshal(msg) if err != nil { t.Fatal(err) } if err := ws.WriteMessage(websocket.BinaryMessage, m); err != nil { t.Fatalf(\u0026#34;%v\u0026#34;, err) } } The sendMessage function takes an inbound message as argument with the WebSocket connection (ws). It marshals the message into a JSON and it sends it over the WebSocket connection as a binary message.\nfunc receiveWSMessage(t *testing.T, ws *websocket.Conn) outbound { t.Helper() _, m, err := ws.ReadMessage() if err != nil { t.Fatalf(\u0026#34;%v\u0026#34;, err) } var reply outbound err = json.Unmarshal(m, \u0026amp;reply) if err != nil { t.Fatal(err) } return reply } receiveWSMessage takes the WebSocket connection (ws) as argument and it fetches a message using ws.ReadMessage(). Once the message is successfully retrieved, it unmarshals it into a outbound message using json.Unmarshal. As a last step, receiveWSMessage returns the outbound message to the test, so the test can continue with its assertions.\nIf we would run the tests, we will see them passing:\n$ go test ./... -v === RUN TestBidsHandler === RUN TestBidsHandler/with_good_bid === RUN TestBidsHandler/with_bad_bid === RUN TestBidsHandler/good_bid_on_expired_auction --- PASS: TestBidsHandler (0.00s) --- PASS: TestBidsHandler/with_good_bid (0.00s) --- PASS: TestBidsHandler/with_bad_bid (0.00s) --- PASS: TestBidsHandler/good_bid_on_expired_auction (0.00s) PASS ok github.com/fteem/go-playground/testing-in-go-web-sockets\t0.013s You can see the example code on Github.\nAlso, to see another approach at testing WebSockets in Go, you can head over to the WebSockets chapter from the book \u0026ldquo;Learn Go with tests\u0026rdquo;.\nMore WebSockets reading If you would like to learn more about the details of the WebSocket protocol, I recommend reading RFC 6455 which defines the protocol itself. In addition, you can read more in follow-up RFCs regarding the WebSocket protocol:\n Clarifying Registry Procedures for the WebSocket Subprotocol Name Registry Well-Known URIs for the WebSocket Protocol Bootstrapping WebSockets with HTTP/2  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-websockets/","summary":"WebSockets offer duplex communication from a non-trusted source to a server that we own across a TCP socket connection. This means that, instead of continually polling the web server for updates and having to perform the whole TCP dance with each request, we can maintain a single TCP socket connection and then send and listen to messages on said connection.\nIn Go\u0026rsquo;s ecosystem there are few different implementations of the WebSocket protocol.","title":"Testing in Go: WebSockets"},{"content":"Go\u0026rsquo;s a great hammer for a lot of nails, one of the areas where I find it fitting is building HTTP servers. The net/http package of Go\u0026rsquo;s standard library makes it easy to attach HTTP handlers to any Go program. What I find delightful is that Go\u0026rsquo;s standard library, also has packages that make testing HTTP servers as easy as building them.\nNowadays, it\u0026rsquo;s widely accepted that test coverage is important and useful. Having the quick feedback loop when changing your code is valuable, hence we invest time in testing our code. When combined with methodologies like continious integration and continious delivery, a good test suite becomes an invaluable part of the software project.\nKnowing the value of a good test suite, what approach should we - developers using Go to build HTTP servers - take to testing our HTTP servers?\nHere\u0026rsquo;s everything you need to know to test your Go HTTP servers well.\nOrdering some pizzas As with any other article in this series on testing in Go, let\u0026rsquo;s create an example implementation that we can use as a test subject.\nHere\u0026rsquo;s a small implementation of a pizza restaurant API with three endpoints:\n List all pizzas on the menu: GET /pizzas Make a simple pizza order: POST /orders List all orders in the system: GET /orders  Here\u0026rsquo;s the code:\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) type Pizza struct { ID int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Price int `json:\u0026#34;price\u0026#34;` } type Pizzas []Pizza func (ps Pizzas) FindByID(ID int) (Pizza, error) { for _, pizza := range ps { if pizza.ID == ID { return pizza, nil } } return Pizza{}, fmt.Errorf(\u0026#34;Couldn\u0026#39;t find pizza with ID: %d\u0026#34;, ID) } type Order struct { PizzaID int `json:\u0026#34;pizza_id\u0026#34;` Quantity int `json:\u0026#34;quantity\u0026#34;` Total int `json:\u0026#34;total\u0026#34;` } type Orders []Order type pizzasHandler struct { pizzas *Pizzas } func (ph pizzasHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) switch r.Method { case http.MethodGet: if len(*ph.pizzas) == 0 { http.Error(w, \u0026#34;Error: No pizzas found\u0026#34;, http.StatusNotFound) return } json.NewEncoder(w).Encode(ph.pizzas) default: http.Error(w, \u0026#34;Method not allowed\u0026#34;, http.StatusMethodNotAllowed) } } type ordersHandler struct { pizzas *Pizzas orders *Orders } func (oh ordersHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) switch r.Method { case http.MethodPost: var o Order if len(*oh.pizzas) == 0 { http.Error(w, \u0026#34;Error: No pizzas found\u0026#34;, http.StatusNotFound) return } err := json.NewDecoder(r.Body).Decode(\u0026amp;o) if err != nil { http.Error(w, \u0026#34;Can\u0026#39;t decode body\u0026#34;, http.StatusBadRequest) return } p, err := oh.pizzas.FindByID(o.PizzaID) if err != nil { http.Error(w, fmt.Sprintf(\u0026#34;Error: %s\u0026#34;, err), http.StatusBadRequest) return } o.Total = p.Price * o.Quantity *oh.orders = append(*oh.orders, o) json.NewEncoder(w).Encode(o) case http.MethodGet: json.NewEncoder(w).Encode(oh.orders) default: http.Error(w, \u0026#34;Method not allowed\u0026#34;, http.StatusMethodNotAllowed) } } func main() { var orders Orders pizzas := Pizzas{ Pizza{ ID: 1, Name: \u0026#34;Pepperoni\u0026#34;, Price: 12, }, Pizza{ ID: 2, Name: \u0026#34;Capricciosa\u0026#34;, Price: 11, }, Pizza{ ID: 3, Name: \u0026#34;Margherita\u0026#34;, Price: 10, }, } mux := http.NewServeMux() mux.Handle(\u0026#34;/pizzas\u0026#34;, pizzasHandler{\u0026amp;pizzas}) mux.Handle(\u0026#34;/orders\u0026#34;, ordersHandler{\u0026amp;pizzas, \u0026amp;orders}) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, mux)) } The orders and the pizzas are kept in-memory – the example is simple on purpose and adding any storage solution will greatly complicate the example. The body of the POST /orders endpoint expects a JSON body, with a pizza_id and quantity.\nThis server has a bunch of downsides and is absolutely not ready for production usage. It never checks the Accept header of the request, the errors responses are lacking additional details and proper envelopes. Our little HTTP server also never validates the data the client sends – if the quantity is missing from the request body of the POST /orders it will create a new order with a total of $0:\n$ curl -X POST localhost:8080/orders -d \u0026#39;{\u0026#34;pizza_id\u0026#34;:1,\u0026#34;quantity\u0026#34;:0}\u0026#39; | jq { \u0026#34;pizza_id\u0026#34;: 1, \u0026#34;quantity\u0026#34;: 0, \u0026#34;total\u0026#34;: 0 } Lastly, it allows us to order only one type of pizza per order. What a weird pizza shop, isn\u0026rsquo;t it? Still, as an example for this article it will do just fine.\nLet\u0026rsquo;s run it locally and send a few requests using cURL. To see all of the available pizzas on the menu:\n$ curl -X GET localhost:8080/pizzas | jq [ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Pepperoni\u0026#34;, \u0026#34;price\u0026#34;: 12 }, { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;Capricciosa\u0026#34;, \u0026#34;price\u0026#34;: 11 }, { \u0026#34;id\u0026#34;: 3, \u0026#34;name\u0026#34;: \u0026#34;Margherita\u0026#34;, \u0026#34;price\u0026#34;: 10 } To see the (empty) list of orders:\n$ curl -X GET localhost:8080/orders null To create an order of four Pepperoni pizzas:\n$ curl -X POST localhost:8080/orders -d \u0026#39;{\u0026#34;pizza_id\u0026#34;:1,\u0026#34;quantity\u0026#34;:4}\u0026#39; | jq { \u0026#34;pizza_id\u0026#34;: 1, \u0026#34;quantity\u0026#34;: 4, \u0026#34;total\u0026#34;: 48 } From the response it is clear that the total is $48. To see the new order in the list of orders:\n$ curl -X GET localhost:8080/orders | jq [ { \u0026#34;pizza_id\u0026#34;: 1, \u0026#34;quantity\u0026#34;: 4, \u0026#34;total\u0026#34;: 48 } ] Great! Our simple HTTP server is working as it should. So, how do we test it?\nTesting the pizzasHandler As mentioned in the first section of this article, Go ships with everything we need to test our HTTP server in a single package called net/http/httptest (docs). Simply put, this package provides utilities for HTTP testing.\nLet\u0026rsquo;s create a main_test.go file where we will add our tests. First, we will test our pizzasHandler:\nfunc TestPizzasHandler(t *testing.T) { tt := []struct { name string method string input *Pizzas want string statusCode int }{ { name: \u0026#34;without pizzas\u0026#34;, method: http.MethodGet, input: \u0026amp;Pizzas{}, want: \u0026#34;Error: No pizzas found\u0026#34;, statusCode: http.StatusNotFound, }, { name: \u0026#34;with pizzas\u0026#34;, method: http.MethodGet, input: \u0026amp;Pizzas{ Pizza{ ID: 1, Name: \u0026#34;Foo\u0026#34;, Price: 10, }, }, want: `[{\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;Foo\u0026#34;,\u0026#34;price\u0026#34;:10}]`, statusCode: http.StatusOK, }, { name: \u0026#34;with bad method\u0026#34;, method: http.MethodPost, input: \u0026amp;Pizzas{}, want: \u0026#34;Method not allowed\u0026#34;, statusCode: http.StatusMethodNotAllowed, }, } for _, tc := range tt { t.Run(tc.name, func(t *testing.T) { request := httptest.NewRequest(tc.method, \u0026#34;/orders\u0026#34;, nil) responseRecorder := httptest.NewRecorder() pizzasHandler{tc.input}.ServeHTTP(responseRecorder, request) if responseRecorder.Code != tc.statusCode { t.Errorf(\u0026#34;Want status \u0026#39;%d\u0026#39;, got \u0026#39;%d\u0026#39;\u0026#34;, tc.statusCode, responseRecorder.Code) } if strings.TrimSpace(responseRecorder.Body.String()) != tc.want { t.Errorf(\u0026#34;Want \u0026#39;%s\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, tc.want, responseRecorder.Body) } }) } } In this test we take the common table-driven approach to testing the handler. We provide three cases: without any pizzas on the menu, with some pizzas on the menu and with a bad HTTP method being used.\nThen, for each of the test cases we run a subtest, which creates a new request and a responseRecorder.\nThe httptest.NewRequest function returns a new http.Request, which we can then use to invoke the handler with. The returned http.Request represents an incoming request to the handler. By creating this struct within the test we do not have to rely on booting up an actual HTTP server and sending an actual HTTP request to it. The http.Request struct gives us the ability to simulate a real request just by passing the struct to the handler under test.\nThe httptest.NewRequest function is essential to unit testing HTTP handlers here. Yet, it does only half of the job - \u0026ldquo;sending\u0026rdquo; a request to the handler. What about the other half - the response?\nWriting the response is done using the httptest.ResponseRecorder – it represents an actual implementation of http.ResponseWriter (the second argument of pizzasHandler\u0026rsquo;s ServeHTTP method). It records its mutations and allows us to make any assertions on it later in the test.\nThe httptest.ResponseRecorder and http.Request duo are all we need to sucessfully test any HTTP handler in Go.\nIf we run the above test, we\u0026rsquo;ll see the following output:\n$ go test -v -run PizzasHandler === RUN TestPizzasHandler === RUN TestPizzasHandler/without_pizzas === RUN TestPizzasHandler/with_pizzas === RUN TestPizzasHandler/with_bad_method --- PASS: TestPizzasHandler (0.00s) --- PASS: TestPizzasHandler/without_pizzas (0.00s) --- PASS: TestPizzasHandler/with_pizzas (0.00s) --- PASS: TestPizzasHandler/with_bad_method (0.00s) PASS ok _/Users/Ilija/Documents/go-playground/testing-in-go-http-servers\t0.023s (In case you\u0026rsquo;re following along, I recommend breaking the tests by changing any of the expected values and seeing how these tests fail.)\nTesting the pizzasHandler is straightforward - we have only one GET endpoint. How about we test our ordersHandler, which is a tad more complicated?\nTesting the ordersHandler The ordersHandler is more complicated relative to the pizzaHandler because it contains two endpoints, the POST one creates a new order while the GET one returns the list of all orders. This means that when testing, we will have to cover more cases.\nHere\u0026rsquo;s a test:\nfunc TestOrdersHandler(t *testing.T) { tt := []struct { name string method string pizzas *Pizzas orders *Orders body string want string statusCode int }{ { name: \u0026#34;with a pizza ID and quantity\u0026#34;, method: http.MethodPost, pizzas: \u0026amp;Pizzas{ Pizza{ ID: 1, Name: \u0026#34;Margherita\u0026#34;, Price: 8, }, }, orders: \u0026amp;Orders{}, body: `{\u0026#34;pizza_id\u0026#34;:1,\u0026#34;quantity\u0026#34;:1}`, want: `{\u0026#34;pizza_id\u0026#34;:1,\u0026#34;quantity\u0026#34;:1,\u0026#34;total\u0026#34;:8}`, statusCode: http.StatusOK, }, { name: \u0026#34;with a pizza and no quantity\u0026#34;, method: http.MethodPost, pizzas: \u0026amp;Pizzas{ Pizza{ ID: 1, Name: \u0026#34;Margherita\u0026#34;, Price: 8, }, }, orders: \u0026amp;Orders{}, body: `{\u0026#34;pizza_id\u0026#34;:1}`, want: `{\u0026#34;pizza_id\u0026#34;:1,\u0026#34;quantity\u0026#34;:0,\u0026#34;total\u0026#34;:0}`, statusCode: http.StatusOK, }, { name: \u0026#34;with no pizzas on menu\u0026#34;, method: http.MethodPost, pizzas: \u0026amp;Pizzas{}, orders: \u0026amp;Orders{}, body: `{\u0026#34;pizza_id\u0026#34;:1,\u0026#34;quantity\u0026#34;:1}`, want: \u0026#34;Error: No pizzas found\u0026#34;, statusCode: http.StatusNotFound, }, { name: \u0026#34;with GET method and no orders in memory\u0026#34;, method: http.MethodGet, pizzas: \u0026amp;Pizzas{}, orders: \u0026amp;Orders{}, body: \u0026#34;\u0026#34;, want: \u0026#34;[]\u0026#34;, statusCode: http.StatusOK, }, { name: \u0026#34;with GET method and with orders in memory\u0026#34;, method: http.MethodGet, pizzas: \u0026amp;Pizzas{}, orders: \u0026amp;Orders{ Order{ Quantity: 10, PizzaID: 1, Total: 100, }, }, body: \u0026#34;\u0026#34;, want: `[{\u0026#34;pizza_id\u0026#34;:1,\u0026#34;quantity\u0026#34;:10,\u0026#34;total\u0026#34;:100}]`, statusCode: http.StatusOK, }, { name: \u0026#34;with bad HTTP method\u0026#34;, method: http.MethodDelete, pizzas: \u0026amp;Pizzas{}, orders: \u0026amp;Orders{}, body: \u0026#34;\u0026#34;, want: \u0026#34;Method not allowed\u0026#34;, statusCode: http.StatusMethodNotAllowed, }, } for _, tc := range tt { t.Run(tc.name, func(t *testing.T) { request := httptest.NewRequest(tc.method, \u0026#34;/orders\u0026#34;, strings.NewReader(tc.body)) responseRecorder := httptest.NewRecorder() handler := ordersHandler{tc.pizzas, tc.orders} handler.ServeHTTP(responseRecorder, request) if responseRecorder.Code != tc.statusCode { t.Errorf(\u0026#34;Want status \u0026#39;%d\u0026#39;, got \u0026#39;%d\u0026#39;\u0026#34;, tc.statusCode, responseRecorder.Code) } if strings.TrimSpace(responseRecorder.Body.String()) != tc.want { t.Errorf(\u0026#34;Want \u0026#39;%s\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, tc.want, responseRecorder.Body) } }) } } The tests are similar to the previous, but here each of the requests that we create using the httptest.NewRequest function also take a body as the third parameter. The body has to be of type io.Reader, which is an interface that wraps the basic Read method.\nIn cases where you need to wrap a simple string as an io.Reader one function that I\u0026rsquo;ve found fitting is string.NewReader. As you might notice if you visit its documentation, it is just a plain wrapper around the string as a read-only io.Reader.\nIn the rest of the test we - once again - create a responseRecorder and then pass it along with the request to the ordersHandler\u0026rsquo;s ServeHTTP function. Right after we compare the Body of the responseRecorder and the expected body from the test case.\nIf we run the test, we will see the following output:\n$ go test -v -run OrdersHandler === RUN TestOrdersHandler === RUN TestOrdersHandler/with_a_pizza_ID_and_quantity === RUN TestOrdersHandler/with_a_pizza_and_no_quantity === RUN TestOrdersHandler/with_no_pizzas_on_menu === RUN TestOrdersHandler/with_GET_method_and_no_orders_in_memory === RUN TestOrdersHandler/with_GET_method_and_with_orders_in_memory === RUN TestOrdersHandler/with_bad_HTTP_method --- PASS: TestOrdersHandler (0.00s) --- PASS: TestOrdersHandler/with_a_pizza_ID_and_quantity (0.00s) --- PASS: TestOrdersHandler/with_a_pizza_and_no_quantity (0.00s) --- PASS: TestOrdersHandler/with_no_pizzas_on_menu (0.00s) --- PASS: TestOrdersHandler/with_GET_method_and_no_orders_in_memory (0.00s) --- PASS: TestOrdersHandler/with_GET_method_and_with_orders_in_memory (0.00s) --- PASS: TestOrdersHandler/with_bad_HTTP_method (0.00s) PASS ok _/Users/Ilija/Documents/go-playground/testing-in-go-http-servers\t0.011s (In case you\u0026rsquo;re following along, I recommend breaking the tests by changing any of the expected values and seeing how these tests fail.)\nAs you can see, the testing package in combination with the net/http/httptest package, using the httptest.NewRequest and httptest.Recorder functions provide flexibility and enough power to test any HTTP server.\nTo undersand all of the possibilities, I recommend checking out the net/http/httptest package documentation.\nP.S. You can read more about the jq tool on its homepage.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-testing-http-servers/","summary":"Go\u0026rsquo;s a great hammer for a lot of nails, one of the areas where I find it fitting is building HTTP servers. The net/http package of Go\u0026rsquo;s standard library makes it easy to attach HTTP handlers to any Go program. What I find delightful is that Go\u0026rsquo;s standard library, also has packages that make testing HTTP servers as easy as building them.\nNowadays, it\u0026rsquo;s widely accepted that test coverage is important and useful.","title":"Testing in Go: HTTP Servers"},{"content":"Go v1.14 ships with improvements across different aspects of the language. Two of them are brand new t.Cleanup, and b.Cleanup methods, added to the testing package.\nThe introduction of these methods will make it easier for our tests to clean up after themselves. This was always achievable through the careful composition of (sub)tests and helper functions, but since Go 1.14, the testing package will ship with one right way to do that.\nLet\u0026rsquo;s explore through a scenario, one very common in web development, how these methods work, and how to put them in use.\nIn this article, we will focus on the t.Cleanup function, but the points made here apply to the b.Cleanup function too.\nVulnerable Authentication A web service that we own has an authentication middleware that uses HTTP Basic Authentication. The middleware takes the Authorization header values of an HTTP request using the BasicAuth helper method and authenticates the request. Depending on the authentication result, it will return an error response or let the request go through.\nThe AuthMiddleware authorization middleware:\ntype AuthMiddleware struct { db *gorm.DB } func (am *AuthMiddleware) Validate(username, password string) bool { var u User if err := am.db.Where(\u0026#34;username = ? AND password = ?\u0026#34;, username, password).First(\u0026amp;u).Error; err != nil { return false } return true } func (am *AuthMiddleware) Middleware(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { if u, p, ok := r.BasicAuth(); ok \u0026amp;\u0026amp; am.Validate(u, p) { next.ServeHTTP(w, r) } else { http.Error(w, \u0026#34;Forbidden\u0026#34;, http.StatusForbidden) } }) } The AuthMiddleware is a struct that has a db attribute of the type *gorm.DB, which, in fact, is a Gorm database connection pool. The Validate method of the middleware will check the validity of the authorization credentials sent by the client. (Yes, this is a very dumb and vulnerable service - stores plain text passwords in the database. No, you should never keep your customers' passwords in plain text.)\nTo do that, it uses the Request.BasicAuth method that returns the username and password provided in the request\u0026rsquo;s Authorization header. Then, we invoke the Validate method with u (the username) and p (the password) as arguments, that returns a bool.\nWhen the request successfully authorized, the response of the endpoint will be returned. If the request does not supply proper HTTP Basic Authentication credentials, or the supplied credentials are invalid, it will return an HTTP 403 Forbidden error.\nThe simplistic server that builds the router and mounts the handler and the middleware:\nfunc main() { db, err := gorm.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;./cleanups.db\u0026#34;) if err != nil { log.Fatal(err) } defer db.Close() aum := \u0026amp;AuthMiddleware{db} r := mux.NewRouter() r.Use(aum.Middleware) r.HandleFunc(\u0026#34;/foo\u0026#34;, func(w http.ResponseWriter, r *http.Request) { io.WriteString(w, \u0026#34;6 x 9 = 42\\n\u0026#34;) }) log.Fatal(http.ListenAndServe(\u0026#34;:8888\u0026#34;, r)) } The main function opens a Gorm connection to an SQLite3 database, builds a mux router, and mounts a handler at the /foo URI. Then, it mounts the router on a server and starts listening on 127.0.0.1:8888.\nSo, a sensible question would be, how can we test such a middleware? Since there is a database connection in play here, we have to make sure the database contains the actual username and password we want to send in the test.\nTesting the Vulnerable Authentication Given that the authorization middleware expects a database connection, testing it can be a messy exercise. To test it, we will have to open a database connection (to a test database) and then use it to initialize a test server that mounts the router. Then, we have to send requests to that same server and run our assertions on its response body and status.\nLet\u0026rsquo;s take a stab at it:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httptest\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/jinzhu/gorm\u0026#34; ) func TestServer(t *testing.T) { db, err := gorm.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;./cleanups_test.db\u0026#34;) if err != nil { t.Fatal(err) } defer db.Close() r := Router(db)  tcs := []struct { name string username string password string responseBody string responseStatus int }{ { name: \u0026#34;with invalid username-password combo\u0026#34;, username: \u0026#34;jane\u0026#34;, password: \u0026#34;doe\u0026#34;, responseBody: \u0026#34;Forbidden\u0026#34;, responseStatus: http.StatusForbidden, }, { name: \u0026#34;with valid username-password combo\u0026#34;, username: \u0026#34;jane\u0026#34;, password: \u0026#34;doe123\u0026#34;, responseBody: \u0026#34;6 x 9 = 42\u0026#34;, responseStatus: http.StatusOK, }, } ts := httptest.NewServer(r) defer ts.Close() client := ts.Client() req, err := http.NewRequest(\u0026#34;GET\u0026#34;, fmt.Sprintf(\u0026#34;%s/foo\u0026#34;, ts.URL), nil) if err != nil { t.Fatal(err) }  for _, tc := range tcs { t.Run(tc.name, func(t *testing.T) { req.SetBasicAuth(tc.username, tc.password)  res, err := client.Do(req) if err != nil { t.Fatal(err) } defer res.Body.Close() response, err := ioutil.ReadAll(res.Body) if err != nil { t.Errorf(err) } if res.StatusCode != tc.responseStatus { t.Errorf(\u0026#34;Want \u0026#39;%d\u0026#39;, got \u0026#39;%d\u0026#39;\u0026#34;, tc.responseStatus, res.StatusCode) } if strings.TrimSpace(string(response)) != tc.responseBody { t.Errorf(\u0026#34;Want \u0026#39;%s\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, tc.responseBody, string(response)) } }) } } We first open a database connection to a test database and pass the connection as an argument to the Router function. In the second highlighted block, we mount the returned router from the Router function on the test HTTP server. Also, we create a client for the server that we will use to send requests to the server.\nWe then build a new request for the server, and in the next highlighted block, we attach the username and the password of the test case to the request using the Request.SetBasicAuth method.\nWe send the request to the HTTP server using the client.Do method, and get a response back. We then parse the response and do our assertions on the status code of the response and the contents of the body.\nIf we ran this test, it would fail. Why? Although the test setup is correct, the test database is empty. When we send a request to the HTTP server, it will try to validate the credentials our test sends, and it will find an empty database:\n$ go test ./... -v -count=1 === RUN TestServer TestServer: server_test.go:17: no such table: users (/app/server_test.go:16) [2020-02-16 17:29:26] no such table: users --- FAIL: TestServer (0.01s) FAIL FAIL\tgithub.com/fteem/go-playground/testing-in-go-cleanup\t0.015s FAIL This means our test is missing an initial seed of test data, where we create the users table and put some records in it so we can use them in the test.\nAdding data and cleaning it up, the old way The widely-approved approach to seeding the test database is to insert some records before running the test and then remove them once the test is done. The benefit being that the database will always be empty after the tests are done running, without the need to recreate the database and its tables every time we run the tests. Precisely what our failing tests need.\nAchieving this in the most idiomatic way is by using a cleanup closure that is returned by the function that inserts the data. Usually, the returning cleanup function \u0026ldquo;pattern\u0026rdquo; looks like this:\nfunc createUser(t *testing.T, db *gorm.DB) func() { user := User{Username: \u0026#34;jane\u0026#34;, Password: \u0026#34;doe123\u0026#34;} if err := db.Create(\u0026amp;user).Error; err != nil { t.Fatal(err) } return func() { db.Delete(\u0026amp;user) } }  func TestServer(t *testing.T) { db, err := gorm.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;./cleanups_test.db\u0026#34;) if err != nil { t.Fatal(err) } defer db.Close() cleanup := createUser(t, db) defer cleanup()  r := Router(db) tcs := []struct { name string username string password string responseBody string responseStatus int }{ { name: \u0026#34;with invalid username-password combo\u0026#34;, username: \u0026#34;jane\u0026#34;, password: \u0026#34;doe\u0026#34;, responseBody: \u0026#34;Forbidden\u0026#34;, responseStatus: http.StatusForbidden, }, { name: \u0026#34;with valid username-password combo\u0026#34;, username: \u0026#34;jane\u0026#34;, password: \u0026#34;doe123\u0026#34;, responseBody: \u0026#34;6 x 9 = 42\u0026#34;, responseStatus: http.StatusOK, }, } ts := httptest.NewServer(r) defer ts.Close() client := ts.Client() req, err := http.NewRequest(\u0026#34;GET\u0026#34;, fmt.Sprintf(\u0026#34;%s/foo\u0026#34;, ts.URL), nil) if err != nil { t.Fatal(err) } for _, tc := range tcs { t.Run(tc.name, func(t *testing.T) { req.SetBasicAuth(tc.username, tc.password) res, err := client.Do(req) if err != nil { t.Fatal(err) } defer res.Body.Close() response, err := ioutil.ReadAll(res.Body) if err != nil { t.Error(err) } if res.StatusCode != tc.responseStatus { t.Errorf(\u0026#34;Want \u0026#39;%d\u0026#39;, got \u0026#39;%d\u0026#39;\u0026#34;, tc.responseStatus, res.StatusCode) } if strings.TrimSpace(string(response)) != tc.responseBody { t.Errorf(\u0026#34;Want \u0026#39;%s\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, tc.responseBody, string(response)) } }) } } The createUser function takes a database connection as an argument and uses it to insert a new User in the users table. After that, it will return a closure that, when invoked, will remove the added user.\nThe reason we pass the testing.T pointer to the createUser function is to be able to fail the test if the database cannot be opened for writing. We check the db.Error field on the Gorm database connection pool for any errors and invoke the t.Fatal function, if we hit any errors.\n(You can read more about the behavior of t.Fatal in my article on the topic.)\nIn the test itself, we invoke createUser with the test database connection and the testing.T pointer. The return value of createUser is a function which we store in the cleanup variable. Then, we defer the invocation of cleanup to happen at the exit of the test function. Using cleanup, we can remove the data from the test database before exiting the tests.\nWhile the approach above works and it\u0026rsquo;s idiomatic Go, it has a few downsides worth mentioning:\n It works fine for one test case, but if the test file has many tests that modify the state of the test database, they will get contaminated with cleanup-like functions. Adding to the above point, imagine tests where we have to clean up other things, such as processes, files, or open sockets. That will lead to a substantial increase in cleanup-closures pollution. It adds cognitive overhead when reading the code, which otherwise is a straightforward testing code The definition of the cleanup function is buried in the createUser function, visually separated from the test function that uses/invokes it. A reader of the test file can experience difficulty navigating the functions and putting the pieces together  Because of these reasons, the Go authors decided to add a t.Cleanup function to the testing package. The change was merged on November 4, 2019 – right on time to get into the v1.14 release.\nLet\u0026rsquo;s explore how t.Cleanup can make our life easier.\nAdding data and cleaning it up, using t.Cleanup With the t.Cleanup, and b.Cleanup methods, we get better control to cleaning up after our tests. t.Cleanup registers a function to be called when the test and all its subtests complete. This means that even if our tests run as subtests, which is the case in our example, the cleanup will only happen after all the subtests are done.\nHere\u0026rsquo;s the reworked version of our tests:\nfunc createUser(t *testing.T, db *gorm.DB) { user := User{Username: \u0026#34;jane\u0026#34;, Password: \u0026#34;doe123\u0026#34;} if err := db.Create(\u0026amp;user).Error; err != nil { t.Fatal(err) } t.Cleanup(func() { db.Delete(\u0026amp;user) }) } func TestServer(t *testing.T) { db, err := gorm.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;./cleanups_test.db\u0026#34;) if err != nil { t.Fatal(err) } defer db.Close() createUser(t, db)  r := Router(db) // Snipped for brewity... } While the code change is small, there is a substantial difference between the new and the old versions.\nThe most significant difference lies in the fact that the createUser function takes care of its clean up now. The invoker function (TestServer) does not need to worry about the cleanup of the data added in the database – we know that the createUser will remove the data. Most importantly, it will remove the data just in time – once all of the subtests are done.\nHaving t.Cleanup, and b.Cleanup in the standard library does not stop us from using the old way using composition and returning cleanup callbacks – it is still a valid way to clean up any state or files that our tests might create. But, using the new t.Cleanup \u0026amp; b.Cleanup functions things get a bit easier: there\u0026rsquo;s now a way to do just that, and the standard library supports it.\nAnd having the Go v1 compatibility promise in mind – it is here to stay.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-clean-tests-using-t-cleanup/","summary":"Go v1.14 ships with improvements across different aspects of the language. Two of them are brand new t.Cleanup, and b.Cleanup methods, added to the testing package.\nThe introduction of these methods will make it easier for our tests to clean up after themselves. This was always achievable through the careful composition of (sub)tests and helper functions, but since Go 1.14, the testing package will ship with one right way to do that.","title":"Testing in Go: Clean Tests Using t.Cleanup"},{"content":"Hardcoding the expected values in an assertion is a straightforward approach in testing. Most of the time, we know the expected output of the unit under test, so simply adding the raw value to the assertion works well.\nThings can get tricky when we are testing a unit whose output is cumbersome to hardcode. The straightforward remedy is to extract this cumbersome value to a file that we can then read and compare the output of the unit under test to the output of the file.\nIn Go, we call such files golden files. Golden files contain the expected output of a test. When tests run, they read the contents of the golden file and compare it to the output of the unit under test.\nAs always, let\u0026rsquo;s make our lives easier and discuss golden files using an example.\nBook reports Imagine you own a small library or a book store. Your inventory software exposes an API where you can get the list of books in said inventory. You want a program that will take all that data and format it in a Markdown table. Maybe you want to print this table or send it to your accountant. The possibilities are endless!\nLet\u0026rsquo;s see a simulation of such a program:\n// report/report.go  package report import ( \u0026#34;bytes\u0026#34; \u0026#34;log\u0026#34; \u0026#34;text/template\u0026#34; \u0026#34;github.com/fteem/go-playground/golden-files/books\u0026#34; ) const ( header string = ` | Title | Author | Publisher | Pages | ISBN | Price | | ------------- | ------------- | --------- | ------- | ------ | ------- | ` rowTemplate string = \u0026#34;| {{ .Title }} | {{ .Author }} | {{ .Publisher }} | {{ .Pages }} | {{ .ISBN }} | {{ .Price }} |\\n\u0026#34; ) func Generate(books []books.Book) string { buf := bytes.NewBufferString(header) t := template.Must(template.New(\u0026#34;table\u0026#34;).Parse(rowTemplate)) for _, book := range books { err := t.Execute(buf, book) if err != nil { log.Println(\u0026#34;Error executing template:\u0026#34;, err) } } return buf.String() } In the report package, we have a single function Generate which generates the report Markdown table. It gets all the books from the books.Books package, iterates over them and uses the rowTemplate to generate each of the rows of the table. In the end, it returns the whole Markdown table as in a single string.\nLet\u0026rsquo;s take a quick peek at the books package:\n// books/books.go  package books type Book struct { ISBN string Title string Author string Pages int Publisher string Price int } var Books []Book = []Book{ Book{ ISBN: \u0026#34;978-1591847786\u0026#34;, Title: \u0026#34;Hooked\u0026#34;, Author: \u0026#34;Nir Eyal\u0026#34;, Pages: 256, Publisher: \u0026#34;Portfolio\u0026#34;, Price: 19, }, Book{ ISBN: \u0026#34;978-1434442017\u0026#34;, Title: \u0026#34;The Great Gatsby\u0026#34;, Author: \u0026#34;F. Scott Fitzgerald\u0026#34;, Pages: 140, Publisher: \u0026#34;Wildside Press\u0026#34;, Price: 12, }, Book{ ISBN: \u0026#34;978-1784756260\u0026#34;, Title: \u0026#34;Then She Was Gone: A Novel\u0026#34;, Author: \u0026#34;Lisa Jewell\u0026#34;, Pages: 448, Publisher: \u0026#34;Arrow\u0026#34;, Price: 29, }, Book{ ISBN: \u0026#34;978-1094400648\u0026#34;, Title: \u0026#34;Think Like a Billionaire\u0026#34;, Author: \u0026#34;James Altucher\u0026#34;, Pages: 852, Publisher: \u0026#34;Scribd, Inc.\u0026#34;, Price: 9, }, } The books package contains just the list of the books in our fake inventory.\nIf we ran the code we would get the following output:\n$ go run main.go | Title | Author | Publisher | Pages | ISBN | Price | | ------------- | ------------- | --------- | ------- | ------ | ------- | | Hooked | Nir Eyal | Portfolio | 256 | 978-1591847786 | 19 | | The Great Gatsby | F. Scott Fitzgerald | Wildside Press | 140 | 978-1434442017 | 12 | | Then She Was Gone: A Novel | Lisa Jewell | Arrow | 448 | 978-1784756260 | 29 | | Think Like a Billionaire | James Altucher | Scribd, Inc. | 852 | 978-1094400648 | 9 | Given that this blog is generated using Markdown, here\u0026rsquo;s the table rendered:\n   Title Author Publisher Pages ISBN Price     Hooked Nir Eyal Portfolio 256 978-1591847786 19   The Great Gatsby F. Scott Fitzgerald Wildside Press 140 978-1434442017 12   Then She Was Gone: A Novel Lisa Jewell Arrow 448 978-1784756260 29   Think Like a Billionaire James Altucher Scribd, Inc. 852 978-1094400648 9    Not the prettiest table in the world, still a good overview of the inventory. Now that we have the report in place let\u0026rsquo;s see how we can test it.\nTesting our reports Testing the Generate function is straightforward, using the table-driven approach:\npackage report import ( \u0026#34;strings\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/fteem/go-playground/golden-files/books\u0026#34; ) func TestGenerate(t *testing.T) { testcases := []struct { name string books []books.Book want string }{ { name: \u0026#34;WithInventory\u0026#34;, books: []books.Book{ books.Book{ Title: \u0026#34;The Da Vinci Code\u0026#34;, Author: \u0026#34;Dan Brown\u0026#34;, Pages: 592, ISBN: \u0026#34;978-0552161275\u0026#34;, Price: 7, }, books.Book{ Title: \u0026#34;American on Purpose\u0026#34;, Author: \u0026#34;Craig Ferguson\u0026#34;, Pages: 288, ISBN: \u0026#34;978-0061959158\u0026#34;, Price: 19, }, }, want: ` | Title | Author | Pages | ISBN | Price | | ------------- | ------------- | ------ | ----- | ------ | | The Da Vinci Code | Dan Brown | 592 | 978-0552161275 | 7 | | American on Purpose | Craig Ferguson | 288 | 978-0061959158 | 19 | `, }, { name: \u0026#34;EmptyInventory\u0026#34;, books: []books.Book{}, want: ` | Title | Author | Pages | ISBN | Price | | ------------- | ------------- | ------ | ----- | ------ | `, }, } for _, testcase := range testcases { got := Generate(testcase.books) if got != testcase.want { t.Errorf(\u0026#34;Want:\\n%s\\nGot:%s\u0026#34;, testcase.want, got) } } } The formatting of the expected output is rather hard to scan. That\u0026rsquo;s because our test cases test the actual output of the table, which is a string with a particular format.\nEven worse, in cases when these inconvenient strings are hardcoded, a failing test can be hard to debug if there\u0026rsquo;s a mismatch in leading or trailing whitespace. Consider this case, for example:\n$ go test -v === RUN TestGenerate --- FAIL: TestGenerate (0.00s) report_test.go:54: Want: | Title | Author | Pages | ISBN | Price | | ------------- | ------------- | ------ | ----- | ------ | | The Da Vinci Code | Dan Brown | 592 | 978-0552161275 | 7 | | American on Purpose | Craig Ferguson | 288 | 978-0061959158 | 19 | Got: | Title | Author | Pages | ISBN | Price | | ------------- | ------------- | ------ | ----- | ------ | | The Da Vinci Code | Dan Brown | 592 | 978-0552161275 | 7 | | American on Purpose | Craig Ferguson | 288 | 978-0061959158 | 19 | FAIL exit status 1 FAIL\tgithub.com/fteem/go-playground/golden-files/report-verbose\t0.005s While the wanted and the gotten values look identical, the test is failing because one of the values has trailing whitespace. To avoid hardcoding such outputs in our tests, we resort to using golden files.\nConverting to golden files To use the golden files, we need to extract the tables to a separate file in the testdata directory. If the testdata directory is foreign to you: it is a directory that the go build tool will ignore when building the binaries of your programs. You can read more about it in my post on fixtures in Go.\nUsing this approach, we want to move the two table outputs to two different files:\n testdata/empty_inventory.golden, and testdata/with_inventory.golden  Both of them will have the corresponding output of the test cases:\n$ cat report/testdata/empty_inventory.golden | Title | Author | Publisher | Pages | ISBN | Price | | ------------- | ------------- | --------- | ------- | ------ | ------- | $ cat report/testdata/with_inventory.golden | Title | Author | Publisher | Pages | ISBN | Price | | ------------- | ------------- | --------- | ------- | ------ | ------- | | The Da Vinci Code | Dan Brown | Corgi | 592 | 978-0552161275 | 7 | | American on Purpose | Craig Ferguson | Harper Collins | 288 | 978-0061959158 | 19 | Now, let\u0026rsquo;s change up our test cases to use the golden files to compare the outputs:\npackage report import ( \u0026#34;io/ioutil\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/fteem/go-playground/golden-files/books\u0026#34; ) func TestGenerate(t *testing.T) { testcases := []struct { name string books []books.Book golden string \t}{ { name: \u0026#34;WithInventory\u0026#34;, books: []books.Book{ books.Book{ Title: \u0026#34;The Da Vinci Code\u0026#34;, Author: \u0026#34;Dan Brown\u0026#34;, Publisher: \u0026#34;Corgi\u0026#34;, Pages: 592, ISBN: \u0026#34;978-0552161275\u0026#34;, Price: 7, }, books.Book{ Title: \u0026#34;American on Purpose\u0026#34;, Author: \u0026#34;Craig Ferguson\u0026#34;, Publisher: \u0026#34;Harper Collins\u0026#34;, Pages: 288, ISBN: \u0026#34;978-0061959158\u0026#34;, Price: 19, }, }, golden: \u0026#34;with_inventory\u0026#34;, \t}, { name: \u0026#34;EmptyInventory\u0026#34;, books: []books.Book{}, golden: \u0026#34;empty_inventory\u0026#34;, \t}, } for _, testcase := range testcases { got := Generate(testcase.books) content, err := ioutil.ReadFile(\u0026#34;testdata/\u0026#34; + testcase.golden + \u0026#34;.golden\u0026#34;) if err != nil { t.Fatalf(\u0026#34;Error loading golden file: %s\u0026#34;, err) } want := string(content)  if got != want { t.Errorf(\u0026#34;Want:\\n%s\\nGot:\\n%s\u0026#34;, want, got) } } } The notable changes are on the highlighted lines above:\n we add a golden attribute to each test case, representing the name of its golden file for each of the test cases, we open the respective golden file and read all of its contents we use the contents to compare the expected (want) and the actual (got) values  This approach removes hardcoded strings from our tests, and it comes with two important features:\nFirst, golden files are coupled to the test cases (a.k.a. the inputs). That means that if the inputs change, the output will change, so you will have to update the contents of the golden file. Also, if you add another test case, you will probably have to create a golden file for it. If you forget to create it, your tests will fail - which is a good thing!\nSecond, golden files contain the expected outcome of a test case. So, if the implementation of the code under test changes, your test will fail - which is also a good thing! But that also means our golden files will be out of date, and we have to update them.\nKeeping our golden files up to date is a caveat that we always have to keep in mind. As our applications evolve and their functionalities change, the golden files will have to follow suit. If we\u0026rsquo;re working on a project with many golden files, keeping them up to date can be a frustrating exercise. Therefore it\u0026rsquo;s often a good idea to automate this, so it becomes an effortless task.\nHere\u0026rsquo;s a straightforward way to automate the golden file updating.\nKeeping our golden files up to date The whole idea here is, after any change of the implementation or the test inputs, to update the golden files saving ourselves time from copy-pasting outputs to files.\nThe usual approach in the wild is to provide a command-line flag, usually -update, which you can use with the go test tool:\n// report/report_test.go var ( update = flag.Bool(\u0026#34;update\u0026#34;, false, \u0026#34;update the golden files of this test\u0026#34;) ) func TestMain(m *testing.M) { flag.Parse() os.Exit(m.Run()) } The update flag will be a bool that we will use in our function that will read and write to the golden files.\nBefore Go v1.13, the test\u0026rsquo;s init function invoked flag.Parse(). Since Go v1.13, the TestMain function should invoke the flag.Parse() function. This change of behavior is due to changes introduced in Go 1.13, where the testing package internally parses the flags before it runs the tests. Consequently, if we would skip the TestMain function, go test would not recognize the -update flag.\n(You can read more about the change in this Github issue.)\nIf you are unsure about the meaning of the TestMain function, you can read more about it in my article on the topic here.\nLet\u0026rsquo;s see the rest of the test file and the notable changes:\nfunc TestGenerate(t *testing.T) { testcases := []struct { name string books []books.Book golden string }{ { name: \u0026#34;WithInventory\u0026#34;, books: []books.Book{ books.Book{ Title: \u0026#34;The Da Vinci Code\u0026#34;, Author: \u0026#34;Dan Brown\u0026#34;, Publisher: \u0026#34;Corgi\u0026#34;, Pages: 592, ISBN: \u0026#34;978-0552161275\u0026#34;, Price: 7, }, books.Book{ Title: \u0026#34;American on Purpose\u0026#34;, Author: \u0026#34;Craig Ferguson\u0026#34;, Publisher: \u0026#34;Harper Collins\u0026#34;, Pages: 288, ISBN: \u0026#34;978-0061959158\u0026#34;, Price: 19, }, }, golden: \u0026#34;with_inventory\u0026#34;, }, { name: \u0026#34;EmptyInventory\u0026#34;, books: []books.Book{}, golden: \u0026#34;empty_inventory\u0026#34;, }, } for _, testcase := range testcases { got := Generate(testcase.books) want := goldenValue(t, testcase.golden, got, *update)  if got != want { t.Errorf(\u0026#34;Want:\\n%s\\nGot:\\n%s\u0026#34;, want, got) } } } func goldenValue(t *testing.T, goldenFile string, actual string, update bool) string { t.Helper() goldenPath := \u0026#34;testdata/\u0026#34; + goldenFile + \u0026#34;.golden\u0026#34; f, err := os.OpenFile(goldenPath, os.O_RDWR, 0644) defer f.Close() if update { _, err := f.WriteString(actual) if err != nil { t.Fatalf(\u0026#34;Error writing to file %s: %s\u0026#34;, goldenPath, err) } return actual } content, err := ioutil.ReadAll(f) if err != nil { t.Fatalf(\u0026#34;Error opening file %s: %s\u0026#34;, goldenPath, err) } return string(content) } The significant changes are in the highlighted lines above.\nThe goldenValue function takes the goldenFile name as an argument, with the actual value of the test returned by the function under test and with the update bool passed from the flag.\nThen it takes three steps:\n It opens the golden file in an R/W mode. If the update flag is true, it will update the golden file with the contents saved in the actual argument and return it. If the update flag is not set, it will continue to read the contents of the golden file and return them as a string.  If any of the reading or writing steps fail, it will crash the test and stop further test execution.\nLet\u0026rsquo;s test this in action. First, the usual, flag-less run of go test:\n$ go test -v ./report/... === RUN TestGenerate --- PASS: TestGenerate (0.00s) PASS ok github.com/fteem/go-playground/golden-files/report0.005s \u0026gt;}} Now, let\u0026rsquo;s change our implementation. We will remove the publisher column from the report that will make our tests fail because the golden file expects the Publisher column to be present:\n$ go test -v ./report/... === RUN TestGenerate --- FAIL: TestGenerate (0.00s) report_test.go:61: Want: | Title | Author | Publisher | Pages | ISBN | Price | | ------------- | ------------- | --------- | ------- | ------ | ------- | | The Da Vinci Code | Dan Brown | Corgi | 592 | 978-0552161275 | 7 | | American on Purpose | Craig Ferguson | Harper Collins | 288 | 978-0061959158 | 19 | Got: | Title | Author | Pages | ISBN | Price | | ------------- | ------------- | ------- | ------ | ------- | | The Da Vinci Code | Dan Brown | 592 | 978-0552161275 | 7 | | American on Purpose | Craig Ferguson | 288 | 978-0061959158 | 19 | report_test.go:61: Want: | Title | Author | Publisher | Pages | ISBN | Price | | ------------- | ------------- | --------- | ------- | ------ | ------- | Got: | Title | Author | Pages | ISBN | Price | | ------------- | ------------- | ------- | ------ | ------- | FAIL FAIL\tgithub.com/fteem/go-playground/golden-files/report\t0.006s FAIL The difference in the two failing tests is noticeable – we\u0026rsquo;re missing the column. Since we know that this is the new behavior of the report going forward, we only want to update the golden files. Let\u0026rsquo;s add the -update flag:\n$ go test -v ./report/... -update === RUN TestGenerate --- PASS: TestGenerate (0.00s) PASS ok github.com/fteem/go-playground/golden-files/report\t0.006s Nothing special, only passing tests? Let\u0026rsquo;s inspect the contents of the golden files:\n$ cat report/testdata/with_inventory.golden report/testdata/empty_inventory.golden report/testdata/with_inventory.golden | Title | Author | Pages | ISBN | Price | | ------------- | ------------- | ------- | ------ | ------- | | The Da Vinci Code | Dan Brown | 592 | 978-0552161275 | 7 | | American on Purpose | Craig Ferguson | 288 | 978-0061959158 | 19 | report/testdata/empty_inventory.golden | Title | Author | Pages | ISBN | Price | | ------------- | ------------- | ------- | ------ | ------- | Voilà! The using the -update flag, we removed the \u0026ldquo;Publisher\u0026rdquo; from our golden files, and the tests pass.\nFew words of caution While the golden files are a simple technique that improves our tests' legibility, they come with a few caveats.\nIt\u0026rsquo;s important to remember that you have to version these files. They are part of the project, and if you do not check them in your version control, your test suite will fail the moment it\u0026rsquo;s run in continuous integration.\nAlso, like fixtures, you should keep them in your testdata directory. The go build tool ignores any files in a testdata directory, and it excludes these files when building the binary. While we are comparing golden files and fixtures, there is another similarity between the two - the test files are not self-sufficient. This means that you will have to know the contents of another file to understand what is the expected outcome of your tests.\nFurthermore, parsing the golden files can be funny (or frustrating), depending on their content. Be careful when you\u0026rsquo;re storing content like the one I showed in the example above. If the golden file has lots of whitespaces, new lines or indentation, parsing, and comparing it to other strings can be annoying to debug.\nLastly, the -update flag has an important caveat: it must be available in all packages of your project to function. If you would like to be able to run go test ./... -update to update all golden files in your project, all packages in the project must know of -update.\nEven if there\u0026rsquo;s one package that is not aware of -update, running the tests will error out:\n❯ go test ./... -v -update ? github.com/fteem/go-playground/golden-files\t[no test files] flag provided but not defined: -update Such a behavior is because my Go module has more than one package in it, while only one of them (report) knows of -update\u0026rsquo;s existence.\nIn general, the benefits you get with golden files are great, but I suggest treading carefully, given the caveats mentioned above.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-golden-files/","summary":"Hardcoding the expected values in an assertion is a straightforward approach in testing. Most of the time, we know the expected output of the unit under test, so simply adding the raw value to the assertion works well.\nThings can get tricky when we are testing a unit whose output is cumbersome to hardcode. The straightforward remedy is to extract this cumbersome value to a file that we can then read and compare the output of the unit under test to the output of the file.","title":"Testing in Go: Golden Files"},{"content":"When it comes to timeouts, there are two types of people: those who know how tricky they can be, and those who are yet to find out.\nAs tricky as they are, timeouts are a reality in the connected world we live in. As I am writing this, on the other side of the table, two persons are typing on their smartphones, probably chatting to people very far from them. All made possible because of networks.\nNetworks and all their intricacies are here to stay, and we, who write servers for the web, have to know how to use them efficiently and guard against their deficiencies.\nWithout further ado, let\u0026rsquo;s look at timeouts and how they affect our net/http servers.\nServer timeouts - first principles In web programming, the general classification of timeouts is client and server timeouts. What inspired me to dive into this topic was an interesting server timeout problem I found myself in. That\u0026rsquo;s why, in this article, we will focus on server-side timeouts.\nTo get the basic terminology out of the way: timeout is a time interval (or limit) in which a specific action must complete. If the operation does not complete in the given time limit, a timeout occurs, and the operation is canceled.\nInitializing a net/http server in Golang reveals a few basic timeout configurations:\nsrv := \u0026amp;http.Server{ ReadTimeout: 1 * time.Second, WriteTimeout: 1 * time.Second, IdleTimeout: 30 * time.Second, ReadHeaderTimeout: 2 * time.Second, TLSConfig: tlsConfig, Handler: srvMux, } This server of http.Server type can be initialized with four different timeouts:\n ReadTimeout: the maximum duration for reading the entire request, including the body WriteTimeout: the maximum duration before timing out writes of the response IdleTimetout: the maximum amount of time to wait for the next request when keep-alive is enabled ReadHeaderTimeout: the amount of time allowed to read request headers  A graphical representation of the above timeouts:\n  Before you start thinking that these are all the timeouts you need, tread carefully! There\u0026rsquo;s more than meets the eye here. These timeout values provide much more fine-grained control, and they are not going to help us to timeout our long-running HTTP handlers.\nLet me explain.\nTimeouts and deadlines If we look at the source of net/http, in particular, the conn type, we will notice that it uses net.Conn connection under the hood which represents the underlying network connection:\n// Taken from: https://github.com/golang/go/blob/bbbc658/src/net/http/server.go#L247 // A conn represents the server-side of an HTTP connection. type conn struct { // server is the server on which the connection arrived.  // Immutable; never nil.  server *Server // * Snipped *  // rwc is the underlying network connection.  // This is never wrapped by other types and is the value given out  // to CloseNotifier callers. It is usually of type *net.TCPConn or  // *tls.Conn.  rwc net.Conn // * Snipped * } In other words, it\u0026rsquo;s the actual TCP connection that our HTTP request travels on. From a type perspective, it\u0026rsquo;s a *net.TCPConn or *tls.Conn if it\u0026rsquo;s a TLS connection.\nThe serve function, calls the readRequest function for each incoming request. readRequest uses the timeout values that we set on the server to set deadlines on the TCP connection:\n// Taken from: https://github.com/golang/go/blob/bbbc658/src/net/http/server.go#L936 // Read next request from connection. func (c *conn) readRequest(ctx context.Context) (w *response, err error) { // *Snipped*  t0 := time.Now() if d := c.server.readHeaderTimeout(); d != 0 { hdrDeadline = t0.Add(d) } if d := c.server.ReadTimeout; d != 0 { wholeReqDeadline = t0.Add(d) } c.rwc.SetReadDeadline(hdrDeadline) if d := c.server.WriteTimeout; d != 0 { defer func() { c.rwc.SetWriteDeadline(time.Now().Add(d)) }() } // *Snipped* } From the snippet above, we can conclude that the timeout values set on the server end up as TCP connection deadlines instead of HTTP timeouts.\nSo, what are deadlines then? How do they work? Will they timeout our connection if our request takes too long?\nA simple way to think about deadlines is as a point in time at which restrictions on specific actions on the connection are enforced. For example, if we set a write deadline after the deadline time passes, any write actions on the connection will be forbidden.\nWhile we can create timeout-like behavior using deadlines, we cannot control the time it takes for our handlers to complete. Deadlines operate on the connection, so our server will fail to return a result only after the handlers try to access connection properties (such as writing to http.ResponseWriter).\nTo see this in action, let\u0026rsquo;s create a tiny handler that takes longer to complete relative to the timeouts we set on the server:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func slowHandler(w http.ResponseWriter, req *http.Request) { time.Sleep(2 * time.Second) io.WriteString(w, \u0026#34;I am slow!\\n\u0026#34;) } func main() { srv := http.Server{ Addr: \u0026#34;:8888\u0026#34;, WriteTimeout: 1 * time.Second, Handler: http.HandlerFunc(slowHandler), } if err := srv.ListenAndServe(); err != nil { fmt.Printf(\u0026#34;Server failed: %s\\n\u0026#34;, err) } } The server above has a single handler, which takes 2 seconds to complete. On the other hand, the http.Server has a WriteTimeout set to 1 second. Due to the configuration of the server, we expect the handler to be unable to write the response to the connection.\nWe can start the server using go run server.go. To send a request we can curl localhost:8888:\n$ time curl localhost:8888 curl: (52) Empty reply from server curl localhost:8888 0.01s user 0.01s system 0% cpu 2.021 total The request took 2 seconds to complete, and the response from the server was empty. While our server knows that we cannot write to our response after 1 second, the handler still took 100% more (2 seconds) to complete.\nWhile this is a timeout-like behavior, it would be more useful to stop our server from further execution when it reaches the timeout, ending the request. In our example above, the handler proceeds to process the request until it completes, although it takes 100% longer (2 seconds) than the response write timeout time (1 second).\nThe natural question is, how can we have efficient timeouts for our handlers?\nHandler timeout Our goal is to make sure our slowHandler does not take longer than 1 seconds to complete. If it does take longer, our server should stop its execution and return a proper timeout error.\nIn Go, as with other programming languages, composition is very often the favored approach to writing and designing code. The net/http package of the standard library is one of the places where having compatible components that one can put together with little effort is an obvious design choice.\nIn that light, the net/http packages provide a TimeoutHandler - it returns a handler that runs a handler within the given time limit.\nIts signature is:\nfunc TimeoutHandler(h Handler, dt time.Duration, msg string) Handler It takes a Handler as the first argument, a time.Duration as the second argument (the timeout time) and a string, the message returned when it hits the timeout.\nTo wrap our slowHandler within a TimeoutHandler, all we have to do is:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func slowHandler(w http.ResponseWriter, req *http.Request) { time.Sleep(2 * time.Second) io.WriteString(w, \u0026#34;I am slow!\\n\u0026#34;) } func main() { srv := http.Server{ Addr: \u0026#34;:8888\u0026#34;, WriteTimeout: 5 * time.Second, Handler: http.TimeoutHandler(http.HandlerFunc(slowHandler), 1*time.Second, \u0026#34;Timeout!\\n\u0026#34;), } if err := srv.ListenAndServe(); err != nil { fmt.Printf(\u0026#34;Server failed: %s\\n\u0026#34;, err) } } The two notable changes are:\n We wrap our slowHanlder in the http.TimetoutHandler, setting the timeout to 1 second and the timeout message to \u0026ldquo;Timeout!\u0026rdquo;. We increase the WriteTimeout to 5 seconds, to give the http.TimeoutHandler time to kick in. If we don\u0026rsquo;t do this when the TimeoutHandler kicks in, the deadline will pass, and it won\u0026rsquo;t be able to write to the response.  If we started the server again and hit the slow handler we\u0026rsquo;ll get the following output:\n$ time curl localhost:8888 Timeout! curl localhost:8888 0.01s user 0.01s system 1% cpu 1.023 total After a second, our TimeoutHandler will kick in, stop processing the slowHandler, and return a plain \u0026ldquo;Timeout!\u0026rdquo; message. If the message we set is blank, then the handler will return the default timeout response, which is:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Timeout\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Timeout\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Regardless of the output, this is pretty neat, isn\u0026rsquo;t it? Our application now is protected from long-running handlers and specially crafted requests made to cause very long-running handlers, leading to a potential DoS (Denial of Service) attack.\nIt\u0026rsquo;s worth noting that although setting timeouts is a great start, it\u0026rsquo;s still elementary protection. If you\u0026rsquo;re under threat of an imminent DoS attack, you should look into more advanced protection tools and techniques. (Cloudflare is a good start.)\nOur slowHandler is a simple example-only handler. But, what if our application was much more complicated, making external calls to other services or resources? What if we had an outgoing request to a service such as S3 when our handler would time out?\nWhat would happen then?\nUnhandled timeouts and request cancellations Let\u0026rsquo;s expand our example a bit:\nfunc slowAPICall() string { d := rand.Intn(5) select { case \u0026lt;-time.After(time.Duration(d) * time.Second): log.Printf(\u0026#34;Slow API call done after %s seconds.\\n\u0026#34;, d) return \u0026#34;foobar\u0026#34; } } func slowHandler(w http.ResponseWriter, r *http.Request) { result := slowAPICall() io.WriteString(w, result+\u0026#34;\\n\u0026#34;) } Let\u0026rsquo;s imagine that initially we didn\u0026rsquo;t know that our slowHandler took so long to complete because it was sending a request to an API - using the slowAPICall function.\nThe slowAPICall function is straightforward: using select and a time.After it blocks between 0 and 5 seconds. Once that period passes, the time.After method sends a value through its channel and \u0026quot;foobar\u0026quot; will be returned.\n(An alternative approach is to use sleep(time.Duration(rand.Intn(5)) * time.Second), but we will stick to select because it will make our life simpler in the next example.)\nIf we run our server, we would expect the timeout handler to cut off the request processing after 1 second. Sending a request proves that:\n$ time curl localhost:8888 Timeout! curl localhost:8888 0.01s user 0.01s system 1% cpu 1.021 total By looking at the server output, we will notice that it prints the loglines after a few seconds instead of when the timeout handler kicks in:\n$ go run server.go 2019/12/29 17:20:03 Slow API call done after 4 seconds. Such behavior suggests that although the request timed out after 1 second, the server proceeded to process the request fully. That\u0026rsquo;s why it printed the logline after 4 seconds passed.\nWhile this example is trivial and naive, such behavior in production servers can become a rather big problem. For example, imagine if the slowAPICall function spawned hundreds of goroutines, each of them processing some data. Or if it was issuing multiple API calls to various systems. Such long-running processes will eat up resources from your system, while the caller/client won\u0026rsquo;t ever use their result.\nSo, how can we guard our system from such unoptimized timeouts or request cancellations?\nContext timeouts and cancellation Go comes with a neat package for handling such scenarios called context.\nThe context package was promoted to the standard library as of Go 1.7. Previously it was part of the Go Sub-repository Packages, with the name golang.org/x/net/context\nThe package defines the Context type. It\u0026rsquo;s primary purpose is to carry deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes. If you would like to learn more about the context package, I recommend reading \u0026ldquo;Go Concurrency Patterns: Context\u0026rdquo; on Golang\u0026rsquo;s blog.\nThe Request type that is part of the net/http package already has a context attached to it. As of Go 1.7, Request has a Context function, which returns the request\u0026rsquo;s context. For incoming server requests, the server cancels the context when the client\u0026rsquo;s connection closes, when the request is canceled (in HTTP/2), or when the ServeHTTP method returns.\nThe behavior we are looking for is to stop all further processing on the server-side when the client cancels the request (we hit CTRL + C on our cURL) or the TimeoutHandler steps in after some time and ends the request. That will effectively close all connections and free all other resources taken up by the running handler (and all of its children goroutines).\nLet\u0026rsquo;s use the request Context to pass it to the slowAPICall function as an argument:\nfunc slowAPICall(ctx context.Context) string { d := rand.Intn(5) select { case \u0026lt;-time.After(time.Duration(d) * time.Second): log.Printf(\u0026#34;Slow API call done after %d seconds.\\n\u0026#34;, d) return \u0026#34;foobar\u0026#34; } } func slowHandler(w http.ResponseWriter, r *http.Request) { result := slowAPICall(r.Context()) io.WriteString(w, result+\u0026#34;\\n\u0026#34;) } Now that we utilize the request context, how can we put it in action? The Context type has a Done attribute, which is of type \u0026lt;-chan struct{}. Done closes when the work done on behalf of the context should be canceled, which is what we need in the example.\nLet\u0026rsquo;s handle the ctx.Done channel in the select block in the slowAPICall function. When we receive an empty struct via the Done channel, this signifies the context cancellation, and we have to return a zero-value string from the slowAPICall function:\nfunc slowAPICall(ctx context.Context) string { d := rand.Intn(5) select { case \u0026lt;-ctx.Done(): log.Printf(\u0026#34;slowAPICall was supposed to take %s seconds, but was canceled.\u0026#34;, d) return \u0026#34;\u0026#34; case \u0026lt;-time.After(time.Duration(d) * time.Second): log.Printf(\u0026#34;Slow API call done after %d seconds.\\n\u0026#34;, d) return \u0026#34;foobar\u0026#34; } } (This is the reason we used a select block, instead of the time.Sleep - we can just handle the Done channel in the select here.)\nIn our limited example, this does the trick – when we receive value through the Done channel, we log a line to STDOUT and return an empty string. In more complicated situations, such as sending real API requests, you might need to close down connections or clean up file descriptors.\nLet\u0026rsquo;s spin up the server again and send a cURL request:\n# The cURL command: $ curl localhost:8888 Timeout! # The server output: $ go run server.go 2019/12/30 00:07:15 slowAPICall was supposed to take 2 seconds, but was canceled. So check this out: we ran a cURL to the server, it took longer than 1 second, and our server canceled the slowAPICall function. And we didn\u0026rsquo;t need to write almost any code for it. The TimeoutHandler did this for us - when the handler took longer than expected, the TimeoutHandler stopped the execution of the handler and canceled the request context.\nThe TimeoutHandler performs the context cancellation in the timeoutHandler.ServeHTTP method:\n// Taken from: https://github.com/golang/go/blob/bbbc658/src/net/http/server.go#L3217-L3263 func (h *timeoutHandler) ServeHTTP(w ResponseWriter, r *Request) { ctx := h.testContext if ctx == nil { var cancelCtx context.CancelFunc ctx, cancelCtx = context.WithTimeout(r.Context(), h.dt) defer cancelCtx() } r = r.WithContext(ctx) // *Snipped* } Above, we use the request context by invoking context.WithTimeout on it. The timeout value h.dt, which is the second argument received by the TimeoutHandler, is applied to the context. The returned context is a copy of the request context with a timeout attached. Right after, it\u0026rsquo;s set as the request\u0026rsquo;s context using the r.WithContext(ctx) invocation.\nThe context.WithTimeout function makes the context cancellation. It returns a copy of the Context with a timeout set to the duration passed as an argument. Once it reaches the timeout, it cancels the context.\nHere\u0026rsquo;s the code that does it:\n// Taken from: https://github.com/golang/go/blob/bbbc6589/src/context/context.go#L486-L498 func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } // Taken from: https://github.com/golang/go/blob/bbbc6589/src/context/context.go#L418-L450 func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { // *Snipped*  c := \u0026amp;timerCtx{ cancelCtx: newCancelCtx(parent), deadline: d, } // *Snipped*  if c.err == nil { c.timer = time.AfterFunc(dur, func() { c.cancel(true, DeadlineExceeded) }) } return c, func() { c.cancel(true, Canceled) } } Here we meet deadlines again. The WithDeadline function sets a function that executes after the duration d passes. Once the duration passes, it invokes the cancel method on the context, which will close the done channel of the context and will set the context\u0026rsquo;s timer attribute to nil.\nThe closing of the Done channel effectively cancels the context, which allows our slowAPICall function to stop its execution. That\u0026rsquo;s how the TimeoutHandler timeouts long-running handlers.\n(If you would like to read the code that does the above, you should see the cancel functions on the cancelCtx type and the timerCtx type.)\nResilient net/http servers Connection deadlines provide low-level fine-grained control. While their names contain \u0026ldquo;timeout\u0026rdquo; they do not have the behavior that folks commonly expect from timeouts. They are in fact very powerful, but they expect the programmer to know how to wield that weapon.\nOn the other hand, when working with HTTP handlers, the TimeoutHandler should be our go-to tool. The design chosen by the Go authors, of having composable handlers, provides flexibility, so much that we could even have different timeouts per handler if we decided to. TimeoutHandler provides execution control while maintaining the behavior that we commonly expect when thinking of timeouts.\nOn top of that, the TimeoutHandler works well with the context package. While the context package is simple, it carries cancellation signals and request-scoped data, that we can use to make our applications adhere better to the intricacies of networks.\nBefore we close, here are three suggestions on how to think of timeouts while writing your HTTP servers:\n Most-often, reach for TimeoutHandler. It does what we commonly expect of timeouts. Never forget context cancellations. The context package is simple to use and can save your servers lots of processing resources. Especially againts bad actors or misbehaving networks. By all means, use deadlines. Just make sure you test thoroughly that they provide you the functionality that you want.  To read more on the topic:\n \u0026ldquo;The complete guide to Go net/http timeouts\u0026rdquo; on Cloudflare\u0026rsquo;s blog \u0026ldquo;So you want to expose Go on the Internet\u0026rdquo; on Cloudflare\u0026rsquo;s blog \u0026ldquo;Use http.TimeoutHandler or ReadTimeout/WriteTimeout?\u0026rdquo; on Stackoverflow \u0026ldquo;Standard net/http config will break your production environment\u0026rdquo; on Simon Frey\u0026rsquo;s blog  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/make-resilient-golang-net-http-servers-using-timeouts-deadlines-context-cancellation/","summary":"When it comes to timeouts, there are two types of people: those who know how tricky they can be, and those who are yet to find out.\nAs tricky as they are, timeouts are a reality in the connected world we live in. As I am writing this, on the other side of the table, two persons are typing on their smartphones, probably chatting to people very far from them. All made possible because of networks.","title":"Make resilient Go net/http servers using timeouts, deadlines and context cancellation"},{"content":"One of the biggest misconceptions is that doubles are a specific implementation of mocks or other testing constructs that we use in testing.\nDummies, mocks, stubs, fakes, and spies ARE test doubles. Test double is the category of these test constructs. Over the years, there has been some confusion around this concept.\nIt is my observation that this confusion arises from the naming of testing constructs that the popular testing frameworks use. Also, the words mock and doubles have been used interchangeably over the years, and their definitions got skewed.\nIn any case, without further ado, let\u0026rsquo;s dive in and explore each of these categories of test doubles.\n  Dummies The simplest type of test double is a test dummy. In a nutshell, it means that the instance is just a placeholder for another one, but its functions do not return anything.\nLet\u0026rsquo;s imagine the following scenario. We have a Phonebook type that has a slice of Person as an attribute. Each Person has a FirstName, LastName, and Phone attributes. Also, the Phonebook has a Find method through which we can find a person\u0026rsquo;s phone number using their first and last names.\nThe Find method uses a Searcher object whose Search function it uses to find the entry in the slice of people. Searcher\u0026rsquo;s implementation is not essential at this moment.\npackage main import ( \u0026#34;errors\u0026#34; ) var ( ErrMissingArgs = errors.New(\u0026#34;FirstName and LastName are mandatory arguments\u0026#34;) ErrNoPersonFound = errors.New(\u0026#34;No person found\u0026#34;) ) type Searcher interface { Search(people []*Person, firstName string, lastName string) *Person } type Person struct { FirstName string LastName string Phone string } type Phonebook struct { People []*Person } func (p *Phonebook) Find(searcher Searcher, firstName, lastName string) (string, error) { if firstName == \u0026#34;\u0026#34; || lastName == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, ErrMissingArgs } person := searcher.Search(p.People, firstName, lastName) if person == nil { return \u0026#34;\u0026#34;, ErrNoPersonFound } return person.Phone, nil } Imagine we want to test the Find method of the Phonebook. How would you approach it? Here\u0026rsquo;s one way:\ntype DummySearcher struct{} func (ds DummySearcher) Search(people []*Person, firstName, lastName string) *Person { return \u0026amp;Person{} } func TestFindReturnsError(t *testing.T) { phonebook := \u0026amp;Phonebook{} want := ErrMissingArgs _, got := phonebook.Find(DummySearcher{}, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;) if got != want { t.Errorf(\u0026#34;Want \u0026#39;%s\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, want, got) } } To test that the Find method returns an error when one of the arguments is blank, we do not care about the implementation of the Searcher argument. In such cases, where the functionality of the injected dependency is irrelevant, all we need is an instance that we can just pass in, and the compiler won\u0026rsquo;t complain.\nSuch instances are called dummies. They are test doubles that have no functionality and that we don\u0026rsquo;t want people to use.\nStubs Using the same example from above, how would we test that the Find method when supplied the firstName and lastName arguments will work as expected?\ntype StubSearcher struct { phone string } func (ss StubSearcher) Search(people []*Person, firstName, lastName string) *Person { return \u0026amp;Person{ FirstName: firstName, LastName: lastName, Phone: ss.phone, } } func TestFindReturnsPerson(t *testing.T) { fakePhone := \u0026#34;+31 65 222 333\u0026#34; phonebook := \u0026amp;Phonebook{} phone, _ := phonebook.Find(StubSearcher{fakePhone}, \u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;) if phone != fakePhone { t.Errorf(\u0026#34;Want \u0026#39;%s\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, fakePhone, phone) } } When we want to make the Searcher implementation return an actual value that we can assert against, we need a stub. Instead of understanding what it would take to set up and/or implement a proper Searcher, you just create a stub implementation that returns only one value. This is the idea behind stubs.\nSpies Again, using the Phonebook and Searcher example from above, let\u0026rsquo;s imagine we would like to write a test where we want to be sure we invoke the Searcher.Search function. How can we do that?\ntype SpySearcher struct { phone string searchWasCalled bool } func (ss *SpySearcher) Search(people []*Person, firstName, lastName string) *Person { ss.searchWasCalled = true return \u0026amp;Person{ FirstName: firstName, LastName: lastName, Phone: ss.phone, } } func TestFindCallsSearchAndReturnsPerson(t *testing.T) { fakePhone := \u0026#34;+31 65 222 333\u0026#34; phonebook := \u0026amp;Phonebook{} spy := \u0026amp;SpySearcher{phone: fakePhone} phone, _ := phonebook.Find(spy, \u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;) if !spy.searchWasCalled { t.Errorf(\u0026#34;Expected to call \u0026#39;Search\u0026#39; in \u0026#39;Find\u0026#39;, but it wasn\u0026#39;t.\u0026#34;) } if phone != fakePhone { t.Errorf(\u0026#34;Want \u0026#39;%s\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, fakePhone, phone) } } You can think of spies as an upgrade of stubs. While they return a predefined value, just like stubs, spies also remember whether we called a specific method. Often, spies also keep track of how many times we call a particular function.\nThat\u0026rsquo;s what spy is - a stub that keeps track of invocations of its methods.\nMocks In the beginning, people started using mock for similar (but not the same) things, and the word got left hanging in the air without a proper definition. Some think of stubs as mocks; others do not even think of mocks as types of instances.\nIt\u0026rsquo;s generally accepted to use “mocking” when thinking about creating objects that simulate the behavior of real objects or units.\nBut mocks are a thing of their own. They have the same characteristics as the stubs \u0026amp; spies, with a bit more.\nAlso, in Go, they are a bit tricky to implement, especially in a generic way. Still, for this example, we will do a home-made implementation:\ntype MockSearcher struct { phone string methodsToCall map[string]bool } func (ms *MockSearcher) Search(people []*Person, firstName, lastName string) *Person { ms.methodsToCall[\u0026#34;Search\u0026#34;] = true return \u0026amp;Person{ FirstName: firstName, LastName: lastName, Phone: ms.phone, } } func (ms *MockSearcher) ExpectToCall(methodName string) { if ms.methodsToCall == nil { ms.methodsToCall = make(map[string]bool) } ms.methodsToCall[methodName] = false } func (ms *MockSearcher) Verify(t *testing.T) { for methodName, called := range ms.methodsToCall { if !called { t.Errorf(\u0026#34;Expected to call \u0026#39;%s\u0026#39;, but it wasn\u0026#39;t.\u0026#34;, methodName) } } } func TestFindCallsSearchAndReturnsPersonUsingMock(t *testing.T) { fakePhone := \u0026#34;+31 65 222 333\u0026#34; phonebook := \u0026amp;Phonebook{} mock := \u0026amp;MockSearcher{phone: fakePhone} mock.ExpectToCall(\u0026#34;Search\u0026#34;) phone, _ := phonebook.Find(mock, \u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;) if phone != fakePhone { t.Errorf(\u0026#34;Want \u0026#39;%s\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, fakePhone, phone) } mock.Verify(t) } This approach is more involved, but there\u0026rsquo;s no magic to it. The MockSearcher implementation has a methodsToCall map, which will store all of the methods that we expect to call on an instance of this type.\nThe ExpectToCall method will take a method name as an argument. It will store the method to the methodsToCall map (as the key) and a false as the value. By setting it to false, we set a mark on that method that we expect to call it (yet we still haven\u0026rsquo;t called it).\nIn MockSearcher\u0026rsquo;s Search method, we mark the Search method as called. We do this by setting the true value for the \u0026quot;Search\u0026quot; key in the methodsToCall map. In essence, the key we\u0026rsquo;ve set to false in the ExpectToCall method we set to true here.\nLastly, the Verify method will go over all of the methods that we marked as to-be-called on the mock. If it finds one still set to false, it will mark the test as failed.\nMocks work by setting certain expectations on them. We implement some stub-like functionality while keeping track of the methods that have been called. Finally, we ask the mock to verify if our code met all of its expectations.\nIt\u0026rsquo;s worth stating that this is a home-made solution, and as such, it has some caveats. If you would like to use mocks in your tests, there are some excellent Golang libraries out there like golang/mock or stretchr/testify.\nFakes These test doubles, unlike stubs, spies, and mocks, truly have an implementation. In our example, this would mean that a fake would have an actual implementation of the Search method.\nLet\u0026rsquo;s see a Searcher fake in action:\ntype FakeSearcher struct{} func (fs FakeSearcher) Search(people []*Person, firstName string, lastName string) *Person { if len(people) == 0 { return nil } return people[0] } func TestFindCallsSearchAndReturnsEmptyStringForNoPerson(t *testing.T) { phonebook := \u0026amp;Phonebook{} fake := \u0026amp;FakeSearcher{} phone, _ := phonebook.Find(fake, \u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;) if phone != \u0026#34;\u0026#34; { t.Errorf(\u0026#34;Wanted \u0026#39;\u0026#39;, got \u0026#39;%s\u0026#39;\u0026#34;, phone) } } What you see is a FakeSearcher type, who\u0026rsquo;s Search method has an implementation that (kinda) makes sense. If the slice of *Person is empty, it will return nil. Otherwise, it will return the first item in the slice.\nWhile this Search method is not production-ready, because it doesn\u0026rsquo;t make much sense, it still has the behavior of a fake Searcher. If we didn\u0026rsquo;t have it\u0026rsquo;s implementation accessible (looking at it as a black box), one could think it\u0026rsquo;s the real deal instead of a fake.\nThat\u0026rsquo;s what fakes are - implementations that look like the real thing. But they only do the trick in the scope of the test.\nAnother such familiar example in the community is an in-memory database driver used as fake to a real database driver.\nWhen To Use What Now that we went through all of the test doubles and their implementations, the last question that we need to answer is: what test double should we use in which circumstances?\nAs with many other things in software development, the answer is: it depends.\nYou must keep in mind is what are you really testing. That is also known as the unit under test. If the unit under test requires a double of any sort, you should provide the simplest test double that will make your test do its work and that it will suffice to make the test pass.\nSo, refrain from using bloated mocks if a stub does the trick. The rule of thumb is: use the simplest test double that you can. And after the test passes, see if you can refactor and simplify further.\nAnd lastly, make sure not to downright mock out everything – sometimes invoking the actual implementation (e.g., like in an integration test) can be a great idea.\nAdditional reading:\n \u0026ldquo;The Little Mocker\u0026rdquo; by Uncle Bob \u0026ldquo;TestDouble\u0026rdquo; by Martin Fowler \u0026ldquo;Testing on the Toilet: Know Your Test Doubles\u0026rdquo; by Andrew Trenk  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-test-doubles-by-example/","summary":"One of the biggest misconceptions is that doubles are a specific implementation of mocks or other testing constructs that we use in testing.\nDummies, mocks, stubs, fakes, and spies ARE test doubles. Test double is the category of these test constructs. Over the years, there has been some confusion around this concept.\nIt is my observation that this confusion arises from the naming of testing constructs that the popular testing frameworks use.","title":"Testing in Go: Test Doubles by Example"},{"content":"In software engineering, over the years folks have developed many patterns, techniques and refactoring maneuvers. Some have been long forgotten, while others have stood the test of times.\nSuch a long-standing technique is dependency injection. It is a concept and a programming technique where a construct is passed (injected) to another construct that depends on it.\nIn Golang, like in other languages, we use it to simplify our code and make it more testable. But, how much more? Let\u0026rsquo;s code through an example and see how dependency injection can help us out.\nSending notifications Imagine we are building an e-commerce website where people buy goods and we ship them the goods. When their order ships, we want to inform them through a notification.\nLet\u0026rsquo;s look at a very simple simulation of sending an SMS notification over an API:\npackage notifications import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/fteem/order-notifications/sms\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) func InformOrderShipped(receiver user.User, orderID string) bool { message := fmt.Sprintf(\u0026#34;Your order #%s is shipped!\u0026#34;, orderID) err := sms.Send(receiver, message) if err != nil { return false } return true } For the sake of the example, we\u0026rsquo;ll simulate a network call in the sms.Send with arbitrary sleep time, so the function takes a few seconds to execute:\npackage sms import ( \u0026#34;time\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) func Send(receiver user.User, message string) error { // Simulating API call... \ttime.Sleep(3 * time.Second) return nil } Let us see a simple test for the InformOrderShipped function and what kind of challenges it brings:\npackage notifications import \u0026#34;testing\u0026#34; func TestInformOrderShipped(t *testing.T) { user := User{ Name: \u0026#34;Peggy\u0026#34;, Phone: \u0026#34;+12 345 678 999\u0026#34;, } orderID := \u0026#34;12345\u0026#34; got := InformOrderShipped(user, orderID) want := true if want != got { t.Errorf(\u0026#34;Want \u0026#39;%t\u0026#39;, got \u0026#39;%t\u0026#39;\u0026#34;, want, got) } } While these tests do test the functionality of InformOrderShipped, it already has two issues:\n It lasts three seconds because of invoking sms.Send sleeps for three seconds. There\u0026rsquo;s no way to easily test what would happen if sms.Send actually returns an error.  Issue number one is something we can ignore for now, as it\u0026rsquo;s only a side-effect of the implementation of sms.Send. Issue number two, the lack of an easy way to mock sms.Send, is larger so we will address it first.\nInjecting the ability to send SMSes The simplest maneuver we can do in InformOrderShipped, instead of depending on the sms package, is to pass in the Send function as a function closure argument:\npackage notifications import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) func InformOrderShipped(receiver user.User, orderID string, sendSMS func(user.User, string) error) bool { message := fmt.Sprintf(\u0026#34;Your order #%s is shipped!\u0026#34;, orderID) err := sendSMS(receiver, message) if err != nil { return false } return true } Because Go allows us to provide the function as an argument, all we need to do is to specify its arguments and return types and invoke it in the main function. Just by having this in place, we achieve:\n Injecting the dependency on the sms.Send function, using a type rather then importing the actual function. We remove the explicit dependency on the sms package. We make our code easy to mock and test.  To prove these points, we will modify the test to include the two scenarios, when the SMS is successfully sent and when it returns an error:\npackage notifications import ( \u0026#34;errors\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) func TestInformOrderShipped(t *testing.T) { cases := []struct { user user.User orderID string sendingError error name string want bool }{ { user: user.User{\u0026#34;Peggy\u0026#34;, \u0026#34;+12 345 678 999\u0026#34;}, orderID: \u0026#34;12345\u0026#34;, sendingError: nil, want: true, name: \u0026#34;Successful send\u0026#34;, }, { user: user.User{\u0026#34;Peggy\u0026#34;, \u0026#34;+12 345 678 999\u0026#34;}, orderID: \u0026#34;12345\u0026#34;, sendingError: errors.New(\u0026#34;Sending failed\u0026#34;), want: false, name: \u0026#34;Unsuccessful send\u0026#34;, }, } for _, tc := range cases { t.Run(tc.name, func(t *testing.T) { mockSend := func(user.User, string) error { return tc.sendingError } got := InformOrderShipped(tc.user, tc.orderID, mockSend) if tc.want != got { t.Errorf(\u0026#34;Want \u0026#39;%t\u0026#39;, got \u0026#39;%t\u0026#39;\u0026#34;, tc.want, got) } }) } } In the test we use the table-driven approach, where we define two different test cases: when the SMS sending fails and when it does not.\nBecause our InformOrderShipped function expects a function as a third argument, in our test we create a function mock that has no functionality but returning an error value.\nThis allows us to pass in the mocked function, easily control its return value and avoid waiting for three seconds for the test to finish. We decouple our code, we make it more testable and, on top of that, it executes instantly.\nBut, can we take this further?\nNotifications are more than SMS SMSes are a bit outdated. Nowadays we very often rely on our cellular internet connections, native apps and push notifications to get real-time information about our orders. Also, as much as we dislike it, email is still the online communication king.\nBut you know what\u0026rsquo;s the best of the three? All of them. People want to be kept in the know, especially when the items that they spend their hard-earned monies on have been dispatched.\nSo, how can we make our code even more flexible, while keeping it easy to test and maintain?\nInterfaces to the rescue!\nGolang interfaces are a powerful construct. They are simple, named collections of method signatures. Interfaces are implicitly implemented, meaning a type implements an interface by implementing the functions specified in the interface. No need for explicit implements statements. (Yes, like yours Java.)\nLet\u0026rsquo;s introduce an interface called Sender, which defines a Send function:\ntype Sender interface { Send(user.User, string) error } Those of you that are very attentive will notice that the Send function in Sender has the same signature as the sms.Send function from the earlier example. That\u0026rsquo;s intentional - we want any implementor of the Sender interface to be able to send a notification to a User.\nLet\u0026rsquo;s make a sms.Dispatcher type which will implement the Sender interface and use it in our code:\npackage sms import ( \u0026#34;time\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) type Dispatcher struct{} func (d Dispatcher) Send(receiver user.User, message string) error { // Simulating API call... \ttime.Sleep(3 * time.Second) return nil } Now, we can pass an instance of the Dispatcher type in the InformOrderShipped function, which will invoke its Send function. Given that we already have the Sender interface defined, we can use it as an argument:\nfunc InformOrderShipped(receiver user.User, orderID string, sender Sender) bool { message := fmt.Sprintf(\u0026#34;Your order #%s is shipped!\u0026#34;, orderID) err := sender.Send(receiver, message) if err != nil { return false } return true } Why? Well, Dispatcher already implements the Sender function, which means that we can pass an instance and it will work. Here\u0026rsquo;s an example:\npackage main import ( \u0026#34;github.com/fteem/order-notifications/orders\u0026#34; \u0026#34;github.com/fteem/order-notifications/sms\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) func main() { u := user.User{\u0026#34;Peggy\u0026#34;, \u0026#34;+123 456 789\u0026#34;} orderID := \u0026#34;123\u0026#34; dispatcher := sms.Dispatcher{} orders.InformOrderShipped(u, orderID, dispatcher) } How does such a change influence our tests? Interestingly, it doesn\u0026rsquo;t. While we lose the ability to pass in a function closure as an argument, we can still create a mock type that implements the Sender interface and use it as argument to the InformOrderShipped function:\npackage orders import ( \u0026#34;errors\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) type mockSender struct { sendingError error } func (ms mockSender) Send(u user.User, m string) error { return ms.sendingError } func TestInformOrderShipped(t *testing.T) { cases := []struct { user user.User orderID string sendingError error name string want bool }{ { user: user.User{\u0026#34;Peggy\u0026#34;, \u0026#34;+12 345 678 999\u0026#34;}, orderID: \u0026#34;12345\u0026#34;, sendingError: nil, want: true, name: \u0026#34;Successful send\u0026#34;, }, { user: user.User{\u0026#34;Peggy\u0026#34;, \u0026#34;+12 345 678 999\u0026#34;}, orderID: \u0026#34;12345\u0026#34;, sendingError: errors.New(\u0026#34;Sending failed\u0026#34;), want: false, name: \u0026#34;Unsuccessful send\u0026#34;, }, } for _, tc := range cases { t.Run(tc.name, func(t *testing.T) { ms := mockSender{tc.sendingError} got := InformOrderShipped(tc.user, tc.orderID, ms) if tc.want != got { t.Errorf(\u0026#34;Want \u0026#39;%t\u0026#39;, got \u0026#39;%t\u0026#39;\u0026#34;, tc.want, got) } }) } } Just a simple mockSender type does the trick. Because it implements the Send function and due to Go\u0026rsquo;s implicitly implementing interfaces mockSender is also a Sender. That means we can use it as an argument to the InformOrderShipped function.\nThe flexibility that the Sender interface provides us cannot be overstated. Although the example is small and trivial, introducing another type of notification for the InformOrderShipped is simple:\npackage push import ( \u0026#34;time\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) type Notifier struct{} func (n Notifier) Send(receiver user.User, message string) error { // Simulating API call... \ttime.Sleep(1 * time.Second) return nil } This would result in no changes in the InformOrderShipped function, while the Notifier\u0026rsquo;s Send method can be used as the one of the Dispatcher:\npackage main import ( \u0026#34;github.com/fteem/order-notifications/orders\u0026#34; \u0026#34;github.com/fteem/order-notifications/push\u0026#34; \u0026#34;github.com/fteem/order-notifications/sms\u0026#34; \u0026#34;github.com/fteem/order-notifications/user\u0026#34; ) func main() { dispatcher := sms.Dispatcher{} notifier := push.Notifier{} u := user.User{\u0026#34;Peggy\u0026#34;, \u0026#34;+123 456 789\u0026#34;} orderID := \u0026#34;123\u0026#34; orders.InformOrderShipped(u, orderID, dispatcher) orders.InformOrderShipped(u, orderID, notifier) } With dependency injection in action, we were able not only to decouple our InformOrderShipped function from the sms package, but also by using an interface for dependency injection we got to use polymorphism. Simply put, polymorphism through interfaces allowed us to send SMSes and push notifications in the same InformOrderShipped function.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-dependency-injection/","summary":"In software engineering, over the years folks have developed many patterns, techniques and refactoring maneuvers. Some have been long forgotten, while others have stood the test of times.\nSuch a long-standing technique is dependency injection. It is a concept and a programming technique where a construct is passed (injected) to another construct that depends on it.\nIn Golang, like in other languages, we use it to simplify our code and make it more testable.","title":"Testing in Go: Dependency Injection"},{"content":"One of the most feature-full ORMs for Go that I have worked with is Gorm. If you would like to learn more about it, I recommend checking out its official website and its documentation.\n  Recenlty I wanted to write a small database seeding abstraction. Database seeding is a process in which an initial set of data is provided to a database when it is being set up or installed.\nYet, in true Go fashion my goal was to keep the abstraction tiny, yet provide some structure to folks that would write seeds in this application. This is absolutely not the only way you can achieve this, the options are plenty. Still, this is one approach that I have found to be working well.\nWe will have three different components:\n Create a Seed abstraction. Identify path for the seeds and how to collect them in a single seeds package. Create a seeder command line tool that can run the seeds against a database.  First, to define a small Seed type that would be coupled to the gorm.DB connection instance:\n// pkg/seed/seed.go package seed import ( \u0026#34;github.com/jinzhu/gorm\u0026#34; ) type Seed struct { Name string Run func(*gorm.DB) error } Next, we need to define a path where we\u0026rsquo;ll store the seeds and how to collect them:\n// pkg/seeds/seeds.go package seeds import ( \u0026#34;github.com/fteem/seeding/pkg/seed\u0026#34; ) func All() []seed.Seed { return []seed.Seed{} } The seeds package will contain all instances of seed.Seed and collect them in the All function. This will allow the third component, a CLI tool, to iterate over them and execute them against a database. Additionally, in the same seeds package we can have separate files for seeding various types of data.\nFor example:\n// pkg/seeds/users.go package seeds func CreateUser(db *gorm.DB, name string, age int) error { return db.Create(\u0026amp;users.User{Name: name, Age: age}).Error } The usage of the function in All:\n// pkg/seeds/seeds.go import ( \u0026#34;github.com/fteem/seeding/pkg/seed\u0026#34; ) func All() []seed.Seed { return []seed.Seed{ seed.Seed{ Name: \u0026#34;CreateJane\u0026#34;, Run: func(db *gorm.DB) error { CreateUser(db, \u0026#34;Jane\u0026#34;, 30) }, }, seed.Seed{ Name: \u0026#34;CreateJohn\u0026#34;, Run: func(db *gorm.DB) error { CreateUser(db, \u0026#34;John\u0026#34;, 30) }, }, } } The example above is contrived, but it can work really well if you have to compose seeds using multiple such functions.\nLast, a very simple command line tool that can running the seeds we defined:\n// pkg/seeder/seeder.go package main import ( \u0026#34;log\u0026#34; \u0026#34;github.com/fteem/seeding/pkg/seeds\u0026#34; \u0026#34;github.com/jinzhu/gorm\u0026#34; _ \u0026#34;github.com/jinzhu/gorm/dialects/mysql\u0026#34; ) func main() { dbConn := openConnection() defer dbConn.Close() for _, seed := range seeds.All() { if err := seed.Run(dbConn); err != nil { log.Fatalf(\u0026#34;Running seed \u0026#39;%s\u0026#39;, failed with error: %s\u0026#34;, seed.Name, err) } } } func openConnection() *gorm.DB { db, err := gorm.Open(\u0026#34;mysql\u0026#34;, \u0026#34;user:password@/dbname?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Couldn\u0026#39;t establish database connection: %s\u0026#34;, err) } return db } The binary produced by this is quite a simple one: loads all of the seeds using the seeds.All function, iterates over the collection and executes their Run function. If an error occurs, the whole program bombs.\nThat\u0026rsquo;s it. Very thin and simple way to abstract away your database seeds using Gorm. Before you go, let me know in the comments how you approach database seeding.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/simple-golang-database-seeding-abstraction-gorm/","summary":"One of the most feature-full ORMs for Go that I have worked with is Gorm. If you would like to learn more about it, I recommend checking out its official website and its documentation.\n  Recenlty I wanted to write a small database seeding abstraction. Database seeding is a process in which an initial set of data is provided to a database when it is being set up or installed.","title":"Simple Golang database seeding abstraction for Gorm"},{"content":"When I was researching the topic of test fixtures, I couldn\u0026rsquo;t find much about their beginnings. My first search was about the name of the person who coined \u0026ldquo;test fixtures\u0026rdquo;. Unfortunately, that was not a fruitful endeavor. The next logical step was to look for the etymology of the phrase \u0026ldquo;test fixtures\u0026rdquo;, but the only search result that made sense was a Wikipedia page on the topic.\nJudging by the Wiki page, it\u0026rsquo;s clear that Ruby on Rails has heavily popularized test fixtures as a concept. Likely though, folks that have been in the industry for a longer time will say that the idea of test fixtures is older than Rails itself.\nTest fixtures contribute to setting up the system for the testing process by providing it with all the necessary data for initialization. The setup using fixtures is done to satisfy any preconditions there may be for the code under test. For example, code that we want to test might require some configuration before being executed or tested. In such cases, we would have to recreate these preconditions to run the code every time we have to test the code.\nMore annoyingly, if the configuration of the tested code would change, we would have to update the configuration structure everywhere where we test that particular code.\nTo avoid such scenarios, we use fixtures. Fixtures allow us to reliably and repeatably create the state our code relies on upon without worrying about the details. When the required state of the code under test changes, we need to tweak a fixture instead of scouring all tests for the code that needs changing.\nI know, I know. My introduction made you dizzy from all the praise of fixtures. So let\u0026rsquo;s stop the sales pitch here and move on to see how simple fixtures can be and how you can master them as another tool in your testing tool belt.\nMaking a simple grade book As always, when talking about code without having code to look at is not great. Let\u0026rsquo;s introduce an example representing a grade book populated from a CSV file, using a builder function. After, we will create a lookup method per column and add some tests for both functions.\ntype Record struct { student string subject string grade string } type Gradebook []Record The Record type will have three attributes: student, subject and grade, all three of type string. The Gradebook type is just a slice of Records, nothing more.\nNext, let\u0026rsquo;s create a builder function for a Gradebook. We want the function to be simple - receive a path to a CSV file as an argument and return a Gradebook with all of the records parsed from the CSV.\nfunc NewGradebook(csvFile io.Reader) (Gradebook, error) { var gradebook Gradebook reader := csv.NewReader(csvFile) for { line, err := reader.Read() if err == io.EOF { break } if err != nil { return gradebook, err } if len(line) \u0026lt; 3 { return gradebook, fmt.Errorf(\u0026#34;Invalid file structure\u0026#34;) } gradebook = append(gradebook, Record{ student: line[0], subject: line[1], grade: line[2], }) } return gradebook, nil } Although a bit bloated, the function doesn\u0026rsquo;t do much. It receives an io.Reader as an argument (which is the file reader), wraps it in a CSV reader, and reads it line by line. For each line it reads, it will create a new Record struct and append it to the collection of Record\u0026rsquo;s gradebook. After parsing the whole file, it will exit the loop and return the grade book.\nOf course, in true Go fashion, we gracefully handle the errors in every step of the reading and parsing the file. If there\u0026rsquo;s an error in any scenario, the function will return the error along with the empty gradebook.\nThe last piece of the puzzle is the function that will find all records in the grade book for a particular student:\nfunc (gb *Gradebook) FindByStudent(student string) []Record { var records []Record for _, record := range *gb { if student == record.student { records = append(records, record) } } return records } The FindByStudent function takes the student name as argument. First, it will loop through the Gradebook\u0026rsquo;s records and collect the records where the student name matches. Then, it will return the records found for the particular student name.\nTo manually test the code, let\u0026rsquo;s create a small CSV file, called grades.csv:\nJane,Chemistry,A John,Biology,A Jane,Algebra,B Jane,Biology,A John,Algebra,B John,Chemistry,C In the main function of the file, we will parse it and then get all of Jane\u0026rsquo;s grades:\nfunc main() { csvFile, err := os.Open(\u0026#34;grades.csv\u0026#34;) if err != nil { fmt.Println(fmt.Errorf(\u0026#34;error opening file: %v\u0026#34;, err)) } grades, err := NewGradebook(csvFile) fmt.Printf(\u0026#34;%+v\\n\u0026#34;, grades.FindByStudent(\u0026#34;Jane\u0026#34;)) } The output of the function will be:\n$ go run grades.go [{student:Jane subject:Chemistry grade:A} {student:Jane subject:Algebra grade:B} {student:Jane subject:Biology grade:A}] From the output, it is clear what are Jane\u0026rsquo;s grades in the grade book we have created. Having these two types and two functions is good enough to explain how we can use fixtures in the testing we\u0026rsquo;re about to do.\nTesting the builder function Whenever we need to test a piece of code, we have to identify its key components. In other words, we have to understand the essential steps that that code takes to accomplish its mission. For example, to test the NewGradebook function, an overly simplified breakdown of its doings would look like:\n Read through each of the lines of the CSV When reading through each line, create a new struct from the data Put the new struct in the collection of structs Return the collection of structs  Now, there\u0026rsquo;s no need to test if opening a file and parsing it works - we trust Go to take care of that. So instead, we are interested in two things: will our function handle invalid CSV files gracefully, and will it create a Gradebook that we expect from a valid file?\nTo test the error handling, we will introduce a test function:\nfunc TestNewGradebook_ErrorHandling(t *testing.T) { cases := []struct { fixture string returnErr bool name string }{ { fixture: \u0026#34;testdata/grades/empty.csv\u0026#34;, returnErr: false, name: \u0026#34;EmptyFile\u0026#34;, }, { fixture: \u0026#34;testdata/grades/invalid.csv\u0026#34;, returnErr: true, name: \u0026#34;InvalidFile\u0026#34;, }, { fixture: \u0026#34;testdata/grades/valid.csv\u0026#34;, returnErr: false, name: \u0026#34;ValidFile\u0026#34;, }, } for _, tc := range cases { t.Run(tc.name, func(t *testing.T) { _, err := NewGradebook(tc.fixture) returnedErr := err != nil if returnedErr != tc.returnErr { t.Fatalf(\u0026#34;Expected returnErr: %v, got: %v\u0026#34;, tc.returnErr, returnedErr) } }) } } To run these test cases, we will need three accompanying CSV files in the root of our project: empty.csv, invalid.csv and valid.csv. An empty CSV, an invalid CSV and a valid CSV file, respectively.\nEach of these files is fixtures - files that go together with the test suite, enabling us to assume the state of the system that we run our tests on. Now, the content of these files should be evident from the file names. The invalid.csv will contain just text, but not in a CSV format. The empty.csv will be just an empty file, while the valid.csv file will be a real CSV that our function can parse and use. Lastly, the nonexisting.csv actually will not be a file – we want our tests to fail when this path is passed to the NewGradebook function. And this is the first thing we need to remember about fixtures: we can (and should) create as many fixture files as it makes sense, but not more.\nFixtures should always be placed in a directory (in our example testdata) at the root of our project. We should always put our fixtures in the testdata directory at the root of our project because go test will ignore that path when building our packages. Quoting the output of go help test:\n The go tool will ignore a directory named \u0026ldquo;testdata\u0026rdquo;, making it available to hold ancillary data needed by the tests.\n Placing it in the root of the package works great because when we run go test, for each package in the directory tree, go test will execute the test binary with its working directory set to the source directory of the package under test. (Read more about it in Dave Cheney\u0026rsquo;s article on the topic.)\nIn the example above, we used two nested directories: testdata and grades. We use two nested directories because we want to logically group our fixtures and leave the room for another kind of fixtures within the same project if need be. Software is built to grow, so why not set some sane defaults from the start.\nTesting the FindByStudent function The functionality of the FindByStudent function is a linear search through a Gradebook type (which is a slice of Record\u0026rsquo;s). It compares the student name from the argument and the name of each of the records in the Gradebook. When a match is found, the matching record is added to the collection records.\nTesting this function is can be based on a couple of state assumptions. The first one is to test FindByStudent we have to have a Gradebook available. The Gradebook can be in three states: empty, without a matching Record, and with a Record that matches the student name from the argument. If we flipped this on its head, it would mean that to test the function, we will need three different Gradebooks: one empty, one without a matching Record, and one with a matching Record.\nTo create such Gradebook\u0026rsquo;s, we can take two different approaches: define the Gradebook\u0026rsquo;s directly in the test or use a fixture file. Using the first approach might be preferable, but we will use the second approach to see how we can use fixtures. While we already have the fixture files from the previous test, we can use them in the test of the FindByStudent function:\nfunc TestFindByStudent(t *testing.T) { cases := []struct { fixture string student string want Gradebook name string }{ { fixture: \u0026#34;fixtures/grades/empty.csv\u0026#34;, student: \u0026#34;Jane\u0026#34;, want: Gradebook{}, name: \u0026#34;EmptyFixture\u0026#34;, }, { fixture: \u0026#34;fixtures/grades/valid.csv\u0026#34;, student: \u0026#34;Jane\u0026#34;, want: Gradebook{ Record{ student: \u0026#34;Jane\u0026#34;, subject: \u0026#34;Chemistry\u0026#34;, grade: \u0026#34;A\u0026#34;, }, Record{ student: \u0026#34;Jane\u0026#34;, subject: \u0026#34;Algebra\u0026#34;, grade: \u0026#34;A\u0026#34;, }, }, name: \u0026#34;ValidFixtures\u0026#34;, }, } for _, tc := range cases { t.Run(tc.name, func(t *testing.T) { gradebook, err := NewGradebook(tc.fixture) if err != nil { t.Fatalf(\u0026#34;Cannot create gradebook: %v\u0026#34;, err) } got := gradebook.FindByStudent(tc.student) for idx, gotGrade := range got { wantedGrade := tc.want[idx] if gotGrade != wantedGrade { t.Errorf(\u0026#34;Expected: %v, got: %v\u0026#34;, wantedGrade, gotGrade) } } }) } } In this test function, we have defined two test cases: the first one uses the empty.csv fixture, while the other uses the valid.csv fixture. By looking at the test cases, it is clear what we expect to get from each one. For example, when working with the empty CSV, we hope to get a blank grade book - no grades, no grade book. But, on the other hand, when working with the valid.csv we expect to get a Gradebook, with all student grades specified.\nThe test function does not have any magic. It merely builds a Gradebook using the NewGradebook function and the fixture file. Then, we invoke the FindByStudent function on the Gradebook, and we make sure that all of the grades that we got are the ones we expected.\nIf we run the test, we\u0026rsquo;ll get an output looking like this:\n$ go test -v -run=TestFindByStudent === RUN TestFindByStudent === RUN TestFindByStudent/EmptyFixture === RUN TestFindByStudent/ValidFixture --- PASS: TestFindByStudent (0.00s) --- PASS: TestFindByStudent/EmptyFixture (0.00s) --- PASS: TestFindByStudent/ValidFixture (0.00s) PASS ok _/Users/Ilija/Documents/fixtures\t0.004s The tests pass - building the Gradebooks with the fixtures worked well, so we could range over the test cases and test our expectations.\nTidying up our tests Looking at both test functions that we wrote at the beginning of the t.Run blocks, we can notice that we have to create a new Gradebook using the NewGradebook builder function. In essence, this is the test setup in these two test functions - we have to have an instance of the Gradebook type to run our tests.\nWhen we use fixtures, the failure to use a fixture can mean that we can\u0026rsquo;t run the tests - they depend on the fixture files being available and usable. If the fixture renders to be unusable, we have to stop the tests further and bail out with an error.\nIt is a quick win to extract a test helper to use in the test setup for such reasons. We can extract all error handling for loading the fixture and test setup outside of the test functions. Let\u0026rsquo;s create a small function that will do just that:\nfunc buildGradebook(t *testing.T, path string) *Gradebook { gradebook, err := NewGradebook(path) if err != nil { t.Fatalf(\u0026#34;Cannot create Gradebook: %v\u0026#34;, err) } return \u0026amp;gradebook } The buildGradebook is simply a wrapper around the call to NewGradebook, with one key difference: if a Gradebook cannot be produced using NewGradebook it will mark the test as failed. Signaling the failure is done using t.Fatalf, where instead of returning an empty Gradebook, we immediately make the test fail. In other words: being unable to create a Gradebook is an unrecoverable error. A nice side-effect is that the caller function of buildGradebook does not need to handle the error that might be returned from NewGradebook - that will all be handled by buildGradebook.\nIf we revisit our TestFindByStudent function now, it will not have changed much. Still, it will contain the improvements coming from the buildGradebook function:\nfunc TestFindByStudent(t *testing.T) { cases := []struct { fixture string student string want Gradebook name string }{ { fixture: \u0026#34;fixtures/grades/empty.csv\u0026#34;, student: \u0026#34;Jane\u0026#34;, want: Gradebook{}, name: \u0026#34;EmptyFixture\u0026#34;, }, { fixture: \u0026#34;fixtures/grades/valid.csv\u0026#34;, student: \u0026#34;Jane\u0026#34;, want: Gradebook{ Record{ student: \u0026#34;Jane\u0026#34;, subject: \u0026#34;Chemistry\u0026#34;, grade: \u0026#34;A\u0026#34;, }, Record{ student: \u0026#34;Jane\u0026#34;, subject: \u0026#34;Algebra\u0026#34;, grade: \u0026#34;A\u0026#34;, }, }, name: \u0026#34;ValidFixture\u0026#34;, }, } for _, tc := range cases { t.Run(tc.name, func(t *testing.T) { gradebook := buildGradebook(t, tc.fixture) got := gradebook.FindByStudent(tc.student) for idx, gotGrade := range got { wantedGrade := tc.want[idx] if gotGrade != wantedGrade { t.Errorf(\u0026#34;Expected: %v, got: %v\u0026#34;, wantedGrade, gotGrade) } } }) } } If we would remove any of the fixture files, we will see how the test will be marked as failed due to the t.Fatal invocation:\n$ rm testdata/grades/valid.csv # We remove the fixture $ go test ./... -count=1 -v -run=TestFindByStudent === RUN TestFindByStudent === RUN TestFindByStudent/ValidFixture === RUN TestFindByStudent/EmptyFixture --- FAIL: TestFindByStudent (0.00s) --- FAIL: TestFindByStudent/ValidFixture (0.00s) grades_test.go:8: Cannot create Gradebook: open testdata/grades/valid.csv: no such file or directory --- PASS: TestFindByStudent/EmptyFixture (0.00s) FAIL FAIL\t_/Users/Ilija/Documents/fixtures\t0.004s By having another function that takes care of building the Gradebook, we can offload the complexity of the missing fixtures outside of the tests themselves. While these concepts are simple, they\u0026rsquo;re powerful as they lead to cleaner tests with local test functions that are easy to maintain.\nEDIT October 8, 2019: As Andreas Schröpfer suggested in the comments, it\u0026rsquo;s more idiomatic Go when the function receives a io.Reader instead of a file path. I have updated the example code and the article to reflect that. Thanks Andreas!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-fixtures/","summary":"When I was researching the topic of test fixtures, I couldn\u0026rsquo;t find much about their beginnings. My first search was about the name of the person who coined \u0026ldquo;test fixtures\u0026rdquo;. Unfortunately, that was not a fruitful endeavor. The next logical step was to look for the etymology of the phrase \u0026ldquo;test fixtures\u0026rdquo;, but the only search result that made sense was a Wikipedia page on the topic.\nJudging by the Wiki page, it\u0026rsquo;s clear that Ruby on Rails has heavily popularized test fixtures as a concept.","title":"Testing in Go: Fixtures"},{"content":"Before we begin: The content in this article assumes knowledge of table-driven tests in Go. If you are unfamiliar with the concept, read this article to familiarize yourself.\nWith table-driven tests as the most popular testing approach, there is one annoying problem that every programmer will face: running selective tests. That\u0026rsquo;s because the traditional method of testing using table-driven tests in a single test function is not decomposable in granular subfunctions.\nIn other words, we cannot ask our go test tool to run a particular test case from a slice of test cases. Here\u0026rsquo;s an example of a small test function that uses table-driven tests:\nfunc TestOlder(t *testing.T) { cases := []struct { age1 int age2 int expected bool }{ // First test case \t{ age1: 1, age2: 2, expected: false, }, // Second test case \t{ age1: 2, age2: 1, expected: true, }, } for _, c := range cases { _, p1 := NewPerson(c.age1) _, p2 := NewPerson(c.age2) got := p1.older(p2) if got != c.expected { t.Errorf(\u0026#34;Expected %v \u0026gt; %v, got %v\u0026#34;, p1.age, p2.age, got) } } } There\u0026rsquo;s no need to understand what the function under test does, although you can figure it out by looking at the tests. How do I run the TestOlder function with the second test case without running the first case?\nWith the approach used above, that is not possible. go test -run regex can target function names based on the supplied regex. But it has no way of understanding the internals of the function.\nThat\u0026rsquo;s one reason Marcel van Lohuizen in 2016 proposed the addition of programmatic sub-tests and sub-benchmarks. The changes were added to the language as of version 1.7. You can read more about it in the proposal and the related discussion.\nWhat are subtests, and how do they work? Subtests are a construct in Go\u0026rsquo;s testing package that split our test functions into granular test processes. They unlock helpful functionality such as better handling of errors, more control over running tests, concurrency, and more straightforward code.\nThe actualization of subtests in the testing package is the Run method. It takes two arguments: the names of the subtest and the sub-test function. The name is an identifier of the subtests, which unlocks running a specific subtest using the go test command. Like with ordinary test functions, subtests are reported after the parent test function is done, meaning all subtests have finished running.\nWe will explore parallel tests in a different article, so feel free to ignore that part for now. If you would like to get familiar with it now, there is a good section about it on the official blog post about subtests.\nPlease note that there are caveats to parallel tests; that\u0026rsquo;s why we will look into them separately.\n Without going into too much detail, under the hood, Run runs the function in a separate goroutine and blocks until it returns or calls t.Parallel to become a parallel test. What happens under the hood and how subtests are architected is an exciting topic to explore. Yet, it\u0026rsquo;s pretty extensive to be covered in this article.\nHow to use t.Run Let\u0026rsquo;s look at the TestOlder function again, this time refactored to use t.Run for each of the test cases runs:\nfunc TestOlder(t *testing.T) { cases := []struct { name string age1 int age2 int expected bool }{ { name: \u0026#34;FirstOlderThanSecond\u0026#34;, age1: 1, age2: 2, expected: false, }, { name: \u0026#34;SecondOlderThanFirst\u0026#34;, age1: 2, age2: 1, expected: true, }, } for _, c := range cases { t.Run(c.name, func(t *testing.T) { _, p1 := NewPerson(c.age1) _, p2 := NewPerson(c.age2) got := p1.older(p2) if got != c.expected { t.Errorf(\u0026#34;Expected %v \u0026gt; %v, got %v\u0026#34;, p1.age, p2.age, got) } }) } } There are a few notable changes. We changed the struct of the cases to include a string attribute name. Each of the test cases has a name that describes the case itself. For example, the first case has the name FirstOlderThanSecond because age1 is larger than age2 in that case.\nNext, in the for loop, we wrap the whole test in a t.Run block, where the first argument is the name of the test case. The second argument is a function that will (not) mark the test as failed based on the inputs and expected output.\nIf we run the test, we\u0026rsquo;ll see something like this:\n$ go test -v -count=1 === RUN TestOlder === RUN TestOlder/FirstOlderThanSecond === RUN TestOlder/SecondOlderThanFirst --- PASS: TestOlder (0.00s) --- PASS: TestOlder/FirstOlderThanSecond (0.00s) --- PASS: TestOlder/SecondOlderThanFirst (0.00s) PASS ok person\t0.004s From the output, it\u0026rsquo;s noticeable that right after go test runs TestOlder it spawns off two more test functions: TestOlder/FirstOlderThanSecond and TestOlder/SecondOlderThanFirst. It\u0026rsquo;s worth noting that TestOlder will not finish running until these two functions exit.\nThe following few lines of the output paint that picture better because the output is nested. It makes it clear that TestOlder is a parent to the other two functions. The change in the output is due to spawning off two subtests in a test function. We should also note the naming of the subtests – they are prefixed with the function that spawns them.\nSelectively running subtests with go test As we already saw when using the traditional approach, running a specific test case is impossible. One of the pros of using subtests is that running only a particular subtest is straightforward and intuitive.\nReusing the examples from before, running any of the subtests is just a matter of supplying the full name of the subtest: its parent test function, followed by a slash and the subtest name.\nFor example, if we would like to run the subtest FirstOlderThenSecond from the TestOlder test function, we can execute:\n$ go test -v -count=1 -run=\u0026#34;TestOlder/FirstOlderThanSecond\u0026#34; === RUN TestOlder === RUN TestOlder/FirstOlderThanSecond --- PASS: TestOlder (0.00s) --- PASS: TestOlder/FirstOlderThanSecond (0.00s) PASS That\u0026rsquo;s it. Just by supplying the full name of the subtest, we can run a specific subtest. Remember, the -run flag can take any regex. So, if we would like to run all of the subtests under the TestOlder test, we can do it by providing an \u0026ldquo;umbrella\u0026rdquo; regex:\n$ go test -v -count=1 -run=\u0026#34;TestOlder\u0026#34; === RUN TestOlder === RUN TestOlder/FirstOlderThanSecond === RUN TestOlder/SecondOlderThanFirst --- PASS: TestOlder (0.00s) --- PASS: TestOlder/FirstOlderThanSecond (0.00s) --- PASS: TestOlder/SecondOlderThanFirst (0.00s) PASS By supplying TestOlder to the -run flag, we run both the TestOlder/FirstOlderThanSecond and the TestOlder/SecondOlderThanFirst subtests.\nShared Setup and Teardown Another somewhat hidden side of subtests is unlocking the ability to create isolated setup and teardown functions.\nThe setup function is run to set up a test\u0026rsquo;s state before the actual testing happens. For example, if we had to open a connection to a database and fetch some records used in the test, we would put such functionality in the setup function. In line with that, the teardown function of that test would close down the connection to the database and clean up the state. That\u0026rsquo;s because teardown functions are run after the test finishes.\nLet\u0026rsquo;s use our TestOlder function from earlier to explore how setup and teardown are made and how they work:\nfunc setupSubtest(t *testing.T) { t.Logf(\u0026#34;[SETUP] Hello 👋!\u0026#34;) } func teardownSubtest(t *testing.T) { t.Logf(\u0026#34;[TEARDOWN] Bye, bye 🖖!\u0026#34;) } func TestOlder(t *testing.T) { cases := []struct { name string age1 int age2 int expected bool }{ { name: \u0026#34;FirstOlderThanSecond\u0026#34;, age1: 1, age2: 2, expected: false, }, { name: \u0026#34;SecondOlderThanFirst\u0026#34;, age1: 2, age2: 1, expected: true, }, } for _, c := range cases { t.Run(c.name, func(t *testing.T) { setupSubtest(t) defer teardownSubtest(t) _, p1 := NewPerson(c.age1) _, p2 := NewPerson(c.age2) got := p1.older(p2) t.Logf(\u0026#34;[TEST] Hello from subtest %s \\n\u0026#34;, c.name) if got != c.expected { t.Errorf(\u0026#34;Expected %v \u0026gt; %v, got %v\u0026#34;, p1.age, p2.age, got) } }) } } We introduce two new functions here: setupSubtest and teardownSubtest. While they do not contain any particular functionality, understanding their invocation is essential here. Looking at the two lines where they are invoked, we can see that the setupSubtest is called right inside when the subtest is run.\nThe following line is where the teardownSubtest function is invoked, but this time using the defer keyword. It\u0026rsquo;s a feature of Go that we use to our advantage here: defer allows us to invoke a function that will execute at the end of the calling function. In other words, when the subtest function finishes, the teardownSubtest function will be invoked. Go makes setup and teardown functions easy with' defer': they are not separately defined or contain any remarkable setup. They are two simple functions that use Go\u0026rsquo;s built-in functionality.\nIf we rerun the test, we will see the following output:\n$ go test -v -count=1 -run=\u0026#34;TestOlder\u0026#34; === RUN TestOlder === RUN TestOlder/FirstOlderThanSecond === RUN TestOlder/SecondOlderThanFirst --- PASS: TestOlder (0.00s) --- PASS: TestOlder/FirstOlderThanSecond (0.00s) person_test.go:33: [SETUP] Hello 👋! person_test.go:71: [TEST] Hello from subtest FirstOlderThanSecond person_test.go:37: [TEARDOWN] Bye, bye 🖖! --- PASS: TestOlder/SecondOlderThanFirst (0.00s) person_test.go:33: [SETUP] Hello 👋! person_test.go:71: [TEST] Hello from subtest SecondOlderThanFirst person_test.go:37: [TEARDOWN] Bye, bye 🖖! PASS ok person\t0.005s We can see that the setup is always run before the teardown. By looking at the output, it is clear that the assertion and error marking are made in between. In cases where the assertion would fail, the particular subtest would be marked as failed, and Go will report the error at the end of the test run.\nTestMain Before we wrap up this post, we will look at one last feature that the testing package has: TestMain.\nThere are times when our test file has to do some extra setup or teardown before or after the tests in a file are run. Therefore, when a test file contains a TestMain function, the test will call TestMain(m *testing.M) instead of running the tests directly.\nThink of it in this way: every test file contains a \u0026ldquo;hidden\u0026rdquo; TestMain function, and its contents look something like this:\nfunc TestMain(m *testing.M) { os.Exit(m.Run()) } TestMain will run in the main goroutine, and it does the setup or teardown necessary around a call to m.Run. m.Run runs all of the test functions in the test file. TestMain will take the result of the m.Run invocation and then call os.Exit with the result as an argument. One important thing to note is that when we use TestMain, flag.Parse is not run, so if our tests depend on command-line flags, we have to call it explicitly.\nThere are a few use-cases where you would use TestMain: global startup and shutdown callbacks or other state setups. You can read some more in Chris Hines' 2015 article on the topic.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-subtests/","summary":"Before we begin: The content in this article assumes knowledge of table-driven tests in Go. If you are unfamiliar with the concept, read this article to familiarize yourself.\nWith table-driven tests as the most popular testing approach, there is one annoying problem that every programmer will face: running selective tests. That\u0026rsquo;s because the traditional method of testing using table-driven tests in a single test function is not decomposable in granular subfunctions.","title":"Testing in Go: Subtests"},{"content":"Coming from Ruby, which has excellent testing tools and libraries, the notion of table-driven tests was unusual for me. The widespread testing libraries in Ruby, such as RSpec, force the programmer to approach testing from a BDD standpoint. Thus, coming to Go and learning about the table-driven test was a new way of looking at tests for me.\nLooking back, Dave Cheney\u0026rsquo;s 2013 seminal blog post \u0026ldquo;Writing table driven-tests in Go\u0026rdquo; was very likely my gateway to table-driven tests. In it, he points out to the tests of the math [source] and time [source] packages, where The Go authors have used table-driven tests. I encourage you to go visit these two links, they offer a good perspective to testing in Go.\nI remember that at the beginning, the idea of table-driven tests was exceptionally provocative. The Rubyist in me was screaming, \u0026ldquo;What is this blasphemy?!\u0026rdquo;. \u0026ldquo;These weird for loops don\u0026rsquo;t seem right\u0026rdquo; and \u0026ldquo;What are these data structures that I have to define to run a simple spec!?\u0026rdquo; These were some of the first thoughts that came to my mind.\nThe approach is very far from bad. Go\u0026rsquo;s philosophy to testing is different from Ruby\u0026rsquo;s, yet it has an identical goal: make sure that our code works as expected so that we can sleep tight at night.\nLet\u0026rsquo;s explore table-driven tests, understand their background, the approach, and their pros and cons.\nWhat are table-driven tests? As the name suggests, these are tests that are driven by tables. So, you might be wondering, \u0026ldquo;what kind of tables?!\u0026rdquo;. Here\u0026rsquo;s the idea: every function under test has inputs and expected outputs.\nFor example, the function Max docs from the math package takes two arguments and has one return value. Both arguments are numbers of type float64, and the returned value is also a float64 number. So, when invoked, Max will return the larger number from the two arguments. So, Max has two inputs and one expected output. The output is one of the inputs.\nWhat would a test look like for Max? First, we would probably test its basic functionality, e.g., between 1 and 2, it will return 2. Also, we will probably test with negative numbers, e.g., between -100 and -200 it will return-100. Then, we will probably throw in a test that uses 0 or some arbitrary floating-point number. Finally, we can try the edge cases - huge and tiny numbers. Who knows, maybe we can hit some edge case.\nLooking at the above paragraph, the input values and the expected outcomes change. Still, the number of values that are in play is always the same, three: two arguments and one expected return value. Given that the value number is constant, we can put it in a table:\n   Argument 1 Argument 2 Code representation Expected return     1 2 Max(1, 2) 2   -100 -200 Max(-100, -200) -100   0 -200 Max(0, -200) 0   -100 0 Max(-100, 0) 0   100 0 Max(100, 0) 100   0 200 Max(0, 200) 200   100 0 Max(100, 0) 100   0 200 Max(0, 200) 200   -8.31373e-02 1.84273e-02 Max(-8.31373e-02, 1.84273e-02) 1.84273e-02    Following this idea, what if we would try to express this table in a very simple Go structure?\ntype TestCase struct { arg1 float64 arg2 float64 expected float64 } That should do the trick: it has three attributes of type float64: arg1, arg2 and expected. We are going to skip the third column as that is only there for more clarity.\nWhat about the data? Could we next add the data to a slice of TestCase? Let\u0026rsquo;s give it a shot:\nfunc TestMax(t *testing.T) { cases := []TestCase{ TestCase{ arg1: 1.0, arg2: 2.0, expected: 2.0, }, TestCase{ arg1: -100, arg2: -200, expected: -100, }, TestCase{ arg1: 0, arg2: -200, expected: 0, }, TestCase{ arg1: -8.31373e-02, arg2: 1.84273e-02, expected: 1.84273e-02, }, } } We intentionally omitted some of the cases for brevity and because what we have above clearly painted the picture. We have a test function already and cases of type []TestCase. The last piece of the puzzle is to iterate over the slice. For each of the TestCase structs invoke the Max function using the two arguments. Then, compare the expected attribute of the TestCase with the actual result of the invocation of Max.\nfunc TestMax(t *testing.T) { cases := []TestCase{ TestCase{ arg1: 1.0, arg2: 2.0, expected: 2.0, }, TestCase{ arg1: -100, arg2: -200, expected: -100, }, TestCase{ arg1: 0, arg2: -200, expected: 0, }, TestCase{ arg1: -8.31373e-02, arg2: 1.84273e-02, expected: 1.84273e-02, }, } for _, tc := range cases { got := math.Max(tc.arg1, tc.arg2) if got != tc.expected { t.Errorf(\u0026#34;Max(%f, %f): Expected %f, got %f\u0026#34;, tc.arg1, tc.arg2, tc.expected, got) } } } Let\u0026rsquo;s dissect the for loop:\nFor each of the cases, we invoke the math.Max function, with tc.arg1 andtc.arg2 as arguments. Then, we compare what the invocation returned with the expected value in tc.expected. The comparison will tells us if math.Max returned what we expected, and if that\u0026rsquo;s not the case, it will mark the test as failed. If any of the tests fail, the error message will look like this:\n$ go test math_test.go -v === RUN TestMax --- FAIL: TestMax (0.00s) math_test.go:41: Max(-0.083137, 0.018427): Expected 0.000000, got 0.018427 FAIL FAIL\tcommand-line-arguments\t0.004s Having a structured and typed test case is the magic behind table-driven tests. It\u0026rsquo;s also the reason for the name: a TestCase represents a row from a table. With the for loop we evaluate each of the rows and use its cells as arguments and expected values.\nConvert ordinary to table-driven tests As always, when talking about programming, it\u0026rsquo;s easier if we write some actual code while talking. In this section, we will first add some straightforward tests. After that, we will convert them to table-driven tests.\nConsider this type Person, which has two functions: older and NewPerson. The latter being a constructor, while the former is a function that can decide what Person is older between two of them:\npackage person import \u0026#34;errors\u0026#34; var ( AgeTooLowError = errors.New(\u0026#34;A person must be at least 1 years old\u0026#34;) AgeTooHighError = errors.New(\u0026#34;A person cannot be older than 130 years\u0026#34;) ) type Person struct { age int } func NewPerson(age int) (error, *Person) { if age \u0026lt; 1 { return AgeTooLowError, nil } if age \u0026gt;= 130 { return AgeTooHighError, nil } return nil, \u0026amp;Person{ age: age, } } func (p *Person) older(other *Person) bool { return p.age \u0026gt; other.age } Next, let\u0026rsquo;s add some tests for these two functions:\npackage person import ( \u0026#34;testing\u0026#34; ) func TestNewPersonPositiveAge(t *testing.T) { err, _ := NewPerson(1) if err != nil { t.Errorf(\u0026#34;Expected person, received %v\u0026#34;, err) } } func TestNewPersonNegativeAge(t *testing.T) { err, p := NewPerson(-1) if err == nil { t.Errorf(\u0026#34;Expected error, received %v\u0026#34;, p) } } func TestNewPersonHugeAge(t *testing.T) { err, p := NewPerson(150) if err == nil { t.Errorf(\u0026#34;Expected error, received %v\u0026#34;, p) } } func TestOlderFirstOlderThanSecond(t *testing.T) { _, p1 := NewPerson(1) _, p2 := NewPerson(2) if p1.older(p2) { t.Errorf(\u0026#34;Expected p1 with age %d to be younger than p2 with age %d\u0026#34;, p1.age, p2.age) } } func TestOlderSecondOlderThanFirst(t *testing.T) { _, p1 := NewPerson(2) _, p2 := NewPerson(1) if !p1.older(p2) { t.Errorf(\u0026#34;Expected p1 with age %d to be older than p2 with age %d\u0026#34;, p1.age, p2.age) } } These tests are conventional. Also, the tests covering the same function typically have the same structure of setup, assertion, and error reporting. Having a similar test layout is another reason why table-driven tests are good. Table-driven tests eliminate the repetition of boilerplate code and substitute it with a simple for loop.\nLet\u0026rsquo;s refactor the tests into table-driven tests. We will begin with a TestOlder function:\nfunc TestOlder(t *testing.T) { cases := []struct { age1 int age2 int expected bool }{ { age1: 1, age2: 2, expected: false, }, { age1: 2, age2: 1, expected: true, }, } for _, c := range cases { _, p1 := NewPerson(c.age1) _, p2 := NewPerson(c.age2) got := p1.older(p2) if got != c.expected { t.Errorf(\u0026#34;Expected %v \u0026gt; %v, got %v\u0026#34;, p1.age, p2.age, got) } } } There isn\u0026rsquo;t much happening here. The only difference compared to the tests we saw before is the inline definition and initialization of the cases slice. We define the type with its attributes and add values to it right away instead of first defining the type and initializing a slice of it after.\nNext, we will create a TestNewPerson function:\nfunc TestNewPerson(t *testing.T) { cases := []struct { age int err error }{ { age: 1, err: nil, }, { age: -1, err: AgeTooLowError, }, { age: 150, err: AgeTooHighError, }, } for _, c := range cases { err, _ := NewPerson(c.age) if err != c.err { t.Errorf(\u0026#34;Expected %v, got %v\u0026#34;, c.err, err) } } } This test follows the same structure: defining the cases slice by initializing the slice inline. Then, in the loop, we assert that the errors that we expect are the same as the ones returned by the invocation of the NewPerson function.\nIf you have a test file that you would like to refactor to use a table-driven approach, follow these steps:\n Group all tests that focus on one function one after another in the test file Identify the inputs/arguments to the function under test in each of the test functions Identify the expected output on each of the tests Extract the inputs and the expected outputs into another test, wrapping them into a type (struct) that will accommodate all inputs and the expected output Create a slice of the new type, populate it with all inputs and expected outputs and introduce a loop where you will create the assertion between the expected and the actual output  Why should you use table-driven tests? One of the reasons I like the table-driven approach to testing is how effortless it is to add different test cases. Table-driven tests make adding a new test case to just adding another entry in the cases slice. Compared to the classic style of writing a test function where you have to figure out a name for the function, set up the state, and execute the assertion, table-driven tests make this a breeze.\nTable-driven tests centralize the actual test of a function to a single function block. The classical approach to testing has only one set of inputs and expected outputs within one single function block. When using table-driven tests, we can add virtually unlimited test cases within a single test function block. In other words, table-driven tests are just a DRYed out version of the classical approach.\nLastly, having all cases centralized in a single slice gives more transparency to the quality of our test inputs. For example, are we trying to use arbitrary big or small numbers as inputs, or very long and very short strings, etc.? You get the idea.\nLet\u0026rsquo;s take a quick look at the TestOlder test function again:\nfunc TestOlder(t *testing.T) { cases := []struct { age1 int age2 int expected bool }{ { age1: 1, age2: 2, expected: false, }, { age1: 2, age2: 1, expected: true, }, } for _, c := range cases { _, p1 := NewPerson(c.age1) _, p2 := NewPerson(c.age2) got := p1.older(p2) if got != c.expected { t.Errorf(\u0026#34;Expected %v \u0026gt; %v, got %v\u0026#34;, p1.age, p2.age, got) } } } If I ask you: only by looking at the cases slice, what kind of other test cases can you come up with, what would you answer? One case that immediately comes to mind is testing when the two age int\u0026rsquo;s are the same. We can add more cases, but I\u0026rsquo;ll let you think that one through. (Hint: think about edge cases. 😉)\nIt\u0026rsquo;s not all rainbows and unicorns. This approach has some downsides. For example, running a specific test case (via `go test -run foo') is more difficult - we cannot target a single case; we have to run the whole function. But, there\u0026rsquo;s a trick to achieve both: it\u0026rsquo;s called subtests and we\u0026rsquo;ll look into them in another article.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-table-driven-tests/","summary":"Coming from Ruby, which has excellent testing tools and libraries, the notion of table-driven tests was unusual for me. The widespread testing libraries in Ruby, such as RSpec, force the programmer to approach testing from a BDD standpoint. Thus, coming to Go and learning about the table-driven test was a new way of looking at tests for me.\nLooking back, Dave Cheney\u0026rsquo;s 2013 seminal blog post \u0026ldquo;Writing table driven-tests in Go\u0026rdquo; was very likely my gateway to table-driven tests.","title":"Testing in Go: Table-Driven Tests"},{"content":"If you remember anything from this article, remember this: go test is a command that automates the execution of test files and functions in a Go project. The go test command ships with Go itself, so if you have Golang installed, there\u0026rsquo;s nothing to check - it\u0026rsquo;s available on your machine.\ngo test will recompile each package and any files with names matching the file pattern *_test.go. These *_test.go files can contain test functions, benchmark functions, and example functions. Each listed package will cause the execution of a separate test binary.\ngo test compiles test files that declare a package, ending with the suffix *_test.go as a separate package. It then links them with the main test binary and runs them.\nWhile go test seems simple on the surface, it has many options and commands. It allows for control of what test to be run, such as file-specific or package-specific tests. It has flags for skipping tests, reporting test coverage, and other options. Also, it has intelligent caching mechanisms under the hood to avoid rebuilding packages every time we run our tests.\ngo test is a compact yet a rich tool that every Gopher should have under their belt. We will not look at all its features, but at the end of this article, we will have a good understanding of the workings of the tool.\nRunning modes go test has two running modes. Understanding them is essential to have an easy time working with the tool:\n Local directory mode, or running without arguments Package list mode, or running with arguments  In the local directory mode, go test compiles the package sources and tests found in the current directory and then runs the resulting test binary. This mode disables caching. After the package test finishes, go test prints a summary line showing the test status (\u0026lsquo;ok\u0026rsquo; or \u0026lsquo;FAIL\u0026rsquo;), the package name, and elapsed time.\nTo run your tests in this mode, run go test in your project\u0026rsquo;s root directory.\nIn the package list mode, go test compiles and tests each package listed as arguments to the command. If a package test passes, go test prints only the final \u0026lsquo;ok\u0026rsquo; summary line. If a package test fails, go test prints the complete test output.\nTo run your test in this mode, run go test with explicit package arguments. For example, we can run go test PACKAGE_NAME to test a specific package or go test ./... to test all packages in a directory tree. Or we can run go test . to run all tests in the current directory.\nIn our daily work with go test, the difference between the two modes is caching.\nWhen we run go test in package list mode, it will cache successful package test results to avoid unnecessary reruns. When it can find a test result in the cache, go test will redisplay the cached result instead of rerunning the tests. When this happens, go test will annotate the test results with (cached) in place of the elapsed time in the summary line.\nTest run control One of the significant features of the go test command is controlling what test files and test functions we can run. As we discussed before, go test has two modes to supply package or file names. Additionally, we can also selectively run one or more test functions.\nTo have an easier time further in this post, we will define a type Person. It will have two functions: a constructor NewPerson and a function older, which will take a *Person and return if one *Person is more senior than another *Person.\npackage person import \u0026#34;errors\u0026#34; type Person struct { age int } func NewPerson(age int) (*Person, error) { if age \u0026lt; 1 { return nil, errors.New(\u0026#34;A person is at least 1 years old\u0026#34;) } return \u0026amp;Person{ age: age, }, nil } func (p *Person) older(other *Person) bool { return p.age \u0026gt; other.age } Let\u0026rsquo;s add tests for the constructor and the older function. We want to test that the constructor will return an error when a negative integer is passed as the age argument:\npackage person import ( \u0026#34;testing\u0026#34; ) func TestNewPersonPositiveAge(t *testing.T) { _, err := NewPerson(1) if err != nil { t.Errorf(\u0026#34;Expected person, received %v\u0026#34;, err) } } func TestNewPersonNegativeAge(t *testing.T) { p, err := NewPerson(-1) if err == nil { t.Errorf(\u0026#34;Expected error, received %v\u0026#34;, p) } } Let\u0026rsquo;s add two more tests for the older function. We will create two *Person with different ages and check for the return value of the older function:\nfunc TestOlderFirstOlderThanSecond(t *testing.T) { p1, _ := NewPerson(1) p2, _ := NewPerson(2) if p1.older(p2) { t.Errorf(\u0026#34;Expected p1 with age %d to be younger than p2 with age %d\u0026#34;, p1.age, p2.age) } } func TestOlderSecondOlderThanFirst(t *testing.T) { p1, _ := NewPerson(2) p2, _ := NewPerson(1) if !p1.older(p2) { t.Errorf(\u0026#34;Expected p1 with age %d to be older than p2 with age %d\u0026#34;, p1.age, p2.age) } } The first way to control test runs is by supplying the test files as arguments to the go test command. For example, if we have a person.go and person_test.go files, we need to run:\n$ go test person.go person_test.go ok command-line-arguments\t0.005s The go test command prints only the final ok because all the test cases passed. If we would like to see a more detailed output, we can use the -v flag:\n$ go test person.go person_test.go -v === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) === RUN TestOlderFirstOlderThanSecond --- PASS: TestOlderFirstOlderThanSecond (0.00s) === RUN TestOlderSecondOlderThanFirst --- PASS: TestOlderSecondOlderThanFirst (0.00s) PASS ok command-line-arguments\t0.005s The second way to run the test for the person package is to supply its name to the go test command:\n$ go test person ok person\t0.004s This way, the go test locates the package, builds it, and runs its tests. (Adding the -v flag will produce the same output as before.)\nThe third way to run tests is by specifying a test function to be run, using the -run flag. The flag takes an argument, a regex that will try to match against any test functions in the current directory. For example, if we would like to run the TestNewPersonPositiveAge and TestNewPersonNegativeAge function, we can do this:\n$ go test -run TestNewPerson -v === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) PASS ok person\t0.004s If we mistakenly supply a regexp that will not match anything, go test will inform us about it:\n$ go test -run TestFoo -v testing: warning: no tests to run PASS ok person\t0.004s Failing Fast When running tests, we often want to lower the waiting time and stop at the first test failure we hit. The default mode is to wait for all tests to finish before reporting the errors. So this can be a helpful feature, especially for larger projects.\nTo do this, go test has a special flag we can use: -failfast. Fail fast does what says on the tin: it will stop at the first test that fails, aborting the running test suite/files. To see it in action, we will break one of the test functions for the older function that we introduced earlier:\n// Removing everything else for brewity...  func TestOlderFirstOlderThanSecond(t *testing.T) { p1, _ := NewPerson(100) p2, _ := NewPerson(2) if p1.older(p2) { t.Errorf(\u0026#34;Expected p1 with age %d to be younger than p2 with age %d\u0026#34;, p1.age, p2.age) } } We know this test will fail: p1 will be older than p2 because they are 100 and 2 years old, respectively. If we run go test, it will run all the test functions, ignoring when some fail:\n$ go test -v === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) === RUN TestOlderFirstOlderThanSecond --- FAIL: TestOlderFirstOlderThanSecond (0.00s) person_test.go:26: Expected p1 with age 100 to be younger than p2 with age 2 === RUN TestOlderSecondOlderThanFirst --- PASS: TestOlderSecondOlderThanFirst (0.00s) FAIL exit status 1 FAIL\tperson\t0.004s Now, let\u0026rsquo;s see the difference if we add the -failfast flag:\n$ go test -v -failfast === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) === RUN TestOlderFirstOlderThanSecond --- FAIL: TestOlderFirstOlderThanSecond (0.00s) person_test.go:26: Expected p1 with age 100 to be younger than p2 with age 2 FAIL exit status 1 FAIL\tperson\t0.004s By adding the -failfast flag, we stopped right where we got the first failure\n when running the TestOlderFirstOlderThanSecond test function.  This option is useful when we do some heavier refactorings of our code. If our refactor breaks some tests, instead of being overwhelmed by all the errors, we can add the -failfast flag and fix our mistakes one by one.\nNext time you do some big refactors, give it a shot; it might save you a few grey hairs as you\u0026rsquo;re fixing the tests.\nCoverage Another exciting feature that is packed in go test is test coverage. Taken from Go\u0026rsquo;s website from the blog post on coverage:\n Test coverage is a term that describes how much of a package\u0026rsquo;s code is exercised by running the package\u0026rsquo;s tests. If executing the test suite causes 80% of the package\u0026rsquo;s source statements to be run, we say that the test coverage is 80%.\n We will not go into detail here on how the coverage tools work. I recommend referring to the \u0026ldquo;Test coverage for Go\u0026rdquo; section in the post above to understand how it measures the coverage.\nIf we would like to check the test coverage on our Person type and its functions, we can run go test -cover:\n$ go test -cover PASS coverage: 100.0% of statements ok person\t0.004s 100% coverage is excellent - it means that our tests cover all the functionality of our program. We can add some more functionality to the NewPerson constructor function to see the coverage tool in action. Creating a person that is 1000 years old doesn\u0026rsquo;t make much sense, especially knowing the older person ever recorded was 122 years old. We can extend the constructor to validate that the newly created Person instance cannot be older than 130 years:\npackage person import \u0026#34;errors\u0026#34; type Person struct { age int } func NewPerson(age int) (*Person, error) { if age \u0026lt; 1 { return nil, errors.New(\u0026#34;A person is at least 1 years old\u0026#34;) } if age \u0026gt;= 130 { return nil, errors.New(\u0026#34;A person cannot be older than 130 years\u0026#34;) } return \u0026amp;Person{ age: age, }, nil } func (p *Person) older(other *Person) bool { return p.age \u0026gt; other.age } If we rerun the coverage report, we will see the following output:\n$ go test -cover -v === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) === RUN TestOlderFirstOlderThanSecond --- PASS: TestOlderFirstOlderThanSecond (0.00s) === RUN TestOlderSecondOlderThanFirst --- PASS: TestOlderSecondOlderThanFirst (0.00s) PASS coverage: 83.3% of statements ok person\t0.004s Whoops, our coverage dropped from 100% to 83.3%. To see where our problem is, we can ask go test to create a coverage profile for us, using the -coverprofile flag:\n$ go test -coverprofile=prof.out PASS coverage: 83.3% of statements ok person\t0.004s The output is a prof.out file, with the following contents:\n$ cat prof.out mode: set person/person.go:9.42,10.13 1 1 person/person.go:14.2,14.16 1 1 person/person.go:18.2,20.3 1 1 person/person.go:10.13,12.3 1 1 person/person.go:14.16,16.3 1 0 person/person.go:23.44,25.2 1 1 We don\u0026rsquo;t have to understand the output here, as its format is not user-friendly. Go has another tool that we can use with the profile file to visualize the coverage report better: go tool cover. Using the prof.out profile file, we can generate an HTML page that will visualize what tests cover which parts of the code:\n$ go tool cover -html=prof.out This command pops open our browser with a page looking like this:\n  If we look at the image above, the red-colored code is the one that is never exercised by our tests. In other words, the red code is not covered, while the green one is. The grey code is not tracked because it\u0026rsquo;s boilerplate and should not be tested from the coverage tool perspective.\nFrom the image, it\u0026rsquo;s clear that our tests never run the new branch where we handle unreasonably old age as the argument. Let\u0026rsquo;s add another quick test function that will cover this functionality:\n// person_test.go func TestNewPersonHugeAge(t *testing.T) { p, err := NewPerson(150) if err == nil { t.Errorf(\u0026#34;Expected error, received %v\u0026#34;, p) } } After running go test -coverprofile=hundred.out -v we will see the coverage go back to 100% again:\n$ go test -coverprofile=hundred.out -v === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) === RUN TestNewPersonHugeAge --- PASS: TestNewPersonHugeAge (0.00s) === RUN TestOlderFirstOlderThanSecond --- PASS: TestOlderFirstOlderThanSecond (0.00s) === RUN TestOlderSecondOlderThanFirst --- PASS: TestOlderSecondOlderThanFirst (0.00s) PASS coverage: 100.0% of statements ok person\t0.004s Here\u0026rsquo;s the HTML output of the coverage profile:\n  The go test and go tool cover tools packs more combined functionality. I encourage you to read more about it in the official blog post and to experiment further with the tools.\nRunning modes Software is built to serve highly mutable business requirements, which results in applications that grow and evolve. Such applications are (hopefully) well tested, with tests operating on unit, integration and end-to-end levels.\nA common technique on larger projects is to be explicit about what type of tests we want to run. For example, when running go test, do we want to include running the integration tests of the project or just the unit tests? In such cases, two practical techniques come out of the box with Go: build tags and short mode.\nUsing -short mode The -short mode for go test allows us to mark any long-running tests to be skipped in this mode. go test and the testing package support this via the t.Skip(), the testing.Short() functions and the -short flag.\nWe can skip a test function by checking if the short mode is on and invoking the t.Skip function if that returns true. Let\u0026rsquo;s see this by changing an earlier example:\nfunc TestOlderFirstOlderThanSecond(t *testing.T) { if testing.Short() { t.Skip(\u0026#34;Skipping long-running test.\u0026#34;) } p1, _ := NewPerson(1) p2, _ := NewPerson(2) if p1.older(p2) { t.Errorf(\u0026#34;Expected p1 with age %d to be younger than p2 with age %d\u0026#34;, p1.age, p2.age) } } If we run the tests using go test -v, we should see no change in the output:\n$ go test -v === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) === RUN TestNewPersonHugeAge --- PASS: TestNewPersonHugeAge (0.00s) === RUN TestOlderFirstOlderThanSecond --- PASS: TestOlderFirstOlderThanSecond (0.00s) === RUN TestOlderSecondOlderThanFirst --- PASS: TestOlderSecondOlderThanFirst (0.00s) PASS ok person\t0.004s If we would enable the short mode using the -short flag, we should see the change in the behavior and output:\n$ go test -short -v === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) === RUN TestNewPersonHugeAge --- PASS: TestNewPersonHugeAge (0.00s) === RUN TestOlderFirstOlderThanSecond --- SKIP: TestOlderFirstOlderThanSecond (0.00s) person_test.go:30: Skipping long-running test. === RUN TestOlderSecondOlderThanFirst --- PASS: TestOlderSecondOlderThanFirst (0.00s) PASS ok person\t0.005s We can see that the output contains one SKIP line, meaning in short mode, go test skipped the test function. We can use -short in other ways, besides skipping a test. For example, mocking network calls instead of opening a connection or loading simple fixtures instead of loading them from a database.\nThe options are many; it all depends on the function that the test is covering.\nUsing build tags go test supports build tags out of the box, like the -short flag. While we apply the short mode on the function level, we use the build tags on a file level. The nature of build tags does not allow us to use them to skip one or a few functions. Instead, build tags are used to run (or skip) a particular type of test file from our test suite.\nThere are a couple of rules on build tags. As indicated in this Stack Overflow answer:\n build tags are special comments, with the format // +build TAGNAME we have to place the tag on the first line of the file we have to add an empty line after the tag the tag name comment cannot have a dash, but it allows underscores  Following these rules, we can add a tag to our person_test.go file from earlier:\n// +build person_tests  package person import ( \u0026#34;testing\u0026#34; ) // Snipped...  (The person_tests tag is useless when we have only one file in the test suite, but we will add it for experimentation purposes.)\nTo add the build tag to our go test command, we need to run go test -tags=TAG_NAME. To run the files with the person_tests build tag:\n$ go test -tags=person_tests -v === RUN TestNewPersonPositiveAge --- PASS: TestNewPersonPositiveAge (0.00s) === RUN TestNewPersonNegativeAge --- PASS: TestNewPersonNegativeAge (0.00s) === RUN TestNewPersonHugeAge --- PASS: TestNewPersonHugeAge (0.00s) === RUN TestOlderFirstOlderThanSecond --- PASS: TestOlderFirstOlderThanSecond (0.00s) === RUN TestOlderSecondOlderThanFirst --- PASS: TestOlderSecondOlderThanFirst (0.00s) PASS ok person\t0.005s Based on the supplied tag, go test detects the files tagged with person_tests and runs them. If we provided a tag that does not exist in the package, the output would report that no files are found:\n$ go test -tags=foo -v ? person\t[no test files] Notable mentions Covering all the features that go test packs in a single post is a hard undertaking. Here I will mention some other useful features that you should try to use and read more on:\n List tests with -list: to list tests, benchmarks, or examples matching a regular expression passed as the argument. The -list flags are analogous to the -run flag that we discussed before. When we use this flag, go test will not run any tests, benchmarks, or examples. Disabling caching with -count: as discussed before, go test by default caches test results for packages. It then uses them to skip running tests that have are not modified between two runs. Although it can improve the performance, there are times when we would like to disable the caching using the -count=1 flag. Get JSON output using -json: if we would like to take the go test output and process it using a program, having it in a JSON format is better than plain text. This flag will convert the output to JSON, so processing it with a program is less cumbersome. Use more CPU cores using -cpu: this flag will set the GOMAXPROCS variable to the argument that we pass to the flag. It limits the number of operating system threads that can execute user-level Go code simultaneously. Detect race conditions using -race: since Go provides concurrent code primitives, race conditions are always a risk. Go\u0026rsquo;s tooling is great in this regard - it has a fully integrated race conditions detector in its toolchain. You can read more about it in its announcement blog post.  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-go-test/","summary":"If you remember anything from this article, remember this: go test is a command that automates the execution of test files and functions in a Go project. The go test command ships with Go itself, so if you have Golang installed, there\u0026rsquo;s nothing to check - it\u0026rsquo;s available on your machine.\ngo test will recompile each package and any files with names matching the file pattern *_test.go. These *_test.go files can contain test functions, benchmark functions, and example functions.","title":"Testing in Go: go test"},{"content":"Programming languages and tools often have conventions. These conventions help make our work more straightforward. Just like all tools out there, Go also has some conventions when it comes to testing. Some are defined in the language itself (official), while others are coined by community members (unofficial).\nIn this article we will look at the naming conventions for files, functions and variables separately.\n  File and package naming conventions Go\u0026rsquo;s testing package comes with an expectation that any test file must have a _test.go suffix. For example, if we would have a file called person.go its test file must be named person_test.go. This is due to the package building process, where Go knows to ignore these files when building the package due to their naming. Simply, it ignores test files as they are not needed for the program to run.\nAdditionally, Go ships with a command line tool called go test. This tool automates testing the packages named by the import paths. It recompiles each package along with any files with names that match the file pattern *_test.go. This means that go test recognizes these files as special and compiles them as a separate package, and then links and runs them with the main test binary.\nWhen it comes to packages, Go by default expects that all test files are part of the same package that they test. For example, if person.go defines a person package, the respective person_test.go should also be part of the person package. This also means that both, the person.go and person_test.go files should be placed in the same directory - we let Go worry what files should be loaded depending on what go command we run.\nLooking at Golang\u0026rsquo;s source code oddly I found some disregard for these rules. For example, the tests for the fmt package in the standard library, belong to a fmt_test package, instead of the fmt package.\nAt first, my observation was that this is wrong and for some reason it is not fixed yet. After a more thorough research it was obvious that this is an intentional approach and not a mistake. As explained in this Stack Overflow answer, the best way to look at this is to differentiate the two approaches as \u0026ldquo;black box\u0026rdquo; and \u0026ldquo;white box\u0026rdquo; testing.\nThe black box approach, where the test and the production code are in separate packages, allows us to test only the exported identifiers of a package. This means that our test package will not have access to any of the internal functions, variables or constants that are in the production code.\nThe white box approach, where the test and the production code are in the same package, allows us to test both the non-exported and expored identifiers of the package. This is the preferrable approach when writing unit tests that require access to non-exported variables, functions, and methods.\nI personally find the white box approach preferrable, because this is the default behaviour of the tooling that ships with the language. We as users of said tooling should employ good judgement and conventions to write code that is testable and avoid touching non-exported identifiers in the tests. In other words, we should adhere to the defaults, unless we have a really good reason not to.\nIn any case, if you would like to learn how to idiomatic Go and how to organise your packages properly, the source code of the language is the best place to learn from.\n  Function naming conventions While the file naming convention is enforced by the language and its toolkit, test function naming conventions are loosely enforced by Go, but are community driven.\nIn Go, each test file is composed of one or many test functions. Each test function has the following signature structure:\nfunc TestXxx(*testing.T) What\u0026rsquo;s important to notice is that Xxx does not start with a lowercase letter. The function name serves to identify the test routine. A simple test function looks like this (stolen from here):\nfunc TestAbs(t *testing.T) { got := Abs(-1) if got != 1 { t.Errorf(\u0026#34;Abs(-1) = %d; want 1\u0026#34;, got) } } And that\u0026rsquo;s all that\u0026rsquo;s enforced by Go and it\u0026rsquo;s toolkit. Still, there are a few common ways to name your test functions. For example, we have a simple type Person with age attribute. It receives a function older which checks what if one Person is older than another Person, by comparing their age attributes.\npackage main type Person struct { age int64 } func (p *Person) older(other *Person) bool { return p.age \u0026gt; other.age } We would write a test function for older, looking like this:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;testing\u0026#34; ) func TestOlder(t *testing.T) { p1 := \u0026amp;Person{21} p2 := \u0026amp;Person{22} if !p1.older(p2) { t.Fatalf(fmt.Sprintf(\u0026#34;Expected %d \u0026gt; %d\u0026#34;, p1.age, p2.age)) } } Here we name our test function TestOlder, which clearly states the function under test - older. This is in line with what the testing package expects - a PascalCased function name, starting with Test. What comes after is up to us.\nIn our small example, calling the test function TestOlder is the most common approach that you will see in the wild. But, what if we want to test the same function (older) in more test functions? Do we use TestOlder1, TestOlder2, etc. as test function names? Or is there a better way?\nFor such scenarios, I have found a few approaches in the wild:\nThe Golang source code itself has a naming convention. If we zero in on an example, like the test where the strings.Compare function is tested, we can see the convention in action:\n The base test function follows the format of Test + the name of the function under test. For example TestCompare, which tests the Compare function. More specific tests, for example a test that compares two idential strings, is called TestCompareIndentialStrings. Tests that are more specific express that in the name, using the PascalCase naming scheme.  We can see the same pattern in other files, for example in flag_test.go, where the functionality of the flags package is tested. Notable examples there are the TestUserDefined and TestUserDefinedForCommandLine test functions:\nfunc TestUserDefined(t *testing.T) { // Snipped... } func TestUserDefinedForCommandLine(t *testing.T) { // Snipped... } Moving on to another popular Golang project, consul by HashiCorp, we can see a different test functions naming convention. If we look at the api_test.go file, where the API client is tested, we can see that the project uses a naming convention where:\n The base test function follows the format of Test + the name of the package where the function is placed, with the function name appended after an underscore (_). For example, the API.Debug.Heap() function is tested in the TestAPI_DebugHeap test function. Similarly, the API.SetupTLSConfig is tested in TestAPI_SetupTLSConfig test function. There are functions like API.Agent.Services() that require more specific tests. That\u0026rsquo;s why, for example there are TestAPI_AgentServices and TestAPI_AgentServicesWithFilter, where in the latter there is more specific functionality being tested.  func TestAPI_AgentServices(t *testing.T) { // Snipped... } func TestAPI_AgentServicesWithFilter(t *testing.T) { // Snipped... } These are just a few examples of test function naming conventions, so expect to find some others in the ecosystem. There are various conventions when it comes to naming testing functions, but all of them have to follow the basic format of TestXxx that the testing package enforces.\nVariable naming conventions While there is strict enforcement of the file name convention, and a loose enforcement of test function naming, things are very relaxed when it comes to variables naming. Basically, Golang does not enforce any conventions on the naming of the variables that we can use in our tests via the tooling.\nThis in theory means that everyone can come up with their own variable names. But, what does that mean in practice? What do popular open source projects do when it comes to naming variables?\nBefore we dive in any open source projects, we have to go back to the basics. I am not sure if this is well known (enough), as I have found it a bit too burried in the Github wiki, but Go has a nice \u0026ldquo;Go Code Review Comments\u0026rdquo; page where variable names are discussed.\nWhile the section is short, it says a lot about how we should be naming our variables:\n Variable names in Go should be short rather than long. This is especially true for local variables with limited scope. Prefer c to lineCount. Prefer i to sliceIndex.\n This part is self-explanatory. Go errs on the side of short variable names. In my personal opinion this does not make sense in a time of very powerful text editors that autocomplete our code. I prefer to be lazy and read what each variable means than figuring out what c, t or p mean. Still, if you believe in consistency, we should all follow the same guidelines when writing Go.\nFuther, it says:\n The basic rule: the further from its declaration that a name is used, the more descriptive the name must be.\n This is something I personally like as a rule – the cognitive weight should be small when regaining context of what a variable or concept means. In such cases, configuration (or conf) can do wonders compared to c.\nLastly, it states:\n Common variables such as loop indices and readers can be a single letter (i, r). More unusual things and global variables need more descriptive names.\n The i, j \u0026amp; k variable names for indices are very commonly used, especially in C-inspired languages, so if you are a little bit experienced (or been exposed) to them this will be expected.\nBut, are we bikeshedding here? Why are we discussing variable names, does it matter that much?\nWell, Go tests are just code. Being code, we should expect that all tests follow these guidelines just like all other code does. Also, we should write our tests using these guidelines so our tests feel familiar to others that will work with them. There shouldn\u0026rsquo;t be a major change of code style when switching between business logic and tests.\nNow, let\u0026rsquo;s go back to popular open source projects writen in Go:\nLooking at Terraform, another popular HashiCorp project, one thing that is ubiquitous about its test suite is that the project has both, the actual/expected and the got/want naming convention when it comes to test failures.\nBasically, the test case has an expected value, which is what we expect the function under test to return. The actual value is what the function under test returned. What is convenient about following that naming convention is that expected and actual clearly state that those are the values that will have to be compared with each other, which will drive the decision if the test will pass or not:\n// From: https://github.com/hashicorp/terraform/blob/250527d923f07130c36e65f9bb43b58fcbfe66cf/httpclient/useragent_test.go#L41-L43 if c.expected != actual { t.Fatalf(\u0026#34;Expected User-Agent \u0026#39;%s\u0026#39; does not match \u0026#39;%s\u0026#39;\u0026#34;, c.expected, actual) } Another way to achieve the same is the got/want naming, where the comparison looks like:\n// From: https://github.com/hashicorp/terraform/blob/250527d923f07130c36e65f9bb43b58fcbfe66cf/backend/unparsed_value_test.go#L34-L45 if got, want := diags[3].Description().Summary, undeclPlural; got != want { t.Errorf(\u0026#34;wrong summary for diagnostic 3\\ngot: %s\\nwant: %s\u0026#34;, got, want) } The idea behind the naming is the same, but the goal is to fail with a practical message to whoever\u0026rsquo;s debugging your code in the future.\nFrom here on, delving in the variables conventions further would not prove to be productive, yet following the naming conventions that we discussed above is good enough for your tests. If you would like to read more on the topic, I suggest reading the \u0026ldquo;Names\u0026rdquo; section of Effective Go and \u0026ldquo;Variable Names\u0026rdquo; section of the Go Code Review Comments wiki page.\n  Making things boring Probably you now:\n Why do you bother me with these rules and conventions? go fmt takes care of my code, isn\u0026rsquo;t that enough?\n I hear you and I get your point.\nHere\u0026rsquo;s how I look at it: easy conventions to follow diminish entropy, which makes for simpler and predictable code. The less cognitive load we have to absorb when working with a piece of code – the better.\nIn other words: I like boring code. Boring code is good. I like code that will dully adhere to Go\u0026rsquo;s naming conventions, regardless if I find them appealing or not. Conventions are put in place to make our lives easier, by not having to think if it should be i or index, and knowing that conf will always mean configuration.\nAnd I hope that you will find the boringness of such conventions liberating and empowering over time.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-naming-conventions/","summary":"Programming languages and tools often have conventions. These conventions help make our work more straightforward. Just like all tools out there, Go also has some conventions when it comes to testing. Some are defined in the language itself (official), while others are coined by community members (unofficial).\nIn this article we will look at the naming conventions for files, functions and variables separately.\n  File and package naming conventions Go\u0026rsquo;s testing package comes with an expectation that any test file must have a _test.","title":"Testing in Go: Naming Conventions"},{"content":"All developers appreciate code that works, yet we spend much of our working hours debugging existing code. When fixing existing code, what our test failures communicate is paramount to the debugging experience we have.\nThat\u0026rsquo;s why in this article we will look at what it means to write a meaningful test failure message. We will look at its structure and how we can use some simple techniques to improve our test failure messages. Whether it\u0026rsquo;s a colleague of ours, or our future selves, a great error message can make people\u0026rsquo;s lifes easier and they\u0026rsquo;ll be grateful for it.\n  Anatomy of a test case Before we continue on exploring failure messages and their traits, we should create a function that we can test. When talking about test failures without having some actual code to test would be a waste of our time. Let\u0026rsquo;s start simple - a very small function Max that receives a slice of ints as arguments and returns the biggest int:\n// max.go package main func Max(numbers []int) int { var max int for _, number := range numbers { if number \u0026gt; max { max = number } } return max } The function traverses the slice of ints and it compares each of its elements, assigning the larger one to the max variable. At the end, it returns the max as the result. We will use table-driven tests to test this function. After that, we can disuss its anatomy.\nfunc TestMax(t *testing.T) { cases := []struct{ input []int expected int }{ { input: []int{1, 2, 3, 4, 5}, expected: 100, }, { input: []int{-1, -2, -3, -4, -5}, expected: 100, }, { input: []int{0}, expected: 1, }, } for _, c := range cases { actual := Max(c.input) expected := c.expected if actual != expected { t.Fatalf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) } } } Running the tests will produce the following output:\n› go test --- FAIL: TestMax (0.00s) max_test.go:31: Expected 100, got 5 FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing\t0.004s Great, now that we have something working, we can dissect our test function. The function has three main parts:\n  The setup: in our example we use table-driven tests, where each of the structs has an input and an expected output. When the input is passed to the function, the expected result is the expected attribute of the case struct. When testing more complicated functions, this is where we would do any other setup that would be mandatory for the test to run. Some examples are loading more complicated fixtures (from fixture files) or opening a connection to a database and querying some data.\n  Building the assertion: this is where the testing happens. In table driven tests, this usually means that we have some sort of a for loop that traverses the structs and passes the input to the function under test (in this case Max). Then, we compare the output and the expected value, which will inform us if the function has passed the test.\n  Reporting: when the assertion is false, meaning the result and the expected value are not the same, the test function has to report that something went wrong. This is where we will focus for the rest of this article.\n  Now that we understand the anatomy of a common test case, let\u0026rsquo;s open the discussion of what are the traits of a good and a bad test failure message.\nTraits of an failure message To define the traits of an test failure message, let\u0026rsquo;s examine the output of the failed test from the previous section:\n› go test -v === RUN TestMax --- FAIL: TestMax (0.00s) max_test.go:31: Expected 100, got 5 FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing\t0.004s It has three segments:\n Test status (pass or fail) Function name that was run and failed Failure message(s)  Although the failure message is the one where we get most of the information about the failure of the test, we rely on the output as a whole to get useful information/context about the failure. In the failure message, we can see that it contains two parts: what was expected and what was received.\nIs this good enough? I would say: yes and no.\nYes, because it succintly communicates what our test case expected, and what it received. No, because it does not provide any other context, although there is plenty of it in the test function. This hidden knowledge can hinder us when fixing the test.\nSo, back to the original question: what are the traits of a bad and a good test failure message?\nBad failure messages in failed test(s) hide data and behaviour from the programmer, obstructing them in fixing the failing test(s). Good failure messages, on the other hand, contain just enough information so the programmer can make the test pass.\nHere\u0026rsquo;s a list of data points that we could expose in our test failure messages:\n the line number of the failed test in the source file the source file of the test itself the expression that failed the left and right values in the equality comparison the surrounding state - values of the variables participating in the expression that failed  Keep in mind that these are just guidelines and there is no hard and fast rule. There have been times where my tests have included enough information, and still debugging and fixing them was hard. There are many times when a small refactoring exercise can do wonders for your functions - make sure you run the tests often and add some more as you go.\nIn theory such rich failure messages should be useful. But, how do we actually create them in practice? At the center of all this is a very simple and common technique - inspecting values of types.\nInspecting Primitive Types Golang has a quite a list of primitive types and always having a value is a trait they share. Even variables that were only declared have a value without explicitly defining it, called zero values. Inspecting primitive types in a test failure means we only have to look at their value.\nUnsurprisingly, this is simple in Golang. To inspect a value of a primitive type we only need to print its value using a comibnation of fmt\u0026rsquo;s Sprintf and Println functions. Sprintf requires a format verb, which will be %v (stands for value).\nHere\u0026rsquo;s a simple program that inspects a few primitive types, priting their values:\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(fmt.Sprintf(\u0026#34;Boolean: %v\u0026#34;, true)) fmt.Println(fmt.Sprintf(\u0026#34;Integer: %v\u0026#34;, 42)) fmt.Println(fmt.Sprintf(\u0026#34;String: %v\u0026#34;, \u0026#34;Hello world\u0026#34;)) fmt.Println(fmt.Sprintf(\u0026#34;Float: %v\u0026#34;, 3.14)) } The main function prints four different values, each of them of a primitive type. We\u0026rsquo;ve added the type names in the printing statements to aid visual inspection. If we would run it, the program would produce the following output:\n› go run whatever.go Boolean: true Integer: 42 String: Hello world Float: 3.14 This is a very simple way to inspect any values of primitive type - pass them to Sprintf (with the %v formatting verb) and send its output to Println. If we look at our tests from earlier, you will notice that we actually already use it:\n// Snipped... for _, c := range cases { actual := Max(c.input) if actual != c.expected { out := fmt.Sprintf(\u0026#34;Running: Max(%v)\\n\u0026#34;, c.input) + fmt.Sprintf(\u0026#34;Argument: %v \\n\u0026#34;, c.input) + fmt.Sprintf(\u0026#34;Expected result: %d\\n\u0026#34;, c.expected) + fmt.Sprintf(\u0026#34;Actual result: %d\\n\u0026#34;, actual) t.Fatalf(out) } } We print the input and the argument using the %v verb and we print the expected and actual results using the %d – denoting a base 10 integer representation of the value. Using this approach we are able to send any output to the person battling the failed specs. Here are some other formatting verbs that we can use:\nBoolean: - %t\tthe word true or false Integer: - %b\tbase 2 - %c\tthe character represented by the corresponding Unicode code point - %d\tbase 10 - %o\tbase 8 String: - %s\tthe uninterpreted bytes of the string or slice - %q\ta double-quoted string safely escaped with Go syntax There are more verbs available in the fmt package, head over to the documentation to check them out.\n  Inspecting Custom Types When it comes to inspecting state of custom types, things can easily get hairy. All custom types start simple, with few attributes. But as codebases grow, the size and complexity of custom types can (read: will) grow. A test that once used a very simple type to check a behaviour of certain function, now might produce an output containing a huge struct.\nSo, in such cases how can we show only the relevant values when the tests fail?\nJust like with the primitive types, printing the internals of a custom type is a simple exercise in Go - using the fmt package\u0026rsquo;s Sprintf, using the verbs %v and %+v.\nTo look at Sprintf\u0026rsquo;s workings in combination with structs, we will create a type Person. It has two attributes age (with type int64) and name (with type string):\ntype Person struct { age int64 name string } The Person will implement a function older which will return a boolean, when a Person is older than another Person. It will do that by comparing the ages of the two Person structs:\nfunc (p *Person) older(other *Person) bool { return p.age \u0026gt; other.age } Having the topic of testing in the focus here, let\u0026rsquo;s also add a test function for the older function:\nfunc TestOlder(t *testing.T) { cases := []struct { person1 *Person person2 *Person expected bool }{ { person1: \u0026amp;Person{ name: \u0026#34;Jane\u0026#34;, age: 22, }, person2: \u0026amp;Person{ name: \u0026#34;John\u0026#34;, age: 23, }, expected: false, }, { person1: \u0026amp;Person{ name: \u0026#34;Michelle\u0026#34;, age: 55, }, person2: \u0026amp;Person{ name: \u0026#34;Michael\u0026#34;, age: 40, }, expected: true, }, { person1: \u0026amp;Person{ name: \u0026#34;Ellen\u0026#34;, age: 80, }, person2: \u0026amp;Person{ name: \u0026#34;Elliot\u0026#34;, age: 80, }, expected: true, }, } for _, c := range cases { actual := c.person1.older(c.person2) if actual != c.expected { out := fmt.Sprintf(\u0026#34;Running: older(%v)\\n\u0026#34;, c.person2) + fmt.Sprintf(\u0026#34;Argument: %v \\n\u0026#34;, c.person2) + fmt.Sprintf(\u0026#34;Expected result: %t\\n\u0026#34;, c.expected) + fmt.Sprintf(\u0026#34;Actual result: %t\\n\u0026#34;, actual) t.Fatalf(out) } } } As you can see, we use the same table-driven tests approach and similar formatting for the failure output. If we run the test, we should expect the last test case to fail, because the two persons that we will compare are not older than the other.\n› go test --- FAIL: TestOlder (0.00s) person_test.go:57: Running: older(\u0026amp;{80 Elliot}) Argument: \u0026amp;{80 Elliot} Expected result: true Actual result: false FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing_person\t0.004s Here we can observe a similar output to the one we had in the previous examples. The only difference is in the way the struct is formatted: while we see the values of its attributes, we cannot see the names of the attributes. To fix this, we can apply the %+v formatting verb, which will produce the following output:\n› go test --- FAIL: TestOlder (0.00s) person_test.go:57: Running: older(\u0026amp;{age:80 name:Elliot}) Argument: \u0026amp;{age:80 name:Elliot} Expected result: true Actual result: false FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing_person\t0.004s The %+v formatting verb when printing structs adds field names to the values, so it is easier for us to understand the state of the struct. Obviously, this way of printing all attributes can be problematic when we are facing big structs.\nIn such cases, there\u0026rsquo;s a neat trick that we can use: defining a String function for the struct. By having a String method, our type will implicitly implement the Stringer interface. A Stringer is a type that can describe itself as a string. The fmt package (and many others) look for this interface to print values.\nIf we would implement a String function for our type, our custom type will be able to describe itself. The cool part is that we could have the String function in the test file itself (person_test.go), or in the file with the type definition (person.go). Wherever Golang finds the function it will use it when printing the struct.\n// person_test.go func (p *Person) String() string { out := fmt.Sprintf(\u0026#34;\\nAge: %d\\n\u0026#34;, p.age) + fmt.Sprintf(\u0026#34;Name: %s\\n\u0026#34;, p.name) return out } By having the String function, we can change the approach we use in the failure reporting in the test itself:\nif actual != c.expected { out := fmt.Sprint(\u0026#34;Argument: \u0026#34;, c.person2) + fmt.Sprintf(\u0026#34;Expected result: %t\\n\u0026#34;, c.expected) + fmt.Sprintf(\u0026#34;Actual result: %t\\n\u0026#34;, actual) t.Fatalf(out) } Note that in the line where we build the output we use just fmt.Sprint with the argument of c.person2, which is the struct itself. We do not specify what attributes will be printed, the String function takes care of everything.\nThe output will be:\n› go test --- FAIL: TestOlder (0.00s) person_test.go:62: Argument: Age: 80 Name: Elliot Expected result: true Actual result: false FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing_person\t0.004s By implementing the Stringer interface, we let our Golang\u0026rsquo;s fmt package take care of the printing.\nBut, could we take this idea further? Imagine if the structs that we use to build our table-driven tests could actually describe themselves?\nSelf-describing test cases From our test that we wrote earlier, let\u0026rsquo;s extract a type (TestCase) and use it in our TestOlder test function:\ntype TestCase struct { person1 *Person person2 *Person expected bool } func TestOlder(t *testing.T) { cases := []TestCase{ { person1: \u0026amp;Person{ name: \u0026#34;Ellen\u0026#34;, age: 80, }, person2: \u0026amp;Person{ name: \u0026#34;Elliot\u0026#34;, age: 80, }, expected: true, }, } for _, c := range cases { actual := c.person1.older(c.person2) if actual != c.expected { out := fmt.Sprint(\u0026#34;Argument: \u0026#34;, c.person2) + fmt.Sprintf(\u0026#34;Expected result: %t\\n\u0026#34;, c.expected) + fmt.Sprintf(\u0026#34;Actual result: %t\\n\u0026#34;, actual) t.Fatalf(out) } } } (I also removed two of the test cases for brewity.)\nThis will not change the output of the test - we extracted a type that we defined inline in the previous versions of the test. If we think about the failure output that our test function produces, couldn\u0026rsquo;t our new type TestCase implement the Stringer interface too? What if we define a String function on TestCase which will print out every test failure in the same, structured format, standardized across all our test functions in this test file?\nHere\u0026rsquo;s an example of a String function that TestCase can implement:\nfunc (tc TestCase) String() string { out := fmt.Sprint(\u0026#34;Person 1: \u0026#34;, tc.person1, \u0026#34;\\n\u0026#34;) + fmt.Sprint(\u0026#34;Person 2: \u0026#34;, tc.person2, \u0026#34;\\n\u0026#34;) + fmt.Sprintf(\u0026#34;Expected result: %t\\n\u0026#34;, tc.expected) return out } To put this function in action, we need to make a small modification to the assertion in the test function:\nfor _, c := range cases { actual := c.person1.older(c.person2) if actual != c.expected { out := fmt.Sprint(c) + fmt.Sprintf(\u0026#34;Actual result: %t\u0026#34;, actual) t.Fatalf(out) } } And the output, on failure, will look like:\n› go test --- FAIL: TestOlder (0.00s) person_test.go:71: Person 1: Age: 80 Name: Ellen Person 2: Age: 80 Name: Elliot Expected result: true Actual result: false FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing_person\t0.004s Now, we can see very clearly what was the expected result, the actual result and the state of the variables that are in play for the particular test case. We can improve the formatting of the output even more, but for our purposes this will do fine.\nI hope that this makes it clear that tests are just code. If we use Golang\u0026rsquo;s power to construct test cases as structs and use them in tests, we can also use other Golang goodies like the Stringer interface and make our test cases report their failures better.\n  Simplicity and verbosity Before we wrap up this walkthrough that we embarked on, there\u0026rsquo;s one last thing that I would like us to discuss. I would go on a limb and say that you are probably asking yourself one of these two questions already:\nIs there a simpler way to do this? Why can\u0026rsquo;t we let a testing library or framework take care of the failures messages for us?\nThe answer would be: sure, you can totally do that.\nBut before you opt-in to use a testing library, I want to you understand few things so you can make better choices for your projects in the future.\n Go is simple by design. If you look at the The Go Programming Language Specification you can see how simple and short it is. This is a feature of the language, not a shortcoming. Go ships with a lightweight testing framework. It has out of the box support for writing and running test files, which many other languages do not have. Tests in Go are just code, so they should be as simple as any Go code. Naming a test file, writing the tests and running them should all be simple actions. Analogous to that, a test assertion should be a very simple comparison between two values.  Having these three principles in mind, I hope you can appreciate why writing some failures messages in Golang tests can be a verbose but simple thing to do. As Rob Pike, one of Golang\u0026rsquo;s authors, says in his \u0026ldquo;Go Proverbs\u0026rdquo; talk:\n Clear is better than clever\u0026hellip; There are languages where cleverness is considered a virtue. Go doesn\u0026rsquo;t work that way. Especially when you\u0026rsquo;re learning Go out of the box, you should be thinking of writing simple and clear code. That has a lot to do with maintability, stability and the ability of other people to read your code.\n Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-writing-practical-failure-messages/","summary":"All developers appreciate code that works, yet we spend much of our working hours debugging existing code. When fixing existing code, what our test failures communicate is paramount to the debugging experience we have.\nThat\u0026rsquo;s why in this article we will look at what it means to write a meaningful test failure message. We will look at its structure and how we can use some simple techniques to improve our test failure messages.","title":"Testing in Go: Writing Practical Failure Messages"},{"content":"A short overview of the testing package The testing package from Golang\u0026rsquo;s standard library provides support for automated testing of Go packages. It is intended to be used in combination with the go test command. In combination with go test, this package expects certain naming conventions that we will cover in another article.\nStill, for this article, we have to know that:\n Every test file ends with *_test.go Every test function has the format TestXxx, where Xxx must not start with a lowercase letter  The testing package exposes two different modes: testing and benchmarking. While what we will be discussing here is transferable to benchmarking as well, we will focus on how to fail our tests in a good way and how to provide meaningful error messages.\nLogging with Log and Logf If we look at the index of T type in the testing package, there\u0026rsquo;s a list of functions that represent errors or failures:\nQuite some options, right? But before we dive into these different functions, let\u0026rsquo;s look at another one: Logf (docs).\nYou might be thinking: \u0026ldquo;I came here to read about signaling test failures, and for some reason, you\u0026rsquo;re forcing me to read about logging\u0026rdquo;. Trust me, there\u0026rsquo;s a connection here.\nLog formats its arguments using default formatting, analogous to Println, while Logf takes one or more arguments: a format string and additional arguments. It formats its arguments according to the format (analogous to Printf). Both these functions save the text in the error log. Compared to Println and Printf, the difference is that Log and Logf save the output to the error log (instead of os.Stdout), and they also add a final newline.\nWhen tests fail or when the -test.v flag is present, the text is printed out. Basically, Log \u0026amp; Logf are the Println and Printf of the testing package, but with a twist - they print only in verbose mode or when a test fails. An example:\npackage main import \u0026#34;testing\u0026#34; func TestFoo(t *testing.T) { t.Logf(\u0026#34;Testing Foo\u0026#34;) } If we would run this using go test, there won\u0026rsquo;t be any output. But, if we run it using the -test.v flag, we\u0026rsquo;ll see something like this:\n$ go test -test.v === RUN TestFoo --- PASS: TestFoo (0.00s) foo_test.go:6: Testing Foo PASS ok github.com/fteem/testing_in_go\t0.006s As you can see above, the test returns PASS because there was no test that got marked as failed. If we would like to mark a test as failed, we would have to invoke t.Fail() inside the test. Let\u0026rsquo;s do that:\npackage main import \u0026#34;testing\u0026#34; func TestMax(t *testing.T) { t.Logf(\u0026#34;Testing Foo\u0026#34;) t.Fail() } Now, when we run go test, we should see the test marked as a failure:\n$ go test --- FAIL: TestMax (0.00s) max_test.go:6: Testing Foo FAIL exit status 1 FAIL\tgithub.com/fteem/testing_in_go\t0.006s What\u0026rsquo;s great about this type of logging is that although the test is marked as a failure on line 7, the t.Logf call is on line 6, and the output clearly shows that. If we added any other logging below, we would see a separate line for each of the t.Logf calls:\npackage main import \u0026#34;testing\u0026#34; func TestMax(t *testing.T) { t.Logf(\u0026#34;Testing Foo\u0026#34;) t.Fail() t.Logf(\u0026#34;Another log from Foo\u0026#34;) } And the output of the go test invocation:\n$ go test --- FAIL: TestMax (0.00s) max_test.go:6: Testing Foo max_test.go:8: Another log from Foo FAIL exit status 1 FAIL\tgithub.com/fteem/testing_in_go\t0.006s This behavior is due to the way t.Logf functions. With every invocation, it adds the log lines to the error log. Still, it dumps the whole log to STDOUT only when the tests fail by running all of them and seeing if any were marked as failed. That\u0026rsquo;s why in the above example, we see that the failure is marked on line 7, yet all the logs are present (from line 6 and line 8).\nSo why are Log and Logf` important? Because all of the following functions that we will explore rely on them to write their outputs to the error log. And log output is essential to showing the failures of the failing tests.\nSignaling test Failure To illustrate the different types of failing a test in Golang, we will first need to write a small function that we can test. Let\u0026rsquo;s use a simple function Max that takes a slice of `int\u0026rsquo;s and returns the largest integer of them all:\n// max.go package main func Max(numbers []int) int { var max int for _, number := range numbers { if number \u0026gt; max { max = number } } return max } Let\u0026rsquo;s write a small test function:\npackage main import \u0026#34;testing\u0026#34; func TestMax(t *testing.T) { input := []int{1, 2, 3, 4, 5} actual := Max(input) expected := 6 if actual != expected { t.Logf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) } } The TestMax function defines an input slice of int\u0026rsquo;s, the result of the invocation of Max with the input as argument (called actual) and the expected value of the invocation.\nSuppose the expected value does not match the actual result. In that case, we want to tell the person (or program) running this test that we received something that we weren\u0026rsquo;t expecting. We do this by invoking t.Logf by providing a nice explanation for the human.\nThe expected value here is wrong. It expects 6 while the maximum element of the input slice is 5. That means that this test should fail when we run it:\n$ go test PASS ok github.com/fteem/testing_in_go\t0.006s Huh? Here\u0026rsquo;s the first thing we have to understand about signaling failures in tests: we have to tell the testing package that this is a failed test. And we are the ones to define what failure means. Usually, it\u0026rsquo;s actual != expected, but other times it can be something else. What testing only cares about is recording if there was a test failure or not. There are multiple ways to do this, t.Fail being the easiest one.\nLet\u0026rsquo;s add a call to t.Fail after the t.Logf call:\npackage main import \u0026#34;testing\u0026#34; func TestMax(t *testing.T) { input := []int{1, 2, 3, 4, 5} actual := Max(input) expected := 6 if actual != expected { t.Fail() t.Logf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) } } Let\u0026rsquo;s run it:\n$ go test -v --- FAIL: TestMax (0.00s) max_test.go:11: Expected 6, got 5 FAIL exit status 1 FAIL\tgithub.com/fteem/testing_in_go\t0.006s Boom! Our test failed, as expected. You can notice that the log is now visible, including our call to Logf with our informative error message Expected 6, got 5.\nNow that we have our first test failure signaled let\u0026rsquo;s look at different ways we can signal test failures.\nDelayed vs. immediate failure Golang\u0026rsquo;s testing package promotes two types of failures. The first failure type immediately stops the tests from running. And the second failure type registers the failure but reports it only after all tests finish running. These functions are aptly named Fail and FailNow to reflect the two different behaviors.\nLet\u0026rsquo;s explore their behaviour and usage by continuing testing the Max function we already built.\nWe could write one other test case checking that the slice passed as an argument is not empty. If it is, we will return -1. Otherwise, we will return the maximum item we find. Let\u0026rsquo;s write the new test first:\npackage main import \u0026#34;testing\u0026#34; func TestMax(t *testing.T) { input := []int{1, 2, 3, 4, 5} actual := Max(input) expected := 5 if actual != expected { t.Fail() t.Logf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) } } func TestMaxEmptySlice(t *testing.T) { input := []int{} actual := Max(input) expected := -1 if actual != expected { t.Fail() t.Logf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) } } If we run it, without adding any new functionality to the Max function, it will fail:\n$ go test --- FAIL: TestMaxEmptySlice (0.00s) max_test.go:22: Expected -1, got 0 FAIL exit status 1 FAIL\t_/users/Ilija/Documents/testing\t0.005s We can see here that the TestMax function is run and passes, while the TestMaxEmptySlice fails. We achieve that by marking the test as failed using t.Fail(). Let\u0026rsquo;s add the new functionality to Max, which would make the test pass:\nfunc Max(numbers []int) int { if len(numbers) == 0 { return -1 } var max int for _, number := range numbers { if number \u0026gt; max { max = number } } return max } While the change does not make much sense, for our purpose, it will do the trick. Let\u0026rsquo;s run the test:\n$ go test PASS ok _/Users/Ilija/Documents/testing\t0.004s Now, let\u0026rsquo;s look into the two things that the Max function does. We could theoretically attach an importance level to both of them. For example, the guard clause which returns -1 when the slice argument is empty has lower importance than the actual algorithm that detects the maximum element of the slice. If someone is expanding that algorithm and it goes south, we want to be very loud and \u0026ldquo;stop the world\u0026rdquo;. That\u0026rsquo;s because none of the other functionalities of the function are more relevant than that one.\nIn cases like these, we can use the FailNow() function to mark the failed test and immediately stop any further execution of the particular test that tests the max detection. Let\u0026rsquo;s use it in our tests:\npackage main import \u0026#34;testing\u0026#34; func TestMax(t *testing.T) { input := []int{1, 2, 3, 4, 5} actual := Max(input) expected := 5 if actual != expected { t.Logf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) t.FailNow() } } func TestMaxEmptySlice(t *testing.T) { input := []int{} actual := Max(input) expected := -1 if actual != expected { t.Logf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) t.Fail() } } Also, we need to make the Max function misbehave. To short-circuit this quickly, let\u0026rsquo;s make the Max function return -100 so we can see the difference.\nIf we run this now, there would not be a difference in how the tests will run, although we use FailNow:\n$ go test -v === RUN TestMax --- FAIL: TestMax (0.00s) max_test.go:11: Expected 5, got -100 === RUN TestMaxEmptSlice --- FAIL: TestMaxEmptySlice (0.00s) max_test.go:22: Expected -1, got -100 FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing\t0.005s That is because the TestMax function only does one assertion. Let\u0026rsquo;s rework our tests a bit to use table-driven tests:\ntype TestCase struct { input []int expected int } func TestMax(t *testing.T) { cases := []TestCase{ TestCase{ input: []int{1, 2, 3, 4, 5}, expected: 5, }, TestCase{ input: []int{-1, -2, -3, -4, -5}, expected: -1, }, TestCase{ input: []int{0}, expected: 0, }, } for _, c := range cases { actual := Max(c.input) expected := c.expected if actual != expected { t.Logf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) t.Fail() } } } What the table-driven tests do is they loop over multiple test cases (often structs with the expected input and output), and they set assertions on them. If we would run the tests now, with using t.Fail() instead of t.FailNow() we should see the following output:\n$ go test --- FAIL: TestMax (0.00s) max_test.go:31: Expected 5, got -100 max_test.go:31: Expected -1, got -100 max_test.go:31: Expected 0, got -100 --- FAIL: TestMaxEmptySlice (0.00s) max_test.go:43: Expected -1, got -100 FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing\t0.005s We actually get all failing cases for both tests. Let\u0026rsquo;s replace the t.Fail() invocation to t.FailNow() in the TestMax function and run the test:\n$ go test -v === RUN TestMax --- FAIL: TestMax (0.00s) max_test.go:31: Expected 5, got -100 === RUN TestMaxEmptSlice --- FAIL: TestMaxEmptySlice (0.00s) max_test.go:43: Expected -1, got -100 FAIL exit status 1 FAIL\t_/Users/Ilija/Documents/testing\t0.004s You can see that instead of running each of the test cases and marking them as failures, the test function stopped right after hitting the first failing case.\nReporting the failure is the critical difference between the two, t.Fail() and t.FailNow(). Using the latter, we can stop the tests and communicate with the developer that something is wrong quickly. In comparison, imagine if we had to wait for all test cases to complete before we have some sort of output. The long feedback loop would slow down development speed and waste time running all tests.\nHaving a clear difference and use cases for Fail and FailNow in mind, let\u0026rsquo;s look into how we can combine failure reporting (Log and Logf) with failure marking (Fail and FailNow) in a more structured approach.\nSignal \u0026amp; report failures in one go Understanding the basics and variations of logging and signaling errors is crucial to understand what we will talk about now. If you look at all the tests we wrote so far, although we switched up the approaches by using table-driven tests, two steps were constant:\n In all tests, we had to check for a mismatch between the expected and the actual values, and We had to call report (Log) and signal failure (Fail) if there was a mismatch  Luckily, the testing package makes our life a bit easier by implementing functions that combine both the logging and the test failure. And because there are two ways to signal test failures, there are two functions to do this:Error and Fatal, with their variants.\nLet\u0026rsquo;s reuse the tests that we wrote above, namely the TestMax and TestMaxEmptySlice functions. If we would like to quickly collapse the invocation of t.FailNow() and t.Log() we can simply use t.Fatal(). We use t.Logf() instead of t.Log() in our test functions but conveniently for us, the testing package also implements a t.Fatalf() function, which is a combination of t.FailNow() + t.Logf().\nLet\u0026rsquo;s see how we can use it in our TestMax test function:\nfunc TestMax(t *testing.T) { cases := []TestCase{ TestCase{ input: []int{1, 2, 3, 4, 5}, expected: 5, }, TestCase{ input: []int{-1, -2, -3, -4, -5}, expected: -1, }, TestCase{ input: []int{0}, expected: 0, }, } for _, c := range cases { actual := Max(c.input) expected := c.expected if actual != expected { t.Fatalf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) } } } The change is small. We keep the log format and content. Still, instead of passing it to t.Logf(), we pass it to t.Fatalf() as an argument, while t.FailNow() can be removed entirely. If we rerun our specs we will not see any difference in the behavior or the output in comparison to the previous implementation:\n$ go test --- FAIL: TestMax (0.00s) max_test.go:31: Expected 5, got -100 --- FAIL: TestMaxEmptySlice (0.00s) max_test.go:42: Expected -1, got -100 FAIL exit status 1 FAIL\t_/users/Ilija/Documents/testing\t0.005s The style of invocation of t.Fatalf() we see here also applies to t.Error() and t.Errorf(). We can make a small change to our TestMaxEmptySlice function and use t.Errorf() instead of a combination of t.Logf() and t.Fail():\nfunc TestMaxEmptySlice t *testing.T) { input := []int{} actual := Max(input) expected := -1 if actual != expected { t.Errorf(\u0026#34;Expected %d, got %d\u0026#34;, expected, actual) } } The usage of t.Errorf() is the same as t.Fatalf() in the previous example. As expected, the output and the behavior of the test function also will not change:\n$ go test --- FAIL: TestMax (0.00s) max_test.go:31: Expected 5, got -100 --- FAIL: TestMaxEmptySlice (0.00s) max_test.go:42: Expected -1, got -100 FAIL exit status 1 FAIL\t_/users/Ilija/Documents/testing\t0.005s When to use Error(f) or Fatal(f) So, we took a look at all the variations of signaling test failures and logging such failures and the behavior of the respective functions. For those wondering when we should use Error or Fatal, I think that\u0026rsquo;s an essential question that we should explore and come up with a good answer.\nNow, there\u0026rsquo;s no hard and fast answer here. In cases like these, we need to look at guidelines on when to use these functions. If we look at the composition of these two functions, it will look something like this:\n* Error() = Fail() + Log() * Errorf() = Fail() + Logf() * Fatal() = FailNow() + Log() * Fatalf() = FailNow() + Logf() By looking at the composition of these functions, getting a clearer indication of the intended usage is easier:\nIf marking the test function as failed, but continuing its execution can/will provide the user (the programmer) with more information that can aid them in fixing the failure – it\u0026rsquo;s better to use Error(f) instead of Fatal(f). If unsure, start with Error(f) and work your way towards a definitive approach. There are multiple examples of this scenario. For instance, if your test function executes queries against a test database, not failing on the error from the first query might give you more debugging information.\nSuppose a test function cannot recover from a failure, and its execution doesn\u0026rsquo;t make sense. In that case, it\u0026rsquo;s better to use Fatal(f) and stop the further execution. Such cases are errors while loading fixtures or filesystem permission errors.\nThese are two guidelines you can use to choose what functions to use. Of course, there are exceptions to this, so it\u0026rsquo;s up to us to use good judgment when writing our test functions.\nIn closing In this article, we explored a lot of the details around failing tests. We went deep in to understand how failure logging is done using Go\u0026rsquo;s testing package - although it was unclear at that moment how it is related to failing tests. Then we went on to explore signaling test failures and the different approaches we can take when marking our tests as failed.\nWe looked in-depth about the difference between Fail and FailNow, and how to apply them better in our tests. In the end, we looked at some neat functions that the testing package has that make our lives a bit simpler. We discussed two different strategies of using the Error and the Fatal functions in our tests.\nIf you would like to learn more about marking tests as failed in Go, you can check the documentation of the testing package.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-failing-tests/","summary":"A short overview of the testing package The testing package from Golang\u0026rsquo;s standard library provides support for automated testing of Go packages. It is intended to be used in combination with the go test command. In combination with go test, this package expects certain naming conventions that we will cover in another article.\nStill, for this article, we have to know that:\n Every test file ends with *_test.go Every test function has the format TestXxx, where Xxx must not start with a lowercase letter  The testing package exposes two different modes: testing and benchmarking.","title":"Testing in Go: Failing Tests"},{"content":"If you have any programming experience, whether that\u0026rsquo;s as a student or a professional, there\u0026rsquo;s a good chance you have heard about testing. It\u0026rsquo;s an omnipresent topic, be it at conferences, books, or articles. (See what I did there?)\nAlso, it seems like a topic that everyone agrees on - yes, testing is good, and we should do it. There are many reasons why folks consider testing good for your code\u0026rsquo;s quality. But, before we go down the rabbit hole and discuss the pros and cons of testing, let\u0026rsquo;s learn how we can test our Go code.\nOf course, through actual examples that you can follow along.\nWhat is testing? Throughout my career, I have written thousands of test cases. And I have failed quite a bit at writing them, especially as a novice. So if you are new to testing or just haven\u0026rsquo;t gotten it under your belt yet – worry not. I know how you feel, and that feeling stops here.\nBefore you start with testing, there\u0026rsquo;s one idea I would like you to internalize: tests are just code. We are in control of what we will write and how complicated we\u0026rsquo;ll make our tests. But, just like with our programs, we need to keep the code quality high in our tests, too.\nTests invoke the code that powers your programs and checks if what the code returns is what is expected.\nIt all revolves around setting expectations and then making your program meet these expectations. Usually, languages provide you with packages or libraries to test your code, with each language or library having its testing conventions. But at its core, testing is just meeting expectations.\nThat\u0026rsquo;s testing in a nutshell. Let\u0026rsquo;s move on.\nWhat is a test? So, what is a test then? Repeatable steps to verify if a piece of code is working as it is supposed to.\nWhat is a test in Go terms? Similarly, it\u0026rsquo;s code that we can run many times, and it will check if our program\u0026rsquo;s code is working as expected.\nThat\u0026rsquo;s it. Shall we write one?\nTesting our Go code To write a test, we first have to have a program to test. So let\u0026rsquo;s implement a function that will take a slice of int and return its largest number:\nfunc Max(numbers []int) int { var max int for _, number := range numbers { if number \u0026gt; max { max = number } } return max } We take a slice of ints and return the largest. So, how can we test that our code works as expected?\nLet\u0026rsquo;s write a function that will take two arguments: a slice of ints and the maximum of the ints in that slice. We will call it TestMax:\nfunc TestMax(numbers []int, expected int) string { output := \u0026#34;Pass\u0026#34; actual := Max(numbers) if actual != expected { output = fmt.Sprintf(\u0026#34;Expected %v, but instead got %v!\u0026#34;, expected, actual) } return output } The TestMax function will check if he Max function call matches the expected result. If it does, it will simply return \u0026quot;Pass\u0026quot;, otherwise it will return an informative string with what it was expecting and what it got.\nLet\u0026rsquo;s use it in our main function:\nfunc main() { fmt.Println(TestMax([]int{1, 2, 3, 4}, 4)) } The main function will invoke the TestMax once here, with a slice that contains 1,2,3,4 as argument and 4 as the expected maximum.\nYou might already be thinking that the example will pass. Let\u0026rsquo;s run it:\n$ go run max.go Pass The example passed, great! So let\u0026rsquo;s add two more:\nfunc main() { fmt.Println(TestMax([]int{1, 2, 3, 4}, 4)) fmt.Println(TestMax([]int{4, 2, 1, 4}, 3)) fmt.Println(TestMax([]int{0, 0, 0, 0}, 1)) } Here we add two more examples, with two different pairs of arguments:\n A slice containing 4,2,1,4 and 3, the expected maximum A slice containing four zeroes, and 1 as the expected maximum  If we ran it, both of these examples would fail. The failure would be that none of the two slices of ints that we added match the expected maximum we pass as a second argument to both calls. For example, the maximum is 4 in the second example, while we expect a 3. In the third example, the maximum is 0 while we expect 1.\nTesting our Max function can be done with just one function (TestMax). As long as we can supply input for the function and expected output, we can test our functions.\nWhat is essential to understand here is that testing can be straightforward. We can check if our function is working as expected without any fancy frameworks and libraries - only plain Go code. Of course, if you have any experience with testing, you already know that this approach does not scale too far, but it\u0026rsquo;s terrific to understand the idea that tests are just code.\nUsing this approach, we could technically even write our own testing framework/library. The good thing is that Go already has a testing package included in its standard library so that we can avoid that.\nTesting with Go\u0026rsquo;s testing package Golang\u0026rsquo;s testing package supports automated testing of Go packages. Moreover, it exposes valuable functions that we can use to get a couple of benefits: a better-looking code, a standardized approach to testing, and nicer looking output. Also, we eliminate the need to create our reporting of failed/passed tests.\nLet\u0026rsquo;s see how we could test our Max function using the testing package.\nFirst, we need to create a max_test.go file, the test counterpart to our max.go (where our Max function is defined). Most importantly, both of the files have to be part of the same package (in our example main):\n// max_test.go package main import \u0026#34;testing\u0026#34; func TestMax(t *testing.T) { actual := Max([]int{1, 2, 3, 4}) if actual != 4 { t.Errorf(\u0026#34;Expected %d, got %d\u0026#34;, 4, actual) } } The testing package that is imported allows for benchmarking and testing. In our test, we use the testing.T type, which, when passed to Test* functions, manages the test state and formats the test logs.\nWithin the TestMax function, we get the Max function and assign it to actual. Then, we compare actual to the expected result (4). If the comparison fails, we make the test fail by using the t.Errorf function and supply the error message.\nWhat happens when we run go test Golang\u0026rsquo;s testing package also comes with its buddy – the go test command. This command automates testing the packages named by the import paths. go test recompiles each package along with any files with names matching the file pattern *_test.go.\nTo run this file, we have to use the go test command:\n$ go test PASS ok github.com/fteem/testing_in_go\t0.007s As you can see, we did not need to tell Golang which tests to run - it figured this out on its own. Golang can figure what tests to run on its own because go test is smartly done, with two different running modes.\nThe first mode is called local directory mode. This mode is active when the command is invoked with no arguments. For example, in local directory mode, go test will compile the package sources and the tests found in the current directory and then run the resulting test binary.\nAfter the package test finishes, go test prints a summary line showing the test status (ok or FAIL), the package name, and the elapsed time. We can see in the output that our tests have passed! Looking at the output above, we can also see that they passed in 0.007s. Pretty fast!\nThe second mode is called package list mode. This mode is activated when the command is invoked with explicit arguments. In this mode, go test will compile and test each of the packages listed as arguments. If a package test passes, go test prints only the final \u0026lsquo;ok\u0026rsquo; summary line. If a package test fails, go test prints the complete test output.\nFor now, we can stick with using the first mode. However, we will see when and how to use the second mode in one of the following articles.\nDealing with test failures Now that we have a passing example, let\u0026rsquo;s experience the look and feel of test failures. We will add another example, which we will purposely fail:\nfunc TestMaxInvalid(t *testing.T) { actual := Max([]int{1, 2, 3, 4}) if actual != 5 { t.Errorf(\u0026#34;Expected %d, got %d\u0026#34;, 5, actual) } } The TestMaxInvalid is very similar to the test function we had before, with the only difference being that we have the wrong expectations. More specifically, we know that Max will return 4 here, but we are expecting a 5.\nWhile we are here, let\u0026rsquo;s add one more example where we would pass an empty slice as an argument to Max and expect -1 as a result:\nfunc TestMaxEmpty(t *testing.T) { actual := Max([]int{}) if actual != -1 { t.Errorf(\u0026#34;Expected %v, got %d\u0026#34;, -1, actual) } } Let\u0026rsquo;s run go test again and see the output:\n$ go test --- FAIL: TestMaxInvalid (0.00s) max_test.go:15: Expected 5, got 4 --- FAIL: TestMaxEmpty (0.00s) max_test.go:22: Expected -1, got 0 FAIL exit status 1 FAIL\tgithub.com/fteem/testing_in_go\t0.009s The two new tests failed unsurprisingly. If we inspect the output here, we will notice that there are two lines per failed test. Both of these lines start with --- FAIL:  and have the test function name after. At the end of the line, there\u0026rsquo;s also the time it took for the test function to run.\nWe see the test file name with the line number of where the failure occurred in the following lines. More specifically, this is wherein both of our test files we invoke t.Errorf.\nLet\u0026rsquo;s make our tests pass. First, we need to fix the expectation in the TestMaxInvalid test function:\nfunc TestMaxInvalid(t *testing.T) { actual := Max([]int{1, 2, 3, 4}) if actual != 4 { t.Errorf(\u0026#34;Expected %d, got %d\u0026#34;, 4, actual) } } Now, when we run it we should see one less failure:\n$ go test --- FAIL: TestMaxEmpty (0.00s) max_test.go:22: Expected -1, got 0 FAIL exit status 1 FAIL\tgithub.com/fteem/testing_in_go\t0.006s Good. Technically, we could remove the TestMaxInvalid as it is the same as the TestMax function. However, to make the other test pass, we need to return -1 when the slice received as an argument in Max is empty:\npackage main func Max(numbers []int) int { if len(numbers) == 0 { return -1 } var max int for _, number := range numbers { if number \u0026gt; max { max = number } } return max } The len function will check the length of the numbers slice. If it\u0026rsquo;s 0, it will return -1. So let\u0026rsquo;s rerun the tests:\n$ go test PASS ok github.com/fteem/testing_in_go\t0.006s Our tests are passing again. With our new change, the Max function will return -1 when the slice in arguments is empty.\nIn closing What we talked about in this article is what tests are. We understood that testing is valuable and that tests are just code - nothing more. We saw how we could test our code without any libraries or frameworks, with just simple Golang code.\nThen, we went on to explore Golang\u0026rsquo;s testing package. We saw how an actual test function looks like. We talked about function definitions, the testing.T argument that we have to pass in, and failing a test. Then we added some more tests for our Max function and made its tests pass.\nAs you can see, testing, in a nutshell, is a straightforward but powerful technique. With a little bit of code, we can assure that our code functions in an expected matter, that we can control. And with any new functionality added to our code, we can easily throw in another test to ensure it is covered.\nThere is much more to testing that we will explore in other articles, but now that we are confident with these basic ideas and approaches, we can build our knowledge on top of them.\nBefore we stop here, please let me know what you like and dislike about testing your code? Also, what topics in testing you find confusing or challenging?\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-in-go-first-principles/","summary":"If you have any programming experience, whether that\u0026rsquo;s as a student or a professional, there\u0026rsquo;s a good chance you have heard about testing. It\u0026rsquo;s an omnipresent topic, be it at conferences, books, or articles. (See what I did there?)\nAlso, it seems like a topic that everyone agrees on - yes, testing is good, and we should do it. There are many reasons why folks consider testing good for your code\u0026rsquo;s quality.","title":"Testing in Go: First Principles"},{"content":"The team behind the language started working on a document titled \u0026ldquo;Go 2 Draft Designs\u0026rdquo;. The draft document is part of the design process for Go v2.0. In this article we will zoom in at the proposal for error inspection in Go 2.\nWhat\u0026rsquo;s worth noting is that this is still part of a draft proposal. Still, from where we are standing at the moment, it\u0026rsquo;s certain that these changes will be added to the language starting Go v1.13 and v2.0.\nBefore we go on, it’s good to note that this article is aimed at folks that consider themselves new to the language. Not just with time spent with the language, but also in terms of size of projects/codebases. So if that sounds like you - keep on reading, I promise it will be helpful to understand the pros and cons of errors in Go.\nIf you have experience with Go and error handling you might have a good idea about the topic. Still, you may find something of value in the article. Let me know in the comments section below!\nGo 2 Draft Designs The intent behind the draft documents is to create a discussion cornerstone for the community. They touch three important topics: generics, error handling and error value semantics.\nThe reason for discussing these three topics is… well, us – the community. The Go team got the community’s feedback on the shortcomings of the language via the annual Go user survey. And there is no surprise on the prioritised areas for v2.0: package management, errors and generics.\nPackage management was a big thing, but that area is already addressed with the introduction of modules.\nIn fact, here\u0026rsquo;s a more detailed breakdown of the biggest challenges that people face with Go today:\nImage blatantly linked from Go\u0026rsquo;s blog  If you would like to learn more, the Go team published a blog post with the results and other insights.\nAs we said earlier, in this article we will focus on the error inspection proposal. The error handling and formatting are quite interesting as well, but those are topics for other articles.\nShortcomings of the current errors inspection approach Before we go on to see what are the problems with the current situation in the ecosystem, let’s get a better understanding of errors first. Looking at the topic from my perspective, as a beginner in Go, it’s challenging to understand the shortcomings here.\nGo promotes the idea that errors are values. When something is a value, it means that we can assign it to a variable. This implies that we can work with errors via ordinary programming. No need for special exception flows or rescue blocks. For example, this is an error that’s a value:\nr, err := os.Open(src) if err != nil { return err } defer r.Close() The the os.Open function returns a file for reading or an error. Assigning the error to a variable and checking for its presence (err != nil) is possible because errors are values. In contrast with other languages, when a it\u0026rsquo;s not possible to open a file, we have to catch/handle an exception.\nThis flexibility that Go unlocks is great. But also it changes they way we perceive and use errors as values in our programs. A side-effect of this is that equality checks and type assertion on errors has proved to be tricky and have limitations.\nIf you read the Problem Overview document on error values by Russ Cox, he describes four ways of testing for specific errors:\n Test for equality with sentinel errors, like io.EOF Check for an error implementation type using a type assertion or type switch Ad-hoc checks, like os.IsNotExist, check for a specific kind of error Substring searches in the error text reported by err.Error()  Let\u0026rsquo;s take this a step further.\nError wrapping The people in the Go ecosystem have created various packages that aid error inspection. For example, one of the most popular packages that serves this purpose is pkg/errors. Another one is Uber\u0026rsquo;s multierr. Others include spacemonkeygo/errors, hashicorp/errwrap and upspin.io/error.\nIf you would inspect each of these you would notice different patterns for error wrapping. Error wrapping is a technique where we wrap one error value in another error value, of a different type. The goal is to add more information to it. In 2016 Dave Cheney wrote an article on the topic, titled \u0026ldquo;Don’t just check errors, handle them gracefully\u0026rdquo;.\nThe basic idea is that any error that happens deeper in the call stack will be unavailable for inspection on the surface. We have to annotate errors down the stack, so we can inspect and handle the proper error at a certain level in the stack.\nLet\u0026rsquo;s look at an example: imagine we want to open a file that doesn\u0026rsquo;t exist.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { f, err := os.Open(\u0026#34;notes.txt\u0026#34;) if err != nil { fmt.Print(fmt.Errorf(\u0026#34;%+v\u0026#34;, err)) } defer f.Close() } If we run this small program, we will get the following output:\n$ go run test.go open notes.txt: no such file or directory There is no hint of the type of the error or where this error originated from, such as function name or line number. To be able to get more information to user, we would have to add annotation to our error:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { f, err := os.Open(\u0026#34;notes.txt\u0026#34;) if err != nil { fmt.Print(fmt.Errorf(\u0026#34;Error opening file: %+v\u0026#34;, err)) } defer f.Close() } The output:\n$ go run test.go Error opening file: open notes.txt: no such file or directory% A better way to approach this is to use error wrapping.\nHere’s a very simple example: our type will allow attaching of a timestamp to the error. It will also print the timestamp as part of the error message. The code:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) type ErrorWithTime struct { err error // the wrapped error  t time.Time // the time when the error happened } func (e *ErrorWithTime) Error() string { return fmt.Sprintf(\u0026#34;%v @ %s\u0026#34;, e.err, e.t) } func wrap(err error) *ErrorWithTime { return \u0026amp;ErrorWithTime{err, time.Now()} } func openFile(filename string) (*os.File, error) { f, err := os.Open(filename) if err != nil { return nil, wrap(err) } return f, nil } func main() { file, err := openFile(\u0026#34;notes.txt\u0026#34;) if err != nil { fmt.Print(err) } defer file.Close() } The ErrorWithTime struct has two attributes: the wrapped error err and the time of the error occurrence t. The Error() function will include the timestamp of the occurrence alongside with the error itself. The wrap function is the one doing the magic. It takes an error as an argument and returns the error wrapped in a ErrorWithTime, with the exception timestamp attached (set to time.Now()).\nThe main function does not care about the type of the error. It checks for its presence and prints (if present). If we run the program, this will be the output:\n$ go run test.go open notes.txt: no such file or directory @ 2019-04-05 21:40:06.055665 +0200 CEST m=+0.000287159% I admit - the timestamp of the error occurrence might not be that useful in this context. What is important is that it paints the idea how we can attach more information to errors by wrapping them. If you read Dave’s article I linked above, you will see the shortcomings of this approach and the argument for unwrapping.\nNow, having this in mind, let\u0026rsquo;s move back to the error inspection proposal and see what the authors are proposing.\nGo 2 Error Inspection While wrapping works, it comes at a certain cost, which the draft design document addresses:\n If a sentinel error is wrapped, then a program cannot check for the sentinel by a simple equality comparison. And if an error of some type T is wrapped (presumably in an error of a different type), then type-asserting the result to T will fail. If we encourage wrapping, we must also support alternatives to the two main techniques that a program can use to act on errors, equality checks and type assertions.\n So, let\u0026rsquo;s see how the authors of the proposal are going to address the two most important aspects of error wrapping: equality comparison and type assertion.\nUnwrapping In the draft document the authors acknowledge the need for an unwrapping mechanism. The idea behind that to be able to do any comparisons or assertions, we have to be able to unwrap errors. This is in fact a simple functionality of the custom error type, but it’s of exceptional importance.\nThat\u0026rsquo;s why they introduce the Wrapper interface:\npackage errors // A Wrapper is an error implementation // wrapping context around another error. type Wrapper interface { // Unwrap returns the next error in the error chain. \t// If there is no next error, Unwrap returns nil. \tUnwrap() error } The Unwrap function here does not have a body because we’re looking at an interface definition. This interface is quite important though. All types that will implement Wrapper will have inspection of wrapped errors.\nLet\u0026rsquo;s see a contrived example of a custom error type that implements the Wrapper interface:\n// ErrorWithTime is an error with a timestamp type ErrorWithTime struct { err error // the wrapped error \tt time.Time // the time when the error happened } For the ErrorWithTime to implement the Wrapper interface, it needs to have a Unwrap function. The function will return the error that the custom error type contains:\nfunc (e *ErrorWithTime) Unwrap() error { return e.err } That\u0026rsquo;s all. This will allow any of the next aspects, that we will discuss further, to function well with the ErrorWithTime type.\nType assertion using As Now, let’s combine two ideas: opening a file that does not exist and returning an error that contains a time of occurrence. Let\u0026rsquo;s reintroduce the ErrorWithTime type and its related functions:\ntype ErrorWithTime struct { err error // the wrapped error \tt time.Time // the time when the error happened } // Implements the Error interface func (e *ErrorWithTime) Error() string { return fmt.Sprintf(\u0026#34;Error: %s, ocurred at: %s\\n\u0026#34;, e.err, e.t) } // Implements the Wrapper interface func (e *ErrorWithTime) Unwrap() error { return e.err } To reiterate, the Unwrap function is the one that implements the Wrapper interface. And the Error function implements the Error interface. This means that we can unwrap any error value of our ErrorWithTime type.\nNow, let\u0026rsquo;s create a simple function that can open a file and return an error (if any):\nfunc openFile(path string) error { _, err := os.Open(path) if err != nil { return \u0026amp;ErrorWithTime{ err: err, t: time.Now(), } } return nil } This function is a tad useless because it only returns a potential error, but it does the trick for our example. If the os.Open call returns an error we will wrap it in a ErrorWithTime and attach the current time to it. Then, we\u0026rsquo;ll return it.\nNow, let\u0026rsquo;s see the main function:\nfunc main() { err := openFile(\u0026#34;non-existent-file\u0026#34;) if err != nil { var timeError *ErrorWithTime if xerrors.As(err, \u0026amp;timeError) { fmt.Println(\u0026#34;Failed at: \u0026#34;, timeError.t) } var pathError *os.PathError if xerrors.As(err, \u0026amp;pathError) { fmt.Println(\u0026#34;Failed at path:\u0026#34;, pathError.Path) } } } Here\u0026rsquo;s how the new As function helps by taking care of the type assertion. It receives the error from the openFile function and asserts the error\u0026rsquo;s type to *ErrorWithTime. If the assertion is successful, it will use its t attribute to display the time when the error happened.\nThe same goes for asserting the error type to *os.PathError. Again, the *ErrorWithTime implements the Wrapper interface. This allows the xerrors.As function to unwrap the error and check for the type of the error under wraps. Let’s run the main function:\n$ go run as.go Failed at: 2019-04-21 18:11:01.922332 +0200 CEST m=+0.000303480 Failed at path: non-existent Note that the error type returned from the openFile function is *ErrorWithTime. But, once it’s casted to a *os.PathError we cannot access the t attribute. This is because *ErrorWithTime implements t – not *os.PathError.\nLet\u0026rsquo;s test that with code:\nfunc main() { err := openFile(\u0026#34;non-existent-file\u0026#34;) if err != nil { var pathError *os.PathError if xerrors.As(err, \u0026amp;pathError) { fmt.Println(\u0026#34;Failed at path:\u0026#34;, pathError.Path) fmt.Println(\u0026#34;Failed at:\u0026#34;, pathError.t) } } } This fails with the error:\n./test.go:44:44: pathError.t undefined (type *os.PathError has no field or method t) Value checking with Is While As allows us to take a value and assert its type, Golang has errors which are resistive to type assertions. They are special and have a special name - sentinel errors. Their name descends from the practice in computer programming of using a specific value to signify that no further processing is possible.\nWhen a caller handles a sentinel error, they have to compare the returned error value to a predeclared value using the equality operator. Here\u0026rsquo;s an example (adapted from A Tour of Go) that handles a io.EOF error:\npackage main import ( \u0026#34;io\u0026#34; \u0026#34;strings\u0026#34; ) func main() { r := strings.NewReader(\u0026#34;Hello, Reader!\u0026#34;) b := make([]byte, 8) for { _, err := r.Read(b) if err == io.EOF { break } } } The example above creates a strings.Reader and consumes its output 8 bytes at a time. When the reading hits a io.EOF (I/O End Of File) error, it will break the for loop and exit the program.\nSo, how does the new Is function help us in such cases? Well, if we would use the xerrors package in the same example, it would look like this:\npackage main import ( \u0026#34;io\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;golang.org/x/xerrors\u0026#34; ) func main() { r := strings.NewReader(\u0026#34;Hello, Reader!\u0026#34;) b := make([]byte, 8) for { _, err := r.Read(b) if xerrors.Is(err, io.EOF) { break } } } The change is simple on the surface, but considerable under the hood. The Is function takes an error value and a sentinel error as arguments. If the error value implements Wrapper, it will unwrap its chain of error until it reaches (or not) the sentinel error. Hence, if it finds the sentinel error it will return true, otherwise false.\nLet\u0026rsquo;s expand the above example with our ErrorWithTime type and see the Is function in action:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; \u0026#34;golang.org/x/xerrors\u0026#34; ) type ErrorWithTime struct { err error // the wrapped error \tt time.Time // the time when the error happened } func (e *ErrorWithTime) Error() string { return fmt.Sprintf(\u0026#34;Error: %s, ocurred at: %s\\n\u0026#34;, e.err, e.t) } func (e *ErrorWithTime) Unwrap() error { return e.err } func readReader(r io.Reader) error { buffer := make([]byte, 8) for { _, err := r.Read(buffer) if err != nil { return \u0026amp;ErrorWithTime{ err: err, t: time.Now(), } } } } func main() { r := strings.NewReader(\u0026#34;Hello, Reader!\u0026#34;) err := readReader(r) if xerrors.Is(err, io.EOF) { fmt.Println(err) } } When run, this will produce:\n$ go run eof.go Error: EOF, ocurred at: 2019-04-21 11:32:41.842139 +0200 CEST m=+0.000228985 The readReader function takes a io.Reader as argument and read it until the reading returns an error. When it returns the error, it will wrap it in an \u0026amp;ErrorWithTime and returned to the caller (main). The caller then uses xerrors.Is to check if the error returned is actually a io.EOF under wraps. If it is, it will print the error.\nThis works because ErrorWithType implements Wrapper. This allows the caller to print the error message from the error value, while still being able to detect the error under wraps.\nPutting it in practice with xerrors So you might be wondering, how you can start using the Is and As functions in your current Go programs. Well, as you have noticed in the examples we used the xerrors package. This was in fact announced by Marcel van Lohuizen at dotGo 2019 in Paris - you can check his talk here. (If you\u0026rsquo;re curious how the event was in general, I published a report on it here.)\nThe xerrors package is built to support transitioning to the Go 2 proposal for error values. Most of the functions and types from xerrors will be incorporated into the standard library’s errors package in Go 1.13. The idea is that by using this package you can make your Go 1.12 code be compatible with 1.13 (and later version 2).\nYou can read its documentation and check out the examples included.\nIt is also worth mentioning that replacing equality checks with xerrors.Is and type assertions with xerrors.As will not change the meaning of existing programs that do not wrap errors and it will future-proof programs against wrapping.\nAs with any language changes, there will be situations where the new functions will not do the trick. For example, sometimes callers want to perform many checks against the same error. One such case would be when the caller would compare the error value against more than one sentinel value. In such cases we can still use Is and As. The drawback is in the way these functions walk through the chain of wrapped errors. This means they would walk up the chain multiple times, which is wasteful.\nIn any case, improving the situation with error inspection in Go is a good step forward. I am used to more conventional error handling. Still, I think that this is not a step in the wrong direction when it comes to error inspection. Also, I recommend reading the discussion section of the error inspection draft. It lays out some good guidelines on how to define and use your error types.\nWhat is your opinion on the proposal? Do you think it will simplify your life as a Go developer? Or do you maybe prefer a different approach? Let me know in the comments below!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/deep-dive-in-upcoming-go-error-inspection-changes/","summary":"The team behind the language started working on a document titled \u0026ldquo;Go 2 Draft Designs\u0026rdquo;. The draft document is part of the design process for Go v2.0. In this article we will zoom in at the proposal for error inspection in Go 2.\nWhat\u0026rsquo;s worth noting is that this is still part of a draft proposal. Still, from where we are standing at the moment, it\u0026rsquo;s certain that these changes will be added to the language starting Go v1.","title":"Deep Dive in the Upcoming Go Error Inspection Changes"},{"content":"This year\u0026rsquo;s dotGo in Paris was awesome. The people were great in general. The organisers and volunteers did a good job. The attendees that I interacted with were cool – I had some interesting conversations and made couple of connections. The talks were informative and engaging. If this is where you stop reading, please give dotGo a shot next year - I am sure it will be great! And please find me in the crowd and talk to me, because I\u0026rsquo;d love to talk to you.\nIf the first paragraph didn\u0026rsquo;t convince you, in this article I will share how dotGo 2019 went for me. I\u0026rsquo;ll try to cover multiple aspects of it: venue, general organisation, content, etc. After, I will share with you my four favourite talks of the day.\nKeep in mind, this is all my perception of the conference and the talks. Feel free to politely disagree with me in the comments.\nRegistration Since we were a bit late (arrived 30mins after the registration started), the registration went really smooth because most of the attendees were already in. We were greeted by the volunteers that registered us in and we got our lanyards from:\n  We did grab quite a bit fruits and coffee before the talks started, so we had enough energy to push it through until lunchtime. It\u0026rsquo;s worth noting that there was plenty of coffee and breakfast snacks to fill up everyone\u0026rsquo;s bellies before the talks started.\nThe venue As a tradition, the dot conferences are organised in the beautiful Théâtre de Paris. Basically, what you should expect is a classic French theater that was opened in 1891. What I realised about conference venues in general is that theaters are the ideal for conferences: well lit, great acoustics, good seats and general layout.\nI mean, look at this beauty:\nApologies for the slight blurriness 🙏  And another view at the stage from my seat:\n  I rest my case.\nThe lobby The lobby was where the sponsors stands and the food were situated. This is what it looked like from the second floor looking downwards:\nThose chandeliers are 🔥  The conference had thirteen sponsors, where only five of them had stands. The stands were loaded with stickers (yay!) and other interesting showcases from the sponsors. We did chat with quite a bit of them, we even found an ex-colleague that works for one of the sponsor companies. So overall, the lobby was fun and always crowded.\nMy four favourite talks dotGo had 17 speakers, out of which five did lightning talks and 12 had long-form (20 mins) talks. Every of the long-form talks had a short Q\u0026amp;A session right after with the MC of the conference - Dave Cheney.\nNow, before I go on to list out the talks that I enjoyed most, I have to say that I enjoyed all talks and I believe that all were informative. Also, picking four talks out is hard. After the videos are out I will probably rewatch some of them – a change of heart is a possibility that I am not ruling out.\nBut until then, in no particular order, my four favourite talks of the day:\nBryan Boreham - Tune Your Garbage-Collector! Bryan\u0026rsquo;s talk was about tuning Go\u0026rsquo;s Garbage collector. Go is a garbage collected language and while that brings a lot of ease of use for developers, it also has downsides. For example, if our programs use the memory in an unoptimised manner, Go\u0026rsquo;s garbage collector will have to do extra work to free up the memory that is not in use by our program.\nPhoto from @dotgoeu\u0026rsquo;s Twitter feed  If you\u0026rsquo;re not familiar with how the garbage collector can be tweaked, I recommend looking at the runtime package. Tweaking of the garbage collector is done via the GOGC environment variable. This is what the documentation says on it:\n The GOGC variable sets the initial garbage collection target percentage. A collection is triggered when the ratio of freshly allocated data to live data remaining after the previous collection reaches this percentage. The default is GOGC=100. Setting GOGC=off disables the garbage collector entirely.\n While in the beginning Bryan starts out with a bit of theory (and a Java joke), the talk is very practical. He laid out three different memory allocation patterns and scenarios in which you might want to tweak the garbage collector:\n Memory allocation is high but stable over time, with no fluctuations. In these scenarios he explained how we can make the garbage collector be more sensitive to any potential fluctuations, by lowering the GOGC value from 100 to 50. Memory allocation is small but rapid, which causes the GC to run many times although the allocation is not excessive. In these scenarios, he explained, we can make the garbage collector less sensitive to the fluctutations, by increasing the GOGC value from 100 to 400. This would make the GC wait for four times more memory to be allocated before it starts running. The program runs for very short time, so the memory allocation is not relevant. In such cases, we can turn off the GC by setting the GOGC value to off. One interesting scenario was compilation - if we turn off the GC when we compile our programs, we can speed it up at the cost of memory spent.  Overall, it was a very interesting talk that broadened my horizons on Go\u0026rsquo;s garbage collection and tweaking it.\nEllen Körbes - Building a dilator using Go Ellen\u0026rsquo;s talk was probably one of the wackiest talks I\u0026rsquo;ve ever been to. Being a trans person, Ellen explained a very specific problem they have - how to build a dilator that they can make without a lot of effort. Obviously, they thought about 3D printing.\nPhoto from @dotgoeu\u0026rsquo;s Twitter feed  It was very interesting to see Ellen\u0026rsquo;s thought process, the inception (or rather the necessity) of the idea, finding ways to build the 3D model of the dilator using various tools before they settled on using Go for it.\nI mean, no wonder - if I\u0026rsquo;d pick a technology to do this I would probably pick Go. Ellen said it best:\n Another thing is: this is JavaScript. And I am NOT sticking JavaScript in my body.\n If there\u0026rsquo;s one talk I would recommend watching once the videos are out, it would be this one.\nIgnat Korchagin - Go as a scripting language (in Linux) Ignat\u0026rsquo;s talk was very entertaining. Being an systems engineer in Cloudflare, he wanted to use Go as a scripting language.\nPhoto from @dotgoeu\u0026rsquo;s Twitter feed  To achieve that, we embarked on a journey together. A thing to remember about Linux scripts is, to have a program be executable as a script the first line of the file has to be a \u0026ldquo;shebang\u0026rdquo; line. This line must contain the absolute path to the interpreter that will run the file. The line usually starts with #!.\nThe problem is - this works only for languages where # is a comment, which is not the case Go.\nOur journey started with finding ways to hack the shebang line in his Go programs. He explained all of the weird hacks he had to do to be able to take the arguments from the command line to the program. Eventually, he took us for an even deeper dive into how Linux executes the scripts and how the kernel understands the shebang line to pick the correct executor of the script.\nAt the end we arrived at the destination - called binfmt_misc. He explained how this is solvable with a bit of kernel \u0026ldquo;magic\u0026rdquo;. Linux (the kernel) has a module called binfmt_misc (docs) which allows us to invoke almost every program by simply typing its name in the shell. It does this by allowing the user to specify a handler that will know what interpreter should run for a specific file type.\nAfter that, I found another interesting article where the author explains the binfmt_misc module and how they created their own executable files using a #!~[TODO] shebang.\nOverall, the talk was entertaining and I enjoyed learning a bit more about Linux (the kernel) and this specific module.\nMarcel van Lohuizen - Errors in Go 2 Marcel works on Golang within Google, with focus on core libraries. His talk was about Go\u0026rsquo;s errors, where we are now, and how errors will evolve in the future.\nBasically, Marcel\u0026rsquo;s talk was about Golang\u0026rsquo;s Design Proposal #29934, which touches upon two important aspects of errors in Go - inspection and printing.\nPhoto from @dotgoeu\u0026rsquo;s Twitter feed  The author team - Jonathan Amsterdam, Russ Cox, Marcel van Lohuizen and Damien Neil - propose several additions and changes to the standard library’s errors and fmt packages. The goal is to make errors more informative for both programs and people.\nIf you would like to explore the upcoming changes to the language, you can check the new xerrors package. The package will support transitioning to the Go 2 proposal for error values. Also, watch this space - I am already working on an article that explores the proposal and the xerrors package.\ndotGo 2019 was great As you can see from the content, the venue and the organisation of the conference – I had a blast at dotGo 2019! The feedback from the community on Twitter also seems to be great. I personally think that all the speakers made a great job. The talks were informative, intellectualy challenging and entertaining.\nI will be back in 2020, and I hope to see you there!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/my-first-dotgo-conference/","summary":"This year\u0026rsquo;s dotGo in Paris was awesome. The people were great in general. The organisers and volunteers did a good job. The attendees that I interacted with were cool – I had some interesting conversations and made couple of connections. The talks were informative and engaging. If this is where you stop reading, please give dotGo a shot next year - I am sure it will be great! And please find me in the crowd and talk to me, because I\u0026rsquo;d love to talk to you.","title":"My First dotGo Conference"},{"content":"In this age of cloud platforms, Internet of Things and SaaS products that are easy to integrate with, the effort of automating parts of your life is shrinking down substantially with every year that goes by. Additionally, these services have very generous free plans (or are quite affordable), you won\u0026rsquo;t have to pay a fortune for this automation. In this article I\u0026rsquo;ll show you how you can create your own commands for your Google Home. We will use Golang to glue together Google Cloud Functions, Google Actions, Google Dialogflow and Twilio.\nI am not an early bird Waking up is hard for me. I prefer to stick around hacking (or watching useless videos on YouTube) in the evening until past midnight, so waking up at 8AM is\u0026hellip; challenging. On the flip side, my team has a standup/daily SCRUM every morning at 10 o\u0026rsquo;clock. Being the \u0026ldquo;early bird\u0026rdquo; that I am, this usually means that I barely make the standup, or I end up being 10 minutes late. Missing the standups often completely misses the point of the standup. But that’s for another discussion.\nNow, since that has been going on lately quite a bit, I decided that I need to automate my life a little bit. I wanted to SMS my team lead every time I am running late, by telling my Google Home that I am late for work. This would effectively tell my team to delay the standup for a bit, so I don\u0026rsquo;t miss the standup.\nGenius? I know, right!?\nI decided to glue together multiple platforms and services to achieve this. Sending SMSes - Twilio Messaging API. Running the code in the cloud - Google Cloud Function. Integrating with Google Home - Google Dialog Flow. The glue - Golang.\nBefore we begin\u0026hellip; Before we begin with the cool things and start building, I want to get something out of the way. This article makes some assumptions when it comes to platform and services availability. This means that if you want to follow along, you need the following things:\n You need a functioning Google Cloud Platform account. This is not free, but Google gives some free credit ($300 I believe) for the first year. Also, I recommend creating a new project on Google Cloud Platform. This will allow you to have an easier time managing the resources used by this exercise. Install the Google Cloud SDK, also known as the gcloud command line tool. This is essential for easier management of your GCP projects and resources via the command line. You need a Twilio account - at least for a proof of concept you can get some free SMSes. If you would like to take this further, you\u0026rsquo;ll be charged for it. You also need to make sure you have a verified phone number on Twilio. This phone number will be the source of the SMSes that you will be sending via their API. You need a Google Dialogflow account. We will use this to create the agent and action, which we\u0026rsquo;ll integrate with Google Assistant. (Optionally) You need a Google Home device, for an extra coolness effect. This will work with any Google Assistant-enabled device, including your laptop which can run a simulator in the browser.  Hooking up to Twilio\u0026rsquo;s Messaging API The great part about Twilio is that their blog has helpful resources on how to send SMSes using Golang. While you can read the step by step tutorial on their blog, I\u0026rsquo;ll cover most of the required steps here as well.\nBe able to send an SMS we first need to find the Account SID and Auth Key in our Twilio account\u0026rsquo;s dashboard:\nYou should obviously click on \u0026lsquo;View\u0026rsquo; to see the Auth Token  Save those two and the verified phone number, because we\u0026rsquo;ll need to add them to our Golang program. The endpoint that our Golang program will call to send an SMS via Twilio is:\nhttps://api.twilio.com/2010-04-01/Accounts/ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Messages.json You can see its docs here. The request body will take three parameters:\n From - the phone number that we send the SMS from To - the recipient number of the SMS Body - the content of the SMS  Additionally, the endpoint uses basic authentication. This means that we will need to provide the Account SID and the Auth Token as a user and pass to it.\nLet\u0026rsquo;s start sketching out the program. First, let\u0026rsquo;s create the URL encoded form that we will send to the API:\nsmsResponse := SendSMSResponse{} msgData := url.Values{} msgData.Set(\u0026#34;To\u0026#34;, to) msgData.Set(\u0026#34;From\u0026#34;, from) msgData.Set(\u0026#34;Body\u0026#34;, body) msgDataReader := *strings.NewReader(msgData.Encode()) This uses the url package, which allows us to create a url.Values struct that will contain the data we want to send to the endpoint.\nclient := http.Client{ Timeout: time.Duration(5 * time.Second), } We create an http.Client struct, from the net/http package, which we will use to issue HTTP calls. We also configure it slightly, so it\u0026rsquo;s default timeout is set to 5 seconds.\nvar endpointURL = \u0026#34;https://api.twilio.com/2010-04-01/Accounts/%s/Messages.json\u0026#34; We\u0026rsquo;ll define the endpoint as a variable - we\u0026rsquo;ll also put a %s at the place of where the Account SID should be placed so we can use fmt.Sprintf to replace it when we issue the HTTP request.\nreq, newReqErr := http.NewRequest( \u0026#34;POST\u0026#34;, fmt.Sprintf(endpointURL, accountSid), \u0026amp;msgDataReader, ) if newReqErr != nil { return smsResponse, newReqErr } We create a new net/http Request, using the http.NewRequest constructor function. It takes three arguments:\n The HTTP verb (GET, POST, PUT, PATCH or DELETE) The URL to be called The body of the request  req.Header.Add(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/x-www-form-urlencoded\u0026#34;) We will specify the Content-Type header to x-www-form-urlencoded, so Twilio\u0026rsquo;s API understands what kind of content we are sending to it. In this case, we will be sending a URL encoded form.\nreq.SetBasicAuth(accountSid, authToken) Before we send the request, we will also have to set the basic authentication using the Account SID and the Auth Token.\nresp, requestErr := client.Do(req) Now that we have all of the things in place, we can issue the request - by using the client.Do function. This function will take the request and execute it, while returning a response. In case something goes bad, it will return an error as well.\nIf we look at the documentation of the endpoint that we\u0026rsquo;re calling, we can see an example of the response. In Golang, to convert the response JSON to a meaningful struct, we have to create a struct that our program can decode from a JSON. There\u0026rsquo;s a very nice tool for this purpose - called \u0026ldquo;JSON-to-Go\u0026rdquo;. By pasting the example on the left hand side, this website will automatically generate a struct that we can use in our program.\nYou can copy the autogenerated struct to your program and rename it to SendSMSResponse  This is what the actual struct will look like:\ntype SendSMSResponse struct { Sid string `json:\u0026#34;sid\u0026#34;` DateCreated string `json:\u0026#34;date_created\u0026#34;` DateUpdated string `json:\u0026#34;date_updated\u0026#34;` DateSent interface{} `json:\u0026#34;date_sent\u0026#34;` AccountSid string `json:\u0026#34;account_sid\u0026#34;` To string `json:\u0026#34;to\u0026#34;` From string `json:\u0026#34;from\u0026#34;` MessagingServiceSid interface{} `json:\u0026#34;messaging_service_sid\u0026#34;` Body string `json:\u0026#34;body\u0026#34;` Status string `json:\u0026#34;status\u0026#34;` NumSegments string `json:\u0026#34;num_segments\u0026#34;` NumMedia string `json:\u0026#34;num_media\u0026#34;` Direction string `json:\u0026#34;direction\u0026#34;` APIVersion string `json:\u0026#34;api_version\u0026#34;` Price interface{} `json:\u0026#34;price\u0026#34;` PriceUnit string `json:\u0026#34;price_unit\u0026#34;` ErrorCode interface{} `json:\u0026#34;error_code\u0026#34;` ErrorMessage interface{} `json:\u0026#34;error_message\u0026#34;` URI string `json:\u0026#34;uri\u0026#34;` SubresourceUris struct { Media string `json:\u0026#34;media\u0026#34;` } `json:\u0026#34;subresource_uris\u0026#34;` } Having this in place, will allow us to take the body of the response from the call to Twilio, decode it to a SendSMSResponse struct using the encode/json package:\nsmsResponse := SendSMSResponse{} unmarshalErr := json.NewDecoder(resp.Body).Decode(\u0026amp;smsResponse) That\u0026rsquo;s about it when it comes to calling Twilio\u0026rsquo;s API. We made a function that builds the payload send to the API, executes the call and parses the JSON in the response to a struct that we can use in our Go program.\nDefining the function to call Before we deploy our function to Google Cloud Platform, we need to finish up defining it and hooking it up to the code that calls the Twilio API.\nThe name of our function will be SendSMS. Since the function will be invoked via HTTP call, it will have to take a request and response as arguments. For now, it will return a simple JSON as a response.\npackage app import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) type Response struct { Body string `json:\u0026#34;body\u0026#34;` } func SendSMS(w http.ResponseWriter, r *http.Request) { twilioResponse, err := sendRequest( \u0026#34;PUT YOUR NUMBER HERE\u0026#34;, \u0026#34;Hey Alex, I am running late today, can we please postpone the standup a bit? Thanks! Ilija\u0026#34;, ) if err != nil { json.NewEncoder(w).Encode(Response{ Body: \u0026#34;Something bad happened, please try again.\u0026#34;, }) return } json.NewEncoder(w).Encode(Response{ Body: fmt.Sprintf(\u0026#34;Message %s\u0026#34;, twilioResponse.Status), }) } To make this work, we are also missing the Twilio API part. Before we go into that, let\u0026rsquo;s see what this function does:\n Uses the sendRequest function from our Twilio API integration. This function takes the body of the SMS and the receiver\u0026rsquo;s number as arguments. The sendRequest function might return an error. If it does, we return an error message in the response JSON. If the function returns no errors, we will send a JSON representing a successful scheduling of an SMS on Twilio\u0026rsquo;s side.  Let\u0026rsquo;s see the full integration with Twilio\u0026rsquo;s API:\npackage app import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/url\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) type SendSMSResponse struct { Sid string `json:\u0026#34;sid\u0026#34;` DateCreated string `json:\u0026#34;date_created\u0026#34;` DateUpdated string `json:\u0026#34;date_updated\u0026#34;` DateSent interface{} `json:\u0026#34;date_sent\u0026#34;` AccountSid string `json:\u0026#34;account_sid\u0026#34;` To string `json:\u0026#34;to\u0026#34;` From string `json:\u0026#34;from\u0026#34;` MessagingServiceSid interface{} `json:\u0026#34;messaging_service_sid\u0026#34;` Body string `json:\u0026#34;body\u0026#34;` Status string `json:\u0026#34;status\u0026#34;` NumSegments string `json:\u0026#34;num_segments\u0026#34;` NumMedia string `json:\u0026#34;num_media\u0026#34;` Direction string `json:\u0026#34;direction\u0026#34;` APIVersion string `json:\u0026#34;api_version\u0026#34;` Price interface{} `json:\u0026#34;price\u0026#34;` PriceUnit string `json:\u0026#34;price_unit\u0026#34;` ErrorCode interface{} `json:\u0026#34;error_code\u0026#34;` ErrorMessage interface{} `json:\u0026#34;error_message\u0026#34;` URI string `json:\u0026#34;uri\u0026#34;` SubresourceUris struct { Media string `json:\u0026#34;media\u0026#34;` } `json:\u0026#34;subresource_uris\u0026#34;` } var ( endpointURL = \u0026#34;https://api.twilio.com/2010-04-01/Accounts/%s/Messages.json\u0026#34; accountSid = os.Getenv(\u0026#34;TWILIO_ACCOUNT_SID\u0026#34;) authToken = os.Getenv(\u0026#34;TWILIO_AUTH_TOKEN\u0026#34;) from = os.Getenv(\u0026#34;TWILIO_FROM_PHONE\u0026#34;) ) func sendRequest(to string, body string) (SendSMSResponse, error) { msgData := url.Values{} msgData.Set(\u0026#34;To\u0026#34;, to) msgData.Set(\u0026#34;From\u0026#34;, from) msgData.Set(\u0026#34;Body\u0026#34;, body) msgDataReader := *strings.NewReader(msgData.Encode()) client := http.Client{ Timeout: time.Duration(5 * time.Second), } req, newReqErr := http.NewRequest( \u0026#34;POST\u0026#34;, fmt.Sprintf(endpointURL, accountSid), \u0026amp;msgDataReader, ) if newReqErr != nil { return smsResponse, newReqErr } req.Header.Add(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/x-www-form-urlencoded\u0026#34;) req.SetBasicAuth(accountSid, authToken) resp, requestErr := client.Do(req) defer req.Body.Close() if requestErr != nil { return smsResponse, requestErr } smsResponse := SendSMSResponse{} decodeErr := json.NewDecoder(resp.Body).Decode(\u0026amp;smsResponse) if decodeErr != nil { return smsResponse, decodeErr } return smsResponse, nil } The differences from the code in this snippet and the code from the previous section are:\n We define the Account SID, the Auth Token and the source phone number by taking them from the environment variables. In Golang, one can do this using os.Getenv('NAME_OF_VARIABLE'). We take care of any errors that might occur before and during sending the HTTP request to Twilio  Take note that both of the files are part of the same package - app. This is mandatory, so the function SendSMS can invoke the sendRequest function.\nNow that we have both the Twilio API integration and the SendSMS functions, let\u0026rsquo;s see how we can deploy them to GCP.\nRunning our code on Google Cloud Platform Before we go on to deploy the function, there are some basics about Cloud Functions that are good to know. If you have used Cloud Function or AWS Lambda, you might know most of the things I am about to explain. If this is the case, you can skip this and go to the section on deploying the function.\nIf you look at the main page of the documentation for the Cloud Functions, this is the explanation you\u0026rsquo;ll find:\n Google Cloud Functions is a lightweight compute solution for developers to create single-purpose, stand-alone functions that respond to Cloud events without the need to manage a server or runtime environment.\n Let\u0026rsquo;s break this apart, so we get a better understanding of what Google Cloud Functions are.\nFunctions are lightweight and single purpose. As you already saw in the code above, a Google Cloud Function is really just a function. Being this simple, they do not need any complex setup or configurations.\nFunctions are stand-alone and respond to Cloud events. When Google Cloud receives a certain event (or a trigger), it will invoke the function.\nGoogle Cloud Platform supports two types of functions:\n HTTP functions - functions invoked when an HTTP trigger is received Background functions - functions invoked when an event is received. The type of events and their source can vary.  The last part of the definition of GC Functions is the lack of need to manage a server or runtime environment. In other words, this explains that functions are serverless. This is a side-effect of the nature of Cloud Functions. The runtime is made opaque by the vendor (Google). The only thing we need to configure is the name of the function. Google Cloud Platform takes care of the rest.\nNow, serverless doesn\u0026rsquo;t literally mean an absence of servers. In fact, there are servers that create the cloud. And since Cloud Functions run in the cloud, they run on Google\u0026rsquo;s servers. In this context, serverless means that we, as developers, don\u0026rsquo;t need to care about the infrastructure where our code is being run on.\nWe will not delve any more into serverless or Google Cloud Functions basics. If you want to read more, I recommend the documentation - it\u0026rsquo;s concise and helpful.\nDeploying the Google Cloud Function Assuming that you have your gcloud CLI tool installed, to deploy the function it\u0026rsquo;s just one simple command:\ngcloud functions deploy SendSMS \\  --runtime go111 \\  --trigger-http \\  --region=europe-west1 Before we continue, let\u0026rsquo;s understand the deploy command that we\u0026rsquo;ll run. After the deploy keyword, we supply the function name (in our example it\u0026rsquo;s SendSMS). After that, with the --runtime flag we tell GCP that our function will run in Go 1.11 (that\u0026rsquo;s the go111 part). Then, we tell GCP that we want our function to be an HTTP function – meaning it will get triggered via a HTTP request. Lastly, in our example I set the --region, which is the Cloud region where our function will be deployed to. Because my physical location is in western Europe, I prefer the europe-west1 region.\nOnce we run it, the output will be something like this:\n› gcloud functions deploy SendSMS --runtime go111 --trigger-http --region=europe-west1 Deploying function (may take a while - up to 2 minutes)...done. availableMemoryMb: 256 entryPoint: SendSMS httpsTrigger: url: https://europe-west1-hip-courier-234516.cloudfunctions.net/SendSMS labels: deployment-tool: cli-gcloud name: projects/hip-courier-234516/locations/europe-west1/functions/SendSMS runtime: go111 serviceAccountEmail: hip-courier-234516@appspot.gserviceaccount.com sourceUploadUrl: https://storage.googleapis.com/gcf-upload-europe-west1-... status: ACTIVE timeout: 60s updateTime: \u0026#39;2019-03-17T22:54:03Z\u0026#39; versionId: \u0026#39;2\u0026#39; Now, the output is quite detailed here. We can see the various settings the function has, from the available memory, the HTTPS trigger URL, the name of the function and so on.\nBut, what\u0026rsquo;s most important for us is to try and trigger the function. There are two ways to do this: via a cURL request to the httpsTrigger endpoint, or by using a gcloud command. The gcloud command to trigger the function is:\ngcloud functions call NAME OPTS Let\u0026rsquo;s run it:\n› gcloud functions call SendSMS --region=europe-west1 executionId: uqkmybjc9xab result: | {\u0026#34;body\u0026#34;: \u0026#34;Something bad hapenned, please try again.\u0026#34;} Supplying the --region flag every time you run any command for your Cloud Function can be annoying. You can set your default region using: gcloud config set compute/region europe-west1\n Wait, what? Well, it seems like something went wrong. In fact, the function worked fine. But it seems that something went wrong when sending the SMS via Twilio.\nIf we go back to the Twilio integration, we will notice the following lines:\naccountSid = os.Getenv(\u0026#34;TWILIO_ACCOUNT_SID\u0026#34;) authToken = os.Getenv(\u0026#34;TWILIO_AUTH_TOKEN\u0026#34;) from = os.Getenv(\u0026#34;TWILIO_FROM_PHONE\u0026#34;) These lines expect that the following values will be present as environment variables. This means that we need to set the environment variables for our function, so it can authenticate with Twilio and send SMS.\nAgain we can do this via the web UI or via the command line. Let\u0026rsquo;s use the gcloud CLI tool again:\ngcloud functions deploy SendSMS \\ --set-env-vars \\ TWILIO_ACCOUNT_SID=ACc83f0d68d72e2340ef318fdbcbc7de48,\\ TWILIO_AUTH_TOKEN=e405742cdf254da46eff98c61065bb5e,\\ TWILIO_FROM_PHONE=+3197014200568 \\ --trigger-http \\ --region=europe-west1 What\u0026rsquo;s cool about serverless functions is that they\u0026rsquo;re immutable. This means that every change, regardless if it\u0026rsquo;s configuration, or an actual code change, requires a deploy. As you can notice in the command above, with the flag --set--env-vars we can set multiple environment variables separated by a comma. Of course, we have to supply the trigger flag (--trigger-http) and (optionally) the region flag (--region).\nThe output of the deploy will look like:\nDeploying function (may take a while - up to 2 minutes)...done. availableMemoryMb: 256 entryPoint: SendSMS environmentVariables: TWILIO_ACCOUNT_SID: ACc83f0d68d72e183bbdf318fdbcbc7de48 TWILIO_AUTH_TOKEN: e405742cdf254duy23n98c61065bb5e TWILIO_FROM_PHONE: \u0026#39;+3197014200568\u0026#39; httpsTrigger: url: https://europe-west1-hip-courier-234516.cloudfunctions.net/SendSMS labels: deployment-tool: cli-gcloud name: projects/hip-courier-234516/locations/europe-west1/functions/SendSMS runtime: go111 serviceAccountEmail: hip-courier-234516@appspot.gserviceaccount.com sourceUploadUrl: https://storage.googleapis.com/gcf-upload-europe-west1-b6b2622d-98cf-4a73-a9e3-13427706c715/2c6ce340-bd1f-48ea-b696-23a59ce579eb.zip?GoogleAccessId=service-43664983000@gcf-admin-robot.iam.gserviceaccount.com\u0026amp;Expires=1552926106\u0026amp;Signature=HvRVFFVpEyWoknznuHYUIbiFD53gx4sihWJWtK8Wxuua9E4BJhjdjIUUa7RBWH0UNWlQX%2FpsUm6ub9S%2FjCQYw70JxMW4fTa4fLMJ%2FdcQQGpRRHYlEPLwPjU8aH68NUjYM1zXoWev%2Fl3jAlOTTt2P0lH3ugYwx%2FtHBop4Dbjl8K87bZmf9JUnyjk2FVGlVi7ino8S3ieRJ1tXGf0qXQAQo0DS%2B99Zuy4IsY2S3RS%2BxxKWcRBLKvibWZfZZYAW5g%2Fv%2B47RV9QE4QWRMdZOM0hK2f3URCxqetPi4rB8S5%2B%2FVZVwdyKqUJ45rNaIhTOcJ3j2t%2Fy8A%2BQ45GcNKiM5BPbz5g%3D%3D status: ACTIVE timeout: 60s updateTime: \u0026#39;2019-03-18T15:52:21Z\u0026#39; versionId: \u0026#39;4\u0026#39; If we trigger the cloud function now, we should see it working:\n› gcloud functions call SendSMS --region=europe-west1 executionId: jglb9o1mb5w9 result: | {\u0026#34;body\u0026#34;: \u0026#34;Message queued\u0026#34;} As the message from Twilio states, the SMS was queued and will be sent to your phone soon. I got my SMS in less than 10 seconds, but YMMV. This is what it looked like:\nMy team lead\u0026rsquo;s name is Alex - great guy!  This is awesome. It means that our Google Cloud Function is deployed and the Twilio integration is working as expected.\nNext, let\u0026rsquo;s see how we can plug this into Google Assistant, so it can be used by Google Home.\nGoogle Home Integration Now that we have the Cloud Function operational, let\u0026rsquo;s open Google Dialog Flow and create our first agent:\nFor the project, use the same one that we created in GCP  In my case, I named the agent running-late-sms, but you can choose your own name here - it doesn\u0026rsquo;t matter.\nThe new agent will have two intents: “Default Fallback Intent” and “Default Welcome Intent”. Before we continue modifying these intents, let\u0026rsquo;s get the Dialog Flow basics out of the way.\nVery simply put, an intent is the mapping between the user\u0026rsquo;s command and the agent executing the command. For example, when a user asks \u0026ldquo;Hey Google, what\u0026rsquo;s the weather like outside?\u0026rdquo;, the intent will understand that the user is asking for the weather. Then, the agent can request the data from an API to get the forecast and report it back to the user.\nIntents have four main components:\n A name Training phrases - examples of what a user can say to match a particular intent Action and parameters - defining how data can be extracted from the user\u0026rsquo;s statements/input Response - the response statement to the user  These are the very basics on Dialog Flow Intents. You can read more about them in the documentation.\nDefining our first intent Let’s open the “Default Welcome intent” and change it a bit. First, we can rename it to “Start”. This is because our dialog will have only a single command: “Hey Google, I am running late for standup!“. Once that happens, the agent should match the intent with our statement. Then, a Google Action will invoke the Cloud Function over HTTP.\nNext, we can remove all the training phrases and add a couple of variants that mean \u0026ldquo;I am late for standup/work\u0026rdquo;. For example:\n \u0026ldquo;I will miss the standup today\u0026rdquo; \u0026ldquo;I will be late for standup\u0026rdquo; \u0026ldquo;Running late for standup\u0026rdquo; \u0026ldquo;I will be late for work\u0026rdquo; \u0026ldquo;Running late for work\u0026rdquo;  Google Dialog Flow will apply machine learning on these inputs. This means that your intent will match also statements that are not exactly the same as the training phrases, but statements that have the same intent.\n  Next, we scroll to the bottom of the \u0026ldquo;Fulfillment\u0026rdquo; section where we need to enable the \u0026ldquo;Enable webhook call for this intent\u0026rdquo; option. After that, we can save the intent. The next step we need to take is in the \u0026ldquo;Fulfillment\u0026rdquo; section in sidebar.\nIn the “Fulfillment” page we will enable the webhook by checking the checkbox. In the form, we need to add the information for our webhook. Now, to get the URL of our Google Cloud Function, we can run:\ngcloud functions describe SendSMS This will return the metadata for our function, where we can find the httpsTrigger section with a url:\nhttpsTrigger: url: https://europe-west1-hip-courier-234516.cloudfunctions.net/SendSMS The httpsTrigger URL is the HTTP trigger where our function will be executed. All we need to do here is copy this URL and paste it as the webhook URL in Dialog Flow:\nObviously adding some authentication wouldn\u0026rsquo;t be a bad idea here  That\u0026rsquo;s all. Once we save this when our agent matches the intent, the webhook will be triggered and the Cloud Function will be executed. This will end with a call to Twilio\u0026rsquo;s API which will send an SMS to our phone number.\nSpeaking Google Assistant\u0026rsquo;s lingo Although Dialog Flow\u0026rsquo;s options are quite diverse, setting up a simple intent was straightforward. The intents are backed by Google Actions, which will receive the response from the webhook (our Cloud Function). This means that before we go on to use the intent, we have to make sure our Cloud Function returns a response which Google Actions can understand.\nNow, if we look at the dialog webhook documentation, we will see that there are some rules on the format of the response.\nFor example, the Content-Type in the header of HTTP posts from the Cloud Function have to be application/json. Also, there are other limitations when it comes to the formatting of the JSON.\nFor our purpose, we can return the most simple JSON that Google Assistant can understand:\n{ \u0026#34;payload\u0026#34;: { \u0026#34;google\u0026#34;: { \u0026#34;expectUserResponse\u0026#34;: true, \u0026#34;richResponse\u0026#34;: { \u0026#34;items\u0026#34;: [ { \u0026#34;simpleResponse\u0026#34;: { \u0026#34;textToSpeech\u0026#34;: \u0026#34;RESPONSE_FROM_TWILIO_HERE\u0026#34; } } ] } } } } While the responses can get very complicated, for our simple use case the response above is all we need. Again, we can use the nice JSON-to-Go tool and convert the JSON to Go structs:\ntype DialogFlowResponse struct { Payload Payload `json:\u0026#34;payload\u0026#34;` } type SimpleResponse struct { TextToSpeech string `json:\u0026#34;textToSpeech\u0026#34;` } type Items struct { SimpleResponse SimpleResponse `json:\u0026#34;simpleResponse\u0026#34;` } type RichResponse struct { Items []Items `json:\u0026#34;items\u0026#34;` } type Google struct { ExpectUserResponse string `json:\u0026#34;expectUserResponse\u0026#34;` RichResponse RichResponse `json:\u0026#34;richResponse\u0026#34;` } type Payload struct { Google Google `json:\u0026#34;google\u0026#34;` } To make our life easier, we will also create a simple constructor function. It will take a string (the response from Twilio) as an argument:\nfunc NewDialogFlowResponse(message string) DialogFlowResponse { return DialogFlowResponse{ Payload: Payload{ Google: Google{ ExpectUserResponse: \u0026#34;false\u0026#34;, RichResponse: RichResponse{ Items: []Items{ Items{ SimpleResponse: SimpleResponse{ TextToSpeech: message, }, }, }, }, }, }, } } The constructor will build the nested structs that, when serialized, will result in the JSON that Google Assistant is expecting.\nNow that we have the constructor and the necessary types, we can plug them in the SendSMS function:\nfunc SendSMS(w http.ResponseWriter, r *http.Request) { twilioResponse, err := sendRequest( \u0026#34;PUT YOUR NUMBER HERE\u0026#34;, \u0026#34;Hey Alex, I am running late today, can we please postpone the standup a bit? Thanks! Ilija\u0026#34;, ) if err != nil { errResponse := NewDialogFlowResponse(\u0026#34;Something bad hapenned, please try again.\u0026#34;) json.NewEncoder(w).Encode(errResponse) return } response := NewDialogFlowResponse(fmt.Sprintf(\u0026#34;Message %s\u0026#34;, twilioResponse.Status)) json.NewEncoder(w).Encode(response) } All we had to do here is instead of building the JSON ourselves, we use the new DialogFlowResponse struct to take care of this problem. If we deploy the function to GCP and run it we will see the new output:\n› gcloud functions call SendSMS executionId: 4xo1v0ex57jw result: | {\u0026#34;payload\u0026#34;:{\u0026#34;google\u0026#34;:{\u0026#34;expectUserResponse\u0026#34;:\u0026#34;false\u0026#34;,\u0026#34;richResponse\u0026#34;:{\u0026#34;items\u0026#34;:[{\u0026#34;simpleResponse\u0026#34;:{\u0026#34;textToSpeech\u0026#34;:\u0026#34;Message queued\u0026#34;}}]}}}} This means that once our Google Action invokes the Google Cloud Function, the response can be understood by Google Assistant. And when I say \u0026ldquo;understood\u0026rdquo;, I mean that you will hear your Google Assistant saying out loud \u0026ldquo;Message queued\u0026rdquo;.\nYou don\u0026rsquo;t believe me? Let\u0026rsquo;s see that in action!\nTesting our agent There are two ways to test our new agent - via a Google Home device, or via the simulator.\nIf you\u0026rsquo;re in possession of a Google Home device and if you\u0026rsquo;re logged in with the same account as the one you use on Google Dialogflow or Actions, all you need to do is tell your Google Home \u0026ldquo;OK Google, talk to my test app!\u0026rdquo;. This should do the trick.\nIn this article, we’ll use the simulator. On the right hand side you can click on the “See how it works in Google Assistant” link. This will take you to the Google Actions simulator.\nGoogle Actions is a platform that allows extension of Google Assistant\u0026rsquo;s capabilities. In our case, this means that the Google Dialog Flow agent will invoke a Google Action, which will be the triggered by the Google Assistant. I know it sounds a bit complicated, but in reality these platforms are well connected so the integration is quite simple.\nOnce the simulator opens, you can click on the suggested input \u0026ldquo;Talk to my test app\u0026rdquo; in the bottom of the screen. That will trigger the Dialog Flow agent which will execute the webhook right away:\nYou should obviously click on \u0026lsquo;View\u0026rsquo; to see the Auth Token  You can notice that the response from the Google Assistant contains \u0026ldquo;Message queued\u0026rdquo;, which is Twilio\u0026rsquo;s response. After you see the response, an incoming SMS should pop on your phone\u0026rsquo;s screen.\nIn closing While we have gone through quite the distance in this article, our application is still not shipped to the Play Store for mass-consumption. There are couple of more simple steps that you need to take to release this action to the world.\nNow, before you go on to do this, you have to first think about some of the very rough edges of our action. Basically, at the moment the Google Action that we have created will work only for our use case. If you would like to publish this to the Play Store, you need to make adjustments:\n The user has to be able to configure the content of the message sent and the phone number of their team lead, using their Google Home We have to have a backend where we would store this configuration and every time someone invokes the Google Action (via their Google Home), we would have to process this using our Cloud Function You have to be ready to bear the cost of this. The Twilio API + the Google Cloud Function are not free to use for production, so you will be charged for the usage  I\u0026rsquo;ll leave this up to you. Nevertheless, we still went through the whole process of creating this action. It took many steps:\n Created a Google Dialogflow intent Hooked it up to a Google Action We integrated with Twilio\u0026rsquo;s API using Golang We deployed our Golang program as a Google Cloud Function  And we actually tested our whole integration and we received an SMS to our phones.\nBefore we wrap it up, I am curious: what other kind of such Google Home integrations would your create to automate simple tasks in your life? Let me know in the comments!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/tell-team-running-late-google-home-google-functions-golang-twilio/","summary":"In this age of cloud platforms, Internet of Things and SaaS products that are easy to integrate with, the effort of automating parts of your life is shrinking down substantially with every year that goes by. Additionally, these services have very generous free plans (or are quite affordable), you won\u0026rsquo;t have to pay a fortune for this automation. In this article I\u0026rsquo;ll show you how you can create your own commands for your Google Home.","title":"Tell your team you are running late using Google Home, Google Cloud Functions, Golang and Twilio"},{"content":"One of the most used caching schemes is Least Recently Used (LRU). Caches that use this eviction strategy will remove the least recently used item when their size reaches their capacity. That means that such caches have to keep a track of the order of access of the cached items, so it would evict the correct items.\n  Before we go too much into details about the implementation of an LRU cache, let\u0026rsquo;s first see what are the possible applications of this caching scheme.\nApplications LRU cache applications are diverse. The LRU cache eviction scheme is one of the most widespread and used scheme. Due to its nature, it often does the trick for conventional problems in commercial programming. For example, if one has a fixed amount of memory, the most natural way to cache is to keep recently accessed items.\nSo, what would be one potential application of a LRU cache? Let\u0026rsquo;s see an example.\nOpen your Spotify application (if you have one). Don\u0026rsquo;t have one? Here\u0026rsquo;s a screenshot of mine:\n  You can see in the screenshot above that I have chosen the \u0026ldquo;Recently played\u0026rdquo; view. To no one\u0026rsquo;s surprise, it shows all my recently played media. If you’ve never thought about the implementation of such a screen, let me break the magic down for you. This view is a GUI that lives on top of some sort of an LRU cache.\nCurious how we would model such a \u0026ldquo;Recently played\u0026rdquo; view? Let\u0026rsquo;s take a deeper look.\nEstablishing basic types Let\u0026rsquo;s define couple of types that would represent the Playlists and Songs found on Spotify:\ntype Song struct { duration int64 // seconds \ttitle string artist *Artist } No surprises here - a Song has a duration, a title and an artist. Let\u0026rsquo;s look at a Playlist:\ntype Playlist struct { title string descrption string duration int64 // seconds \tpublishedAt int32 // Unix timestamp \tsongs []*Song } A Playlist has a title, description, duration (which is the sum of the durations of all songs in it). Also, a publishedAt which is the date of the publishing of the playlist. Finally it has songs - a slice of Song pointers representing the songs in the playlist.\nSuch structure of the Playlist struct will allow users to find a playlist and \u0026ldquo;just play it\u0026rdquo;.\nRecently played The \u0026ldquo;Recently played\u0026rdquo; screen in Spotify has 30 items only, where each of the items can be a playlist, an artist or an album. For simplicity of our example here, we will agree that we will only keep track of the recently played playlists. This means that we\u0026rsquo;ll ignore the artists or albums in our version of the \u0026ldquo;Recently Played\u0026rdquo; screen.\nA typical implementation of a LRU cache uses a combination of two simple data structures: a hash table and a linked list. Why? Well, as I mentioned in another article on caching, caches have to be fast along two dimensions:\n Ensuring that as many of the requests for files go to it (cache hit), not over the network or to main memory (cache miss); The overhead of using it should be small: testing membership and deciding when to replace a Playlist should be as fast as possible.  On the first point, we have agreed that LRU will do the job because of the nature of the \u0026ldquo;Recently played\u0026rdquo; screen. This means that we have to keep track of what Playlists are recently played. A data structure that allows us to do this is a linked list. Since Go already provides us a doubly-linked list implementation, there is no need to reinvent the wheel. We will use the container/list package 1.\nOn the second point, the data structure that comes to mind for a scalable membership tests is a hash table. 2 As you might know, hash tables have unique keys for every value. If our program can create a unique key for a Playlist, it will be easy for us to check if the Playlist is in the cache or not.\nKnowing this, let\u0026rsquo;s define the RecentlyPlayed struct and its constructor function:\ntype RecentlyPlayed struct { capacity int size int cache map[int]*list.Element lru *list.List } Things are pretty self explanatory here. capacity will hold the maximum capacity of the cache and size will be the current size of the recently played screen. We will use the cache hash table to retrieve the elements from cache. The lru is a linked list (from the container/list package) that we will use to keep track of the recently played playlists.\nLet\u0026rsquo;s first create a small function that will spawn up a new RecentlyPlayed struct with some sane defaults:\nfunc NewRecentlyPlayed(capacity int) *RecentlyPlayed { rp := RecentlyPlayed{ capacity: capacity, size: 0, lru: list.New(), cache: make(map[string]*list.Element), } return \u0026amp;rp } This function sets the defaults to the struct and returns a pointer to it. Before we continue, let\u0026rsquo;s make a quick stop. Let\u0026rsquo;s take a moment to understand how each of these two data structures will work together.\nFirst, cache is going to be a map that will have a key of type string and a value of type *list.Element. The string will be a hash of the Playlist that will be stored there, while the *list.Element will be a pointer to the element in the doubly-linked list. By having this pointer, we can get the Playlist stored inside it (it\u0026rsquo;s Value). Also, it will be easy to reposition it in the lru list when we play the Playlist.\n  Introducing the player To have a \u0026ldquo;Recently played\u0026rdquo; list of playlists, we obviously need to put it in some sort of a player, that will have a Play function.\nHere\u0026rsquo;s a quick sketch of it, so we can move to the meat of our implementation:\ntype Player struct { playProgress int RecentlyPlayedList *RecentlyPlayed } For the purpose of this example, we can keep the Player quite simple - only the progress of the song currently playing (playProgress) and the recently played list of playlists (RecentlyPlayedList).\nWe will also add a small constructor function for the Player:\nfunc NewPlayer() *Player { p := Player{ RecentlyPlayedList: NewRecentlyPlayed(30), } return \u0026amp;p } Now we need to add the Play function and understand what are the functions related to RecentlyPlayed that Play will have to invoke.\nPlaying a Playlist Obviously, there\u0026rsquo;a already an entity that will have to play the Playlist - the Player. Let\u0026rsquo;s add a function Play to our Player:\nfunc (player *Player) Play(playlist *Playlist) { if cached, playlist := player.RecentlyPlayedList.Get(playlist.hash()); cached { // Play from cache... \t} else { // Fetch over the network and start playing... \tplayer.RecentlyPlayedList.Set(playlist) } } If you thought that I\u0026rsquo;d show you how we\u0026rsquo;ll actually play a media file or stream it over the network I am sorry to disappoint. That\u0026rsquo;s a tad out of the scope of this article. That being said, I am always looking for topic ideas to write on, although I have a huge list already, so if that\u0026rsquo;s something you\u0026rsquo;d like to read on drop a comment below.\n Let\u0026rsquo;s dissect the Play function:\n  The player.RecentlyPlayedList struct is of type *RecentlyPlayed. It has a function Get which will return a bool and a playlist which our player can then play.\n  If it doesn’t find a cached playlist it will fetch/start streaming the playlist over the network. Then, it will cache it using the Set function of the RecentlyPlayedLists struct.\n  So, what is the behaviour and the internals of these two new methods, Get and Set?\nGetting a Playlist from cache To retrieve a Playlist from cache is actually a cheap task, from time perspective. Our cache is hash table-backed which has a O(1) time complexity for the access operation. The trick is once we access an item in cache we also have to move it to the beginning of the lru list.\nIn other words, we need to promote it as the most recently used item in the RecentlyPlayedList. Given that we use a linked list-backed cache, we have to take our item from the list and move it to the front.\nLet\u0026rsquo;s see how that would work in our context:\nfunc (rp *RecentlyPlayed) Get(key string) (*Playlist, bool) { if elem, present := rp.cache[key]; present { rp.lru.MoveToFront(elem) return elem.Value.(*Playlist), true } else { return nil, false } } In case you were expecting some magic here – sorry to disappoint, but this is pretty simple. Its a three step function:\n Checks if it finds the item in the cache. If not it returns a nil. Otherwise, it moves the element to the beginning of the LRU list, and It returns the value of the *list.Element, which is the pointer to the Playlist that our player will play  That\u0026rsquo;s it, pretty simple.\nHash table key for a Playlist Before we move on to Set, let\u0026rsquo;s quickly discuss the implementation of the hash function.\nfunc (playlist *Playlist) hash() string { hash := sha1.New() s := fmt.Sprintf( \u0026#34;%d-%s-%s-%d\u0026#34;, playlist.duration, playlist.title, playlist.description, playlist.publishedAt, ) hash.Write([]byte(s)) sum := hash.Sum(nil) return fmt.Sprintf(\u0026#34;%x\u0026#34;, sum) } As you can see, it\u0026rsquo;s a simple one - it\u0026rsquo;s goal is just to generate a reproducible hash for a Playlist. It basically concatenates the attributes of the Playlist struct and then applies a SHA1 hashing sum on it. As the last step, it returns the hash in a hexidecimal format.\nSetting a Playlist to cache Now that we have the hash function out of the way, let\u0026rsquo;s look at the code of the Set function. After, we can discuss the steps this function takes to add a Playlist to the cache:\nfunc (rp *RecentlyPlayed) Set(playlist *Playlist) { key := playlist.hash() if elem, present := rp.cache[key]; present { rp.lru.MoveToFront(elem) } else { elem := rp.lru.PushFront(playlist) rp.size++ } rp.cache[key] = elem } The Set function takes a *Playlist as an argument. It is then hashed using the hash method that implemented by RecentlyPlayed. It returns a unique key based on some attributes of the Playlist. The key is then used when the Playlist is added in the hash table caches.\nBut before we add it to the hash table cache, we will check if there\u0026rsquo;s already a value in the cache hash table with the same key. If so, we will only move the *Playlist to the front of the lru linked list.\nIf not, we push the *Playlist to the front of the lru linked list, as the most recently used item. This returns a *list.Element, which for its Value expects an interface{} (which is the Go way to say \u0026ldquo;any type\u0026rdquo;). The *list.Element will wrap the *Playlist as its Value.\nThis means that any time we access the elem.Value we will have to cast it to its proper type, since *list.Element does not know the type of its Value (remember, it accepts any type).\nAfter the playlist is added to the front of the lru list, the Set function will increment the RecentlyPlayed\u0026rsquo;s size due to the new item added to the list.\nFinally, the function will cache the *list.Element in the cache hash table\n which we will use to retrieve the playlist with a O(1) time complexity.    Eviction Now that we know how the Get and Set functions work, we need to take one more thing into consideration. That is Spotify’s limitation of the size of the recently played screen. It means that once the number of playlists reaches a threshold, it removes the least recently played playlist. This will make the room to add a new one to the list.\nThis is the eviction algorithm that we have to write for our LRU cache, which powers the recently played screen. In our implementation we\u0026rsquo;ll call the function increment:\nfunc (rp *RecentlyPlayed) increment(element *list.Element) { rp.lru.MoveToFront(element) if rp.size == rp.capacity { lruItem := rp.lru.Back() rp.lru.Remove(lruItem) rp.size-- } } Every time we want to increment the usage of a certain *list.Element, the function will take these two steps:\n Move the accessed element to be beginning of the lru linked list, and When the size of the RecentlyPlayed struct has reached its capacity, remove the last item in the lru linked list  This function will allow us to handle the eviction of the least recently used item in the list of playlists. Now, we can revisit our Set and Get functions and drop this function in:\nfunc (rp *RecentlyPlayed) Set(playlist *Playlist) { key := playlist.hash() if elem, present := rp.cache[key]; present { rp.increment(elem) // \u0026lt;- the change \t} else { elem := rp.lru.PushFront(playlist) rp.size++ } rp.cache[key] = elem } func (rp *RecentlyPlayed) Get(key string) (*Playlist, bool) { if elem, present := rp.cache[key]; present { rp.increment(elem) // \u0026lt;- the change \treturn elem.Value.(*Playlist), true } else { return nil, false } } Now that we have the increment function, we will use it in the Set and Get functions. By doing this, we will update the list of recently used items every time we play a Playlist.\nThis change will unlock two things for our recently played screen:\n It will change the order of the cached playlists, based on the how recently the playlists are played It will remove any playlists once size exceeds capacity  In closing Now that we have a Go-powered sketch of Spotify\u0026rsquo;s recently played screen, let\u0026rsquo;s do a quick recap.\nTo shine some light on the shortcomings:\n This is a barebones model - it lacks any mechanisms to stream/download the playlists via the internet. We agreed that although interesting, this would be hard to cover in this article. The model does not take into account any restarting of the application. This means if we stop and start the program the cached playlists will be gone. This is because our implementation does not store the data on disk (only in memory). We do not have any graphical user interface to interact with the application - only a couple of functions that we can invoke.  While all the above is a shortcoming of our implementation, it still paints the picture of how we could write such a program using Go. The combination of a linked list \u0026amp; a hash table works nice for solving the problem at hand. From time complexity perspective, it scales well. And, for our tiny scenario, the hit-to-miss ratio should is optimal.\nIf you would like to read more of my rambling about caching algorithms, you can also read \u0026ldquo;When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang\u0026rdquo; 3.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n      Package that implements a doubly linked list: https://golang.org/pkg/container/list/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Or a bloom filter - good article on the topic: https://bart.degoe.de/bloom-filters-bit-arrays-recommendations-caches-bitcoin/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Article I published on this very blog: https://ieftimov.com/when-why-least-frequently-used-cache-implementation-golang\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ieftimov.com/post/spotify-recently-played-least-recently-used-cache-golang/","summary":"One of the most used caching schemes is Least Recently Used (LRU). Caches that use this eviction strategy will remove the least recently used item when their size reaches their capacity. That means that such caches have to keep a track of the order of access of the cached items, so it would evict the correct items.\n  Before we go too much into details about the implementation of an LRU cache, let\u0026rsquo;s first see what are the possible applications of this caching scheme.","title":"Barebones model of Spotify's 'Recently Played' screen using a Least Recently Used (LRU) cache in Golang"},{"content":"Over the years, people involved in computer science and engineering have worked really hard on optimisations of various natures. Given that we live in a world with limited resources, humanity has always worked on ways to optimise the costs and speed literally everything.\nIn software engineering, I would argue, the most popular approach to performance improvement is caching. While there are various applications of caching, depending on the area of software engineering, the idea behind caching is quite simple: store data that is often needed/used in fast structure/storage so it can be retrieved very fast.\nIn fact, caches have to be fast along two dimensions:\n Ensuring that as many of the requests for files go to it (cache hit), not over the network or to main memory (cache miss); The overhead of using it should be small: testing membership and deciding when to replace a file should be as fast as possible.  In this article we will focus on the second part: taking a specific implementation approach to Least Frequently Used cache and making its membership test and eviction algorithms performant. Also, we\u0026rsquo;ll also cover the basics and explore where such a caching scheme can be useful.\nThe basics LFU is a caching algorithm in which the Least Frequently Used item in the cache is removed whenever the cache\u0026rsquo;s capacity limit is reached. This means that for every item in our cache we have to keep track of how frequently it is used. Once the capacity is exceeded of the cache, an eviction algorithm will be run which has to pick and expire (remove) items from the cache.\nIf you have ever implemented an LFU cache you\u0026rsquo;ve probably looked into using a min-heap data structure because it handles insertion, deletion, and update in logarithmic time complexity. In this article, we will look at another approach to implementing it.\nBut before we go into the implementation, let\u0026rsquo;s see in what cases LFU is better than the alternatives.\nWhere LFU shines Imagine an asset cache on a CDN, where the assets are cached based on the usage patterns. So, when users request some images for the web page they are requesting, this CDN will add it to its cache for other users to get it even faster.\nFor example, one such image (asset) is the logo of the website. Can you imagine how many times a day Google\u0026rsquo;s logo is requested across all of their products? I\u0026rsquo;d really like to find that number out, but for now, we can probably agree that the number is HUGE.\nSuch asset caches are the perfect use-case for LFU caches. An LFU cache eviction algorithm will never evict frequently accessed assets. In fact, in such a cache Google\u0026rsquo;s logo will be cached virtually forever. In contrast, if there are any images that are going to be accessed due to a new landing page of a new product that\u0026rsquo;s on front page of Reddit, Slashdot \u0026amp; Hackernews, once the hype-storm passes the assets will be evicted faster because the access frequency will drop dramatically, although in the past few days they have been accessed many times.\nAs you might already be noticing, this approach to cache eviction is very efficient in cases where the access patterns of the cached objects do not change often. While LRU caches will evict the assets that would not be accessed recently, the LFU eviction approach would evict the assets that are not needed any more after the hype has settled.\nImplementing an LFU cache Now, let\u0026rsquo;s get to the meat of it. As we said before, instead of looking at a min-heap as a possible data structure that would back our LFU cache, we\u0026rsquo;re going to look at a better approach.\nIn fact, in 2010, a group of researchers Prof. Ketan Shah, Anirban Mitra \u0026amp; Dhruv Matani published a paper titled \u0026ldquo;An O(1) algorithm for implementing the LFU cache eviction scheme\u0026rdquo; (you can check it here) in which they explain an implementation of an LFU cache that has a runtime complexity of O(1) for all of its operations, which include insertion, access and deletion (eviction).\nHere, I\u0026rsquo;ll show you how we can implement this cache and walk you through the implementation.\nThe data structure(s) Nope, it\u0026rsquo;s not going to be some sort of a Frankenstein red-black tree. It\u0026rsquo;s, in fact, two doubly-linked lists and a hash table. Yes, that\u0026rsquo;s all.\nTo be able to understand the fundamentals of this implementation of LFU, let\u0026rsquo;s look at the linked list and hash table as graphics. Before we look at the actual graphics, we need to understand how the hash table and linked lists will be used.\nThe hash table will store all of the items with a key that is processed through a hashing algorithm (for our purpose we can keep it simple) and the value will be the actual item:\nThe linked lists are a bit more complicated. The first one will be the \u0026ldquo;frequency list\u0026rdquo;, which will have all of the frequencies of access. Each of the nodes in this list will have an item list, which will contain all of the items that have been accessed with the corresponding frequency. Additionally, each of the items in the item list will have a pointer to their ancestor in the frequency list:\nIf we look at our graphical example above, we can notice that the items A, B, C and D have been accessed 1 time. The items E and F have been accessed 4 times and so on. The blue lines are the pointers that each of the items in the item lists has to their ancestor in the frequency list.\nSo, what would happen if item E gets accessed one more time? Let\u0026rsquo;s go through the steps:\n Retrieving the item from the hash table is easy (and scales well, O(1)) We would access the item\u0026rsquo;s frequencyParent pointer, from which we can check what is the next frequency in the list If the new frequency is present (e.g. 8), we will push it as the first item of the item list under frequency node 8. If the new frequency is not present, we will create the frequency node 8 and will add E to its item list  That\u0026rsquo;s it. Retrieving the item and refreshing the frequency of the item is O(1). Before we go into implementing the access algorithm, let\u0026rsquo;s first establish the basic types that we would need to make this work.\nTypes As we said earlier, we need to model the types required that will be the backbone of our cache.\nThe first struct will be the CacheItem. This will be the actual item that will be stored in the cache:\ntype CacheItem struct { key string // Key of entry \tvalue interface{} // Value of item \tfrequencyParent *list.Element // Pointer to parent in cacheList } It contains the key by which we can look it up in the hash table, the value which is the actual cached item and a frequencyParent pointer to the pointer in the frequency list.\nThe next struct is the FrequencyItem, which represents each of the items in the frequency list. It contains a set of entries which will be a set of CacheItem pointers. We will use a map to store it so we can treat it as a set, which contains only unique items:\ntype FrequencyItem struct { entries map[*CacheItem]byte // Set of entries \tfreq int // Access frequency } The last struct that we will need to have a smooth running cache is, well, the Cache itself:\ntype Cache struct { bykey map[string]*CacheItem // Hashmap containing *CacheItems for O(1) access \tfreqs *list.List // Linked list of frequencies \tcapacity int // Max number of items \tsize int // Current size of cache } The Cache will contain the hashmap, called bykey (the naming comes from the paper linked above), the frequency list called freqs, the maximum capacity of the cache called capacity and the size of the cache which represents the count of items cached at any given moment.\nNew, set \u0026amp; get Let\u0026rsquo;s look at the first three functions needed to make our cache work. The first one is a little constructor function:\nfunc New() *Cache { cache := new(Cache) cache.bykey = make(map[string]*CacheItem) cache.freqs = list.New() cache.size = 0 cache.capacity = 100 return \u0026amp;c } The constructor New will create a new Cache struct and will set all the defaults to it. In case you\u0026rsquo;re wondering how list.New() works: for the frequency list, we will use Go\u0026rsquo;s container/list package, which contains a neat linked-list implementation. You can check its documentation for more details.\nThe second function, which will be implemented on the Cache, is the Set function:\nfunc (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value // Increment item access frequency here \t} else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ // Eviction, if needed \t// Increment item access frequency \t} } The function will take the cache key and the actual value/item to be cached as arguments. Then, it checks if the item is already cached or not. If it is cached, it will just update the value on the item. Otherwise, it will create a new CacheItem which will encapsulate the actual value, it will set the key, it will add the item to the bykey hashtable and it will increment the size of the cache.\nNow, in both logical branches I have added some comments for the missing pieces:\n Cache will have to know how to increment the access frequency for aCacheItem, but we are yet to implement that; Cache will have to know how to evict an item based on the access frequency if the size reaches the capacity.  We will keep these comments in until we implement the increment and evict functions.\nThe third function that Cache will receive is Get - accessing the item by the key from the hashtable and returning it:\nfunc (cache *Cache) Get(key string) interface{} { if e, ok := cache.bykey[key]; ok { // Increment acess frequency here \treturn e.value } return nil } There\u0026rsquo;s no magic here as well - we check if the bykey hashtable contains a value with the key argument and we return it if present. Otherwise, we return nil. Here, just like in Set, we will leave the placeholder comment where we have to add the frequency increment function call once we implement it.\nUpdating the access frequency As we already saw, with every access action to the cache we have to update the access frequency of the accessed item.\nLet\u0026rsquo;s look at the steps that our Increment function would have to take. First, for the item to be expired we will have to decide if this item is already a part of the hash table and the frequency list or not. If it is, we will have to find out its new frequency value and its next frequency position (node) in the frequency list.\nSecond, we will have to figure out if for the new frequency there\u0026rsquo;s already a node in the frequency list or not. If there is one, we will have to add the item to its list of entries and assign its new access frequency (which is the current access frequency + 1). If there\u0026rsquo;s none, we will have to create a new frequency node in the frequency list (and set all of its sane defaults) and then add the item to its list of entries\nThird, once we have a FrequencyParent detected, our function will have to set the new parent to the item that\u0026rsquo;s being incremented and add it to the parent\u0026rsquo;s list of entries.\nAs the final step, the increment function will remove the item from the entries of the old frequency node (frequencyParent).\nHere\u0026rsquo;s the code in Golang:\nfunc (cache *Cache) increment(item *CacheItem) { currentFrequency := item.frequencyParent var nextFrequencyAmount int var nextFrequency *list.Element if currentFrequency == nil { nextFrequencyAmount = 1 nextFrequency = cache.freqs.Front() } else { nextFrequencyAmount = currentFrequency.Value.(*FrequencyItem).freq + 1 nextFrequency = currentFrequency.Next() } if nextFrequency == nil || nextFrequency.Value.(*FrequencyItem).freq != nextFrequencyAmount { newFrequencyItem := new(FrequencyItem) newFrequencyItem.freq = nextFrequencyAmount newFrequencyItem.entries = make(map[*CacheItem]byte) if currentFrequency == nil { nextFrequency = cache.freqs.PushFront(newFrequencyItem) } else { nextFrequency = cache.freqs.InsertAfter(newFrequencyItem, currentFrequency) } } item.frequencyParent = nextFrequency nextFrequency.Value.(*FrequencyItem).entries[item] = 1 if currentFrequency != nil { cache.remove(currentFrequency, item) } } Let\u0026rsquo;s refer back to our original diagram of the frequency and entries lists and walk through incrementing the E item.\nThe first steps that our increment function will take are to allocate a pointer to node 4 (the frequencyParent) and its value (which is 4). Since node 4 is present in the list, it will find the next node in the frequency list, which in our case is node 7.\nOnce it figures out that the new frequency for the E node should be 5 and not 7, it will append a new frequency node in the list, between nodes 4 and 7:\nOnce the 5 node is added to the list, the function will set the defaults needed for the node to function properly. Then it will set E\u0026rsquo;s pointer to the new frequencyParent (the 5 node):\nAs the last step it will take the item, which has a *CacheItem type, and will add it to the entries list while deleting it from the entries list from the previous frequencyParent:\nLet\u0026rsquo;s look at what are the steps to remove a CacheItem from a FrequencyItem\u0026rsquo;s entries list.\nRemoving entries Once we know the node in the list from which we want to remove it, we can just remove the item from the entries list and also completely remove the FrequencyItem from the frequency list if the entries become empty:\nfunc (cache *Cache) Remove(listItem *list.Element, item *CacheItem) { frequencyItem := listItem.Value.(*FrequencyItem) delete(frequencyItem.entries, item) if len(frequencyItem.entries) == 0 { cache.freqs.Remove(listItem) } } Eviction The last piece of the puzzle is eviction, or in other words, removing the least frequently used items once the cache reaches its maximum capacity.\nWe have to know how many items we want to evict. Usually, our cache would have a low and high bound, so when the high bound is reached we will remove items until the low bound. In our case, we will evict an arbitrary number of items, that the Evict function will take as an argument.\nThe function will start to \u0026ldquo;walk through\u0026rdquo; the frequency list from the beginning towards the end. Since the frequency list is in ascending order, it will start to remove the entries from the first frequency node onwards, until it removes as many items as the arbitrary number passed in.\nIf a frequency node contains no entries due to eviction, the Evict function will have to remove the frequency node from the frequency list as well. It will do that by invoking the Remove function. That way, the eviction will not leave any garbage behind.\nHere\u0026rsquo;s the code of what we described above:\nfunc (cache *Cache) Evict(count int) { for i := 0; i \u0026lt; count; { if item := cache.freqs.Front(); item != nil { for entry, _ := range item.Value.(*FrequencyItem).entries { if i \u0026lt; count { delete(cache.bykey, entry.key) cache.Remove(item, entry) cache.size-- i++ } } } } } Back to Set and Get At the beginning of this article we implemented the Set and Get functions. One thing that we didn\u0026rsquo;t have available back then is the Evict and increment functions, so we can use them accordingly. Let\u0026rsquo;s add their invocation.\nIncrementing access frequency In the Get function, if we find an item in the bykey hash table, we need to increment it\u0026rsquo;s access frequency before we proceed to return its value:\nfunc (cache *Cache) Get(key string) interface{} { if e, ok := cache.bykey[key]; ok { cache.increment(e) return e.value } return nil } With this change, the Cache will increment the frequency of that particular item before we return it. But, are we forgetting something? Also, the Set function makes access to the cached items when it actually caches them. This means that when an item is cached it will immediately be added to the frequency list, under the node with value 1:\nfunc (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value cache.increment(item) } else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ // Eviction, if needed  cache.increment(item) } } Eviction after addition The Set function allows users of our LFU Cache to cache more items in it. A key component of any cache is that it should know how to evict items (free up space) when new items are added to the cache. For an LFU cache, the least frequently used items need to be removed when the cache is at capacity.\nLet\u0026rsquo;s first add a function that will return a bool if the cache has reached its maximum capacity:\nfunc (cache *Cache) atCapacity() bool { return cache.size \u0026gt;= cache.capacity } The function is simple: checks if the current size of the Cache is bigger or equals than the capacity.\nNow, let\u0026rsquo;s put this into use in the Set function. Once we have a new item set in the cache, we have to check if the cache has reached its capacity and then evict a number of items from it.\nFor simplicity, we will remove only 10 items every time we reach max capacity:\nfunc (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value cache.increment(item) } else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ if cache.atCapacity() { cache.Evict(10) } cache.increment(item) } } With this change, if at any point adding an item reaches the capacity of the cache, the cache will evict the least frequently used items.\nIf you would like to see the whole code for this article, you can check out this gist.\nComments on scaling and time complexity LFU is an interesting eviction scheme, especially when compared to LRU, in my opinion, due to its unconventional nature. While its application is limited, the algorithm and the backing data structures explained in the paper used in this article are fascinating due to the scaling ability of the approach.\nIf we revisit the paper that we mentioned at the beginning of the article, we will see that while LFU is not news, but it was traditionally implemented using a min-heap, which has a logarithmic time for insert, lookup and deletion. Interestingly in this paper, the authors explain that the approach they propose has an O(1) time complexity for each of the operations (insertion, lookup and deletion) because the operations are based on a hash table. Additionally, the linked lists do not add any time complexity because we do not traverse the lists at any point - we merely add or remove a node in them if needed (which is an O(1) operation).\nIn closing In this article, we went through the basics of LFU caches. We established what are the most important performance metrics (hit to miss ratio, membership \u0026amp; eviction speed). We saw that while it\u0026rsquo;s not the most widely used caching scheme, it sure can be very performant in some use cases.\nThen we went on to implement it, using an approach that scales quite well in terms of time complexity. We saw the complexities of implementing the eviction and frequency incrementation algorithms. In the end, we explored some more how the approach we used to implement it scales.\nIf you would like to read more on the topic, here are a couple of links that will enrich your knowledge of LFU caches and caching in general:\n \u0026ldquo;An O(1) algorithm for implementing the LFU cache eviction scheme\u0026rdquo; - Prof. Ketan Shah, Anirban Mitra, Dhruv Matani \u0026ldquo;Caching in theory and practice\u0026rdquo; - Pavel Panchekha \u0026ldquo;LFU (Least Frequently Used) Cache Implementation\u0026rdquo;  Geeks for Geeks    Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/when-why-least-frequently-used-cache-implementation-golang/","summary":"Over the years, people involved in computer science and engineering have worked really hard on optimisations of various natures. Given that we live in a world with limited resources, humanity has always worked on ways to optimise the costs and speed literally everything.\nIn software engineering, I would argue, the most popular approach to performance improvement is caching. While there are various applications of caching, depending on the area of software engineering, the idea behind caching is quite simple: store data that is often needed/used in fast structure/storage so it can be retrieved very fast.","title":"When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang"},{"content":"You can spend quite a bit of your programming career without working with trees, or just by simply avoiding them if you don’t understand them (which is what I had been doing for a while).\n  Now, don\u0026rsquo;t get me wrong - arrays, lists, stacks and queues are quite powerful data structures and can take you pretty far, but there is a limit to their capabilities, how you can use them and how efficient that usage can be. When you throw in hash tables to that mix, you can solve quite some problems, but for many of the problems out there trees are a powerful (and maybe the only) tool if you have them under your belt.\nSo, let\u0026rsquo;s look at trees and then we can try to use them in a small exercise.\nA touch of theory Arrays, lists, queues, stacks store data in a collection that has a start and an end, hence they are called \u0026ldquo;linear\u0026rdquo;. But when it comes to trees and graphs, things can get confusing since the data is not stored in a linear fashion.\nTrees are called nonlinear data structures. In fact, you can also say that trees are hierarchical data structures since the data is stored in a hierarchical way.\nFor your reading pleasure, Wikipedia’s definition of trees:\n A tree is a data structure made up of nodes or vertices and edges without having any cycle. The tree with no nodes is called the null or empty tree. A tree that is not empty consists of a root node and potentially many levels of additional nodes that form a hierarchy.\n What the definition states are that a tree is just a combination of nodes (or vertices) and edges (or links between the nodes) without having a cycle.\n  For example, the data structure represented on the diagram is a combination of nodes, named from A to F, with six edges. Although all of its elements look like they construct a tree, the nodes A, D, E and F have a cycle, therefore this structure is not a tree.\nIf we would break the edge between nodes F and E and add a new node called G with an edge between F and G, we would end up with something like this:\n  Now, since we eliminated the cycle in this graph, we can say that we have a valid tree. It has a root with the name A, with a total of 7 nodes. Node A has 3 children (B, D \u0026amp; F) and those have 3 children (C, E \u0026amp; G respectively). Therefore, node A has 6 descendants. Also, this tree has 3 leaf nodes (C, E \u0026amp; G) or nodes that have no children.\nWhat do B, D \u0026amp; F have in common? They are siblings because they have the same parent (node A). They all reside on level 1 because to get from each of them to the root we need to take only one step. For example, node G has level 2, because the path from G to A is: G -\u0026gt; F -\u0026gt; A, hence we need to follow two edges to get to A.\nNow that we know a bit of theory about trees, let’s see how we can solve some problems.\n  Modelling an HTML document If you are a software developer that has never written any HTML, I will just assume that you have seen (or have an idea) what HTML looks like. If you have not, then I encourage you to right click on the page that you are reading this and click on \u0026lsquo;View Source\u0026rsquo;.\nSeriously, go for it, I\u0026rsquo;ll wait\u0026hellip;\nBrowsers have this thing baked in, called the DOM - a cross-platform and language-independent application programming interface, which treats internet documents as a tree structure wherein each node is an object representing a part of the document. This means that when the browser reads your document\u0026rsquo;s HTML code it will load it and create a DOM out of it.\nSo, let’s imagine for a second we are developers working on a browser, like Chrome or Firefox and we need to model the DOM. Well, to make this exercise easier, let’s see a tiny HTML document:\n\u0026lt;html\u0026gt; \u0026lt;h1\u0026gt;Hello, World!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a simple HTML document.\u0026lt;/p\u0026gt; \u0026lt;/html\u0026gt; So, if we would model this document as a tree, it would look something like this:\n  Now, we could treat the text nodes as separate Nodes, but we can make our lives simpler by assuming that any HTML element can have text in it.\nThe html node will have two children, h1 and p, which will have tag, text and children as fields. Let’s put this into code:\ntype Node struct { tag string text string children []*Node } A Node will have only the tag name and children optionally. Let’s try to create the HTML document we saw above as a tree of Nodes by hand:\nfunc main() { p := Node{ tag: \u0026#34;p\u0026#34;, text: \u0026#34;This is a simple HTML document.\u0026#34;, id: \u0026#34;foo\u0026#34;, } h1 := Node{ tag: \u0026#34;h1\u0026#34;, text: \u0026#34;Hello, World!\u0026#34;, } html := Node{ tag: \u0026#34;html\u0026#34;, children: []*Node{\u0026amp;p, \u0026amp;h1}, } } That looks okay, we have a basic tree up and running now.\nBuilding MyDOM - a drop-in replacement for the DOM 😂 Now that we have some tree structure in place, let\u0026rsquo;s take a step back and see what kind of functionality would a DOM have. For example, if MyDOM (TM)would be a drop-in replacement of a real DOM, then with JavaScript we should be able to access nodes and modify them.\nThe simplest way to do this with JavaScript would be to use\ndocument.getElementById(\u0026#39;foo\u0026#39;) This function would lookup in the document tree to find the node whose ID is foo. Let\u0026rsquo;s update our Node struct to have more attributes and then work on writing a lookup function for our tree:\ntype Node struct { tag string id string class string children []*Node } Now, each of our Node structs will have a tag, children which is a slice of pointers to the children of that Node, id which is the ID of that DOM node and class which is the classes that can be applied to this DOM node.\nNow, back to our getElementById lookup function. Let\u0026rsquo;s see how we could implement it. First, let\u0026rsquo;s build an example tree that we can use for our lookup algorithm:\n\u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This is a H1\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; And this is some text in a paragraph. And next to it there\u0026#39;s an image. \u0026lt;img src=\u0026#34;http://example.com/logo.svg\u0026#34; alt=\u0026#34;Example\u0026#39;s Logo\u0026#34;/\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#39;footer\u0026#39;\u0026gt; This is the footer of the page. \u0026lt;span id=\u0026#39;copyright\u0026#39;\u0026gt;2019 \u0026amp;copy; Ilija Eftimov\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; This is a quite complicated HTML document. Let\u0026rsquo;s sketch out its structure in Go using the Node struct as a building block:\nimage := Node{ tag: \u0026#34;img\u0026#34;, src: \u0026#34;http://example.com/logo.svg\u0026#34;, alt: \u0026#34;Example\u0026#39;s Logo\u0026#34;, } p := Node{ tag: \u0026#34;p\u0026#34;, text: \u0026#34;And this is some text in a paragraph. And next to it there\u0026#39;s an image.\u0026#34;, children: []*Node{\u0026amp;image}, } span := Node{ tag: \u0026#34;span\u0026#34;, id: \u0026#34;copyright\u0026#34;, text: \u0026#34;2019 \u0026amp;copy; Ilija Eftimov\u0026#34;, } div := Node{ tag: \u0026#34;div\u0026#34;, class: \u0026#34;footer\u0026#34;, text: \u0026#34;This is the footer of the page.\u0026#34;, children: []*Node{\u0026amp;span}, } h1 := Node{ tag: \u0026#34;h1\u0026#34;, text: \u0026#34;This is a H1\u0026#34;, } body := Node{ tag: \u0026#34;body\u0026#34;, children: []*Node{\u0026amp;h1, \u0026amp;p, \u0026amp;div}, } html := Node{ tag: \u0026#34;html\u0026#34;, children: []*Node{\u0026amp;body}, } We start building this tree bottom - up. That means we create structs from the most deeply nested structs and working up towards body and html. Let\u0026rsquo;s look at a graphic of our tree:\n  Implementing Node Lookup 🔎 So, let\u0026rsquo;s continue with what we were up to - allow JavaScript to call getElementById on our document and find the Node that it\u0026rsquo;s looking for.\nTo do this, we have to implement a tree searching algorithm. The most popular approaches to searching (or traversal) of graphs and trees are Breadth First Search (BFS) and Depth First Search (DFS).\nBreadth-first search ⬅➡ BFS, as its name suggests, takes an approach to traversal where it explores nodes in \u0026ldquo;width\u0026rdquo; first before it goes in \u0026ldquo;depth\u0026rdquo;. Here\u0026rsquo;s a visualisation of the steps a BFS algorithm would take to traverse the whole tree:\nAs you can see, the algorithm will take two steps in depth (over html and body), but then it will visit all of the body\u0026rsquo;s children nodes before it proceeds to explore in depth and visit the span and img nodes.\nIf you would like to have a step-by-step playbook, it would be:\n We start at the root, the html node We push it on the queue We kick off a loop where we loop while the queue is not empty We check the next element in the queue for a match. If a match is found, we return the match and we\u0026rsquo;re done. When a match is not found, we take all of the children of the node-under-inspection and we add them to the queue, so they can be inspected GOTO 4  Let\u0026rsquo;s see a simple implementation of the algorithm in Go and I\u0026rsquo;ll share some tips on how you can remember the algorithm easily.\nfunc findById(root *Node, id string) *Node { queue := make([]*Node, 0) queue = append(queue, root) for len(queue) \u0026gt; 0 { nextUp := queue[0] queue = queue[1:] if nextUp.id == id { return nextUp } if len(nextUp.children) \u0026gt; 0 { for _, child := range nextUp.children { queue = append(queue, child) } } } return nil } The algorithm has three key points:\n The queue - it will contain all of the nodes that the algorithm visits Taking the first element of the queue, checking it for a match, and proceeding with the next nodes if no match is found Queueing up all of the children nodes for a node before moving on in the queue  Essentially, the whole algorithm revolves around pushing children nodes on a queue and inspecting the nodes that are queued up. Of course, if a match is not found at the end we return nil instead of a pointer to a Node.\nDepth-first search ⬇ For completeness sake, let\u0026rsquo;s also see how DFS would work.\nAs we stated earlier, the depth-first search will go first in depth by visiting as many nodes as possible until it reaches a leaf. When then happens, it will backtrack and find another branch on the tree to drill down on.\nLet\u0026rsquo;s see what that means visually:\nIf this is confusing to you, worry not - I\u0026rsquo;ve added a bit more granularity in the steps to aid my explanation.\nThe algorithm starts off just like BFS - it walks down from html to body and to div. Then, instead of continuing to h1, it takes another step to the leaf span. Once it figures out that span is a leaf, it will move back up to div to find other branches to explore. Since it won\u0026rsquo;t find any, it will move back to body to find new branches proceeding to visit h1. Then, it will do the same exercise again - go back to body and find that there\u0026rsquo;s another branch to explore - ultimately visiting p and the img nodes.\nIf you\u0026rsquo;re wondering something along the lines of \u0026ldquo;how can we go back up to the parent without having a pointer to it\u0026rdquo;, then you\u0026rsquo;re forgetting one of the oldest tricks in the book - recursion. Let\u0026rsquo;s see a simple recursive Go implementation of the algorithm:\nfunc findByIdDFS(node *Node, id string) *Node { if node.id == id { return node } if len(node.children) \u0026gt; 0 { for _, child := range node.children { findByIdDFS(child, id) } } return nil }   Finding by class name 🔎 Another functionality MyDOM (TM)should have is the ability to find nodes by a class name. Essentially, when a JavaScript script executes getElementsByClassName, MyDOM should know how to collect all nodes with a certain class.\nAs you can imagine, this is also an algorithm that would have to explore the whole MyDOM (TM)tree and pick up the nodes that satisfy certain conditions.\nTo make our lives easier, let\u0026rsquo;s first implement a function that a Node can receive, called hasClass:\nfunc (n *Node) hasClass(className string) bool { classes := strings.Fields(n.classes) for _, class := range classes { if class == className { return true } } return false } hasClass takes a Node\u0026rsquo;s classes field, splits them on each space character and then loops the slice of classes and tries to find the class name that we are interested in. Let\u0026rsquo;s write a couple of tests that will test this function:\ntype testcase struct { className string node Node expectedResult bool } func TestHasClass(t *testing.T) { cases := []testcase{ testcase{ className: \u0026#34;foo\u0026#34;, node: Node{classes: \u0026#34;foo bar\u0026#34;}, expectedResult: true, }, testcase{ className: \u0026#34;foo\u0026#34;, node: Node{classes: \u0026#34;bar baz qux\u0026#34;}, expectedResult: false, }, testcase{ className: \u0026#34;bar\u0026#34;, node: Node{classes: \u0026#34;\u0026#34;}, expectedResult: false, }, } for _, case := range cases { result := case.node.hasClass(test.className) if result != case.expectedResult { t.Error( \u0026#34;For node\u0026#34;, case.node, \u0026#34;and class\u0026#34;, case.className, \u0026#34;expected\u0026#34;, case.expectedResult, \u0026#34;got\u0026#34;, result, ) } } } As you can see, the hasClass function will detect if a class name is in the list of classes on a Node. Now, let\u0026rsquo;s move on to implementing MyDOM\u0026rsquo;s implementation of finding all Nodes by class name:\nfunc findAllByClassName(root *Node, className string) []*Node { result := make([]*Node, 0) queue := make([]*Node, 0) queue = append(queue, root) for len(queue) \u0026gt; 0 { nextUp := queue[0] queue = queue[1:] if nextUp.hasClass(className) { result = append(result, nextUp) } if len(nextUp.children) \u0026gt; 0 { for _, child := range nextUp.children { queue = append(queue, child) } } } return result } If the algorithm seems familiar, that\u0026rsquo;s because you\u0026rsquo;re looking at a modified findById function. findAllByClassName works just like findById, but instead of returning the moment it finds a match, it will just append the matched Node to the result slice. It will continue doing that until all of the Nodes have been visited.\nIf there are no matches, the result slice will be empty. If there are any matches, they will be returned as part of the result slice.\nLast thing worth mentioning is that to traverse the tree we used a Breadth-first approach here - the algorithm uses a queue for each of the Nodes and loops over them while appending to the result slice if a match is found.\n  Deleting nodes 🗑 Another functionality that is often used in the DOM is the ability to remove nodes. Just like the DOM can do it, also our MyDOM (TM)should be able to handle such operations.\nThe simplest way to do this operation in JavaScript is:\nvar el = document.getElementById(\u0026#39;foo\u0026#39;); el.remove(); While our document knows how to handle getElementById (by calling findById under the hood), our Nodes do not know how to handle a remove function. Removing a Node from the MyDOM (TM)tree would be a two-step process:\n We have to look up to the parent of the Node and remove it from its parent\u0026rsquo;s children collection; If the to-be-removed Node has any children, we have to remove those from the DOM. This means we have to remove all pointers to each of the children and its parent (the node to-be-removed) so Go\u0026rsquo;s garbage collector can free up that memory.  And here\u0026rsquo;s a simple way to achieve that:\nfunc (node *Node) remove() { // Remove the node from it\u0026#39;s parents children collection  for idx, sibling := range n.parent.children { if sibling == node { node.parent.children = append( node.parent.children[:idx], node.parent.children[idx+1:]..., ) } } // If the node has any children, set their parent to nil and set the node\u0026#39;s children collection to nil  if len(node.children) != 0 { for _, child := range node.children { child.parent = nil } node.children = nil } } A *Node would have a remove function, which does the two-step process of the Node\u0026rsquo;s removal.\nIn the first step, we take the node out of the parent\u0026rsquo;s children list, by looping over them and removing the node by appending the elements before the node in the list, and the elements after the node.\nIn the second step, after checking for the presence of any children on the node, we remove the reference to the parent from all the children and then we set the Node\u0026rsquo;s children to nil.\nWhere to next? Obviously, our MyDOM (TM)implementation is never going to become a replacement for the DOM. But, I believe that it\u0026rsquo;s an interesting example that can help you learn and it\u0026rsquo;s pretty interesting problem to think about. We interact with browsers every day, so thinking how they could function under the hood is an interesting exercise.\nIf you would like to play with our tree structure and write more functionality, you can head over to WC3\u0026rsquo;s JavaScript HTML DOM Document documentation and think about adding more functionality to MyDOM.\nObviously, the idea behind this article was to learn more about trees (graphs) and learn about the popular searching/traversal algorithms that are used out there. But, by all means, please keep on exploring and experimenting and drop me a comment about what improvements you did to your MyDOM implementation.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/golang-datastructures-trees/","summary":"You can spend quite a bit of your programming career without working with trees, or just by simply avoiding them if you don’t understand them (which is what I had been doing for a while).\n  Now, don\u0026rsquo;t get me wrong - arrays, lists, stacks and queues are quite powerful data structures and can take you pretty far, but there is a limit to their capabilities, how you can use them and how efficient that usage can be.","title":"Golang Datastructures: Trees"},{"content":"Looking at any programming language you will (hopefully!) find a rich and useful standard library. I started my professional career as a software developer with Ruby, which has quite an easy-to-use and well-documented standard library with a plethora of modules and classes to use. Personally, I find the Enumerable module in Ruby with all its nice methods simply brilliant.\nYou might be coming from a different language, but I am sure that any serious programming language out there has a set of classes, modules, methods and functions to make your life (and work) easy.\nSo, what about Elixirs stdlib?\nNo surprise there too – Elixir has a well-documented and easy-to-use standard library. But, because it works on top of the BEAM virtual machine and inherits plenty from Erlang\u0026rsquo;s rich history, it also has a bit more – something called OTP.\nPhoto by Mario Caruso on UnsplashMeet OTP 👋 From Wikipedia\u0026rsquo;s article on OTP:\n OTP is a collection of useful middleware, libraries, and tools written in the Erlang programming language. It is an integral part of the open-source distribution of Erlang. The name OTP was originally an acronym for Open Telecom Platform, which was a branding attempt before Ericsson released Erlang/OTP as open source. However, neither Erlang nor OTP is specific to telecom applications.\n In continuation, it states:\n It (OTP) contains:\n an Erlang interpreter (called BEAM); an Erlang compiler; a protocol for communication between servers (nodes); a CORBA Object Request Broker; a static analysis tool called Dialyzer; a distributed database server (Mnesia); and many other libraries.   While I do not consider myself an expert in Elixir, Erlang, the BEAM or OTP by any stretch of the imagination, I would like to take you on a journey to one of the most useful and well-known behaviours of OTP – GenServer.\n  In continuation, we will use BEAM processes, so if you\u0026rsquo;re not familiar with spawning new processes, sending and receiving messages to/from them, then it\u0026rsquo;s best to head over to \u0026ldquo;Understanding the basics of Elixir\u0026rsquo;s concurrency model\u0026rdquo; and give it a quick read. It will help you understand processes and concurrency in Elixir so you can apply the knowledge in the project that we work on in this article. I promise.\nShortening a link ✂️ Let\u0026rsquo;s write a URL shortener module that will run in a BEAM process and can receive multiple commands:\n shorten – takes a link, shortens it and returns the short link as a response get – take a short link and return the original one flush – erase the URL shortener memory stop – stop the process  defmodule URLShortener do def start do spawn(__MODULE__, :loop, [%{}]) end def loop(state) do receive do {:stop, caller} -\u0026gt; send caller, \u0026#34;Shutting down.\u0026#34; {:shorten, url, caller} -\u0026gt; url_md5 = md5(url) new_state = Map.put(state, url_md5, url) send caller, url_md5 loop(new_state) {:get, md5, caller} -\u0026gt; send caller, Map.fetch(state, md5) loop(state) :flush -\u0026gt; loop(%{}) _ -\u0026gt; loop(state) end end defp md5(url) do :crypto.hash(:md5, url) |\u0026gt; Base.encode16(case: :lower) end end What the module does is when the process starts it will recursively call the URLShortener.loop/1 function, until it receives the {:stop, caller} message.\nIf we zoom into the {:shorten, url, caller} case we notice that we generate a MD5 digest from the URL and then we update the state map which creates a new map (called new_state). Once we get the digest we store it in a map with the key being the MD5 and the value is the actual URL. The state map will look like:\n%{ \u0026#34;99999ebcfdb78df077ad2727fd00969f\u0026#34; =\u0026gt; \u0026#34;https://google.com\u0026#34;, \u0026#34;76100d6f27db53fddb6c8fce320f5d21\u0026#34; =\u0026gt; \u0026#34;https://elixir-lang.org\u0026#34;, \u0026#34;3097fca9b1ec8942c4305e550ef1b50a\u0026#34; =\u0026gt; \u0026#34;https://github.com\u0026#34;, ... } Then, we send the MD5 value back to the caller. Obviously, this is not how bit.ly or the likes work, as their links are much shorter. (For those interested, here\u0026rsquo;s an interesting discussion on the topic). However, for the purpose of this article, we\u0026rsquo;ll stick to simple MD5 digest of the URL.\nThe other two commands, get and flush, are pretty simple. get returns only a single value from the state map, while flush invokes loop/1 with an empty map, effectively removing all the shortened links from the process' state (memory).\nLet\u0026rsquo;s run our shortener in an IEx session:\niex(22)\u0026gt; shortener = URLShortener.start #PID\u0026lt;0.141.0\u0026gt; iex(23)\u0026gt; send shortener, {:shorten, \u0026#34;https://ieftimov.com\u0026#34;, self()} {:shorten, \u0026#34;https://ieftimov.com\u0026#34;, #PID\u0026lt;0.102.0\u0026gt;} iex(24)\u0026gt; send shortener, {:shorten, \u0026#34;https://google.com\u0026#34;, self()} {:shorten, \u0026#34;https://google.com\u0026#34;, #PID\u0026lt;0.102.0\u0026gt;} iex(25)\u0026gt; send shortener, {:shorten, \u0026#34;https://github.com\u0026#34;, self()} {:shorten, \u0026#34;https://github.com\u0026#34;, #PID\u0026lt;0.102.0\u0026gt;} iex(26)\u0026gt; flush \u0026#34;8c4c7fbc57b08d379da5b1312690be04\u0026#34; \u0026#34;99999ebcfdb78df077ad2727fd00969f\u0026#34; \u0026#34;3097fca9b1ec8942c4305e550ef1b50a\u0026#34; :ok iex(27)\u0026gt; send shortener, {:get, \u0026#34;99999ebcfdb78df077ad2727fd00969f\u0026#34;, self()} {:get, \u0026#34;99999ebcfdb78df077ad2727fd00969f\u0026#34;, #PID\u0026lt;0.102.0\u0026gt;} iex(28)\u0026gt; flush \u0026#34;https://google.com\u0026#34; :ok iex(29)\u0026gt; send shortener, {:get, \u0026#34;8c4c7fbc57b08d379da5b1312690be04\u0026#34;, self()} {:get, \u0026#34;8c4c7fbc57b08d379da5b1312690be04\u0026#34;, #PID\u0026lt;0.102.0\u0026gt;} iex(30)\u0026gt; flush \u0026#34;https://ieftimov.com\u0026#34; :ok iex(31)\u0026gt; send shortener, {:get, \u0026#34;3097fca9b1ec8942c4305e550ef1b50a\u0026#34;, self()} {:get, \u0026#34;3097fca9b1ec8942c4305e550ef1b50a\u0026#34;, #PID\u0026lt;0.102.0\u0026gt;} iex(32)\u0026gt; flush \u0026#34;https://github.com\u0026#34; :ok Working as expected – we send three different URLs for shortening, we receive their MD5 digests back in the process mailbox and when we query for them we get each of them back.\nAlthough our URLShortener module works pretty neatly now, it actually lacks quite a bit of functionality. Sure, it does handle the happy path really well, but when it comes to error handling, tracing or error reporting it falls really short. Additionally, it does not have a standard interface to add more functions to the process – we sort of came up with it as we went on.\nAfter reading all of that you\u0026rsquo;re probably thinking there is a better way to do this. And you\u0026rsquo;d be right to think so – let\u0026rsquo;s learn more about GenServers.\nEnter GenServer 🚪 GenServer is an OTP behaviour. Behaviour in this context refers to three things:\n an interface, which is a set of functions; an implementation, which is the application-specific code, and the container, which is a BEAM process  This means that a module can implement a certain group of functions (interface or signatures), that under the hood implement some callback functions (which are specific to the behaviour you work on), that are run within a BEAM process.\nFor example, GenServer is a generic server behaviour – it expects for each of the functions defined in it\u0026rsquo;s interface a set of callbacks which will handle the requests to the server. This means that the interface functions will be used by the clients of the generic server, a.k.a. the client API, while the callbacks defined will essentially be the server internals (\u0026ldquo;the backend\u0026rdquo;).\nSo, how does a GenServer work? Well, as you can imagine we cannot go too deep on the hows of GenServer, but we need to get a good grasp on some basics:\n Server start \u0026amp; state Asynchronous messages Synchronous messages  Server start \u0026amp; state Just like with our URLShortener we implemented, every GenServer is capable of holding state. In fact, GenServers must implement a init/1 function, which will set the initial state of the server (see the init/1 documentation here for more details).\nTo start the server we can run:\nGenServer.start_link(__MODULE__, :ok, []) GenServer.start_link/3 will invoke the init/1 function of the __MODULE__, passing in :ok as an argument to init/1. This function call will block until init/1 returns, so usually in this function, we do any required setup of the server process (that might be needed). For example, in our case, to rebuild URLShortener using a GenServer behaviour, we will need an init/1 function to set the initial state (empty map) of the server:\ndef init(:ok) do {:ok, %{}} end That\u0026rsquo;s all. start_link/3 will call init/1 with the :ok argument, which will return an :ok and set the state of the process to an empty map.\nSync \u0026amp; async messages 📨 As most servers out there, GenServers can also receive and reply to requests (if needed). As the heading suggests, there are two types of requests that GenServers handle – the ones expect a response (call) and the others that don\u0026rsquo;t (cast). Therefore, GenServers define two callback functions - handle_call/3 and handle_cast/2.\nWe will look at these functions in more depth a bit later.\nReimplementing URLShortener, using GenServer ♻️ Let\u0026rsquo;s look at how we can flip the implementation to use GenServer.\nFirst, let\u0026rsquo;s add the shell of the module, the start_link/1 function and the init/1 function that start_link/1 will invoke:\ndefmodule URLShortener do use GenServer def start_link(opts \\\\ []) do GenServer.start_link(__MODULE__, :ok, opts) end def init(:ok) do {:ok, %{}} end end The notable changes here are the use of the GenServer behaviour in the module, the start_link/1 function which invokes GenServer.start_link/3 which would, in fact, call the init/1 function with the :ok atom as an argument. Also, it\u0026rsquo;s worth noting that the empty map that the init/1 function returns in the tuple is the actual initial state of the URLShortener process.\nLet\u0026rsquo;s give it a spin in IEx:\niex(1)\u0026gt; {:ok, pid} = URLShortener.start_link {:ok, #PID\u0026lt;0.108.0\u0026gt;} That\u0026rsquo;s all we can do at this moment. The difference here is that the GenServer.start_link/3 function will return a tuple with an atom (:ok) and the PID of the server.\nStopping the server ✋ Let\u0026rsquo;s add the stop command:\ndefmodule URLShortener do use GenServer # Client API def start_link(opts \\\\ []), do: GenServer.start_link(__MODULE__, :ok, opts) def stop(pid) do GenServer.cast(pid, :stop) end # GenServer callbacks def init(:ok), do: {:ok, %{}} def handle_cast(:stop, state) do {:stop, :normal, state} end end Yes, I know I said we\u0026rsquo;ll add one command but ended up adding two functions: stop/1 and handle_cast/2. Bear with me now:\nBecause we do not want to get a response back on the stop command, we will use GenServer.cast/2 in the stop/1 function. This means that when that command is called by the client (user) of the server, the handle_cast/2 callback will be triggered on the server. In our case, the handle_cast/2 function will return a tuple of three items – {:stop, :normal, state}.\nReturning this tuple stops the loop and another callback called terminate/2 is called (which is defined in the behaviour but not implemented by URLShortener) with the reason :normal and state state. The process will exit with reason :normal.\nThis way of working with GenServer allows us to only define callbacks and the GenServer behaviour will know how to handle the rest. The only complexity resides in the fact that we need to understand and know most types of returns that the callback functions can have.\nAnother thing worth pointing out is that each function that will be used by the client will take a PID as a first argument. This will allow us to send messages to the correct GenServer process. Going forward we will not acknowledge PIDs presence – we accept that it\u0026rsquo;s mandatory for our URLShortener to work. Later we will look at ways we can skip passing the PIDs as arguments.\nLet\u0026rsquo;s jump back in IEx and start and stop a URLShortener server:\niex(1)\u0026gt; {:ok, pid} = URLShortener.start_link {:ok, #PID\u0026lt;0.109.0\u0026gt;} iex(2)\u0026gt; Process.alive?(pid) true iex(3)\u0026gt; URLShortener.stop(pid) :ok iex(4)\u0026gt; Process.alive?(pid) false That\u0026rsquo;s starting and stopping in all of it\u0026rsquo;s glory.\nShortening a URL Another thing we wanted our server to have is the ability to shorten URLs, by using their MD5 digest as the short variant of the URL. Let\u0026rsquo;s do that using GenServer:\ndefmodule URLShortener do use GenServer # Client API def start_link(opts \\\\ []), do: GenServer.start_link(__MODULE__, :ok, opts) def stop(pid), do: GenServer.cast(pid, :stop) def shorten(pid, url) do GenServer.call(pid, {:shorten, url}) end # GenServer callbacks def init(:ok), do: {:ok, %{}} def handle_cast(:stop, state), do: {:stop, :normal, state} def handle_call({:shorten, url}, _from, state) do short = md5(url) {:reply, short, Map.put(state, short, url)} end defp md5(url) do :crypto.hash(:md5, url) |\u0026gt; Base.encode16(case: :lower) end end Three functions this time, but at least the md5/1 is a replica of the one we had previously. So, let\u0026rsquo;s look at the other two.\nYou might be seeing a pattern - we have a function that will be used by the client (shorten/2) and a callback that will be invoked on the server (handle_call/3). This time, there\u0026rsquo;s a slight difference in the functions used and naming: in shorten/2 we call GenServer.call/2 instead of cast/2, and the callback name is handle_call/3 instead of handle_cast/2.\nWhy? Well, the difference lies in the response - handle_call/3 will send a reply back to the client (hence the :reply atom in the response tuple), while handle_cast/2 does not do that. Basically casting is an async call where the client does not expect a response, while calling is a sync call where the response is expected.\nSo, let\u0026rsquo;s look at the structure of the handle_call/3 callback.\nIt takes three arguments: the request from the client (in our case a tuple), a tuple describing the client of the request (which we ignore), and the state of the server (in our case a map).\nAs a response, it returns a tuple with :reply, stating that there will be a reply to the request, the reply itself (in our case the shortened link) and the state which is the state carried over to the next loop of the server.\nOf course, handle_call/3 has a bit more intricacies that we will look into later, but you can always check it\u0026rsquo;s documentation to learn more.\nFetching a shortened URL 🔗 Let\u0026rsquo;s implement the get command, which when provided with a short version of the link it will return the full URL:\ndefmodule URLShortener do use GenServer # Client API # ... def get(pid, short_link) do GenServer.call(pid, {:get, short_link}) end # GenServer callbacks # ... def handle_call({:get, short_link}, _from, state) do {:reply, Map.get(state, short_link), state} end end The double-function entry pattern again - we add URLShortener.get/2 and another head of the URLShortener.handle_call/3 function.\nThe URLShortener.get/2 will call GenServer.call/2 under the hood, which when executed will cause the handle_call/3 callback to fire.\nThe URLShortener.handle_call/3 this time will take the command (:get) and the short_link as the first argument. Looking inside we see that, again, it\u0026rsquo;s a short function - it only returns a tuple with :reply (which states that the call will have a reply), a call to Map.get/2, whose return will be the actual response of the call, and the state, so the GenServer process maintains the state in the next loop.\nAt this moment, we can safely say that we have a good idea of the basics on writing functionality for a module that implements the GenServer behaviour. As you might be thinking, there\u0026rsquo;s much to explore, but these basics will allow you to create GenServers and experiment.\nBefore you go on, try to implement two more commands:\n flush – an async call which will erase the state of the server count – a sync call returning the number of links in the server\u0026rsquo;s state  More configurations 🎛 If we circle back to URLShortener.start_link/1 and it\u0026rsquo;s internals (namely the invocation of GenServer.start_link/3), we will also notice that we can pass options (opts) to the GenServer.start_link/3 function, that are defaulted to an empty list ([]).\nWhat are the options that we can add here? By looking at the documentation of GenServer.start_link/3 you\u0026rsquo;ll notice multiple interesting options:\n :name - used for name registration. This means that instead of identifying a GenServer by PID, we can put a name on it. :timeout - sets the server startup timeout (in milliseconds) :debug - enables debugging by invoking the corresponding function in the :sys module :hibernate_after - sets the time (in milliseconds) after which the server process will go into hibernation automatically until a new request comes in. This is done by utilising :proc_lib.hibernate/3 :spawn_opt - enables passing more options to the underlying process  Most of these are advanced and are beyond our use-case here. However, there\u0026rsquo;s one configuration we could use right now: :name.\nNaming the server 📢 Let\u0026rsquo;s modify our URLShortener to take a name in it\u0026rsquo;s start_link/1 function and test it in IEx. Additionally, since every URLShortener process will have a name, we can refer to the process by name instead of PID - let\u0026rsquo;s see how that would work in code:\ndefmodule URLShortener do use GenServer # Client API def start_link(name, opts \\\\ []) do GenServer.start_link(__MODULE__, :ok, opts ++ [name: name]) end def stop(name), do: GenServer.cast(name, :stop) def shorten(name, url), do: GenServer.call(name, {:shorten, url}) def get(name, short_link) do GenServer.call(name, {:get, short_link}) end # GenServer callbacks def init(:ok), do: {:ok, %{}} def handle_cast(:stop, state), do: {:stop, :normal, state} def handle_call({:shorten, url}, _from, state), do: {:reply, md5(url), Map.put(state, md5(url), url)} def handle_call({:get, short_link}, _from, state) do {:reply, Map.get(state, short_link), state} end defp md5(url), do: :crypto.hash(:md5, url) |\u0026gt; Base.encode16(case: :lower) end That\u0026rsquo;s all. We added a new argument to URLShortener.start_link/2 and we dropped all usage of PID and replaced it with name.\nLet\u0026rsquo;s take it for a spin in IEx:\niex(1)\u0026gt; {:ok, pid} = URLShortener.start_link(:foo) {:ok, #PID\u0026lt;0.109.0\u0026gt;} iex(2)\u0026gt; URLShortener.shorten(:foo, \u0026#34;https://google.com\u0026#34;) \u0026#34;99999ebcfdb78df077ad2727fd00969f\u0026#34; iex(3)\u0026gt; URLShortener.get(:foo, \u0026#34;99999ebcfdb78df077ad2727fd00969f\u0026#34;) \u0026#34;https://google.com\u0026#34; iex(4)\u0026gt; URLShortener.stop(:foo) :ok iex(5)\u0026gt; Process.alive?(pid) false You can see that this is pretty cool - instead of using PID we added a name :foo to the process which allowed us to refer to it using the name instead of the PID. Obviously, you can see that to inspect the BEAM process in any fashion we will still need the PID, but for the client the name does the trick.\nThis combination of name and PID allows us to have reference to the BEAM process while improving the ease of use for the client.\nIf we would like to simplify things even more, we can turn the URLShortener into a \u0026ldquo;singleton\u0026rdquo; server. Before you freak out - it has none of the drawbacks that the singleton pattern that\u0026rsquo;s infamous in OO programming has. We\u0026rsquo;re merely stating that we could change the URLShortener to have one and only one process running at a certain time, by setting a static name to it:\ndefmodule URLShortener do use GenServer @name :url_shortener_server # Client API def start_link(opts \\\\ []) do GenServer.start_link(__MODULE__, :ok, opts ++ [name: @name]) end def stop, do: GenServer.cast(@name, :stop) def shorten(url), do: GenServer.call(@name, {:shorten, url}) def get(short_link) do GenServer.call(@name, {:get, short_link}) end # GenServer callbacks # ... end You can notice that we added a module attribute @name that holds the name of the process. In all the functions from the client API, we dropped the name from the arguments lists and we simply use @name as a reference to the process. This means that there\u0026rsquo;s going to be only one process for URLShortener with the name :url_shortener_server.\nLet\u0026rsquo;s take it for a spin in IEx:\niex(1)\u0026gt; {:ok, pid} = URLShortener.start_link {:ok, #PID\u0026lt;0.108.0\u0026gt;} iex(2)\u0026gt; URLShortener.shorten(\u0026#34;https://google.com\u0026#34;) \u0026#34;99999ebcfdb78df077ad2727fd00969f\u0026#34; iex(3)\u0026gt; URLShortener.shorten(\u0026#34;https://yahoo.com\u0026#34;) \u0026#34;c88f320dec138ba5ab0a5f990ff082ba\u0026#34; iex(4)\u0026gt; URLShortener.get(\u0026#34;99999ebcfdb78df077ad2727fd00969f\u0026#34;) \u0026#34;https://google.com\u0026#34; iex(5)\u0026gt; URLShortener.stop :ok iex(6)\u0026gt; Process.alive?(pid) false You can notice that although we captured the PID on the first line, we do not need it at all - all of the work is done for us by URLShortener.\nIn this section, you saw how you can utilise names to more easily work with processes. Let\u0026rsquo;s review our full implementation of the URLShortener module.\nOutro 🖖 Before we wrap up this long tutorial, let\u0026rsquo;s have a final look at our new URLShortener module, including the count/1 and flush/1 functions:\ndefmodule URLShortener do use GenServer # Client API def start_link(name, opts \\\\ []) do GenServer.start_link(__MODULE__, :ok, opts ++ [name: name]) end def shorten(name, url) do GenServer.call(name, {:shorten, url}) end def get(name, short) do GenServer.call(name, {:get, short}) end def flush(name) do GenServer.cast(name, :flush) end def stop(name) do GenServer.cast(name, :stop) end def count(name) do GenServer.call(name, :count) end # Callbacks def init(:ok) do {:ok, %{}} end def handle_cast(:flush, _state) do {:noreply, %{}} end def handle_cast(:stop, state) do {:stop, :normal, state} end def handle_call({:shorten, url}, _from, state) do shortened = md5(url) new_state = Map.put(state, shortened, url) {:reply, shortened, new_state} end def handle_call({:get, short}, _from, state) do {:reply, Map.get(state, short), state} end def handle_call(:count, _from, state) do count = Map.keys(state) |\u0026gt; Enum.count {:reply, count, state} end defp md5(url) do :crypto.hash(:md5, url) |\u0026gt; Base.encode16(case: :lower) end end The two callbacks are faily simple - flush will just send a noreply and set the state to an empty map. count on the other hand will have a reply with the count of the items of the map, which is simply the numbers of keys there are in the state map. That\u0026rsquo;s all.\nWhile you got to the end of the article your journey with GenServer does not end here. In fact, it just started. GenServers and OTP are very powerful tools that you can use to build generic servers that can live in small BEAM processes and have a very generic approach to building functionality (calls and callbacks).\nWhile we did cover a lot of ground here we didn\u0026rsquo;t touch on why we named the starting function start_link instead of just start (hint: supervisors convention), or how we would approach testing such a GenServer like URLShortener.\nIn what kind of scenarios have you used GenServers? Or, if you do not have experience with it, where do you see yourself using it in the future?\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/otp-elixir-genserver-build-own-url-shortener/","summary":"Looking at any programming language you will (hopefully!) find a rich and useful standard library. I started my professional career as a software developer with Ruby, which has quite an easy-to-use and well-documented standard library with a plethora of modules and classes to use. Personally, I find the Enumerable module in Ruby with all its nice methods simply brilliant.\nYou might be coming from a different language, but I am sure that any serious programming language out there has a set of classes, modules, methods and functions to make your life (and work) easy.","title":"OTP in Elixir: Learn GenServer by Building Your Own URL Shortener"},{"content":"If you come from an object-oriented background, you might have tried concurrency in your favourite OO language before. Your mileage will vary, but in general OO languages are harder to work with when it comes to concurrency. This is due to their nature - they are designed to keep state in memory and require more expertise and experience to be successful with.\nHow does Elixir stand up to other languages when it comes to concurrency? Well, for starters just being functional and immutable is a big win - no state to manage. But also, Elixir has more goodies packing under the hood and in its standard library.\nBeing based on Erlang\u0026rsquo;s virtual machine (a.k.a. the BEAM), Elixir uses processes to run any and all code. Note that from here on any time we mention processes, unless specified otherwise, we are referring to BEAM processes, not OS processes.\nElixir\u0026rsquo;s processes are isolated from one another, they do not share any memory and run concurrently. They are very lightweight and the BEAM is capable of running many thousands of them at the same time. That\u0026rsquo;s why Elixir exposes primitives for creating processes, communicating between them and various modules on process management.\nLet\u0026rsquo;s see how we can create processes and send messages between them.\nCreating processes One of the simplest (yet powerful) tools in Elixir\u0026rsquo;s toolbelt is IEx - Elixir\u0026rsquo;s REPL, short for Interactive Elixir. If we jump into IEx and run h self, we will get the following output:\niex(1)\u0026gt; h self def self() @spec self() :: pid() Returns the PID (process identifier) of the calling process. Allowed in guard clauses. Inlined by the compiler. As you can see, self() is a built-in function in Elixir which returns the PID (process identifier) of the calling process. If you run it in IEx it will return the PID of IEx:\niex(2)\u0026gt; self #PID\u0026lt;0.102.0\u0026gt; Now, just like IEx is a BEAM process, with its own PID, it can also create new processes. In fact, any BEAM process can spawn BEAM processes. This is done using the Kernel.spawn/1 function:\niex(3)\u0026gt; spawn(fn -\u0026gt; 1 + 1 end) #PID\u0026lt;0.108.0\u0026gt; spawn/1 creates a new process which invokes the function provided as argument, fn -\u0026gt; 1 + 1 end. What you might notice is that we do not see the return value of the anonymous function because the function ran in a different process. What we get instead is the PID of the spawned process.\nAnother thing worth noticing is that once we spawn a process it will run right away, which means that the function will be immediately executed. We can check that using the Process.alive?/1 function:\niex(4)\u0026gt; pid = spawn(fn -\u0026gt; 1 + 1 end) #PID\u0026lt;0.110.0\u0026gt; iex(5)\u0026gt; Process.alive?(pid) false While we don\u0026rsquo;t need to look at the Process module in depth right now, it has quite a bit more functions available for working with processes. You can explore its documentation here.\nNow, let\u0026rsquo;s look at receiving messages.\nReceiving messages in processes For the purpose of our example, let\u0026rsquo;s imagine we open a new IEx session and we tell the IEx process (a.k.a. self) that it might receive a message that it should react to. If this makes you scratch your head a bit, remember that since IEx is a BEAM process it can receive messages just like any other BEAM process.\nThe messages that we would like our IEx process to receive will be:\n tuple containing :hello atom and a string with a name (e.g. {:hello, \u0026quot;Jane\u0026quot;}) tuple containing the :bye atom and a string with a name (e.g. {:bye, \u0026quot;John\u0026quot;})  When the process receives the message in the first case it should reply with \u0026ldquo;Hello Jane\u0026rdquo;, while in the second case it should reply with \u0026ldquo;Bye John\u0026rdquo;. If we could use the cond macro in Elixir, it would look something like:\ncond message do {:hello, name} -\u0026gt; \u0026#34;Hello #{name}\u0026#34; {:bye, name} -\u0026gt; \u0026#34;Bye #{name}\u0026#34; end To receive messages in a process we cannot use cond, but Elixir provides us with a function receive/1 which takes a block as an argument. Although it\u0026rsquo;s not cond, it looks very similar to the example above because it lets us use pattern-matching:\nreceive do {:hello, name} -\u0026gt; \u0026#34;Hello #{name}\u0026#34; {:bye, name} -\u0026gt; \u0026#34;Bye #{name}\u0026#34; end What you\u0026rsquo;re seeing here usage of BEAM\u0026rsquo;s actor model for concurrency in Elixir. If you\u0026rsquo;re not familiar with the model worry not - you can read an interesting ELI5 about it here on Dev.to, or you can just keep on reading and by the end of this article you should have a good idea about it.\nThe receive function takes the received message and tries to pattern-match it to one of the statements in the block. Obviously, it accepts not just a value to return but also a function call. As you can imagine, receive/1 is what is called when the mailbox of the process gets a new message in.\nNow that we fixed up the actions on the mailbox of our process, how can we send a message to our IEx process?\nThis is done via the send/2 function. The function takes the PID and the message itself as arguments. For our example, let\u0026rsquo;s send the following message to our IEx process:\niex(1)\u0026gt; send self(), {:hello, \u0026#34;John\u0026#34;} {:hello, \u0026#34;John\u0026#34;} What you see here is the message being dropped in IEx\u0026rsquo;s mailbox. This means that we need to invoke the receive function in our IEx session so we can process the messages in the mailbox:\niex(2)\u0026gt; receive do ...(2)\u0026gt; {:hello, name} -\u0026gt; \u0026#34;Hello #{name}\u0026#34; ...(2)\u0026gt; {:bye, name} -\u0026gt; \u0026#34;Bye #{name}\u0026#34; ...(2)\u0026gt; end \u0026#34;Hello John\u0026#34; Right after executing the receive block the message will be immediately processed and we will see \u0026quot;Hello John\u0026quot; returned.\nWhat if we never receive a message? One thing to notice here is that if we would just write the receive block in our IEx session it would block until the process receives a message. That\u0026rsquo;s expected - if there is no message in the mailbox matching any of the patterns, the current process will wait until a matching message arrives. This is the default behaviour of receive/1.\nObviously, if we get ourselves stuck in such way we can always stop the IEx session by using Ctrl+C. But, what if a process in our application gets stuck? How can we tell it that it should stop waiting after a certain amount of time if it does not receive a message?\nOne nicety that Elixir provides us with is setting a timeout using after:\niex(6)\u0026gt; receive do ...(6)\u0026gt; {:hello, name} -\u0026gt; \u0026#34;Hello #{name}\u0026#34; ...(6)\u0026gt; {:bye, name} -\u0026gt; \u0026#34;Bye #{name}\u0026#34; ...(6)\u0026gt; after ...(6)\u0026gt; 1_000 -\u0026gt; \u0026#34;Nothing after 1s\u0026#34; ...(6)\u0026gt; end \u0026#34;Nothing after 1s\u0026#34; What happens here is that the timeout function is executed after 1000 milliseconds pass and the receive/1 function exits (hence stops blocking). This prevents processes hanging around waiting forever for a matching message to arrive in their mailboxes.\nLong-running processes So far we were looking at sending and receiving messages to the same process - the IEx process itself. This is quite a simple example and won\u0026rsquo;t help when we would like to put processes into action in a production application.\nAt this point, you might be wondering how to actually spawn a process that would react to multiple incoming messages, instead of just (ab)using the IEx process with the receive/1 function.\nWell, to do this we have to make a process run infinitely (or until we ask it to die). How? By creating an infinite loop in the process itself.\nWTF you mean by \u0026ldquo;an infinite loop\u0026rdquo;?! Yeah, I know, it feels weird, doesn\u0026rsquo;t it? Here\u0026rsquo;s the thing - the BEAM has an optimisation in it, so-called a last-call optimisation (read Joe Armstrong\u0026rsquo;s explanation of this optimisation here), where if the last call in a function is a call to the same function, Elixir will not allocate a new stack frame on the call stack. In fact, it will just jump to the beginning of the same function (instead of running another instance of it), which will prevent a stack overflow happening to our program.\nThis means that it\u0026rsquo;s virtually impossible to smash the stack in the BEAM languages (Erlang \u0026amp; Elixir), if we are just a bit careful when composing these self-invoking functions.\nLong-running processes, continued Let\u0026rsquo;s look at a small module with a single function:\ndefmodule MyProcess do def start do receive do {:hello, name} -\u0026gt; IO.puts \u0026#34;Hello #{name}!\u0026#34; start() {:bye, name} -\u0026gt; IO.puts \u0026#34;Bye #{name}. Shutdown in 3, 2, 1...\u0026#34; end end end The MyProcess.start function when run will wait for a message to arrive in the process' mailbox. Then, it will try to pattern match on the arrived message and execute the associated code. One trick is that at the end of the first case we execute the start function again, which will create an infinite loop in the process, therefore having the process waiting for messages forever.\nLet\u0026rsquo;s look how this will work in IEx:\niex(1)\u0026gt; pid = spawn(MyProcess, :start, []) #PID\u0026lt;0.120.0\u0026gt; iex(2)\u0026gt; send pid, {:hello, \u0026#34;Ilija\u0026#34;} Hello Ilija! {:hello, \u0026#34;Ilija\u0026#34;} iex(3)\u0026gt; send pid, {:hello, \u0026#34;Jane\u0026#34;} Hello Jane! {:hello, \u0026#34;Jane\u0026#34;} iex(4)\u0026gt; send pid, {:bye, \u0026#34;Jane\u0026#34;} Bye Jane. Shutdown in 3, 2, 1... {:bye, \u0026#34;Jane\u0026#34;} First, we use spawn/3 to create a process that will run the MyProcess.run function. spawn/3 is a flavour of spawn/1 - the only difference is that spawn/3 knows how to run a named function in a process, while spawn/1 takes only anonymous functions as arguments.\nThen, you can see that every time we send a {:hello, \u0026quot;Name\u0026quot;} message to the process (using send/2), we see the process printing back the greeting. Once we send the {:bye, \u0026quot;Jane\u0026quot;} message the process prints that it\u0026rsquo;s shutting down.\nHow so? Well, if you look at the MyProcess.start function you will notice that it does not invoke itself after it prints out the shutdown message. This means that once it handles that message the MyProcess.start function will finish and the process will die.\nLet\u0026rsquo;s test that in IEx, using the Process.alive?/1 function:\niex(1)\u0026gt; pid = spawn MyProcess, :start, [] #PID\u0026lt;0.109.0\u0026gt; iex(2)\u0026gt; Process.alive? pid true iex(3)\u0026gt; send pid, {:hello, \u0026#34;Ilija\u0026#34;} Hello Ilija! {:hello, \u0026#34;Ilija\u0026#34;} iex(4)\u0026gt; Process.alive? pid true iex(5)\u0026gt; send pid, {:bye, \u0026#34;Ilija\u0026#34;} Bye Ilija. Shutdown in 3, 2, 1... {:bye, \u0026#34;Ilija\u0026#34;} iex(6)\u0026gt; Process.alive? pid false Now that we know how to send and receive multiple messages to a process in Elixir, you might be wondering what is a good use-case to use processes for?\nThe answer is: keeping state.\nKeeping state using processes You might find this weird, but this is a classic example to keeping state in Elixir. While our example here will not take care of storing state on disk, cover all edge-cases that might occur or be a bullet-proof solution, I hope it will get your brain juices flowing on processes and how to use them.\nLet\u0026rsquo;s write a Store module that will have a start function. It should spawn a process which will invoke a function of the same module, for now, called foo:\n# store.exs defmodule Store do def start do spawn(__MODULE__, :foo, [%{}]) end def foo(map) do IO.puts \u0026#34;Nothing so far\u0026#34; end end Let\u0026rsquo;s briefly dissect the Store.start function: what it does is it spawns a new process calling the foo/1 function and it passes an empty map (%{}) as an argument to the function. If the special keyword __MODULE__ throws you off, it\u0026rsquo;s just an alias to the module name:\niex(1)\u0026gt; defmodule Test do ...(1)\u0026gt; def eql?, do: __MODULE__ == Test ...(1)\u0026gt; end iex(2)\u0026gt; Test.eql? true This means that when we call Store.start we will immediately see the output of the function in the process. Right after, the process will die:\niex(4)\u0026gt; pid = Store.start Nothing so far... #PID\u0026lt;0.117.0\u0026gt; iex(5)\u0026gt; Process.alive? pid false This means that we need to make foo/1 a function that will loop forever. Or at least until we tell it to stop.\nLet\u0026rsquo;s rename foo/1 to loop/1 and make it loop forever:\ndefmodule Store do def start do spawn(__MODULE__, :loop, [%{}]) end def loop(state) do receive do loop(state) end end end If we run this module now in an IEx session the process will work forever. Instead of doing that, let\u0026rsquo;s add a special \u0026ldquo;system\u0026rdquo; message that we can send to the process so we can force it to shut down:\ndefmodule Store do def start do spawn(__MODULE__, :loop, [%{}]) end def loop(state) do receive do {:stop, caller_pid} -\u0026gt; send caller_pid, \u0026#34;Shutting down\u0026#34; _ -\u0026gt; loop(state) end end end So now, you see that when there\u0026rsquo;s no match, the Store.loop/1 function will just recurse, but when the :stop message is received it will just send a \u0026quot;Shutting down\u0026quot; message to the calling PID.\niex(1)\u0026gt; pid = Store.start #PID\u0026lt;0.125.0\u0026gt; iex(2)\u0026gt; send pid, {:stop, self()} {:stop, #PID\u0026lt;0.102.0\u0026gt;} iex(3)\u0026gt; flush() \u0026#34;Shutting down.\u0026#34; :ok What you\u0026rsquo;re seeing here is a very simple example of sending messages between two processes - the Store process and our IEx session process. When we send the :stop message we also send the PID of the IEx session (self), which is then used by Store.loop/1 to send the reply back. At the end, instead of writing a whole receive block for the IEx session we just invoke flush, which flushes the IEx process mailbox and returns all of the messages in the mailbox at that time.\nIf you\u0026rsquo;re feeling deep in the rabbit hole now worry not - we are going to address keeping state in a process right away!\nLet\u0026rsquo;s say that our Store will accept four commands:\n stop - the one we already implemented, which stops the Store process put - adds a new key-value pair to the state map get - fetches a value for a given key from the state map get_all - fetches all of the key-value pairs that are stored in the state map  Putting a value Let\u0026rsquo;s implement the put command:\ndefmodule Store do def start do spawn(__MODULE__, :loop, [%{}]) end def loop(state) do receive do {:put, key, value} -\u0026gt; new_state = Map.put(state, key, value) loop(new_state) {:stop, caller} -\u0026gt; send caller, \u0026#34;Shutting down.\u0026#34; _ -\u0026gt; loop(state) end end end When we send a tuple containing {:put, :foo, :bar} to the process, it will add the :foo =\u0026gt; :bar pair to the state map. The key here is that it will invoke State.loop/1 again with the updated state (new_state). This will make sure that the key-value pair we added will be included in the new state on the next recursion of the function.\nGetting values Let\u0026rsquo;s implement get so we can test get and put together via an IEx session:\ndefmodule Store do def start do spawn(__MODULE__, :loop, [%{}]) end def loop(state) do receive do {:stop, caller} -\u0026gt; send caller, \u0026#34;Shutting down.\u0026#34; {:put, key, value} -\u0026gt; new_state = Map.put(state, key, value) loop(new_state) {:get, key, caller} -\u0026gt; send caller, Map.fetch(state, key) loop(state) _ -\u0026gt; loop(state) end end end Just like with the other commands, there\u0026rsquo;s no magic around get. We use Map.fetch/2 to get the value for the key passed. Also, we take the PID of the caller so we can send back to the caller the value found in the map:\niex(1)\u0026gt; pid = Store.start #PID\u0026lt;0.119.0\u0026gt; iex(2)\u0026gt; send pid, {:put, :name, \u0026#34;Ilija\u0026#34;} {:put, :name, \u0026#34;Ilija\u0026#34;} iex(3)\u0026gt; send pid, {:get, :name, self()} {:get, :name, #PID\u0026lt;0.102.0\u0026gt;} iex(4)\u0026gt; flush {:ok, \u0026#34;Ilija\u0026#34;} :ok iex(5)\u0026gt; send pid, {:put, :surname, \u0026#34;Eftimov\u0026#34;} {:put, :surname, \u0026#34;Eftimov\u0026#34;} iex(6)\u0026gt; send pid, {:get, :surname, self()} {:get, :surname, #PID\u0026lt;0.102.0\u0026gt;} iex(7)\u0026gt; flush {:ok, \u0026#34;Eftimov\u0026#34;} :ok If we look at the \u0026ldquo;conversation\u0026rdquo; we have with the Store process, at the beginning, we set a :name key with the value \u0026quot;Ilija\u0026quot; and we retrieve it after (and we see the reply using flush). Then we do the same exercise by adding a new key to the map in the Store, this time :surname with the value \u0026quot;Eftimov\u0026quot;.\nFrom the \u0026ldquo;conversation\u0026rdquo; perspective, the key piece here is us sending self() - the PID of our current process (the IEx session) - so the Store process knows where to send the reply to.\nGetting a dump of the store Right before we started writing the Store module we mentioned that we will also implement a get_all command, which will return all of the contents of the Store. Let\u0026rsquo;s do that:\ndefmodule Store do def start do spawn(__MODULE__, :loop, [%{}]) end def loop(state) do receive do {:stop, caller} -\u0026gt; send caller, \u0026#34;Shutting down.\u0026#34; {:put, key, value} -\u0026gt; new_state = Map.put(state, key, value) loop(new_state) {:get, key, caller} -\u0026gt; send caller, Map.fetch(state, key) loop(state) {:get_all, caller } -\u0026gt; send caller, state loop(state) _ -\u0026gt; loop(state) end end end If you expected something special here, I am very sorry to disappoint you. The implementation of the get_all command is to return the whole state map of the process to the sender.\nLet\u0026rsquo;s test it out:\niex(1)\u0026gt; pid = Store.start #PID\u0026lt;0.136.0\u0026gt; iex(2)\u0026gt; send pid, {:put, :name, \u0026#34;Jane\u0026#34;} {:put, :name, \u0026#34;Jane\u0026#34;} iex(3)\u0026gt; send pid, {:put, :surname, \u0026#34;Doe\u0026#34;} {:put, :surname, \u0026#34;Doe\u0026#34;} iex(4)\u0026gt; send pid, {:get_all, self()} {:get_all, #PID\u0026lt;0.102.0\u0026gt;} iex(5)\u0026gt; flush %{name: \u0026#34;Jane\u0026#34;, surname: \u0026#34;Doe\u0026#34;} :ok As expected, once we add two key-value pairs to the Store, when we invoke the get_all command the Store process sends back the whole state map.\nWhile this is a very small and contrived example, the skeleton we followed here by keeping state by using recursion, sending commands and replies back and forth to the calling process is actually used quite a bit in Erlang and Elixir.\nA small disappointment First, I am quite happy you managed to get to the end of this article. I believe that once I understood the basics of the concurrency model of Elixir, by going through these exercises were eye-opening for me, and I hope they were for you as well.\nUnderstanding how to use processes by sending and receiving messages is paramount knowledge that you can use going forward on your Elixir journey.\nNow, as promised - a small disappointment.\nFor more than 90% of the cases when you want to write concurrent code in Elixir, you will not use processes like here. In fact, you won\u0026rsquo;t (almost) ever use the send/2 and receive/1 functions. Seriously.\nWhy? Well, that\u0026rsquo;s because Elixir comes with this thingy called OTP, that will help you do much cooler things with concurrency, without writing any of this low-level process management code. Of course, this should not stop you from employing processes when you feel that you strongly need them, or when you want to experiment and learn.\nIf you want to read more about the basics of OTP, check out \u0026ldquo;Roll your own URL shortener using Elixir \u0026amp; GenServer\u0026rdquo;.\nSome more reading If you would like to read a bit more, here are a couple of links that are worth checking out:\n Processes on Elixir\u0026rsquo;s \u0026ldquo;Getting started\u0026rdquo; guide Long-lived processes in Elixir by German Velasco on Thoughtbot\u0026rsquo;s blog Process on Hexdocs.pm Endless recursion on the Elixir Forum  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/understanding-basics-elixir-concurrency-model/","summary":"If you come from an object-oriented background, you might have tried concurrency in your favourite OO language before. Your mileage will vary, but in general OO languages are harder to work with when it comes to concurrency. This is due to their nature - they are designed to keep state in memory and require more expertise and experience to be successful with.\nHow does Elixir stand up to other languages when it comes to concurrency?","title":"Understanding the basics of Elixir's concurrency model"},{"content":"Being new to Elixir and Phoenix, I spend quite some time in the projects' documentation. One thing that stood out for me recently is the first sentence of Phoenix\u0026rsquo;s Plug documentation:\n Plug lives at the heart of Phoenix’s HTTP layer and Phoenix puts Plug front and center.\n So naturally, I felt compelled to take a deeper dive into Plug and understand it better. I hope the following article will help you out in understanding Plug.\nWhat\u0026rsquo;s Plug? As the readme puts it, Plug is:\n A specification for composable modules between web applications Connection adapters for different web servers in the Erlang VM  But, what does this mean? Well, it basically states that Plug 1) defines the way you build web apps in Elixir and 2) it provides you with tools to write apps that are understood by web servers.\nLet\u0026rsquo;s take a dive and see what that means.\nWeb servers, yeehaw! One of the most popular HTTP servers for Erlang is Cowboy. It is a small, fast and modern HTTP server for Erlang/OTP. If you were to write any web application in Elixir it will run on Cowboy, because the Elixir core team has built a Plug adapter for Cowboy, conveniently named plug_cowboy.\nThis means that if you include this package in your package, you will get the Elixir interface to talk to the Cowboy web server (and vice-versa). It means that you can send and receive requests and other stuff that web servers can do.\nSo why is this important?\nWell, to understand Plug we need to understand how it works. Basically, using the adapter (plug_cowboy), Plug can accept the connection request that comes in Cowboy and turn it into a meaningful struct, also known as Plug.Conn.\nThis means that Plug uses plug_cowboy to understand Cowboy\u0026rsquo;s nitty-gritty details. By doing this Plug allows us to easily build handler functions and modules that can receive, handle and respond to requests.\nOf course, the idea behind Plug is not to work only with Cowboy. If you look at this SO answer from José Valim (Elixir\u0026rsquo;s BDFL) he clearly states \u0026ldquo;Plug is meant to be a generic adapter for different web servers. Currently we support just Cowboy but there is work to support others.\u0026rdquo;\nEnter Plug Okay, now that we\u0026rsquo;ve scratched the surface of Cowboy and it\u0026rsquo;s Plug adapter, let\u0026rsquo;s look at Plug itself.\nIf you look at Plug\u0026rsquo;s README, you will notice that there are two flavours of plugs, a function or a module.\nThe most minimal plug can be a function, it just takes a Plug.Conn struct (that we will explore more later) and some options. The function will manipulate the struct and return it at the end. Here\u0026rsquo;s the example from the README:\ndef hello_world_plug(conn, _opts) do conn |\u0026gt; put_resp_content_type(\u0026#34;text/plain\u0026#34;) |\u0026gt; send_resp(200, \u0026#34;Hello world\u0026#34;) end Code blatantly copied from Plug\u0026rsquo;s docs. If you look at the function, it\u0026rsquo;s quite simple. It receives the connection struct, puts its content type to text/plain and returns a response with an HTTP 200 status and \u0026quot;Hello world\u0026quot; as the body.\nThe second flavour is the module Plug. This means that instead of just having a function that will be invoked as part of the request lifecycle, you can define a module that takes a connection and initialized options and returns the connection:\ndefmodule MyPlug do def init([]), do: false def call(conn, _opts), do: conn end Code blatantly copied from Plug\u0026rsquo;s docs. Having this in mind, let\u0026rsquo;s take a step further and see how we can use Plug in a tiny application.\nPlugging a plug as an endpoint So far, the most important things we covered was what\u0026rsquo;s Plug and what is it used for on a high level. We also took a look at two different types of plugs.\nNow, let\u0026rsquo;s see how we can mount a Plug on a Cowboy server and essentially use it as an endpoint:\ndefmodule PlugTest do import Plug.Conn def init(options) do # initialize options options end def call(conn, _opts) do conn |\u0026gt; put_resp_content_type(\u0026#34;text/plain\u0026#34;) |\u0026gt; send_resp(200, \u0026#34;Hello world\u0026#34;) end end What this module will do is, when mounted on a Cowboy server, will set the Content-Type header to text/plain and will return an HTTP 200 with a body of Hello world.\nLet\u0026rsquo;s fire up IEx and test this ourselves:\n› iex -S mix Erlang/OTP 21 [erts-10.2] [source] [64-bit] [smp:4:4] [ds:4:4:10] [async-threads:1] [hipe] [dtrace] Interactive Elixir (1.7.4) - press Ctrl+C to exit (type h() ENTER for help) iex(1)\u0026gt; {:ok, _ } = Plug.Cowboy.http PlugTest, [], port: 3000 {:ok, #PID\u0026lt;0.202.0\u0026gt;} This starts the Cowboy server as a BEAM process, listening on port 3000. If we cURL it we\u0026rsquo;ll see the response body and it\u0026rsquo;s headers:\n› curl -v 127.0.0.1:3000 \u0026gt; GET / HTTP/1.1 \u0026gt; Host: 127.0.0.1:3000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; cache-control: max-age=0, private, must-revalidate \u0026lt; content-length: 11 \u0026lt; content-type: text/plain; charset=utf-8 \u0026lt; date: Tue, 25 Dec 2018 22:54:54 GMT \u0026lt; server: Cowboy \u0026lt; * Connection #0 to host 127.0.0.1 left intact Hello world You see, the Content-Type of the response is set to text/plain and the body is Hello world. In this example, the plug is essentially an endpoint by itself, serving plain text to our cURL command (or to a browser). As you might be able to imagine at this point, you can plug in much more elaborate Plugs to a Cowboy server and it will serve them just fine.\nTo shut down the endpoint all you need to do is:\niex(2)\u0026gt; Plug.Cowboy.shutdown PlugTest.HTTP :ok What we are witnessing here is probably the tiniest web application one can write in Elixir. It\u0026rsquo;s an app that takes a request and returns a valid response over HTTP with a status and a body.\nSo, how does this actually work? How do we accept the request and build a response here?\nDiving into the Plug.Conn To understand this, we need to zoom in the call/2 function of our module PlugTest. I will also throw in an IO.inspect right at the end of the function so we can inspect what this struct is:\ndef call(conn, _opts) do conn |\u0026gt; put_resp_content_type(\u0026#34;text/plain\u0026#34;) |\u0026gt; send_resp(200, \u0026#34;Hello world\u0026#34;) |\u0026gt; IO.inspect end If you start the Cowboy instance again via your IEx session and you hit 127.0.0.1:3000 via cURL (or a browser), you should see something like this in your IEx session:\n%Plug.Conn{ adapter: {Plug.Cowboy.Conn, :...}, assigns: %{}, before_send: [], body_params: %Plug.Conn.Unfetched{aspect: :body_params}, cookies: %Plug.Conn.Unfetched{aspect: :cookies}, halted: false, host: \u0026#34;127.0.0.1\u0026#34;, method: \u0026#34;GET\u0026#34;, owner: #PID\u0026lt;0.316.0\u0026gt;, params: %Plug.Conn.Unfetched{aspect: :params}, path_info: [], path_params: %{}, port: 3000, private: %{}, query_params: %Plug.Conn.Unfetched{aspect: :query_params}, query_string: \u0026#34;\u0026#34;, remote_ip: {127, 0, 0, 1}, req_cookies: %Plug.Conn.Unfetched{aspect: :cookies}, req_headers: [ {\u0026#34;accept\u0026#34;, \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\u0026#34;}, {\u0026#34;accept-encoding\u0026#34;, \u0026#34;gzip, deflate, br\u0026#34;}, {\u0026#34;accept-language\u0026#34;, \u0026#34;en-US,en;q=0.9\u0026#34;}, {\u0026#34;connection\u0026#34;, \u0026#34;keep-alive\u0026#34;}, {\u0026#34;host\u0026#34;, \u0026#34;127.0.0.1:3000\u0026#34;}, {\u0026#34;upgrade-insecure-requests\u0026#34;, \u0026#34;1\u0026#34;}, {\u0026#34;user-agent\u0026#34;, \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\u0026#34;} ], request_path: \u0026#34;/\u0026#34;, resp_body: nil, resp_cookies: %{}, resp_headers: [ {\u0026#34;cache-control\u0026#34;, \u0026#34;max-age=0, private, must-revalidate\u0026#34;}, {\u0026#34;content-type\u0026#34;, \u0026#34;text/plain; charset=utf-8\u0026#34;} ], scheme: :http, script_name: [], secret_key_base: nil, state: :sent, status: 200 } What are we actually looking at? Well, it\u0026rsquo;s actually the Plug representation of a connection. This is a direct interface to the underlying web server and the request that the Cowboy server has received.\nSome of the attributes of the struct are pretty self-explanatory, like scheme, method, host, request_path, etc. If you would like to go into detail what each of these fields is, I suggest taking a look at Plug.Conn\u0026rsquo;s documentation.\nBut, to understand better the Plug.Conn struct, we need to understand the connection lifecycle of each connection struct.\nConnection lifecycle Just like any map in Elixir Plug.Conn allows us to pattern match on it. Let\u0026rsquo;s modify the little endpoint we created before and try to add some extra IO.inspect function calls:\ndefmodule PlugTest do import Plug.Conn def init(options) do # initialize options options end def call(conn, _opts) do conn |\u0026gt; inspect_state |\u0026gt; put_resp_content_type(\u0026#34;text/plain\u0026#34;) |\u0026gt; inspect_state |\u0026gt; put_private(:foo, :bar) |\u0026gt; inspect_state |\u0026gt; resp(200, \u0026#34;Hello world\u0026#34;) |\u0026gt; inspect_state |\u0026gt; send_resp() |\u0026gt; inspect_state end defp inspect_state(conn = %{state: state}) do IO.inspect state conn end end Because Plug.Conn allows pattern matching, we can get the state of the connection, print it out and return the connection itself so the pipeline in the call/2 function would continue working as expected.\nLet\u0026rsquo;s mount this plug on a Cowboy instance and hit it with a simple cURL request:\niex(6)\u0026gt; Plug.Cowboy.http PlugTest, [], port: 3000 {:ok, #PID\u0026lt;0.453.0\u0026gt;} # curl 127.0.0.1:3000 iex(21)\u0026gt; :unset :unset :unset :set :sent You see, when the connection enters the plug it\u0026rsquo;s state changes from :unset to :set to finally :sent. This means that once the plug is invoked the state of the connection is :unset. Then we do multiple actions, or in other words, we invoke multiple functions on the Plug.Conn which add more information to the connection. Obviously, since all variables in Elixir are immutable, each of these function returns a new Plug.Conn instance, instead of mutating the existing one.\nOnce the body and the status of the connection are set, then the state changes to :set. Up until that moment, the state is fixed as :unset. Once we send the response back to the client the state is changed to :sent.\nWhat we need to understand here is that whether we have one or more plugs in a pipeline, they will all receive a Plug.Conn, call functions on it, whether to extract or add data to it and then the connection will be passed on to the next plug. Eventually, in the pipeline, there will be a plug (in the form of an endpoint or a Phoenix controller) that will set the body and the response status and send the response back to the client.\nThere are a bit more details to this, but this is just enough to wrap our minds around Plug and Plug.Conn in general.\nNext-level Plugging using Plug.Router Now that we understand how Plug.Conn works and how plugs can change the connection by invoking functions defined in the Plug.Conn module, let\u0026rsquo;s look at a more advanced feature of plugs - turning a plug into a router.\nIn our first example, we saw the simplest of the Elixir web apps - a simple plug that takes the request and returns a simple response with a text body and an HTTP 200. But, what if we want to handle different routes or HTTP methods? What if we want to gracefully handle any request to an unknown route with an HTTP 404?\nOne nicety that Plug comes with is a module called Plug.Router, you can see its documentation here. The router module contains a DSL that allows us to define a routing algorithm for incoming requests and writing handlers (powered by Plug) for the routes. If you are coming from Ruby land, while Plug is basically Rack, this DSL is Sinatra.rb.\nLet\u0026rsquo;s create a tiny router using Plug.Router, add some plugs to its pipeline and some endpoints.\nQuick aside: What is a pipeline?\nAlthough it has the same name as the pipeline operator (|\u0026gt;), a pipeline in Plug\u0026rsquo;s context is a list of plugs executed one after another. That\u0026rsquo;s really it. The last plug in that pipeline is usually an endpoint that will set the body and the status of the response and return the response to the client.\nNow, back to our router:\ndefmodule MyRouter do use Plug.Router plug :match plug :dispatch get \u0026#34;/hello\u0026#34; do send_resp(conn, 200, \u0026#34;world\u0026#34;) end match _ do send_resp(conn, 404, \u0026#34;oops\u0026#34;) end end Code blatantly copied from Plug.Router\u0026rsquo;s docs. The first thing that you will notice here is that all routers are modules as well. By useing the Plug.Router module, we include some functions that make our lives easier, like get or match.\nIf you notice at the top of the module we have two lines:\nplug :match plug :dispatch This is the router\u0026rsquo;s pipeline. All of the requests coming to the router will pass through these two plugs: match and dispatch. The first one does the matching of the route that we define (e.g. /hello), while the other one will invoke the function defined for a particular route. This means that if we would like to add other plugs, most of the time they will be invoked between the two mandatory ones (match and dispatch).\nLet\u0026rsquo;s mount our router on a Cowboy server and see it\u0026rsquo;s behaviour:\niex(29)\u0026gt; Plug.Cowboy.http MyRouter, [], port: 3000 {:ok, #PID\u0026lt;0.1500.0\u0026gt;} When we hit 127.0.0.1:3000/hello, we will get the following:\n› curl -v 127.0.0.1:3000/hello * Trying 127.0.0.1... * TCP_NODELAY set * Connected to 127.0.0.1 (127.0.0.1) port 3000 (#0) \u0026gt; GET /hello HTTP/1.1 \u0026gt; Host: 127.0.0.1:3000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; cache-control: max-age=0, private, must-revalidate \u0026lt; content-length: 5 \u0026lt; date: Thu, 27 Dec 2018 22:50:47 GMT \u0026lt; server: Cowboy \u0026lt; * Connection #0 to host 127.0.0.1 left intact world As you can see, we received world as the response body and an HTTP 200. But if we hit any other URL, the router will match the other route:\n› curl -v 127.0.0.1:3000/foo * Trying 127.0.0.1... * TCP_NODELAY set * Connected to 127.0.0.1 (127.0.0.1) port 3000 (#0) \u0026gt; GET /foo HTTP/1.1 \u0026gt; Host: 127.0.0.1:3000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 404 Not Found \u0026lt; cache-control: max-age=0, private, must-revalidate \u0026lt; content-length: 4 \u0026lt; date: Thu, 27 Dec 2018 22:51:56 GMT \u0026lt; server: Cowboy \u0026lt; * Connection #0 to host 127.0.0.1 left intact oops As you can see, because the /hello route didn\u0026rsquo;t match we defaulted to the other route, also known as \u0026ldquo;catch all\u0026rdquo; route, which returned oops as the response body and an HTTP 404 status.\nIf you would like to learn more about Plug.Router and its route matching macros you can read more in its documentation. We still need to cover some more distance with Plug.\nBuilt-in Plugs In the previous section, we mentioned the plugs match and dispatch, and plug pipelines. We also mentioned that we can plug in other plugs in the pipeline so we can inspect or change the Plug.Conn of each request.\nWhat is very exciting here is that Plug also comes with already built-in plugs. That means that there\u0026rsquo;s a list of plugs that you can plug-in in any Plug-based application:\n Plug.CSRFProtection Plug.Head Plug.Logger Plug.MethodOverride Plug.Parsers Plug.RequestId Plug.SSL Plug.Session Plug.Static  Let\u0026rsquo;s try to understand how a couple of them work and how we can plug them in our MyRouter router module.\nPlug.Head This is a rather simple plug. It\u0026rsquo;s so simple, I will add all of its code here:\ndefmodule Plug.Head do @behaviour Plug alias Plug.Conn def init([]), do: [] def call(%Conn{method: \u0026#34;HEAD\u0026#34;} = conn, []), do: %{conn | method: \u0026#34;GET\u0026#34;} def call(conn, []), do: conn end What this plug does is it turns any HTTP HEAD request into a GET request. That\u0026rsquo;s all. Its call function receives a Plug.Conn, matches only the ones that have a method: \u0026quot;HEAD\u0026quot; and returns a new Plug.Conn with the method changed to \u0026quot;GET\u0026quot;.\nIf you\u0026rsquo;ve been wondering what the HEAD method is for, this is from RFC 2616:\n The HEAD method is identical to GET except that the server MUST NOT return a message-body in the response. The metainformation contained in the HTTP headers in response to a HEAD request SHOULD be identical to the information sent in response to a GET request. This method can be used for obtaining metainformation about the entity implied by the request without transferring the entity-body itself. This method is often used for testing hypertext links for validity, accessibility, and recent modification.\n Let\u0026rsquo;s plug this plug in our Plug.Router (pun totally intended):\ndefmodule MyRouter do use Plug.Router plug Plug.Head plug :match plug :dispatch get \u0026#34;/hello\u0026#34; do send_resp(conn, 200, \u0026#34;world\u0026#34;) end match _ do send_resp(conn, 404, \u0026#34;oops\u0026#34;) end end Once we cURL the routes we would get the following behaviour:\n› curl -I 127.0.0.1:3000/hello HTTP/1.1 200 OK cache-control: max-age=0, private, must-revalidate content-length: 5 date: Thu, 27 Dec 2018 23:25:13 GMT server: Cowboy › curl -I 127.0.0.1:3000/foo HTTP/1.1 404 Not Found cache-control: max-age=0, private, must-revalidate content-length: 4 date: Thu, 27 Dec 2018 23:25:17 GMT server: Cowboy As you can see, although we didn\u0026rsquo;t explicitly match the HEAD routes using the head macro, the Plug.Head plug remapped the HEAD requests to GET and our handlers still kept on working as expected (the first one returned an HTTP 200, and the second one an HTTP 404).\nPlug.Logger This one is a bit more complicated so we cannot inline all of its code in this article. Basically, if we would plug this plug in our router, it will log all of the incoming requests and response statuses, like so:\nGET /index.html Sent 200 in 572ms This plug uses Elixir\u0026rsquo;s Logger (docs) under the hood, which supports four different logging levels:\n :debug - for debug-related messages :info - for information of any kind (default level) :warn - for warnings :error - for errors  If we would look at the source of its call/2 function, we would notice two logical units. The first one is:\ndef call(conn, level) do Logger.log(level, fn -\u0026gt; [conn.method, ?\\s, conn.request_path] end) # Snipped... end This one will take Elixir\u0026rsquo;s Logger and using the logging level will log the information to the backend (by default it\u0026rsquo;s console). The information that is logged is the method of the request (e.g. GET, POST, etc) and the request path (e.g. /foo/bar). This results in the first line of the log:\nGET /index.html The second logical unit is a bit more elaborate:\ndef call(conn, level) do # Snipped... start = System.monotonic_time() Conn.register_before_send(conn, fn conn -\u0026gt; Logger.log(level, fn -\u0026gt; stop = System.monotonic_time() diff = System.convert_time_unit(stop - start, :native, :microsecond) status = Integer.to_string(conn.status) [connection_type(conn), ?\\s, status, \u0026#34; in \u0026#34;, formatted_diff(diff)] end) conn end) end In short: this section records the time between the start and the stop (end) of the request and prints out the difference between the two (or in other words - the amount of time the response took). Also, it prints out the HTTP status of the response.\nTo do this it uses Plug.Conn.register_before_send/2 (docs) which is a utility function that registers callbacks to be invoked before the response is sent. This means that the function which will calculate the diff and log it to the Logger with the response status will be invoked by Plug.Conn right before the response is sent to the client.\nWrapping up with Plug You actually made it this far - I applaud you. I hope that this was a nice journey for you in Plug and it\u0026rsquo;s related modules/functions and that you learned something new.\nWe looked at quite a bit of details in and around Plug. For some of the modules that we spoke about we barely scratched the surface. For example, Plug.Conn has quite a bit of more useful functions. Or Plug.Router has more functions in its DSL where you can write more elaborate and thoughtful APIs or web apps. In line with this, Plug also offers more built-in plugs. It even has a plug which can serve static files with ease, and plugging it in your Plug-based apps is a breeze.\nBut, aside from all the things that we skipped in this article, I hope that you understood how powerful the Plug model is and how much power it provides us with such simplicity and unobtrusiveness.\nIn future posts, we will look at even more details about other plugs in Plug, but until then please shoot me a comment or a message if you\u0026rsquo;ve found this article helpful (or not).\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/a-deeper-dive-in-elixir-plug/","summary":"Being new to Elixir and Phoenix, I spend quite some time in the projects' documentation. One thing that stood out for me recently is the first sentence of Phoenix\u0026rsquo;s Plug documentation:\n Plug lives at the heart of Phoenix’s HTTP layer and Phoenix puts Plug front and center.\n So naturally, I felt compelled to take a deeper dive into Plug and understand it better. I hope the following article will help you out in understanding Plug.","title":"A deeper dive in Elixir's Plug"},{"content":"Unless you\u0026rsquo;ve been living under a rock for the last couple of years, you probably know what two-factor authentication (2FA) is. It\u0026rsquo;s quite a neat trick actually - you have a password that you have to (obviously) enter correctly (first factor), but you also have to receive a second (random) code through a different medium, sometimes on a different device, that you have to enter to log in (second factor).\nNow, obviously this adds quite a bit of overhead to logging in, but it adds a disproportionate value when it comes to security. If you work in any sort of organisation it was probably no surprise when you were asked to turn on 2FA for all your accounts. If you haven\u0026rsquo;t been asked to (or haven\u0026rsquo;t done it), it\u0026rsquo;s time to act ;)\nBut, what about factor No. 1? The password. Did we give up on them?\nNot really. But, for sure we had to become more vigilant and smarter when setting our passwords. Why? Allow me to explain.\nReader, meet haveibeenpwned.com Let me introduce you to haveibeenpwned.com. It\u0026rsquo;s a free resource for anyone to quickly assess if they may have been put at risk due to an online account of their\u0026rsquo;s having been compromised or \u0026ldquo;pwned\u0026rdquo; in a data breach. As you can imagine, to fulfil its purpose, this service also contains quite a long list of pwned passwords (about 500 million of them to be more precise), which are open for querying through a REST API.\nIf you want to learn more about the project, or it\u0026rsquo;s author, I suggest checking out the About page of the project.\nUsing the pwned passwords API This API allows us to check if any password is present in haveibeenpwned database. This means that if you send an already pwned password it will tell you that this password has been pwned and that it\u0026rsquo;s suggested to choose another one.\nImagine you have a website where people can set their passwords, and once the user finished typing their new password you can ping this service and check if the password they chose has been pwned before.\nNow, if you are thinking along the lines of \u0026ldquo;are you telling me to send a plain-text password across the wire to some random API?\u0026rdquo; then you\u0026rsquo;re a step ahead, well done!\nSorry to disappoint, but no, actually I am not saying that. Instead of sending the whole password in plain-text, this API only requires the 5 characters of the SHA-1 hash of the actual password.\nIn Elixir terms, that would look like:\n:crypto.hash(:sha, \u0026#34;password\u0026#34;) |\u0026gt; Base.encode16 |\u0026gt; String.slice(0..4) Interestingly what it sends back is the remainder of the hashed passwords that match the 5 characters that you sent. Basically, this means if we take a SHA-1 of \u0026ldquo;password\u0026rdquo;:\niex(1)\u0026gt; :crypto.hash(:sha, \u0026#34;password\u0026#34;) |\u0026gt; Base.encode16 \u0026#34;5BAA61E4C9B93F3F0682250B6CF8331B7EE68FD8\u0026#34; We will send only 5BAA6 to the API, while in the response body we will receive a big list of strings that will represent the rest of the SHA-1, or in our example that would be 1E4C9B93F3F0682250B6CF8331B7EE68FD8.\nTroy Hunt, who\u0026rsquo;s the author of haveibeenpwned has written quite an extensive explanation on how this works - you can read it here.\nPinging the API For the purpose of this exercise, we will create a small Mix package that will encapsulate all of the behaviours. If you\u0026rsquo;re not familiar with how to create new packages using Mix, I suggest reading my article Write and publish your first Elixir library.\nWe will call our package Pwnex because somehow my brain always thinks that I have to mix up the main word (pwned) with Elixir to come up with a name. Anyway, let\u0026rsquo;s create it:\n› mix new pwnex * creating README.md * creating .formatter.exs * creating .gitignore * creating mix.exs * creating config * creating config/config.exs * creating lib * creating lib/pwnex.ex * creating test * creating test/test_helper.exs * creating test/pwnex_test.exs Your Mix project was created successfully. You can use \u0026#34;mix\u0026#34; to compile it, test it, and more: cd pwnex mix test Run \u0026#34;mix help\u0026#34; for more commands. Now that we have the package bootstrapped locally, let\u0026rsquo;s open lib/pwnex.ex and add some documentation:\ndefmodule Pwnex do @moduledoc \u0026#34;\u0026#34;\u0026#34; Consults haveibeenpwned.com\u0026#39;s API for pwned passwords. \u0026#34;\u0026#34;\u0026#34; @doc \u0026#34;\u0026#34;\u0026#34; Checks if a given password is already pwned. ##Examples iex\u0026gt; Pwnex.pwned?(\u0026#34;password\u0026#34;) {:pwned, 3_000_000} iex\u0026gt; Pwnex.pwned?(\u0026#34;m4Z2fJJ]r3fxQ*o27\u0026#34;) {:ok, 0} \u0026#34;\u0026#34;\u0026#34; def pwned?(password) do end end The moduledoc briefly explains the purpose of the package, while the doc explains the purpose of the pwned?/1 function and has two examples that we could use in the doctests.\nOur little algorithm Let\u0026rsquo;s see what would be the steps to implement the Pwnex.pwned?/1 function:\ndef pwned?(password) do {hash_head, hash_tail} = password |\u0026gt; sanitize |\u0026gt; hash |\u0026gt; split_password hash_head |\u0026gt; fetch_pwns |\u0026gt; handle_response |\u0026gt; find_pwns(hash_tail) |\u0026gt; return_result end Once more - the pipeline operator in Elixir makes this function so clear and procedure-like that explaining feels a tad redundant. Still, here it is:\n sanitize - we want to remove all leading and trailing whitespaces from the password hash - we want to convert the password to a SHA1 hash and return it\u0026rsquo;s first 5 characters split_password - we want to split the head - first 5 characters that we will send to the API and the tail - the rest of the SHA-1 hash fetch_pwns - we will send an API request to haveibeenpwned to get all (if any) pwns of the password handle_response - depending on the response we will either get the body, or the reason for failure returned find_pwns - we will take the response body, and because haveibeenpwned uses a k-Anonymity model we will need to find the actual match ourselves (if present) return_result - will return the tuple which will contain a result atom and a pwns count  Let\u0026rsquo;s take a step by step approach and implement these functions.\nManipulating the password Let\u0026rsquo;s start easy. In sanitize, we want to trim leading and trailing whitespaces, while in hash we want to turn the password to SHA1 and return it\u0026rsquo;s first five characters.\ndef sanitize(password), do: String.trim(password) There isn\u0026rsquo;t much to explain here really. Instead of using sanitize we can use String.trim/1, but I prefer to have a separate function that we could extend and test for any edge cases.\ndefp hash(password) do :crypto.hash(:sha, password) |\u0026gt; Base.encode16 end :crypto is an Erlang module that provides a set of cryptographic functions. Interestingly, it\u0026rsquo;s not part of the standard library, but it comes included in the distribution. One of the functions, as you can see in the code above, is hash/2, which takes the hashing algorithm as the first argument and the actual string to be hashed as the second argument. It returns the binary hash, that we can convert to hex by using Base.encode16.\nSending request to an API I bet you\u0026rsquo;re thinking HTTPoison. Aren\u0026rsquo;t you? While I was writing this article I was also wondering do we have to include to a whole package just to do a simple GET request. You guessed it - we do not.\nAlthough Elixir does not ship an HTTP client, Erlang does. And just like with :crypto, you can use Erlang\u0026rsquo;s HTTP client from Elixir using :httpc. This module provides the API to an HTTP/1.1 compatible client. I suggest giving it\u0026rsquo;s documentation a quick scan before we move on.\nLet\u0026rsquo;s let\u0026rsquo;s open up IEx and give :httpc a spin:\niex(1)\u0026gt; :httpc.request(\u0026#39;https://api.pwnedpasswords.com/range/21FCB\u0026#39;) {:ok, \\{\\{\u0026#39;HTTP/1.1\u0026#39;, 200, \u0026#39;OK\u0026#39;}, [ {\u0026#39;cache-control\u0026#39;, \u0026#39;public, max-age=2678400\u0026#39;}, {\u0026#39;connection\u0026#39;, \u0026#39;keep-alive\u0026#39;}, {\u0026#39;date\u0026#39;, \u0026#39;Sat, 22 Dec 2018 11:09:46 GMT\u0026#39;}, {\u0026#39;server\u0026#39;, \u0026#39;cloudflare\u0026#39;}, {\u0026#39;vary\u0026#39;, \u0026#39;Accept-Encoding\u0026#39;}, {\u0026#39;content-length\u0026#39;, \u0026#39;19951\u0026#39;}, {\u0026#39;content-type\u0026#39;, \u0026#39;text/plain\u0026#39;}, {\u0026#39;expires\u0026#39;, \u0026#39;Tue, 22 Jan 2019 11:09:46 GMT\u0026#39;}, {\u0026#39;last-modified\u0026#39;, \u0026#39;Thu, 12 Jul 2018 01:32:06 GMT\u0026#39;}, {\u0026#39;set-cookie\u0026#39;, \u0026#39;__cfduid=d51115381191fd7bd0a003d466916efc41545476986; expires=Sun, 22-Dec-19 11:09:46 GMT; path=/; domain=.pwnedpasswords.com; HttpOnly; Secure\u0026#39;}, {\u0026#39;cf-cache-status\u0026#39;, \u0026#39;HIT\u0026#39;}, {\u0026#39;access-control-allow-origin\u0026#39;, \u0026#39;*\u0026#39;}, {\u0026#39;arr-disable-session-affinity\u0026#39;, \u0026#39;True\u0026#39;}, {\u0026#39;cf-ray\u0026#39;, \u0026#39;48d2235cbe93bf5c-AMS\u0026#39;}, {\u0026#39;expect-ct\u0026#39;, \u0026#39;max-age=604800, report-uri=\u0026#34;https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\u0026#34;\u0026#39;}, {\u0026#39;strict-transport-security\u0026#39;, \u0026#39;max-age=31536000; includeSubDomains; preload\u0026#39;}, {\u0026#39;x-content-type-options\u0026#39;, \u0026#39;nosniff\u0026#39;}, {\u0026#39;x-powered-by\u0026#39;, \u0026#39;ASP.NET\u0026#39;} ], \u0026#39;THEBODYISHERE\\r\\nOMGSOMUCHSTUFFHEREWHATISTHISEVEN\u0026#39; ++ ...}} You see, although the output is pretty verbose if you have ever sent an HTTP request via cURL or you\u0026rsquo;ve opened your browser\u0026rsquo;s debugging tools, there shouldn\u0026rsquo;t be any surprises here. The request/1 function will send a request to the pwnedpasswords API and it will return a ton of nested tuples, most of them being the response headers and the raw body of the response.\nFor our purpose, we can keep it simple. We are only interested if the function will return :ok atom as the first item in the tuple, or :error. We can use pattern matching to do this:\niex(1)\u0026gt; {:ok, {_status, _headers, body }} = :httpc.request(\u0026#39;https://api.pwnedpasswords.com/range/21FCB\u0026#39;) So, lets get back to our Pwnex.fetch_pwns/1 function. The function will receive the first 5 characters of the hashed password, it will send that to the API and will return the body of the response:\ndef fetch_pwns(head) do :httpc.request(\u0026#39;https://api.pwnedpasswords.com/range/#{head}\u0026#39;) end Handling the response The handle_response will actually be one function with three bodies:\ndef handle_response({:ok, {_status, _headers, body}}), do: body def handle_response({:error, {reason, _meta}}), do: reason def handle_response(_), do: nil By using pattern matching we can have three types of function bodies. The first one will be invoked when the response status is HTTP 200 OK, the second one when there\u0026rsquo;s an error and the third one for any other case.\nAs you can imagine, we could have used conditional logic here, but having the power of pattern matching allows us to have three tiny functions that are very easy to read, understand and test.\nParsing the response Here\u0026rsquo;s the body of the response:\n003D68EB55068C33ACE09247EE4C639306B:3\\r\\n012C192B2F16F82EA0EB9EF18D9D539B0DD:1\\r\\n01330C689E5D64F660D6947A93AD634EF8F:1\\r\\n0198748F3315F40B1A102BF18EEA0194CD9:1\\r\\n01F9033B3C00C65DBFD6D1DC4D22918F5E9:2\\r\\n0424DB98C7A0846D2C6C75E697092A0CC3E:5\\r\\n047F229A81EE2747253F9897DA38946E241:1\\r\\n04A37A676E312CC7C4D236C93FBD992AA3C:5\\r\\n04AE045B134BDC43043B216AEF66100EE00:2\\r\\n0502EA98ED7A1000D932B10F7707D37FFB4:5\\r\\n0539F86F519AACC7030B728CD47803E5B22:5\\r\\n054A0BD53E2BC83A87EFDC236E2D0498C08:3\\r\\n05AA835DC9423327DAEC1CBD38FA99B8834:1\\r\\n05E0182DEAE22D02F6ED35280BCAC370179:4 If you look carefully you\u0026rsquo;ll notice that it\u0026rsquo;s actually a list of partial SHA-1 hashes separated by \\r\\n. With a closer inspection of the first one:\n003D68EB55068C33ACE09247EE4C639306B:3 you notice that it\u0026rsquo;s actually a part of the hash, a colon : and a number (3 in the example above). This is actually the hash without it\u0026rsquo;s first 5 characters and the number of times that particular password has been pwned.\nThis means that the password who\u0026rsquo;s SHA-1 hash is 5BAA6003D68EB55068C33ACE09247EE4C639306B has been pwned 3 times, according to haveibeenpwned.com.\nWhat we need to with this response body is to split it, to convert it to a list which we will iterate and find our matching hash in. Let\u0026rsquo;s do that:\ndef find_pwns(response, hash_tail) do response |\u0026gt; to_string |\u0026gt; String.split() |\u0026gt; Enum.find(\u0026amp;(String.starts_with?(\u0026amp;1, hash_tail))) end Although find_pwns/2 might look a bit loaded, let me assure you it\u0026rsquo;s not. Let\u0026rsquo;s see what each of the lines do here:\n to_string will convert the character list we receive from fetch_pwns and will convert it to a string so we can parse it in the next steps String.split will split the string on the \\r\\n characters and will create a list of strings, looking like: [\u0026quot;003D68EB55068C33ACE09247EE4C639306B:3\u0026quot;, ...] We will invoke Enum.find which takes the list and a function as arguments. The list is the parsed list of hash tails and their pwns count, while the function is String.starts_with?/2, which will return true when a line starts with the value of hash_tail.  That\u0026rsquo;s all. At the end, the find_pwns/2 function will return either the line that contains the matched hash tail or it will return nil.\nReturning a meaningful result Now that we have found the count of pwns for the hash (or just a nil), we need to handle that and return a meaningful tuple to the user of the module.\nWhen the find_pwns function does find a count, we want to return a tuple like {:pwned, count}. Otherwise, when find_pwns does not find a count it will return nil, which we handle in the second definition of the return_result function:\ndef return_result(line) when is_binary(line) do [_, count] = String.split(line, \u0026#34;:\u0026#34;) {:pwned, count} end def return_result(_), do: {:ok, 0} In the first function body we will take the line, which should be a binary (string), split it at the : character and then return the tuple with the count. In the second function body we take any argument (which in our case is nil) and return a tuple with 0 as the count.\nUsing Pwnex Now, let\u0026rsquo;s load Pwnex in IEx and give it a spin. To load it in IEx, you need to open the root of the module and run iex -S mix. This will open a IEx session and execute mix in it, which will in fact, load and compile the module and make it available for invocation directly from IEx:\n› iex -S mix Erlang/OTP 21 [erts-10.2] [source] [64-bit] [smp:4:4] [ds:4:4:10] [async-threads:1] [hipe] [dtrace] Interactive Elixir (1.7.4) - press Ctrl+C to exit (type h() ENTER for help) iex(1)\u0026gt; h Pwnex Pwnex Consults haveibeenpwned.com\u0026#39;s API for pwned passwords. iex(2)\u0026gt; Pwnex.pwned?(\u0026#34;password\u0026#34;) {:pwned, 3533661} iex(3)\u0026gt; Pwnex.pwned?(\u0026#34;123!@#asd*\u0026amp;(*123SAkjhda\u0026#34;) {:ok, 0} As you can see, password has been pwned about 3.5 million times, while 123!@#asd*\u0026amp;(*123SAkjhda never.\nThat\u0026rsquo;s basically it. We have Pwnex working - it takes our input as a function argument, talks to an API through an Erlang HTTP client, parses its response body, builds a map of hashes and finds any pwns for the given password.\nAs you can see, this whole package does quite a bit in 65 lines of code.\nIn this article, we saw how we can create a new package, use it to communicate with an API over HTTP, we learned why you don\u0026rsquo;t always need HTTPoison, how you can parse a request body and how you can mingle with some data.\nIf you would like to see the actual code that we wrote in this article, head over to its repo on Github.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/haveibeenpwned-password-lookup-elixir/","summary":"Unless you\u0026rsquo;ve been living under a rock for the last couple of years, you probably know what two-factor authentication (2FA) is. It\u0026rsquo;s quite a neat trick actually - you have a password that you have to (obviously) enter correctly (first factor), but you also have to receive a second (random) code through a different medium, sometimes on a different device, that you have to enter to log in (second factor).","title":"Validate your passwords using Elixir and haveibeenpwned.com's API"},{"content":"In a previous post1, we took a look at linked lists and how we can apply them in a hypothetical use-case. In this post, we will look at two similar but powerful data structures.\n  Modelling actions and history Think about Excel or Google docs. You know, the most ubiquitous applications for composing documents that humanity has invented. We\u0026rsquo;ve all used them in some capacity. As you might know, these apps come with various actions one can apply to a text. Like adding colour to the text, underline, various fonts and sizes or organising the content in tables. The list is long, but there\u0026rsquo;s one ubiquitous functionality that we expect from these tools - the ability to \u0026ldquo;Undo\u0026rdquo; and \u0026ldquo;Redo\u0026rdquo; the actions we have applied.\nHave you ever considered how you would program such functionality if given the opportunity? Let\u0026rsquo;s explore a data structure that can help us with such a task.\nLet’s try to think how we would model the actions each of these applications have. Also, later on, we will see how we can keep the history of the actions and \u0026ldquo;Undo\u0026rdquo; them.\nA simple Action struct would look something like:\ntype Action struct { name string metadata Meta // Probably some other data here... } We will store only the name at the moment, while the real-deal would have much more options compared to our example. So now, when the user of the editor applies a function to a bunch of text, we want to store that action in some sort of a collection so we can \u0026ldquo;Undo\u0026rdquo; it later.\ntype ActionHistory struct { top *Action size int } Looking at this ActionHistory data structure, we store a pointer to the Action at the top of the stack and the size of the stack. Once an action is applied, we will link it to the top item. So, when applying an action to the document, this is what could go under the hood.\nfunc (history *ActionHistory) Apply(newAction *Action) { if history.top != nil { oldTop := history.top newAction.next = oldTop } history.top = newAction history.size++ } An Add function would add the latest Action to the top of the ActionHistory. If the history struct has an action present at the top, it would push it down the history by linking it to the new action. Otherwise, it will attach the new action to the top of the list. Now, if you know about linked lists (or read my last post about linked lists in Go) you might see the resemblance here. So far, what we use here is essentially a linked list, none the less.\nWhat about undoing an action? This is what an Undo function would look like:\nfunc (history *ActionHistory) Undo() *Action { topAction := history.top if topAction != nil { history.top = topAction.next } else if topAction.next == nil { history.top = nil } historyAction.size-- return topAction } If you are paying close attention you can notice that this is a bit different than just removing a node from a linked list. Due to the nature of an ActionHistory, we want the last applied action to be the one that will be Undoed first. Which makes sense, right?\nThis is the default behaviour of a stack. A stack is a data structure where you can only insert or delete items at the top of the stack. Think of it like a stack of papers, or stack of plates in your kitchen drawer. If you want to take the bottom plate from a stack you are going to have a hard time. But taking the one at the top is plain simple. Stacks are also considered LIFO structures - meaning Last In First Out, because of the behaviour we explained above.\nThat is basically what our Undo function does. If the stack (a.k.a. ActionHistory) has more than one Action in it, it will set the top link for the second item. Otherwise, it will empty up the ActionHistory by setting the top element to nil.\nFrom a big-O perspective, searching through a stack has O(n) complexity, but insertion and deletion from a stack are super quick - O(1). This is because traversing the whole stack, in worst case scenario, will still take going all n items in it, while inserting and removing items is constant time because we always insert and remove from the top of the stack.\nYou can play with the working version of this code here.\n  Luggage control Most of us have travelled by plane and know all of the security checks that a person has to go through to get on the plane. Sure, it’s for own our safety but sometimes it’s unnecessarily stressful to get through all of the scans, checks and tests.\nOne of the usual sights at airports security checkpoints are the long queues of people and luggage being put on the strip of the X-ray machines while people walk through metal detector gates. Probably there’s more to it that we even don’t know about it, but let’s focus on the X-ray machines that scan our bags.\nHave you thought how would you model the interactions that happen on that machine? Of course, at least the visible ones. Let’s explore this idea for a moment. We would have to somehow represent the luggage on the strip as a collection of items, and the x-ray machine that scans the luggage one piece at a time.\nThe Luggage would be simple, for now:\ntype Luggage struct { weight int passenger string } We can also add a simple constructor function for the Luggage type as well:\nfunc NewLuggage(weight int, passenger string) *Luggage { l := Luggage{ weight: weight, passenger: passenger, // just as an identifier \t} return \u0026amp;l } Then, we can create a Belt where the Luggage is put on and taken to the x-ray scanner:\ntype Belt []*Luggage Not what you were expecting? Well, what we create is a Belt type that is actually a slice of Luggage pointers. Which is what exactly the machine belt is - just a collection of bags that get scanned one by one.\nSo now we need to add a function that knows how to add Luggage to the Belt:\nfunc (belt *Belt) Add(newLuggage *Luggage) { *belt = append(*belt, newLuggage) } Since Belt is actually a slice, we can use the built-in append function which will add the newLuggage to the Belt. The cool part about this implementation the time complexity - because we use append, which is a built-in method, we get an amortised O(1) for insertion. Of course, this comes at space cost, due to the way slices in Go work.\nAs the Belt moves and takes Luggage to the x-ray machine, we will need to somehow take this luggage off and load it into the machine for inspection. But because of the nature of the Belt, the first item that’s put on it is the first item to be scanned. And the last one that is added will be the last one to be scanned. So, we can say that the Belt is a FIFO (First in, first out) data structure.\nThis is what the function Take would look like, keeping in mind the details above:\nfunc (belt *Belt) Take() *Luggage { first, rest := (*belt)[0], (*belt)[1:] *belt = rest return first } It will take the first item and return it, and it will assign everything else in the collection to the beginning of it, so the second item becomes first and so on. If you were wondering, this has a O(1) time complexity since it always takes the first item from the queue.\nUsing our new types and functions can be done as such:\nfunc main() { belt := \u0026amp;Belt{} belt.Add(NewLuggage(3, \u0026#34;Elmer Fudd\u0026#34;)) belt.Add(NewLuggage(5, \u0026#34;Sylvester\u0026#34;)) belt.Add(NewLuggage(2, \u0026#34;Yosemite Sam\u0026#34;)) belt.Add(NewLuggage(10, \u0026#34;Daffy Duck\u0026#34;)) belt.Add(NewLuggage(1, \u0026#34;Bugs Bunny\u0026#34;)) fmt.Println(\u0026#34;Belt:\u0026#34;, belt, \u0026#34;Length:\u0026#34;, len(*belt)) first := belt.Take() fmt.Println(\u0026#34;First luggage:\u0026#34;, first) fmt.Println(\u0026#34;Belt:\u0026#34;, belt, \u0026#34;Length:\u0026#34;, len(*belt)) } The output of the main function will be something like: Belt: \u0026amp;[0x1040a0c0 0x1040a0d0 0x1040a0e0 0x1040a100 0x1040a110] Length: 5 First luggage: \u0026amp;{3 Elmer Fudd} Belt: \u0026amp;[0x1040a0d0 0x1040a0e0 0x1040a100 0x1040a110] Length: 4\nBasically what happens is we add five different Luggage structs on the Belt and we take the first one off, which is the one printed on the second line of the output.\nYou can play with the code from this example here.\n  What about first-class passengers? Yeah, what about them? I mean, they’ve paid so much money for their ticket that it just doesn’t make sense for them to wait in queues as the economy ticket holders. So, how can we prioritise these passengers? What if their luggage has some sort of priority, where the higher the priority is the faster they get through the queue?\nLet’s modify our Luggage struct to enable this:\ntype Luggage struct { weight int priority int passenger string } Also, all Luggage created in the NewLuggage function will have to take the priority level as an argument:\nfunc NewLuggage(weight int, priority int, passenger string) *Luggage { l := Luggage{ weight: weight, priority: priority, passenger: passenger, } return \u0026amp;l } Let’s think this through again. Basically, when a new Luggage is put on the Belt, we need to detect it’s priority and put it as close to the beginning of the Belt as possible based on the detected priority.\nLet’s modify our Add function:\nfunc (belt *Belt) Add(newLuggage *Luggage) { if len(*belt) == 0 { *belt = append(*belt, newLuggage) } else { added := false for i, placedLuggage := range *belt { if newLuggage.priority \u0026gt; placedLuggage.priority { *belt = append((*belt)[:i], append(Belt{newLuggage}, (*belt)[i:]...)...) added = true break } } if !added { *belt = append(*belt, newLuggage) } } } Compared to the previous implementation, this is rather complicated. There are a couple of things going on here and the first case is quite simple. If the belt is empty, we just put the new luggage on the belt and we are done. The Belt will have only one item on it and that one will be the first that can be taken off of it.\nThe second case, when there’s more than one item on the Belt, loops through all of the luggage on the Belt and compares their priority with the new one coming on. Then it finds a Luggage that has a smaller priority it bypasses it and puts the new luggage in front of it. This means, the higher the priority the Luggage has the further to the beginning of the Belt it will be placed.\nOf course, if the loop doesn’t find such a Luggage it will just append it to the end of the Belt. Our new Add function has a time complexity of O(n) because in worst case scenario it will have to traverse the whole slice before it inserts the new Luggage struct. Inherently, searching and accessing any item in our queue will cost us the same - O(n).\nTo demonstrate the new Add functionality, we can run the following code:\nfunc main() { belt := make(Belt, 0) belt.Add(NewLuggage(3, 1, \u0026#34;Elmer Fudd\u0026#34;)) belt.Add(NewLuggage(3, 1, \u0026#34;Sylvester\u0026#34;)) belt.Add(NewLuggage(3, 1, \u0026#34;Yosemite Sam\u0026#34;)) belt.Inspect() belt.Add(NewLuggage(3, 2, \u0026#34;Daffy Duck\u0026#34;)) belt.Inspect() belt.Add(NewLuggage(3, 3, \u0026#34;Bugs Bunny\u0026#34;)) belt.Inspect() belt.Add(NewLuggage(100, 2, \u0026#34;Wile E. Coyote\u0026#34;)) belt.Inspect() } First, it will create a Belt with three Luggage structs on it, each of them with a priority of 1:\n0. \u0026amp;{3 1 Elmer Fudd} 1. \u0026amp;{3 1 Sylvester} 2. \u0026amp;{3 1 Yosemite Sam} Then, it will add a new Luggage with a priority of 2:\n0. \u0026amp;{3 2 Daffy Duck} 1. \u0026amp;{3 1 Elmer Fudd} 2. \u0026amp;{3 1 Sylvester} 3. \u0026amp;{3 1 Yosemite Sam} You see, the new luggage with the highest priority got promoted to the first place in the Belt. Next, we add a new one with even higher priority (3):\n0. \u0026amp;{3 3 Bugs Bunny} 1. \u0026amp;{3 2 Daffy Duck} 2. \u0026amp;{3 1 Elmer Fudd} 3. \u0026amp;{3 1 Sylvester} 4. \u0026amp;{3 1 Yosemite Sam} As expected, the one with the highest priority was put on the first spot in the Belt. Lastly, we add another Luggage, this time with priority 2:\n0. \u0026amp;{3 3 Bugs Bunny} 1. \u0026amp;{3 2 Daffy Duck} 2. \u0026amp;{100 2 Wile E. Coyote} 3. \u0026amp;{3 1 Elmer Fudd} 4. \u0026amp;{3 1 Sylvester} 5. \u0026amp;{3 1 Yosemite Sam} The new Luggage was added right after the Luggage with the same priority as the new one and of course, not at the beginning of the Belt. Basically, our Belt gets implicitly sorted by the priority as we add new Luggage to it.\nIf you are knowledgeable about queues you might think that these are not the most performant ways of implementing priority queues and you are quite right. Implementing priority queues can be done more performant using heaps, that we’ll take a look at in another post.\nThere’s more interesting knowledge around priority queues that we can explore. Until then you can take a look at priority queues’ Wiki page. If you are knowledgeable about queues you might think that these are not the most performant ways of implementing priority queues and you are quite right. Implementing priority queues can be done more performant using heaps, that we’ll take a look at in another post.), especially the “Implementation” section.\nYou can see and play with the code from this example here.\nClosing thoughts In this post, we took a look at what stacks and queues are and we tried to mimic some interesting real-world application to them. I strongly believe that when we learn a topic (especially in computer science) it’s much better to do it through examples and application to a problem and I hope I managed to do exactly that.\nIn further posts we will look at some more priority queues (using heaps), but before we get there we will take a look at some a bit simpler data structures.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n      Data structures in Go: Linked lists\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://ieftimov.com/post/golang-datastructures-stacks-queues/","summary":"In a previous post1, we took a look at linked lists and how we can apply them in a hypothetical use-case. In this post, we will look at two similar but powerful data structures.\n  Modelling actions and history Think about Excel or Google docs. You know, the most ubiquitous applications for composing documents that humanity has invented. We\u0026rsquo;ve all used them in some capacity. As you might know, these apps come with various actions one can apply to a text.","title":"Data structures in Go: Stacks and queues"},{"content":"Data structures and algorithms are the bread and butter of computer science. Although sometimes they appear scary to people, most of them have a simple explanation. Also, when explained well with a problem algorithms can be interesting and fun to learn and apply.\n  This post is aimed at people that are not comfortable with linked lists, or folks that want to see and learn how to build one with Golang. We will see how we can implement them with Go via a (somewhat) practical example, instead of the plain theory and code examples.\nBut first, let\u0026rsquo;s touch on a bit of theory.\nLinked lists Linked lists are one of the simpler data structures out there. Wikipedia\u0026rsquo;s article on linked lists states that:\n In computer science, a linked list is a linear collection of data elements, in which linear order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a group of nodes which together represent a sequence. Under the simplest form, each node is composed of data and a reference (in other words, a link) to the next node in the sequence.\n While all this might look like too much or confusing, let\u0026rsquo;s break it down. A linear data structure is the one where it\u0026rsquo;s elements form a sequence of some sort. Simple as that. Now, why the physical placement in memory doesn\u0026rsquo;t matter? Well, when you have arrays the amount of memory the array takes is fixed, in the sense that if you have an array of 5 items, the language will grab only 5 memory addresses in the memory, one after another. Because these addresses create a sequence, the array knows in what memory range its values will be stored and thus the physical placement in-memory of these values create a sequence.\nWith linked lists, it\u0026rsquo;s a bit different. In the definition you will notice that \u0026ldquo;each element points to the next\u0026rdquo;, using \u0026ldquo;data and a reference (in other words, a link) to the next node\u0026rdquo;. This means that each node of the linked list stores two things: a value and a reference to the next node in the list. Simple as that.\n  Streams of data Everything that humans perceive around them is some sort of information or rather data that our senses and our minds know how to process and convert it into a useful piece of information. Whether we look, or smell, or touch we process data and find meaning from that data. Or, when we browse our social media networks we always resort to a feed of data, ordered chronologically and with no end in sight.\nSo, how can we use linked lists to model such a news feed? Let\u0026rsquo;s first quickly take a glance at a simple Tweet for example:\nFor the purposes of our example social network, let\u0026rsquo;s get inspired by Twitter and create a Post type, that has a body, a publishDate and a link to the next post:\ntype Post struct { body string publishDate int64 // Unix timestamp \tnext *Post // link to the next Post } Next, how can we model a feed of posts? Well, if we know that feeds consist of posts that are linked to another post, then we can try to create a type like that:\ntype Feed struct { length int // we\u0026#39;ll use it later \tstart *Post } The Feed struct will have a beginning (or start) which will point to the first Post in the feed and a length property which will store the size of the Feed at any given moment.\nSo, let\u0026rsquo;s say we want to create a Feed with two posts, the first step is to create an Append function on the Feed type:\nfunc (f *Feed) Append(newPost *Post) { if f.length == 0 { f.start = newPost } else { currentPost := f.start for currentPost.next != nil { currentPost = currentPost.next } currentPost.next = newPost } f.length++ } Then we can invoke it, twice:\nfunc main() { f := \u0026amp;Feed{} p1 := Post{ body: \u0026#34;Lorem ipsum\u0026#34;, } f.Append(\u0026amp;p1) fmt.Printf(\u0026#34;Length: %v\\n\u0026#34;, f.length) fmt.Printf(\u0026#34;First: %v\\n\u0026#34;, f.start) p2 := Post{ body: \u0026#34;Dolor sit amet\u0026#34;, } f.Append(\u0026amp;p2) fmt.Printf(\u0026#34;Length: %v\\n\u0026#34;, f.length) fmt.Printf(\u0026#34;First: %v\\n\u0026#34;, f.start) fmt.Printf(\u0026#34;Second: %v\\n\u0026#34;, f.start.next) } So, what does this code do? First, the main function - it creates a pointer to a Feed struct, two Post structs with some dummy content and it invokes twice the Append function on the Feed, which results in it having a length of 2. We inspect the two values that the Feed has by accessing the start of the Feed (which is, in fact, a Post) and the next item after the start, which is the second Post.\nWhen we run the program, the output will look something like:\nLength: 1 First: \u0026amp;{Lorem ipsum 1257894000 \u0026lt;nil\u0026gt;} Length: 2 First: \u0026amp;{Lorem ipsum 1257894000 0x10444280} Second: \u0026amp;{Dolor sit amet 1257894000 \u0026lt;nil\u0026gt;} You can see, after we add the first Post to the Feed, the length is 1 and the first Post has a body and a publishte (as a Unix timestamp), while it\u0026rsquo;s next value is nil (because there\u0026rsquo;s no more Posts in the Feed). Then, we add the second Post to the Feed and when we inspect the two Posts we see that the first one has the same content as before, but with a pointer to the next Post in the list. The second also has a body and a publishDate but with no pointer to the next Post in the list. Also, the length of the Feed increases as we add more Posts to it.\nLet\u0026rsquo;s go back to the Append function now and deconstruct it so we understand better how to work with linked lists. First, the function creates a pointer to a Post value, with the body argument as body of the Post and the publishDate is set to the Unix timestamp representation of the current time.\nThen, we check if the length of the Feed is 0 - this means that it has no Posts and the first one that is added should be set as the starting Post, conveniently named start.\nBut, if the length of the Feed is more than 0, then our algorithm takes a different turn. It will start with the start of the Feed and it will walk through all the Posts until it finds one that doesn\u0026rsquo;t have a pointer to a next one. Then, it will attach the new Post as the next value on the last Post of the list.\n  Optimising Append Imagine we have a user that scrolls through their Feed, like on any other social network. Since posts are chronologically ordered, based on the publishDate, the Feed will grow more and more as the user scrolls through it and more Posts are attached to the Feed. Given the approach, we took in the Append function, as the Feed gets longer and longer the Append function will become more and more expensive. Why? Because we have to traverse the whole Feed to add a Post at the end of it. If you have heard about Big-O notation, this algorithm has an O(n) time complexity, which means that it will always traverse the whole Feed before it adds a Post to it.\nAs you can imagine, this can be quite inefficient, especially if the Feed grows to be quite long. How can we improve the Append function and decrease the asymptotic complexity of it?\nSee, since our Feed data structure is just a list of Posts, to traverse it we have to know the beginning of the list (called start) that\u0026rsquo;s a pointer of type Post. Because in our example Append always adds a Post to the end of the Feed, we could drastically improve the performance of the algorithm if Feed knows not just of its starting element, but also about it\u0026rsquo;s ending element. Of course, there\u0026rsquo;s always a tradeoff with optimisations, and the tradeoff here is that the data structure will consume a bit more memory (for the new attribute on the Feed structure).\nExtending our Feed data structure is quite easy:\ntype Feed struct { length int start *Post end *Post } But our Append algorithm will have to be tweaked to work with the new structure of a Feed. This is the version of Append using the end attribute of Post:\nfunc (f *Feed) Append(newPost *Post) { if f.length == 0 { f.start = newPost f.end = newPost } else { lastPost := f.end lastPost.next = newPost f.end = newPost } f.length++ } That looks a bit simpler, doesn\u0026rsquo;t it? Let me give you some good news:\n The code is simpler and shorter now, and We drastically improved the time complexity of the function  If you look now at the algorithm, it does two things: if the Feed is empty it will set the new Post as the beginning and the end of the Feed, otherwise it will set the new Post as the end item and it will attach it to the previous Post in the list. On top of how simple it is, this will algorithm now has a big-O complexity of O(1), also known as \u0026ldquo;constant time\u0026rdquo;. That means that Append will perform the same regardless of the length of the Feed structure.\nPretty simple, right? But let\u0026rsquo;s imagine that the Feed is actually a list of Posts on our profile. Hence they are ours, we should be able to delete them. I mean, what kind of a social network doesn\u0026rsquo;t allow it\u0026rsquo;s users to (at least) delete their posts?\n  Removing a Post As we established in the previous section, we want the users of our Feeds to be able to delete their posts. So, how can we model that? If our Feeds were an array, we would just remove the item and be done with it, right?\nWell, this is actually where linked lists shine. When arrays sizes change, the runtime has to capture a new memory block to store the items of the array in. Linked lists due to their design, each item having a pointer to the next node in the list, can be scattered throughout the memory space meaning adding/removing nodes from the list is cheap from a space perspective. When one wants to remove a node from a linked list only the neighbours of the removed node need to be linked, and that is. Garbage collected languages (like Go) make this even easier since we don\u0026rsquo;t have to worry about releasing the allocated memory - the GC will kick in and remove all unused objects.\nTo make our lives a bit easier for this example, let\u0026rsquo;s put a constraint that each of the Posts on a Feedwill have a unique publishDate.This means a publisher can create one Post per second on their Feed. Taking that into effect, this is how we can easily remove a Post from a Feed:\nfunc (f *Feed) Remove(publishDate int64) { if f.length == 0 { panic(errors.New(\u0026#34;Feed is empty\u0026#34;)) } var previousPost *Post currentPost := f.start for currentPost.publishDate != publishDate { if currentPost.next == nil { panic(errors.New(\u0026#34;No such Post found.\u0026#34;)) } previousPost = currentPost currentPost = currentPost.next } previousPost.next = currentPost.next f.length-- } The Remove function will take a publishDate of a Post as an argument by which it will detect what Post needs to be deleted (or unlinked). The function is rather small. If it detects that the start item of the Feed is to be removed it will just reassign the start of the Feed with the second Post in the Feed. Otherwise, it jumps through each of the Posts in the Feed until it runs into a Post that has a matching publishDate to the one passed as the function argument. When it finds one, it will just connect the previous and the next Post in the Feed with each other, effectively dropping the middle (matching) one from the Feed.\nThere\u0026rsquo;s one edge case that we need to make sure that we cover in our Remove function - what if the Feed doesn\u0026rsquo;t have a Post with the specified publishDate? To keep it simple, the function checks for the absence of the next Post in the Feed before it jumps to it. If the next is nil the function panics, telling us that it couldn\u0026rsquo;t find a Post with such publishDate.\n  Inserting a Post Now that we got appending and removing out of the way, let\u0026rsquo;s take a look at (a bit of) a hypothetical case. Imagine that the source that produces the Posts sends them to our application in a non-chronological order. This means that the Posts need to be put in the correct order in the Feed, based on the publishDate. This is how that would look like:\nfunc (f *Feed) Insert(newPost *Post) { if f.length == 0 { f.start = newPost } else { var previousPost *Post currentPost := f.start for currentPost.publishDate \u0026lt; newPost.publishDate { previousPost = currentPost currentPost = previousPost.next } previousPost.next = newPost newPost.next = currentPost } f.length++ } In essence, this is a very similar algorithm to the one in the Remove function, because although both of them do a very different thing (adding v.s. removing a Post in the Feed), they are both based on a search algorithm. That means that both of the functions actually traverse the whole Feed, searching for a Post that matches the publishDate with the one received in the argument of the function. The only difference is that Insert will actually put the new Post in the place where the dates match, while Remove will remove the Post from the Feed.\nAdditionally, this means that both of these functions carry the same time complexity, which is O(n). This means that in a worst-case scenario, the functions will have to traverse the whole Feed to get to the item where the new post needs to be inserted (or the removed).\nWhat if we used arrays? If you are asking that yourself, let me say right up front - you have a point. True, we could store all of the Posts in an array (or a slice in Go), easily push items onto it and also even have random access with an O(1) complexity.\nDue to the nature of arrays, whose values have to be stored in memory one right after another, reading is really fast and cheap. Once you have something stored in an array, retrieving it as easy as accessing it by its 0-based index. When it comes to inserting an item, whether in the middle or at the end, then arrays become less efficient compared to lists. That is because if the array doesn\u0026rsquo;t have more memory reserved for the new item(s), it will have to reserve it and use it. But, if the next memory addresses are not free, it will have to \u0026ldquo;move\u0026rdquo; to a new memory address where there would be space for all of the items in it (new and old).\nLooking at all of the examples and discussion we had so far, we can create a table with time complexity for each of the algorithms we created, and compare them with the same algorithms for arrays:\n╔═══════════╦═════════╦═════════════╗ ║ Action ║ Array ║ Linked list ║ ╠═══════════╬═════════╬═════════════╣ ║ Access ║ O(1) ║ O(n) ║ ║ Search ║ O(n) ║ O(n) ║ ║ Prepend ║ O(1) ║ O(1) ║ ║ Append ║ O(n) ║ O(1) ║ ║ Delete ║ O(n) ║ O(n) ║ ╚═══════════╩═════════╩═════════════╝ As you can see, when you are faced with a certain problem, picking the correct data structure can really make or break the products you create. For ever-growing Feeds, where insertion of Posts is paramount, linked lists do a much better job because insertions are really cheap. But, if we had a different problem on our hands that requires frequent deletions or lots of retrieval/searching, then we would have to pick the correct data structure for the problem we are dealing with.\nYou can see the whole implementation of the Feed and play with it here. Also, Go has it\u0026rsquo;s own linked list implementation, with some nice functions already built in. You can see it\u0026rsquo;s documentation here.\nEDIT 20.02.2018 10:00 CET: Previous verion of the article wrongly stated that the big-O complexity of the delete function is O(1). Changed to O(n) after pointed out by Bart de Goede.\nEDIT 22.02.2018 23:00 CET: Previous verion of the article wrongly stated that the big-O complexity of searching in an array is O(1) instead of O(N). This was a mixup of Access and Search on my side. This is fixed by adding separate rows in the table for Search and Access and their respective time complexities.\nEDIT 25.02.2018 17:00 CET: Previous version of the article had a buggy implementation of the Insert function, which was pointed out by Albert Shirima in the comments.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/golang-datastructures-linked-lists/","summary":"Data structures and algorithms are the bread and butter of computer science. Although sometimes they appear scary to people, most of them have a simple explanation. Also, when explained well with a problem algorithms can be interesting and fun to learn and apply.\n  This post is aimed at people that are not comfortable with linked lists, or folks that want to see and learn how to build one with Golang.","title":"Data structures in Go: Linked lists"},{"content":"If you have ever tried writing a daemon for MacOS you have met with launchd. For those that don\u0026rsquo;t have the experience, think of it as a framework for starting, stopping and managing daemons, applications, processes, and scripts. If you have any *nix experience the word daemon should not be too alien to you.\nFor those unfamiliar, a daemon is a program running in the background without requiring user input. A typical daemon might, for instance, perform daily maintenance tasks or scan a device for malware when connected.\nThis post is aimed at folks that know a little bit about what daemons are, what is the common way of using them and know a bit about Go. Also, if you have ever written a daemon for any other *nix system, you will have a good idea of what we are going to talk here. If you are an absolute beginner in Go or systems this might prove to be an overwhelming article. Still, feel free to give it a shot and let me know how it goes.\nIf you ever find yourself wanting to write a MacOS daemon with Go you would like to know most of the stuff we are going to talk about in this article. Without further ado, let\u0026rsquo;s dive in.\nWhat is launchd and how it works? launchd is a unified service-management framework, that starts, stops and manages daemons, applications, processes, and scripts in MacOS.\nOne of its key features is that it differentiates between agents and daemons. In launchd land, an agent runs on behalf of the logged in user while a daemon runs on behalf of the root user or any specified user.\nDefining agents and daemons An agent/daemon is defined in an XML file, which states the properties of the program that will execute, among a list of other properties. Another aspect to keep in mind is that launchd decides if a program will be treated as a daemon or an agent by where the program XML is located.\nOver at launchd.info, there\u0026rsquo;s a simple table that shows where you would (or not) place your program\u0026rsquo;s XML:\n+----------------+-------------------------------+----------------------------------------------------+ | Type | Location | Run on behalf of | +----------------+-------------------------------+----------------------------------------------------+ | User Agents | ~/Library/LaunchAgents | Currently logged in user | | Global Agents | /Library/LaunchAgents | Currently logged in user | | Global Daemons | /Library/LaunchDaemons | root or the user specified with the key \u0026#39;UserName\u0026#39; | | System Agents | /System/Library/LaunchAgents | Currently logged in user | | System Daemons | /System/Library/LaunchDaemons | root or the user specified with the key \u0026#39;UserName\u0026#39; | +----------------+-------------------------------+----------------------------------------------------+ This means that when we set our XML file in, for example, the /Library/LaunchAgents path our process will be treated as a global agent. The main difference between the daemons and agents is that LaunchDaemons will run as root, and are generally background processes. On the other hand, LaunchAgents are jobs that will run as a user or in the context of userland. These may be scripts or other foreground items and they also have access to the MacOS UI (e.g. you can send notifications, control the windows, etc.)\nSo, how do we define an agent? Let\u0026rsquo;s take a look at a simple XML file that launchd understands:\n\u0026lt;!--- Example blatantly ripped off from http://www.launchd.info/ --\u0026gt; \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.example.app\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;Program\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;/Users/Me/Scripts/cleanup.sh\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; The XML is quite self-explanatory, unless it\u0026rsquo;s the first time you are seeing an XML file. The file has three main properties, with values. In fact, if you take a better look you will see the dict keyword which means dictionary. This actually means that the XML represents a key-value structure, so in Go it would look like:\nmap[string]string{ \u0026#34;Label\u0026#34;: \u0026#34;com.example.app\u0026#34;, \u0026#34;Program\u0026#34;: \u0026#34;/Users/Me/Scripts/cleanup.sh\u0026#34;, \u0026#34;RunAtLoad\u0026#34;: \u0026#34;true\u0026#34;, } Let’s look at each of the keys:\n Label - The job definition or the name of the job. This is the unique identifier for the job within the launchd instance. Usually, the label (and hence the name) is written in Reverse domain name notation. Program - This key defines what the job should start, in our case a script with the path /Users/Me/Scripts/cleanup.sh. RunAtLoad - This key specifies when the job should be run, in this case right after it\u0026rsquo;s loaded.  As you can see, the keys used in this XML file are quite self-explanatory. This is the case for the remaining 30-40 keys that launchd supports. Last but not least these files although have an XML syntax, in fact, they have a .plist extension (which means Property List). Makes a lot of sense, right?\nlaunchd v.s. launchctl Before we continue with our little exercise of creating daemons/agents with Go, let\u0026rsquo;s first see how launchd allows us to control these jobs. While launchd\u0026rsquo;s job is to boot the system and to load and maintain services, there is a different command used for jobs management - launchctl. With launchd facilitating jobs, the control of services is centralized in the launchctl command.\nlaunchctl has a long list of subcommands that we can use. For example, loading or unloading a job is done via:\nlaunchctl unload/load ~/Library/LaunchAgents/com.example.app.plist Or, starting/stopping a job is done via:\nlaunchctl start/stop ~/Library/LaunchAgents/com.example.app.plist To get any confusion out of the way, load and start are different. While start only starts the agent/daemon, load loads the job and it might also start it if the job is configured to run on load. This is achieved by setting the RunAtLoad property in the property list XML of the job:\n\u0026lt;!--- Example blatantly ripped off from http://www.launchd.info/ --\u0026gt; \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.example.app\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;Program\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;/Users/Me/Scripts/cleanup.sh\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt;\u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; If you would like to see what other commands launchctl supports, you can run man launchctl in your terminal and see the options in detail.\nAutomating with Go After getting the basics of launchd and launctl out of the way, why don\u0026rsquo;t we see how we can add an agent to any Go package? For our example, we are going to write a simple way of plugging in a launchd agent for any of your Go packages.\nAs we already established before, launchd speaks in XML. Or, rather, it understands XML files, called property lists (or .plist). This means, for our Go package to have an agent running on MacOS, it will need to tell launchd \u0026ldquo;hey, launchd, run this thing!\u0026rdquo;. And since launch speaks only in .plist, that means our package needs to be capable of generating XML files.\nTemplates in Go While one could have a hardcoded .plist file in their project and copy it across to the ~/Library/LaunchAgents path, a more programmatical way to do this would be to use a template to generate these XML files. The good thing is Go\u0026rsquo;s standard library has us covered - the text/template package (docs) does exactly what we need.\nIn a nutshell, text/template implements data-driven templates for generating textual output. Or in other words, you give it a template and a data structure, it will mash them up together and produce a nice and clean text file. Perfect.\nLet\u0026rsquo;s say the .plist we need to generate in our case is the following:\n\u0026lt;?xml version=\u0026#39;1.0\u0026#39; encoding=\u0026#39;UTF-8\u0026#39;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \\\u0026#34;-//Apple Computer//DTD PLIST 1.0//EN\\\u0026#34; \\\u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\\\u0026#34; \u0026gt; \u0026lt;plist version=\u0026#39;1.0\u0026#39;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;Ticker\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;Program\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;/usr/local/bin/ticker\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardOutPath\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;/tmp/ticker.out.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardErrorPath\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;/tmp/ticker.err.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;KeepAlive\u0026lt;/key\u0026gt;\u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt;\u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; We want to keep it quite simple in our little exercise. It will contain only six properties: Label, Program, StandardOutPath, StandardErrorPath, KeepAlive and RunAtLoad. To generate such a XML, its template would look something like this:\n\u0026lt;?xml version=\u0026#39;1.0\u0026#39; encoding=\u0026#39;UTF-8\u0026#39;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \\\u0026#34;-//Apple Computer//DTD PLIST 1.0//EN\\\u0026#34; \\\u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\\\u0026#34; \u0026gt; \u0026lt;plist version=\u0026#39;1.0\u0026#39;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;{{.Label}}\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;Program\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;{{.Program}}\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardOutPath\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;/tmp/{{.Label}}.out.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardErrorPath\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;/tmp/{{.Label}}.err.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;KeepAlive\u0026lt;/key\u0026gt;\u0026lt;{{.KeepAlive}}/\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt;\u0026lt;{{.RunAtLoad}}/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; As you can see, the difference between the two XMLs is that the second one has the double curly braces with expressions in them in places where the first XML has some sort of a value. These are called \u0026ldquo;actions\u0026rdquo;, which can be data evaluations or control structures and are delimited by \u0026ldquo;{{\u0026rdquo; and \u0026ldquo;}}\u0026rdquo;. Any of the text outside actions is copied to the output untouched.\nInjecting your data Now that we have our template with its glorious XML and curly braces (or actions), let\u0026rsquo;s see how we can inject our data into it. Since things are generally simple in Go, especially when it comes to its standard library, you should not worry - this will be easy!\nTo keep thing simple, we will store the whole XML template in a plain old string. Yes, weird, I know. The best way would be to store it in a file and read it from there, or embed it in the binary itself, but in our little example let\u0026rsquo;s keep it simple:\n// template.go package main func Template() string { return ` \u0026lt;?xml version=\u0026#39;1.0\u0026#39; encoding=\u0026#39;UTF-8\u0026#39;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \\\u0026#34;-//Apple Computer//DTD PLIST 1.0//EN\\\u0026#34; \\\u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\\\u0026#34; \u0026gt; \u0026lt;plist version=\u0026#39;1.0\u0026#39;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;{{.Label}}\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;Program\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;{{.Program}}\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardOutPath\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;/tmp/{{.Label}}.out.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardErrorPath\u0026lt;/key\u0026gt;\u0026lt;string\u0026gt;/tmp/{{.Label}}.err.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;KeepAlive\u0026lt;/key\u0026gt;\u0026lt;{{.KeepAlive}}/\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt;\u0026lt;{{.RunAtLoad}}/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; ` } And the program that will use our little template function:\n// main.go package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;text/template\u0026#34; ) func main() { data := struct { Label string Program string KeepAlive bool RunAtLoad bool }{ Label: \u0026#34;ticker\u0026#34;, Program: \u0026#34;/usr/local/bin/ticker\u0026#34;, KeepAlive: true, RunAtLoad: true, } t := template.Must(template.New(\u0026#34;launchdConfig\u0026#34;).Parse(Template())) err := t.Execute(os.Stdout, data) if err != nil { log.Fatalf(\u0026#34;Template generation failed: %s\u0026#34;, err) } } So, what happens there, in the main function? It\u0026rsquo;s actually quite simple:\n We declare a small struct, which has only the properties that will be needed in the template, and we immediately initialize it with the values for our program. We build a new template, using the template.New function, with the name launchdConfig. Then, we invoke the Parse function on it, which takes the XML template as an argument. We invoke the template.Must function, which takes our built template as argument. From the documentation, template.Must is a helper that wraps a call to a function returning (*Template, error) and panics if the error is non-nil. Actually, template.Must is built to, in a way, validate if the template can be understood by the text/template package. Finally, we invoke Execute on our built template, which takes a data structure and applies its attributes to the actions in the template. Then it sends the output to os.Stdout, which does the trick for our example. Of course, the output can be sent to any struct that implements the io.Writer interface, like a file (os.File).  Make and load my .plist Instead of sending all this nice XML to standard out, let\u0026rsquo;s throw in an open file descriptor to the Execute function and finally save our .plist file in ~/Library/LaunchAgents. There are a couple of main points we need to change.\nFirst, getting the location of the binary. Since it\u0026rsquo;s a Go binary, and we will install it via go install, we can assume that the path will be at $GOPATH/bin. Second, since we don\u0026rsquo;t know the actual $HOME of the current user, we will have to get it through the environment. Both of these can be done via os.Getenv (docs) which takes a variable name and returns its value.\n// main.go package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;text/template\u0026#34; ) func main() { data := struct { Label string Program string KeepAlive bool RunAtLoad bool }{ Label: \u0026#34;com.ieftimov.ticker\u0026#34;, // Reverse-DNS naming convention \tProgram: fmt.Sprintf(\u0026#34;%s/bin/ticker\u0026#34;, os.Getenv(\u0026#34;GOPATH\u0026#34;)), KeepAlive: true, RunAtLoad: true, } plistPath := fmt.Sprintf(\u0026#34;%s/Library/LaunchAgents/%s.plist\u0026#34;, os.Getenv(\u0026#34;HOME\u0026#34;), data.Label) f, err := os.Open(plistPath) t := template.Must(template.New(\u0026#34;launchdConfig\u0026#34;).Parse(Template())) err := t.Execute(f, data) if err != nil { log.Fatalf(\u0026#34;Template generation failed: %s\u0026#34;, err) } } That\u0026rsquo;s about it. The first part, about setting the correct Program property, is done by concatenating the name of the program and $GOPATH:\nfmt.Sprintf(\u0026#34;%s/bin/ticker\u0026#34;, os.Getenv(\u0026#34;GOPATH\u0026#34;)) // Output: /Users/\u0026lt;username\u0026gt;/go/bin/ticker  The second part is slightly more complex, and it\u0026rsquo;s done by concatenating three strings, the $HOME environment variable, the Label property of the program and the /Library/LaunchAgents string:\nfmt.Sprintf(\u0026#34;%s/Library/LaunchAgents/%s.plist\u0026#34;, os.Getenv(\u0026#34;HOME\u0026#34;), data.Label) // Output: /Users/\u0026lt;username\u0026gt;/Library/LaunchAgents/com.ieftimov.ticker.plist  By having these two paths, opening the file and writing to it is very trivial - we open the file via os.Open and we pass in the os.File structure to t.Execute which writes to the file descriptor.\nWhat about the Launch Agent? We will keep this one simple as well. Let\u0026rsquo;s throw in a command to our package, make it installable via go install (not that there\u0026rsquo;s much to it) and make it runnable by our .plist file:\n// cmd/ticker/main.go package ticker import ( \u0026#34;time\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { for range time.Tick(30 * time.Second) { fmt.Println(\u0026#34;tick!\u0026#34;) } } This the ticker program will use time.Tick, to execute an action every 30 seconds. Since this will be an infinite loop, launchd will kick off the program on boot (because RunAtLoad is set to true in the .plist file) and will keep it running. But, to make the program controllable from the operating system, we need to make the program react to some OS signals, like SIGINT or SIGTERM.\nUnderstanding and handling OS signals While there\u0026rsquo;s quite a bit to be learned about OS signals, in our example we will scratch a bit off the surface. (If you know a lot about inter-process communication this might be too much of an oversimplification to you - and I apologize up front. Feel free to drop some links on the topic in the comments so others can learn more!)\nThe best way to think about a signal is that it\u0026rsquo;s a message from the operating system or another process, to a process. It is an asynchronous notification sent to a process or to a specific thread within the same process to notify it of an event that occurred.\nThere are quite a bit of various signals that can be sent to a process (or a thread), like SIGKILL (which kills a process), SIGSTOP (stop), SIGTERM (termination), SIGILL and so on and so forth. There\u0026rsquo;s an exhaustive list of signal types on Wikipedia\u0026rsquo;s page on signals.\nTo get back to launchd, if we look at its documentation about stopping a job we will notice the following:\n Stopping a job will send the signal SIGTERM to the process. Should this not stop the process launchd will wait ExitTimeOut seconds (20 seconds by default) before sending SIGKILL.\n Pretty self-explanatory, right? We need to handle one signal - SIGTERM. Why not SIGKILL? Because SIGKILL is a special signal that cannot be caught - it kills the process without any chance for a graceful shutdown, no questions asked. That\u0026rsquo;s why there\u0026rsquo;s a termination signal and a \u0026ldquo;kill\u0026rdquo; signal.\nLet\u0026rsquo;s throw in a bit of signal handling in our code, so our program knows that it needs to exit when it gets told to do so:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; ) func main() { sigs := make(chan os.Signal, 1) signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM) go func() { \u0026lt;-sigs os.Exit(0) }() for range time.Tick(30 * time.Second) { fmt.Println(\u0026#34;tick!\u0026#34;) } } In the new version, the agent program has two new packages imported: os/signal and syscall. os/signal implements access to incoming signals, that are primarily used on Unix-like systems. Since in this article we are specifically interested in MacOS, this is exactly what we need.\nPackage syscall contains an interface to the low-level operating system primitives. An important note about syscall is that it is locked down since Go v1.4. This means that any code outside of the standard library that uses the syscall package should be migrated to use the new golang.org/x/sys package. Since we are using only the signals constants of syscall we can get away with this.\n(If you want to read more about the package lockdown, you can see the rationale on locking it down by the Go team and the new golang.org/s/sys package.)\nHaving the basics of the packages out of the way, let\u0026rsquo;s go step by step through the new lines of code added:\n We make a buffered channel of type os.Signal, with a size of 1. os.Signal is a type that represents an operating system signal. We call signal.Notify with the new channel as an argument, plus syscall.SIGINT and syscall.SIGTERM. This function states \u0026ldquo;when the OS sends a SIGINT or a SIGTERM signal to this program, send the signal to the channel\u0026rdquo;. This allows us to somehow handle the sent OS signal. The new goroutine that we spawn waits for any of the signals to arrive through the channel. Since we know that any of the signals that will arrive are about shutting down the program, after receiving any signal we use os.Exit(0) (docs) to gracefully stop the program. One caveat here is that if we had any deferred calls they would not be run.  Now launchd can run the agent program and we can load and unload, start and stop it using launchctl.\nPutting it all together Now that we have all the pieces ready, we need to put them together to a good use. Our application will consist of two binaries - a CLI tool and an agent (daemon). Both of the programs will be stored in separate subdirectories of the cmd directory.\nThe CLI tool:\n// cmd/cli/main.go package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;text/template\u0026#34; ) func main() { data := struct { Label string Program string KeepAlive bool RunAtLoad bool }{ Label: \u0026#34;com.ieftimov.ticker\u0026#34;, // Reverse-DNS naming convention \tProgram: fmt.Sprintf(\u0026#34;%s/bin/ticker\u0026#34;, os.Getenv(\u0026#34;GOPATH\u0026#34;)), KeepAlive: true, RunAtLoad: true, } plistPath := fmt.Sprintf(\u0026#34;%s/Library/LaunchAgents/%s.plist\u0026#34;, os.Getenv(\u0026#34;HOME\u0026#34;), data.Label) f, err := os.Open(plistPath) t := template.Must(template.New(\u0026#34;launchdConfig\u0026#34;).Parse(Template())) err := t.Execute(f, data) if err != nil { log.Fatalf(\u0026#34;Template generation failed: %s\u0026#34;, err) } } And the ticker program:\n// cmd/ticker/main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; ) func main() { sigs := make(chan os.Signal, 1) signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM) go func() { \u0026lt;-sigs os.Exit(0) }() for range time.Tick(30 * time.Second) { fmt.Println(\u0026#34;tick!\u0026#34;) } } To install them both, we need to run go install ./... in the project root. The command will install all the sub-packages that are located within the project. This will leave us with two available binaries, installed in the $GOPATH/bin path.\nTo install our launch agent, we need to run only the CLI tool, via the cli command. This will generate the .plist file and place it in the ~/Library/LaunchAgents path. We don\u0026rsquo;t need to touch the ticker binary - that one will be managed by launchd.\nTo load the newly created .plist file, we need to run:\nlaunchctl load ~/Library/LaunchAgents/com.ieftimov.ticker.plist When we run it, we will not see anything immediately, but after 30 seconds the ticker will add a tick! line in /tmp/ticker.out.log. We can tail the file to see the new lines being added. If we want to unload the agent, we can use:\nlaunchctl unload ~/Library/LaunchAgents/com.ieftimov.ticker.plist This will unload the launch agent and will stop the ticker from running. Remember the signal handling we added? This is the case where it\u0026rsquo;s being used! Also, we could have automated the (un)loading of the file via the CLI tool but for simplicity, we left it out. You can try to improve the CLI tool by making it a bit smarter with subcommands and flags, as a follow-up exercise from this tutorial.\nFinally, if you decide to completely delete the launch agent, you can remove the .plist file:\nrm ~/Library/LaunchAgents/com.ieftimov.ticker.plist In closing As part of this (quite long!) article, we saw how we can work with launchd and Golang. We took a detour, like learning about launchd and launchctl, generating XML files using the text/template package, we took a look at OS signals and how we can gracefully shutdown a Go program by handling the SIGINT and SIGTERM signals. There was quite a bit to learn and see, but we got to the end.\nOf course, we only scratched the surface with this article. For example, launchd is quite an interesting tool. You can use it also like crontab because it allows running programs at explicit time/date combinations or on specific days. Or, for example, the XML template can be embedded in the program binary using tools like go-bindata, instead of hardcoding it in a function. Also, you explore more about signals, how they work and how Go implements these low-level primitives so you can use them with ease in your programs. The options are plenty, feel free to explore!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/create-manage-macos-launchd-agents-golang/","summary":"If you have ever tried writing a daemon for MacOS you have met with launchd. For those that don\u0026rsquo;t have the experience, think of it as a framework for starting, stopping and managing daemons, applications, processes, and scripts. If you have any *nix experience the word daemon should not be too alien to you.\nFor those unfamiliar, a daemon is a program running in the background without requiring user input. A typical daemon might, for instance, perform daily maintenance tasks or scan a device for malware when connected.","title":"Create and manage MacOS LaunchAgents using Go"},{"content":"Recently, while writing a small Golang program for setting reminders I came across a small confusion that I guess most newcomers to Golang will have - how to organise a package in a way that will enable it to cleanly contain two or more binaries.\nThis post is not aimed at experienced Golang programmers, it\u0026rsquo;s mostly aimed at beginners to understand how to compose more complex packages, beyond making the usual \u0026ldquo;one package one binary\u0026rdquo; ones. It\u0026rsquo;s essentially what I would like to have read (or understand) after spinning my wheels for a bit while building my first (more complex) package.\nBut, if you are one of the experienced folks I would be very grateful if you finish reading this article and call out any mistakes you might find. Also I, and probably other beginners, would be happy to find out any other alternative approaches to this problem.\nThat being said, let\u0026rsquo;s begin by seeing what an elementary package layout looks like, and then we can continue with building a more complex one.\nFortune telling Imagine we need to build a CLI program in Golang. One that needs to tell us our fortune, or provide advice on a subject that we are thinking about. Just like a Magic 8-Ball.\nLet\u0026rsquo;s begin by fleshing out the main file of this package:\n// eight_ball.go package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) func main() { rand.Seed(time.Now().Unix()) reader := bufio.NewReader(os.Stdin) answers := []string{ \u0026#34;It is certain\u0026#34;, \u0026#34;It is decidedly so\u0026#34;, \u0026#34;Without a doubt\u0026#34;, \u0026#34;Yes, definitely\u0026#34;, \u0026#34;You may rely on it\u0026#34;, \u0026#34;As I see it, yes\u0026#34;, \u0026#34;Most likely\u0026#34;, \u0026#34;Outlook good\u0026#34;, \u0026#34;Yes\u0026#34;, \u0026#34;Signs point to yes\u0026#34;, \u0026#34;Reply hazy try again\u0026#34;, \u0026#34;Ask again later\u0026#34;, \u0026#34;Better not tell you now\u0026#34;, \u0026#34;Cannot predict now\u0026#34;, \u0026#34;Concentrate and ask again\u0026#34;, \u0026#34;Don\u0026#39;t count on it\u0026#34;, \u0026#34;My reply is no\u0026#34;, \u0026#34;My sources say no\u0026#34;, \u0026#34;Outlook not so good\u0026#34;, \u0026#34;Very doubtful\u0026#34;, } fmt.Print(\u0026#34;What is your question? \u0026#34;) reader.ReadString(\u0026#39;\\n\u0026#39;) fmt.Println(answers[rand.Intn(len(answers))]) } The implementation is quite straightforward. We have a list of predefined answers, blatantly ripped off from Wikipedia\u0026rsquo;s article on Magic 8-ball. The program takes the input from STDIN, ignores it (obviously) and with the help of the rand package takes a random answer from the array, which is then printed to STDOUT.\nWe can test this by running go run eight_ball.go:\n› go run main.go What is your question? Will I win the lottery this year? My sources say no I guess I won\u0026rsquo;t be getting rich by wining the lottery. Now, let\u0026rsquo;s throw in another program in our package. This one, following the same theme, can be about fortune cookies.\n// cookie.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) func main() { rand.Seed(time.Now().Unix()) quotes := []string{ \u0026#34;The beginning of wisdom is to desire it.\u0026#34;, \u0026#34;You will have a very pleasant experience.\u0026#34;, \u0026#34;You will inherit some money or a small piece of land.\u0026#34;, \u0026#34;You will live a long, happy life.\u0026#34;, \u0026#34;You will spend old age in comfort and material wealth.\u0026#34;, \u0026#34;You will step on the soil of many countries.\u0026#34;, \u0026#34;You will take a chance in something in the near future.\u0026#34;, \u0026#34;You will witness a special ceremony.\u0026#34;, \u0026#34;Your everlasting patience will be rewarded sooner or later.\u0026#34;, \u0026#34;Your great attention to detail is both a blessing and a curse.\u0026#34;, \u0026#34;Your heart is a place to draw true happiness.\u0026#34;, \u0026#34;Your ability to juggle many tasks will take you far.\u0026#34;, \u0026#34;A friend asks only for your time, not your money.\u0026#34;, \u0026#34;You will be invited to an exciting event.\u0026#34;, } fmt.Println(quotes[rand.Intn(len(quotes))]) } If you are carefully reading the code, you can see the approach is basically the same. We have a list of predefined quotes, and using the math/rand package we print out a random quote when the program is executed.\nIf we run the program, we would get the following output:\n› go run cookie.go You will live a long, happy life. Nice and simple. The program works flawlessly.\nBuilding it So how can we build this now in a binary, and distrubite it for different operating systems and architectures. It\u0026rsquo;s really one of the things that Go really shines for, right?\nIf you have done any Go you would immediately say: using go build. Let\u0026rsquo;s give that a shot:\n› go build # github.com/fortune_telling ./eight_ball.go:11:6: main redeclared in this block previous declaration at ./cookie.go:9:6 Whoops, what happenned? Well, the error is quite self-descriptive. Basically we have the main function defined in both of these files. But, on the other hand if we rename those functions they will not be run when we create binaries out of the programs. Let\u0026rsquo;s try to rename the main function as foo in eight_ball.go, and then try to run the program using go run:\n› go run eight_ball.go # command-line-arguments runtime.main_main·f: relocation target main.main not defined runtime.main_main·f: undefined: \u0026#34;main.main\u0026#34; As you can see, then the binary cannot be built, since Go\u0026rsquo;s compiler complains about the missing main function. On the other hand, the missing main function in eight_ball.go will actually make go build work.\nWhy is that? Well you see, in a package with a name foo there can only be one main function. When the package is built, that main function will be the entry point for the program (in the binary), so it\u0026rsquo;s mandatory the package has it. Since eight_ball.go is missing it, and cookie.go has it, the package main will have a single main function (in cookie.go), rendering the main package as valid.\nSplit the packages Okay, so by now hopefully it\u0026rsquo;s clear that we cannot have two binaries with two entry points in a single package. So, why don\u0026rsquo;t we split the files in two packages. For example, cookie.go can have a cookie package, while eight_ball.go can have an eight_ball package. Both of them will have a main function and everything should work smoothly, right?\nLet\u0026rsquo;s do that and give it a shot. First, let\u0026rsquo;s rename the packages in the cookie.go and eight_ball.go files respectively:\n// cookie.go package cookie import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) func main() { // Snipped } // eight_ball.go package eight_ball import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) func main() { // Snipped } Let\u0026rsquo;s try to build these packages now:\n› go build cookie.go › go build eight_ball.go Okay, cool. We ran go build on the files and there were no problems. That means that Go produced the binaries for each of these files and we could run them.\nNope. It didn\u0026rsquo;t.\nIf we see Go\u0026rsquo;s documentation on the go build command, we will find this segment:\n When compiling a single main package, build writes the resulting executable to an output file named after the first source file (\u0026lsquo;go build ed.go rx.go\u0026rsquo; writes \u0026lsquo;ed\u0026rsquo; or \u0026lsquo;ed.exe\u0026rsquo;) or the source code directory (\u0026lsquo;go build unix/sam\u0026rsquo; writes \u0026lsquo;sam\u0026rsquo; or \u0026lsquo;sam.exe\u0026rsquo;). The \u0026lsquo;.exe\u0026rsquo; suffix is added when writing a Windows executable.\n Also, this:\n When compiling multiple packages or a single non-main package, build compiles the packages but discards the resulting object, serving only as a check that the packages can be built.\n This means that, to produce a binary of a package, whose name will be derived from the folder name it is stored in, we need to build a main package. That means that our cookie.go and eight_ball.go files will have to be contained in their own folders, while their package names have to stay main.\nReorganizing our files What we need to do is quite simple actually. In our working directory let\u0026rsquo;s introduce a folder called cmd, which will store both of our commands.\nLet\u0026rsquo;s run the following commands:\n› mkdir -p cmd/{cookie,eight_ball}/ › mv cookie.go cmd/cookie/main.go › mv eight_ball.go cmd/eight_ball/main.go If we run tree on our working directory, we will see the following structure:\n› tree . └── cmd ├── cookie │ └── main.go └── eight_ball └── main.go If we try to build the packages now we won\u0026rsquo;t get far as well:\n› go build can\u0026#39;t load package: package github.com/fortune_teller: no Go files in /Users/ie/projects/go/src/github.com/fortune_teller But, the restructuring of the packages allows us to now use the go install ./... command, which will install our packages in our $GOPATH/bin directory:\n› go install ./... › cookie A thrilling time is in your immediate future. › eight_ball What is your question? Will I win the lottery this year? Don\u0026#39;t count on it Whoa, so, what happenned? How did these programs just got installed?\nWhat happenned is the following - since we moved the programs to their own subfolders in our workspace, when built (and installed) they will inherit the name of the folder they are in. Therefore, cmd/cookie/main.go will compile into a cookie binary, while cmd/eight_ball/main.go will compile into a eight_ball binary. Then, after buildilng, these binaries will be installed into the Go binaries path ($GOPATH/bin).\nIf you would like to build the binaries for each of the two packages, without installing them to $GOPATH/bin, then you will need to cd in to the paths where the main.go files are, and run go build there:\n› cd cmd/cookie › go build › ./cookie Your greatest fortune is the large number of friends you have. › cd fortune_teller/cmd/eight_ball › go build › ./eight_ball What is your question? Will I win the lottery? Yes, definitely What if I want a library as part of the package? This question makes sense - what if with the package one wants to ship some additional code. Or even better, what if you would like to import code from the package in the CLI programs?\nLet\u0026rsquo;s extract the answers and quotes variables from the CLI programs into a new package, and try to import that one back in:\n// content.go package fortune_teller func Answers() []string { return []string{ \u0026#34;It is certain\u0026#34;, \u0026#34;It is decidedly so\u0026#34;, \u0026#34;Without a doubt\u0026#34;, \u0026#34;Yes, definitely\u0026#34;, \u0026#34;You may rely on it\u0026#34;, \u0026#34;As I see it, yes\u0026#34;, \u0026#34;Most likely\u0026#34;, \u0026#34;Outlook good\u0026#34;, \u0026#34;Yes\u0026#34;, \u0026#34;Signs point to yes\u0026#34;, \u0026#34;Reply hazy try again\u0026#34;, \u0026#34;Ask again later\u0026#34;, \u0026#34;Better not tell you now\u0026#34;, \u0026#34;Cannot predict now\u0026#34;, \u0026#34;Concentrate and ask again\u0026#34;, \u0026#34;Don\u0026#39;t count on it\u0026#34;, \u0026#34;My reply is no\u0026#34;, \u0026#34;My sources say no\u0026#34;, \u0026#34;Outlook not so good\u0026#34;, \u0026#34;Very doubtful\u0026#34;, } } func Quotes() []string { return []string{ \u0026#34;There is a true and sincere friendship between you and your friends.\u0026#34;, \u0026#34;You find beauty in ordinary things, do not lose this ability.\u0026#34;, \u0026#34;Ideas are like children; there are none so wonderful as your own.\u0026#34;, \u0026#34;It takes more than good memory to have good memories.\u0026#34;, \u0026#34;A thrilling time is in your immediate future.\u0026#34;, \u0026#34;Your blessing is no more than being safe and sound for the whole lifetime.\u0026#34;, \u0026#34;Plan for many pleasures ahead.\u0026#34;, \u0026#34;The joyfulness of a man prolongeth his days.\u0026#34;, \u0026#34;Your everlasting patience will be rewarded sooner or later.\u0026#34;, \u0026#34;Make two grins grow where there was only a grouch before.\u0026#34;, \u0026#34;Something you lost will soon turn up.\u0026#34;, \u0026#34;Your heart is pure, and your mind clear, and your soul devout.\u0026#34;, \u0026#34;Excitement and intrigue follow you closely wherever you go!\u0026#34;, \u0026#34;A pleasant surprise is in store for you.\u0026#34;, \u0026#34;May life throw you a pleasant curve.\u0026#34;, \u0026#34;As the purse is emptied the heart is filled.\u0026#34;, } } After extracting these two functions in a top level package, which will return the content for the two commands, we can import the package in the cookie and eight_ball commands, which will utilise the content. By being able to extract code in a common package, it allows us to easily reuse any of the shared code between multiple commands.\nFor example, if we had a database driver that would write to a database (i.e. sqlite), we could easily import this driver in both cookie and eight_ball and use the code within the context of the program.\nLet\u0026rsquo;s modify now the CLI programs to import the top-level package:\n// cmd/cookie/main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ft \u0026#34;github.com/fteem/fortune_teller\u0026#34; ) func main() { rand.Seed(time.Now().Unix()) quotes := ft.Quotes() fmt.Println(quotes[rand.Intn(len(quotes))]) } // cmd/eight_ball/main.go package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ft \u0026#34;github.com/fteem/fortune_teller\u0026#34; ) func main() { rand.Seed(time.Now().Unix()) reader := bufio.NewReader(os.Stdin) answers := ft.Answers() fmt.Print(\u0026#34;What is your question? \u0026#34;) reader.ReadString(\u0026#39;\\n\u0026#39;) fmt.Println(answers[rand.Intn(len(answers))]) } It\u0026rsquo;s as simple as that. Here we purposely alias the package to ft, so we don\u0026rsquo;t have to type fortune_teller every time we want to invoke these functions. To test the commands manually, the simplest way is to install them using go install ./..., which will install all of the packages that can be found in the path (and all of it\u0026rsquo;s subpaths).\nIt works! After trying this approach out, I noticed that some other popular packages use a similar structure of building packages. For example, you can see that BoltDB places it\u0026rsquo;s command line program in a cmd/bolt path. So does packr, and other various libraries that I have noticed. So, I would safely assume that this pattern of organising your packages is clean and safe to use.\nSince you got to the end, I will assume that you would like some more reading resources around building and installing packages, and file structure organisation. I recommend you continue your journey in Go with the following links:\n How to Write Go Code Command go - Compile packages and dependencies Structuring Applications in Go - I think this is probably the origin of the structural pattern used in this article  If you would like to see the code used in this article, you can get it from my Github.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/golang-package-multiple-binaries/","summary":"Recently, while writing a small Golang program for setting reminders I came across a small confusion that I guess most newcomers to Golang will have - how to organise a package in a way that will enable it to cleanly contain two or more binaries.\nThis post is not aimed at experienced Golang programmers, it\u0026rsquo;s mostly aimed at beginners to understand how to compose more complex packages, beyond making the usual \u0026ldquo;one package one binary\u0026rdquo; ones.","title":"Packing multiple binaries in a Golang package"},{"content":"Idempotency is an often used term in computer science. It\u0026rsquo;s meaning to some might not be known, to others it\u0026rsquo;s very well known. The explanation for idempotency on Wikipedia is:\n \u0026hellip; the property of certain operations in mathematics and computer science that they can be applied multiple times without changing the result beyond the initial application.\n Essentially, idempotency is the mathematical way of saying \u0026ldquo;one can apply a certain operation on something many times, without changing the result of the operation after the first time the operation is applied\u0026rdquo;.\nA common example of this would be an UPDATE statement in SQL. For example, imagine you have a SQL table full of student\u0026rsquo;s first and last names, like in a school system. Updating a name of a student, would look like this:\nUPDATE students SET first_name = \u0026#39;John\u0026#39; WHERE id = 123; Applying this query is idempotent, because the first time you run it it will update the name of student with id 123, but if you run it a milion times more after, the result will not change - the name will still stay John.\nLet\u0026rsquo;s think a bit about APIs now. Imagine you have an API to do bank transactions, what would happen if in the middle of a API call for performing a transaction the server throws an exception and the call fails? What if the client crashes and it never receives the message? Or, what if the connection drops mid-way and the client never gets the response of the server, but the server executes the transaction?\nAs you can imagine, there can be many causes of an API call failing, but how would we know if the operation failed or it succeeded? How would we known if a transaction went through, or not?\nImagine if our APIs were smart enough so we could selectively make calls to the API idempotent?\nThe problem at hand I work in Catawiki, where we do auctions. For those not familiar with auctions - auctions are group of items (called lots) that people can bid on during a period of time. Bidding is the process of offering up a price for an item, within the aforementioned time period.\nIf you are reminded of early eBay days, that\u0026rsquo;s perfect. Knowing about how eBay used to work back in the day is enough knowledge about auctions you need for this blog post.\nSo people come to the website, they browse through the various auctions running, they view the items they would like to own and they bid on them. As you can imagine, placing a bid on an item is the most important action in an auction site and the user must know when their bid has been accepted (or not). So, what would happen if the request dies in mid-flight? Or maybe our user\u0026rsquo;s browser gets stuck, and the user tries to click multiple times on the bid button while the browser sits unresponsive.\nHow can we know if the actual bid was placed or not?\nIdempotent APIs When we are dealing with similar systems, one of the way one could tackle this problem is designing APIs that have the ability to be idempotent. Since we already established what idempotency means, idempotent APIs are APIs where any write operations can have effect only once for a given set of parameters.\nIn fact, some companies have already implemented solutions for this, and one of the better examples out there is Stripe.\nStripe\u0026rsquo;s API does that via a HTTP header, called Idempotency-Key, which is a random set of characters. An example cURL request looks like this:\ncurl https://api.stripe.com/v1/charges \\  -u sk_test_BQokikJOvBiI2HlWgH4olfQ2: \\  -H \u0026#34;Idempotency-Key: AGJ6FJMkGQIpHUTX\u0026#34; \\  -d amount=2000 \\  -d currency=usd \\  -d description=\u0026#34;Charge for Brandur\u0026#34; \\  -d customer=cus_A8Z5MHwQS7jUmZ As you can imagine, just like with bidding, designing APIs whose consumers can do actual money transactions are quite important to be very safe from various failures, especially where the sending or the receiving party cannot process the request/response fully.\nSo, how could we design and implement an idempotent API solution for our auctions website? Let\u0026rsquo;s start off by some wishful thinking.\ncurl https://api.example.com/v1/item/:item_id/bid \\  -X POST \\  -H \u0026#34;X-Auth-Token: BGT9FJMkd1Ow\u0026#34; \\  -H \u0026#34;Idempotency-Key: AGJ6FJMkGQIpHUTX\u0026#34; \\  -d amount=2000 Our API would have an endpoint, called POST /v1/item/:item_id/bid, which would create a bid for our item on auction. The request, in it\u0026rsquo;s payload, would contain the amount for the bid, and in the headers it would contain the API token and the idempotency key.\nSimple enough for a first iteration of our solution, but complicated just enough to do the trick for us.\nAdding the endpoint In our simple example auction application, we\u0026rsquo;ll have the following models (and respective associations):\nclass Auction \u0026lt; ApplicationRecord has_many :lots end class Lot \u0026lt; ApplicationRecord has_many :bids belongs_to :auction end class Bid \u0026lt; ApplicationRecord belongs_to :lot belongs_to :user validates :amount, presence: true, numericality: true end class User \u0026lt; ApplicationRecord has_many :bids end Personally, I am used to using Grape on a daily basis to build REST APIs with, so the syntax you will be seeing here will be from Grape. But the general approach and solution can be transfered to other frameworks and languages.\nOur endpoint would look something like this:\nmodule API module V1 module Lots class Bids \u0026lt; Grape::API resource :lots do route_param :lot_id do params do requires :lot_id, type: Integer, desc: \u0026#39;Lot ID\u0026#39; end resource :bids do params do requires :amount, type: Integer, desc: \u0026#39;Amount\u0026#39; end desc \u0026#39;Create a bid for a lot\u0026#39; post do lot = Lot.find(params[:lot_id]) lot.bids.create!(amount: params[:amount]) body false end end end end end end end end As you can notice, this is a very simple endpoint. It\u0026rsquo;s URI is POST /lots/:lot_id/bids, and in the request body it accepts the amount of the bid as an integer. If you would like to see how the endpoint performs, you can fetch the repo, set it up locally and play with it.\nThe first step to adding idempotency token support is to be able to easily send it. If you are using a API browser like Postman or Paw, you have that ability out of the box. These API browsers allow us to send any type of params or headers. For example, this is what a successful request to this endpoint looks like, via Postman:\nAs you can notice, we explicitly set the endpoint to return no body which will set the HTTP status to 204, therefore providing enough context if and when the bid is accepted by the system.\nThe internals of the endpoint are quite simple - we find the lot by the lot_id from the URI, and we create a Bid for it with the amount sent in the params. No magic, very simple endpoint.\nAs you can imagine, when bidding for an item on auction, every bid has to be bigger than the previous one. Therefore, adding a validation on the Bid model to do these kind of checks is required. This is what our Bid model will look like:\nclass Bid \u0026lt; ApplicationRecord belongs_to :lot validates :amount, presence: true, numericality: true validate :amount_larger_than_previous_bid private def amount_larger_than_previous_bid return true if lot.bids.none? return true if amount \u0026gt; lot.bids.last.amount errors.add(:amount, \u0026#39;must to be larger than previous bid\u0026#39;) end en In the model, the Bid#amount_larger_than_previous_bid method will do this check for us, and add the appropriate errors to the amount attribute, if needed. If we try to send another bid to the same lot from before, this is what we will get back:\nIntroducing the key Adding the key to the header, from the perspective of the client, is a very simple feat. Postman, just like any standard HTTP library, allows us to set the headers to our requests. For example, in Postman that would look like:\nThis will apply the Idempotency-Key header to the request, for our API to pick up and validate. So, how would our API accomplish this?\nIn cases like this one, I personally prefer opaque approaches, meaning, an approach that the stack can work with without any additional hassle to the daily work of the developers of the APIs. One of those approaches is by adding a middleware that will take care of logging the idempotency keys and returning the saved responses.\nBut, before we jump in to the middleware, we have to think of how we can store the headers that will be used, and the responses that will be coupled to each of these idempotency headers.\nOf course, the simplest solution that we could work with is using our database. I already feel some of you frowning at this and saying \u0026ldquo;WTF is wrong with this guy?!\u0026rdquo;. I agree, this is not even near optimal, but bear with me for the sake of the example. Let\u0026rsquo;s introduce a tiny IdempotentAction model, which will have idempotency_key, body, headers and status attributes.\nclass IdempotentAction \u0026lt; ApplicationRecord validate_presence_of :idempotency_key, :body, :status, :headers end This will do it for now. This model can store all of the idempotency keys that have been sent to the API, together with the body, status and headers of the response. Now, back to the middleware.\nWe want whenever a client of our APIs sends a request using a Idempotency-Key header to check if that key has been used (and return the saved response if so) or save a new entry to our table with idempotent requests and respond with the response of the API.\nLet\u0026rsquo;s take a look at skeleton of this middleware:\n# lib/idempotent_request.rb class IdempotentRequest IDEMPOTENCY_HEADER = \u0026#39;HTTP_IDEMPOTENCY_KEY\u0026#39;.freeze def initialize app @app = app end def call env dup._call env end def _call env idempotency_key = env[IDEMPOTENCY_HEADER] if idempotency_key.present? # Check if action has been persisted else @app.call(env) end end end This middleware will check each of the requests coming in to the application, fetch if the Idempotency-Key is present in the headers and based on that do a certain action. Let\u0026rsquo;s see what those actions will be:\nclass IdempotentRequest IDEMPOTENCY_HEADER = \u0026#39;HTTP_IDEMPOTENCY_KEY\u0026#39;.freeze def initialize app @app = app end def call env dup._call env end def _call env idempotency_key = env[IDEMPOTENCY_HEADER] if idempotency_key.present? action = IdempotentAction.find_by(idempotency_key: idempotency_key) if action.present? status = action.status headers = Oj.load(action.headers) body = Oj.load(action.body) else status, headers, response = @app.call(env) response = response.body if response.respond_to?(:body) IdempotentAction.create( idempotency_key: idempotency_key, body: Oj.dump(response), status: status, headers: Oj.dump(headers) ) end [status, headers, body] else @app.call(env) end end end If the header is present in the request, we will query the database for and check if there\u0026rsquo;s a IdempotentAction entry present. If it is, the middleware will stop any futher execution in the middleware stack (a.k.a. the rest of the application) and will immediatelly respond with the saved body, status and headers.\nOtherwise, it will make sure it proceeds with the chain of execution, and after all of the request is fulfilled it will store the body, status and headers in a IdempontentAction entry in the database. By doing that any subsequent request using the same Idempotency-Key header will result in the previous response, regardless of the body, URI or params of the request.\nMounting this middleware is as easy as adding this line to the application\u0026rsquo;s config/application.rb file:\nmodule MyApp class Application \u0026lt; Rails::Application # snipped config.middleware.use IdempotentRequest end end Now, if we send a request to our endpoint to create a bid for a lot, with an Idempotency-Key header, in our server logs we will see something like:\nStarted POST \u0026#34;/lots/99/bids\u0026#34; for 127.0.0.1 at 2017-10-28 01:19:35 +0200 IdempotentAction Load (0.2ms) SELECT \u0026#34;idempotent_actions\u0026#34;.* FROM \u0026#34;idempotent_actions\u0026#34; WHERE \u0026#34;idempotent_actions\u0026#34;.\u0026#34;idempotency_key\u0026#34; = ? LIMIT ? [[\u0026#34;idempotency_key\u0026#34;, \u0026#34;5d41d8cd98f00b204e9800998ecf84272\u0026#34;], [\u0026#34;LIMIT\u0026#34;, 1]] Lot Load (0.1ms) SELECT \u0026#34;lots\u0026#34;.* FROM \u0026#34;lots\u0026#34; WHERE \u0026#34;lots\u0026#34;.\u0026#34;id\u0026#34; = ? LIMIT ? [[\u0026#34;id\u0026#34;, 99], [\u0026#34;LIMIT\u0026#34;, 1]] (0.1ms) begin transaction Bid Exists (0.3ms) SELECT 1 AS one FROM \u0026#34;bids\u0026#34; WHERE \u0026#34;bids\u0026#34;.\u0026#34;lot_id\u0026#34; = ? LIMIT ? [[\u0026#34;lot_id\u0026#34;, 99], [\u0026#34;LIMIT\u0026#34;, 1]] Bid Load (0.2ms) SELECT \u0026#34;bids\u0026#34;.* FROM \u0026#34;bids\u0026#34; WHERE \u0026#34;bids\u0026#34;.\u0026#34;lot_id\u0026#34; = ? ORDER BY \u0026#34;bids\u0026#34;.\u0026#34;id\u0026#34; DESC LIMIT ? [[\u0026#34;lot_id\u0026#34;, 99], [\u0026#34;LIMIT\u0026#34;, 1]] SQL (0.4ms) INSERT INTO \u0026#34;bids\u0026#34; (\u0026#34;lot_id\u0026#34;, \u0026#34;amount\u0026#34;, \u0026#34;created_at\u0026#34;, \u0026#34;updated_at\u0026#34;) VALUES (?, ?, ?, ?) [[\u0026#34;lot_id\u0026#34;, 99], [\u0026#34;amount\u0026#34;, 153], [\u0026#34;created_at\u0026#34;, \u0026#34;2017-10-27 23:19:35.787067\u0026#34;], [\u0026#34;updated_at\u0026#34;, \u0026#34;2017-10-27 23:19:35.787067\u0026#34;]] (1.0ms) commit transaction (0.1ms) begin transaction SQL (0.6ms) INSERT INTO \u0026#34;idempotent_actions\u0026#34; (\u0026#34;idempotency_key\u0026#34;, \u0026#34;body\u0026#34;, \u0026#34;status\u0026#34;, \u0026#34;headers\u0026#34;, \u0026#34;created_at\u0026#34;, \u0026#34;updated_at\u0026#34;) VALUES (?, ?, ?, ?, ?, ?) [[\u0026#34;idempotency_key\u0026#34;, \u0026#34;5d41d8cd98f00b204e9800998ecf84272\u0026#34;], [\u0026#34;body\u0026#34;, \u0026#34;[\\\u0026#34;\\\u0026#34;]\u0026#34;], [\u0026#34;status\u0026#34;, 204], [\u0026#34;headers\u0026#34;, \u0026#34;{}\u0026#34;], [\u0026#34;created_at\u0026#34;, \u0026#34;2017-10-27 23:19:35.792024\u0026#34;], [\u0026#34;updated_at\u0026#34;, \u0026#34;2017-10-27 23:19:35.792024\u0026#34;]] (1.0ms) commit transaction As you can tell, the middleware kicks in, picks up the header value and checks for a possible entry in the IdempotentAction model. Then, it proceeds with the exectuion of the request, and afterwards it persists the response with the key in the table. Any subsequent request with the same Idempotency-Key will produce a log like:\nStarted POST \u0026#34;/lots/99/bids\u0026#34; for 127.0.0.1 at 2017-10-28 01:22:09 +0200 IdempotentAction Load (0.2ms) SELECT \u0026#34;idempotent_actions\u0026#34;.* FROM \u0026#34;idempotent_actions\u0026#34; WHERE \u0026#34;idempotent_actions\u0026#34;.\u0026#34;idempotency_key\u0026#34; = ? LIMIT ? [[\u0026#34;idempotency_key\u0026#34;, \u0026#34;5d41d8cd98f00b204e9800998ecf84272\u0026#34;], [\u0026#34;LIMIT\u0026#34;, 1]] That\u0026rsquo;s it! The middleware will pick up the record from the database and it will send the response immediatelly.\nAlthough the idempotent requests mechanism is interesting, keeping all of these keys can be expensive, especially if you do it in an nonoptimal way like by using the database. Whenever you are in doubt if data like this should be stored in a database, always think about how crucial to your business this data is. For the scope of our example, this data is not business critical, therefore we could offload it to a different type of storage.\nWhat would be a cheap way of storing these idempotency keys?\nSwapping the storage A very cheap way of persisting these keys is, believe it or not, by putting them (programatically) in a file. Ruby as a language provides couple of key-value store solutions, like PStore and YAML::Store. I personally prefer YAML::Store because it would allow us to read the contents of the file it writes to, unlike PStore which writes the files in binary format.\nIf you\u0026rsquo;ve never used YAML::Store, think of it as a streamlined approach to writing/reading to a file using YAML. Let\u0026rsquo;s briefly open an irb session and play a little bit with YAML::Store:\n\u0026gt;\u0026gt; require \u0026#39;yaml/store\u0026#39; =\u0026gt; true # Open a new store \u0026gt;\u0026gt; store = YAML::Store.new(\u0026#39;file_to_write_in.yml\u0026#39;) =\u0026gt; #\u0026lt;Psych::Store:0x007fbf83d3e0d8 @opt={}, @filename=\u0026#34;file_to_write_in.yml\u0026#34;, @abort=false, @ultra_safe=false, @thread_safe={}, @lock=#\u0026lt;Thread::Mutex:0x007fbf83d3de30\u0026gt;\u0026gt; # Write something to the store \u0026gt;\u0026gt; store.transaction { store[\u0026#39;name\u0026#39;] = \u0026#39;Ilija Eftimov\u0026#39; } =\u0026gt; \u0026#34;Ilija Eftimov\u0026#34; # Read something from the store \u0026gt;\u0026gt; store.transaction(false) { store[\u0026#39;name\u0026#39;] } =\u0026gt; \u0026#34;Ilija Eftimov\u0026#34; Now, if we check our file where our store is writing to, we will see something like:\n--- name: Ilija Eftimov YAML is super flexible and will know how to marshall different type of objects into YAML. Also, when you want to read from the store, it will unmarshall them back and create objects with their properties.\nAfter that quick crash course in YAML::Store, let\u0026rsquo;s get back to our middlware. This is what it would look like, if we use YAML::Store as a storage engine:\nrequire \u0026#39;yaml/store\u0026#39; class IdempotentRequest IDEMPOTENCY_HEADER = \u0026#39;HTTP_IDEMPOTENCY_KEY\u0026#39;.freeze STORE_FILE_PATH = \u0026#39;idempotency_keys.store\u0026#39;.freeze attr_reader :store def initialize app @app = app @store = YAML::Store.new(Rails.root.join(STORE_FILE_PATH)) end def call env dup._call env end def _call env idempotency_key = env[IDEMPOTENCY_HEADER] if idempotency_key.present? action = store.transaction(false) { store[idempotency_key] } if action.present? status = action[:status] headers = action[:headers] response = action[:response] else status, headers, response = @app.call(env) response = response.body if response.respond_to?(:body) store.transaction do store[idempotency_key] = { status: status, headers: headers.to_h, response: response } end end [status, headers, response] else @app.call(env) end end end Compared to our database solution, the YAML::Store solution is a bit simpler, and more lightweight. As you can notice, the approach is the same - we check if our store already has the idempotency key persisted, and if so we return the saved status, headers and response. Otherwise, we let the middleware chain finish executing, and then we persist the idempotency key with the response data to the store.\nAs with any other solution, this approach has couple of pros and cons. As you can imagine, saving this data to a file is not really reliable. Backing up the file, although it seems simple, it can be quite error prone compared to the already provided solutions to backing up databases. Also the more traffic our service gets, the disk I/O would increase quite a bit, therefore the solution would not scale too far into the future.\nOn the other hand, this solution has no dependency on a database, nor on Active Record. It does have a dependency on YAML::Store, but that one is much cheaper to load to your application because it doesn\u0026rsquo;t have other dependencies that it needs to run (except YAML, which is already loaded by default in your Rails apps). From a code perspective, it\u0026rsquo;s very simple - it feels like saving to a hash that automatically gets dumped onto disk. It requires no additional models, schemas or migrations.\nExpiring the keys Whenever we store this type of data, a good idea is to clean up the used keys after a certain period of time, because the responses that they have stored are already stale and unusable for the clients. Therefore, cleaning this from a relational database or a YAML file will require custom solution, for example, in the form of a scheduled job that would scrape off all the stale keys. Or maybe in another way, still by adding more and more code to our codebase that we would need to maintain.\nOr, we could change our storage, again?\nWhen it comes to storing keys with values the most popular choice (with a good reason!) is Redis. It is riddiculously fast in what it does, writing and reading to it with Ruby is very simple, and it even provides a TTL (Time To Live) which means it will automatically expire our stale keys without us writing a single line of code. Of course, Redis provides much more, but for the purpose of this article, it seems to fit just like a glove.\nNote: If you are unfamiliar with Redis, I would recommend giving a shot at their interactive course to get yourself faimilar with the basics of Redis.\nConnecting to Redis To communicate with Redis via a Rails app, we need to add the redis gem to our bundle. After installing the gem via bundle install, we can immediatelly connect to our local Redis instance without any special configurations. If you are following this tutorial, but haven\u0026rsquo;t installed Redis yet, you can go over to their download page and install it from there.\nIf you are running OSX, you can install it via Homebrew by installing the redis formula.\nHaving Redis running locally, and the redis gem in our app\u0026rsquo;s bundle, we can proceed to update our middleware to work with Redis.\nOrganizing and storing the data We can store our keys in a hash structure, where the key will be the idempotency key, and the value in the hash will be a serialized hash that will contain the status, headers and body of the response. For example:\n# Key : Serialied Hash \u0026#34;1753ae4677\u0026#34;: \u0026#34;{\\\u0026#34;status\\\u0026#34;:204,\\\u0026#34;headers\\\u0026#34;:{},\\\u0026#34;response\\\u0026#34;:[\\\u0026#34;\\\u0026#34;]}\u0026#34; \u0026#34;d3894c01c0\u0026#34;: \u0026#34;{\\\u0026#34;status\\\u0026#34;:422,\\\u0026#34;headers\\\u0026#34;:{\\\u0026#34;Content-Type\\\u0026#34;:\\\u0026#34;text/plain\\\u0026#34;,\\\u0026#34;Content-Length\\\u0026#34;:\\\u0026#34;85\\\u0026#34;},\\\u0026#34;response\\\u0026#34;:[\\\u0026#34;{\\\\\\\u0026#34;status\\\\\\\u0026#34;:422,\\\\\\\u0026#34;error\\\\\\\u0026#34;:\\\\\\\u0026#34;Validation failed: Amount has to be larger then previous bid\\\\\\\u0026#34;}\\\u0026#34;]}\u0026#34; As you can see, both the key and the value are strings, where the value is the JSON serialized hash of the data we need. If you are wondering why JSON - it\u0026rsquo;s because serializing is very fast (with Oj) and it\u0026rsquo;s (somewhat) readable when it\u0026rsquo;s serialized therefore easy to access in Redis and explore/debug.\nLet\u0026rsquo;s modify our middleware to work with Redis:\nmodule IdempotentRequest IDEMPOTENCY_HEADER = \u0026#39;HTTP_IDEMPOTENCY_KEY\u0026#39;.freeze REDIS_NAMESPACE = \u0026#39;idempotency_keys\u0026#39;.freeze attr_reader :redis def initialize app @app = app @redis = ::Redis.current end def call env dup._call env end def _call env idempotency_key = env[IDEMPOTENCY_HEADER] if idempotency_key.present? action = get(idempotency_key) if action.present? status = action[:status] headers = action[:headers] response = action[:response] else status, headers, response = @app.call(env) response = response.body if response.respond_to?(:body) payload = payload(status, headers, response) set(idempotency_key, payload) end [status, headers, response] else @app.call(env) end end private def get(key) data = redis.hgetall namespaced_key(key) return nil if data.blank? { status: data[\u0026#39;status\u0026#39;], headers: Oj.load(data[\u0026#39;headers\u0026#39;]), response: Oj.load(data[\u0026#39;response\u0026#39;]) } end def set(key, payload) redis.hmset namespaced_key(key), *payload end def payload(status, headers, response) [ :status, status, :headers, Oj.dump(headers.to_h), :response, Oj.dump(response) ] end def namespaced_key(idempotency_key) \u0026#34;#{REDIS_NAMESPACE}:#{idempotency_key}\u0026#34; end end If you\u0026rsquo;ve been reading the code so far in our previous solutions, the approach is literally the same, only the way we store and read the data changes, from both storage and code perspective. This time, we use Oj.dump to serialize and Oj.load to deserialize our object to/from JSON. Also, storing the data is done by calling the redis client, namely the hmset and hget methods.\nredis.hget REDIS_NAMESPACE, key hget will execute a HGET command in Redis, which will get the hash that is stored under the REDIS_NAMESPACE value (in our case idempotency_keys), and will access the key with the value of key. If present, this will retrieve the serialized JSON object, or nil if not present.\nredis.hmset REDIS_NAMESPACE, key1, payload1, key2, payload2 hmset will execute a HMSET command in Redis, which will set a new key in the hash, where the key will be the value of key1, and the value will be the hash that payload1 is assigned to. The same key - value pair arguments scheme continues for the rest of the arguments.\nTTL One of the great features of Redis are called \u0026ldquo;Redis expires\u0026rdquo;. What that means is that basically you can set a timeout for a key, which is a limited time to live (TTL). When the time to live elapses, the key is automatically destroyed.\nSo, how can we leverage Redis expires to our advantage? Well, the first question that would pop up in my mind is for how long do we want to keep these keys/responses in our database? Ideally, the answer to this question is: short. Although this mechanism of saving the data can be very useful, if the data is not expired after a certiain period of time, you are looking at an unneeded complexity from data warehousing, security and scaling pespective. Also, most of the data that will not be expired will be stale, because it will be relevant until the client understands that the idempotent request has been fulfilled and will move on with it\u0026rsquo;s operations.\nTherefore, adding a TTL on the key is not a silver bullet, but for most of the cases it\u0026rsquo;s a very good idea. Let\u0026rsquo;s see how we can update our middleware to set the correct TTL on the Redis keys:\nmodule IdempotentRequest IDEMPOTENCY_HEADER = \u0026#39;HTTP_IDEMPOTENCY_KEY\u0026#39;.freeze REDIS_NAMESPACE = \u0026#39;idempotency_keys\u0026#39;.freeze EXPIRE_TIME = 1.day.to_i attr_reader :redis def initialize app @app = app @redis = ::Redis.current end def call env dup._call env end def _call env idempotency_key = env[IDEMPOTENCY_HEADER] if idempotency_key.present? action = get(idempotency_key) if action.present? status = action[:status] headers = action[:headers] response = action[:response] else status, headers, response = @app.call(env) response = response.body if response.respond_to?(:body) payload = payload(status, headers, response) set(idempotency_key, payload) end [status, headers, response] else @app.call(env) end end private def get(key) data = redis.hgetall namespaced_key(key) return nil if data.blank? { status: data[\u0026#39;status\u0026#39;], headers: Oj.load(data[\u0026#39;headers\u0026#39;]), response: Oj.load(data[\u0026#39;response\u0026#39;]) } end def set(key, payload) redis.hmset namespaced_key(key), *payload redis.expire namespaced_key(key), EXPIRE_TIME end def payload(status, headers, response) [ :status, status, :headers, Oj.dump(headers.to_h), :response, Oj.dump(response) ] end def namespaced_key(idempotency_key) \u0026#34;#{REDIS_NAMESPACE}:#{idempotency_key}\u0026#34; end end Let me save you from the trouble of reading the code and finding the differences - we added only the redis.expire expire call after setting the value of the key in the set method. The expire method takes two arguments - the first one is the key and the second one is the expiry time (in seconds). Our code will set these keys to expire after 24 hours from the time of setting them, therefore allowing enough time for the requests to be registered as completed by the clients.\nOf course, if you are implementing a mechanism for idempotent requests for your APIs, the expiration time should be set to your liking, because the data should have a retention period that makes sense for the problem you are solving/facing.\nNevertheless, although our final solution is not very far from our previous ones, whether it\u0026rsquo;s using a relational databse or a storage in file, Redis allows us to more easily scale the solution while keeping itself clean from stale data.\nWrapping up Having all of this in mind, it\u0026rsquo;s clear to see that idempotent requests can be a useful addition to an API, especially where the nature of the API requires such behaviour. For example, Stripe have idempotent requests for their API , because they are working with payments and this sort of mechanism can be useful for clients to not accidentally replay a charge of a card because of a network issue. Also, in our example, idempotent requests can be useful because you don\u0026rsquo;t want the client to try to set the same bid twice, due to the nature of an auction (very time sensitive).\nIn this post we also saw three type of solutions that could work for a mechanism like this one, namely:\n using a relational database; using a YAML::Store; and using Redis  We also briefly discussed what kind of challenges each of these approaches bring, and we also took a stab at implementing the idempotent requests mechanism using a Rails middleware.\nIf you would like to see the actual code of this Rails app, and the middleware we built, you can head over to the sample repo on Github, fetch the code and play with it yourself.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/understand-how-why-add-idempotent-requests-api/","summary":"Idempotency is an often used term in computer science. It\u0026rsquo;s meaning to some might not be known, to others it\u0026rsquo;s very well known. The explanation for idempotency on Wikipedia is:\n \u0026hellip; the property of certain operations in mathematics and computer science that they can be applied multiple times without changing the result beyond the initial application.\n Essentially, idempotency is the mathematical way of saying \u0026ldquo;one can apply a certain operation on something many times, without changing the result of the operation after the first time the operation is applied\u0026rdquo;.","title":"Understanding why and how to add idempotent requests to your APIs"},{"content":"Nowadays, having an API on top of your application is considered common. I\u0026rsquo;ve often been disapointed when I\u0026rsquo;ve been expecting an API of a product I like to find none. There are powerful tools out there that allow easy API integrations, like IFTTT.com. Also, if you want to build a mobile application to work aside your product (or maybe your product is mobile-first), then an API is a must-have - there’s no way around it.\nAlthough APIs are so widespread today, designing, maintaining and expanding them hasn’t become less hard than ever before. Just today, your APIs are expected to work properly, be well designed and documented. So, basically, I believe that the tools haven’t caught up with the expectation of the market - APIs are a must-have, but building them is as hard as ever.\nFor one to build a great API, whether it’s a shiny GraphQL or a RESTful one, the first thing that we need to understand is versioning. Let’s take a dive at this often underestimated aspect of all APIs, and expand our knowledge about it.\nWhat is versioning? Imagine this: you work for a product company, like Twitter. As you can imagine, Twitter provides an API where it’s content can be consumed through. Having millions of users, Twitter normally would like to enable other developers to use their platform and build add-ons or products on top of their APIs.\nAs the product advances and gets newer features, and the old ones get updated, some of the changes that occur to the product might be breaking to some of the consumers of the APIs. So, that becomes a problem - if you do the breaking change a large number of integrations with the API will break. On the other hand, the product must keep on evolving and you simply cannot just stop development because you are scared you will break other’s people apps that consume your APIs.\nAs you can imagine, the best way to approach this is to apply API versioning. That means, when you want to introduce a breaking change to your API, you will have to add a new version of the API, so people that want to use the changed feature can use (for example) version two of the API, while version one will stay intact (but will probably become deprecated). Therefore, you will keep backwards compatibility for other consumers of the old API, while advancing the product.\nVersioning strategies Having said that, let’s look at some strategies of API versioning. Over the years, as we’ve been building APIs, people have invented different ways to version their APIs. One of the most popular are the following:\n Media type versioning Header URI Domain Parameter versioning  Let’s take a look at a quick example of each of them, and how we can implement them using Ruby.\nMedia type versioning This type of versioning is also known as \u0026ldquo;content negotiation\u0026rdquo; or \u0026ldquo;accept header\u0026rdquo;. It basically utilises the Accept media header to specify the version of the API where the request should be processed. For example, it usually looks something like this:\nAccept: application/vnd.mycompany.api+json; version=1.0 This is called a \u0026ldquo;vendor header\u0026rdquo; (hence the vnd in the header name). It supplies the name of the API, the negotiated content type and the version of the API.\nOne of it’s good sides is that you can version the API at the resource level, which will allow you to preserve your URIs between versions and get the resource representation/behaviour based on the negotiated version. On the other hand, exploring is much harder, since just a browser won’t cut it. Additionally, the HTTP headers get distorted to fit in the versioning in them. This makes the clients know the media type for each resource, and hence they need to request the same media type throughout their use of the API, to make sure the integration works normally at all times.\nHeader versioning Another way of versioning APIs is through HTTP headers, usually custom ones. In the wild you can see many variations of this type of versioning, but they all revolve around a common theme - there’s a custom header that controls the versioning for the request lifecycle. By convention, custom HTTP headers are prefixed with X, like X-Custom-Header. When it comes to versioning, you can often see X-API-Version or X-Version.\nThe one very good side about this versioning is that you can preserve all the URIs between versions, because the headers are transparent to the URI.\nURI Versioning URI versioning is achieved by, obviously, specifying the API version in the URI. You have probably seen this type of versioning if you’ve ever worked with a vendor API, like Facebook’s or Twitter’s. It is achieved by adding the version in the URI, like:\nhttps://example.com/api/v1/users Usually the versioning is in the form of vX, where v represents version and X is the version number.\nWhile this type of versioning breaks the RESTfulness of the APIs, since each URI should be a resource and not a version, on the other hand it’s the most widely used type of versioning. It’s very easy to browse an API (and it’s versions) through a browser and it’s dead simple to use.\nDomain versioning This type of versioning can be considered a sub-type of the previous, URI based, versioning. It’s quite simple, and it allows easy routing through the infrastructure where the API is hosted, since subdomains are very easy to configure.\nIt usually looks like:\nv1.api.example.net/users Parameter versioning Parameter versioning is achieved by setting a parameter in the request to use the appropriate API version. For example, this can be done as:\nGET example.net/api/users?version=1 As you can imagine, unlike the previous versioning strategies, the parameter can be left out and the server should know to what version to default to.\nNow, on the other hand, although this can allow you to version the resources easily, if you throw in API versioning as well, things can easily get out of hand. That’s why, people like to version their APIs, usually, via the URI or the headers.\nShow me the code Now that we’ve depleted most of the popular API version strategies, let’s see how we can actually implement them. For the purpose of these examples, we’ll be using Grape API, one of the most popular API DSLs for the Ruby programming language.\nLet\u0026rsquo;s imagine that we have a very simple API endpoint, which will fetch a single user, with a URI GET /user/:id.\nmodule API class Users \u0026lt; Grape::API resource :users do route_param :id do get do User.find(params[:id]) end end end end end Media-type versioning Implementing this type of versioning is rather easy. For example, let\u0026rsquo;s say our company is called \u0026lsquo;BarCo\u0026rsquo;, so we want to make our Accept header look like:\nAccept: application/vnd.barco-v1+json So, how can we implement this quickly, using a before hook that will be executed before any request to our API?\nmodule API module V1 VENDOR = \u0026#39;barco\u0026#39;.freeze VERSION = \u0026#39;v1\u0026#39;.freeze HEADER = \u0026#39;application/vnd.#{API::VENDOR}-#{API::VERSION}+json\u0026#39;.freeze before do error!(\u0026#39;Not found\u0026#39;, 404) unless headers[\u0026#39;Accept\u0026#39;] == HEADER end end end So, before every request comes in, the before hook will validate the Accept header of the request and will raise a HTTP 404 if it cannot find the appropriate API version.\nAs you can see, this example to header based versioning is quite simple and rudimentary, but lucky for us Grape has a built-in strategy for header versioning so we don\u0026rsquo;t have to reinvent the wheel every time we write an API.\nTo do the same, Grape has the Header versioning, and it easy to plug it in your API, like:\nmodule API class Users \u0026lt; Grape::API version \u0026#39;v1\u0026#39;, using: :header, vendor: \u0026#39;barco\u0026#39; resource :users do route_param :id do get do User.find(params[:id]) end end end end end Just by adding the version line in the class, Grape will version this resource for us and will expect the appropriate header to be provided to the request.\nHeader versioning Similarly to our previous approach, we could version our API using custom header versioning. As an example, the API could require the following header:\nX-API-Version: 1 So, using Grape\u0026rsquo;s before hooks, we could write something like:\nmodule API module V1 VERSION = \u0026#39;1\u0026#39;.freeze HEADER = \u0026#39;X-API-Version\u0026#39;.freeze before do return respond_with_404 unless headers.key?(HEADER) return respond_with_404 unless headers[HEADER] == VERSION end def respond_with_404 error!(\u0026#39;Not found\u0026#39;, 404) end end end This before hook will check for the presence of a header in the request headers, and for the value of the header if it exists. Then it will respond with and error if any of the two requirements are not met.\nEasy enough, right? Well, sure, but again, our example is a bit rudimentary and it won\u0026rsquo;t work that elegantly. But fear not - Grape has our backs, again!\nGrape implements the Accept-Version Header strategy, which will accept the following versioning header:\nAccept-Version: v1 Plugging it into the API is also very trivial, just like before:\nmodule API class Users \u0026lt; Grape::API version \u0026#39;v1\u0026#39;, using: :accept_version_header resource :users do route_param :id do get do User.find(params[:id]) end end end end end That\u0026rsquo;s it, versioning with minimal footprint.\nURI Versioning Implementing URI versioining is a bit more involved to do manually in Grape, because it involves basically rewriting the URI that is requested and invoking the proper endpoint based on pieces of the URI.\nThe good thing is that we don\u0026rsquo;t have to do that manually as well, since Grape provides an out-of-the-box solution for URI versioning as well:\nmodule API class Users \u0026lt; Grape::API version \u0026#39;v1\u0026#39;, using: :path resource :users do route_param :id do get do User.find(params[:id]) end end end end end Parameter versioning Just like our previous approaches, we could version our API using a parameter. As an example, the API could require this parameter:\nhttps://example.net/users?v=1 So, using Grape\u0026rsquo;s before hooks, we could write something like:\nmodule API module V1 VERSION = \u0026#39;1\u0026#39;.freeze PARAM = \u0026#39;v\u0026#39;.freeze before do return respond_with_404 unless params.key?(PARAM) return respond_with_404 unless params[PARAM] == VERSION end def respond_with_404 error!(\u0026#39;Not found\u0026#39;, 404) end end end This before hook will check for the presence of a param in the request, and for the value of the param if it exists. Then it will respond with and error if any of the two requirements are not met.\nEasy enough, right? Again, our example is rudimentary. You guessed it - Grape has our backs, again and again.\nGrape implements the Param versioning strategy, which work very similarly, but with a very small footprint:\nmodule API class Users \u0026lt; Grape::API version \u0026#39;1\u0026#39;, using: :param, parameter: \u0026#39;v\u0026#39; resource :users do route_param :id do get do User.find(params[:id]) end end end end end Rolling your own v.s. using built-in strategy In our examples, although quite small, we saw how you could roll out your own versioning strategy. Whichever strategy you pick, I recommend first knowing the differences between all of them so you can do a educated pick instead of blindly following a podcast or a tutorial or a blog post (like this one).\nWhen it comes to rolling your own, I recommend against it. Gems like Grape, that we explored briefly in this post, have perfected these versioning strategies and if you roll your own you can expose your API to various vulnerabilities or bugs.\nOf course, if you still need to do it yourself, or your company uses some custom or non-standard versioining strategy, I recommend looking at what the community has already done. For example, you can see all of Grape\u0026rsquo;s versioning middleware in their Github repo and see how they\u0026rsquo;ve implemented it. The code is quite clean and straightforward.\nIn closing In this post we saw what API versioning means, what are the various versioning strategies, and how we could do it ourselves. Also, we saw how one of the most popular REST API DSLs for Ruby do it. I strongly recommend checking out the source code of Grape\u0026rsquo;s versioning middleware, so you can get a good grasp of how this is actually done under the hood.\nAlso, it\u0026rsquo;s always smart to look at the big players in the field and learn from their experiences. For example, you can take a look at Facebook\u0026rsquo;s Graph API documentation, Github\u0026rsquo;s API documentation or Stripe\u0026rsquo;s API documentation. They\u0026rsquo;ve done a tremendous job documenting their API\u0026rsquo;s. Also, you can see how Stripe uses a custom header versioining, in combination with dates - it\u0026rsquo;s quite interesting.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/versioning-ruby-grape-apis/","summary":"Nowadays, having an API on top of your application is considered common. I\u0026rsquo;ve often been disapointed when I\u0026rsquo;ve been expecting an API of a product I like to find none. There are powerful tools out there that allow easy API integrations, like IFTTT.com. Also, if you want to build a mobile application to work aside your product (or maybe your product is mobile-first), then an API is a must-have - there’s no way around it.","title":"Versioning REST APIs: The Theory and Using Grape in Ruby"},{"content":"Have you ever found yourself publishing an API, either an internal or a public one? Have your ever heard from the consumers of those same APIs back? Are they happy about the functionality of your APIs and their design? You already know, there is no perfect design, but API design has to be taken very seriously. Why? Because evolving and changing APIS is hard and time consuming.\nImagine you are on a team in a company, that has set off to design a company-wide API guideline and a blueprint. As you could imagine, a feat like this one takes time - first you have to put in a draft, then let it settle like a fine French wine, then review it and apply any needed changes. And repeat over, until you have a team wide consensus on the design.\nIn situations like this, I have found interesting how your API should behave when a resource is DELETEd? Of course, aside from the obvious, that the record will be deleted.\nLet\u0026rsquo;s look at couple of points that might be a good food for thought in these occasions.\nIdempotency We have all heard about idempotency and we have heard that all calls to a REST API should be idempotent, except the POST requests. But, what does this mean?\nCrickets sound onFrom Wikipedia:\n Idempotence is the property of certain operations in mathematics and computer science, that can be applied multiple times without changing the result beyond the initial application.\n Crickets sound offSimply put, a call to an idempotent endpoint with a given set of parmeters, should always have the same effect. For example, if you have a User resource, everytime you call PUT /users/1 should have the same effect on the resource. Also, a GET /users/1 is a safe method (or nullipotent), because it does not have any effect on the state of the resource.\nBut, is DELETE idempotent? According to the HTTP specification DELETE should be idempotent.\n+---------+------+------------+ | Method | Safe | Idempotent | +---------+------+------------+ | CONNECT | no | no | | DELETE | no | yes | | GET | yes | yes | | HEAD | yes | yes | | OPTIONS | yes | yes | | POST | no | no | | PUT | no | yes | | TRACE | yes | yes | +---------+------+------------+ This means that whenever a DELETE request is sent, the state of the system after fulfilling the request will always be the same, although the server might implement non-idempotent effects under the hood.\nSo, knowing that a DELETE request will always be idempotent, what should a response of that request be? Let\u0026rsquo;s start from the basics, the status code.\nHTTP status codes We usually take HTTP status codes as an ever-present thing slapped onto a HTTP request. Especially if you are a beginner, understanding how useful status codes are and how much context they can provide for free, can be hard.\nAfter executing any HTTP request, the HTTP code that will be returned is always contextual, which means, it should be based on the effect (and hence the result) of the request. Keeping in mind that a DELETE request is idempotent, what would be an appropriate status code?\nLet\u0026rsquo;s look at some status codes that make sense as a response for a DELETE request:\nHTTP 204 - No content:\n The server has successfully fulfilled the request and that there is no additional content to send in the response payload body.\n HTTP 204 would work - the server has accepted your DELETE request and it has fulfilled it. The server will not return a payload in the response, hence 204 No content.\nHTTP 202 - Accepted:\n The request has been accepted for processing, but the processing has not been completed. The request might or might not eventually be acted upon, as it might be disallowed when processing actually takes place.\n You tell the server to destroy the resource that the URI points to, but since it\u0026rsquo;s a long procedure (maybe a background job) to delete the resource, it returns a HTTP 202 Accepted. This means that the server basically says \u0026ldquo;Cool, I understand, I am on it!\u0026rdquo;. But, it does not mean that the resource is deleted as part of the request/response cycle.\nHTTP 200 OK:\n The request has succeeded.\n The server received your request and responds with 200 OK - which means that it understood your request and deletes the resource described by the URI.\nYou can notice that all of the status codes are closely tied to the response that the API call will return. So, let\u0026rsquo;s talk about the HTTP status codes in combination with some response payloads.\nSending a meaningful response You send a DELETE and the server complies. It executes the logic related to the endpoint and the HTTP verb and deletes the record that you wanted gone. So, how does it respond back?\nFirst scenario would be - no response body with HTTP 204. Makes sense. But what would this actually mean? Well let\u0026rsquo;s say you have a Rails API that returns hypermedia controls in the JSON API spec format. When it returns a resource it will also return the URIs of the associated resources. When you delete a record, it will perish from the database - but if you have a dependent: :destroy in your model, it would remove associated records as well. In this occasion, your client would not know if anything else got removed in the same request-response lifecycle.\nAnother option would be a HTTP 200 OK - but as we saw earlier, 200 OK states that you must return a body in the response. In the HTTP spec, we can see the following:\n The 200 (OK) status code indicates that the request has succeeded. The payload sent in a 200 response depends on the request method. For the methods defined by this specification, the intended meaning of the payload can be summarized as:\n PUT, DELETE a representation of the status of the action   This means that, according to the HTTP spec the response body has to be a representation of the status of the action. In other words, it needs to send back the representation of the resource that has been deleted as a result of the request. But, if we do that, we will add an additional load on the endpoint, because it will need to serialize the deleted resource, and as we all know serialization is expensive.\nA third option would be HTTP 204 - Accepted. But as we saw earlier, Accepted as a status code is very contextual on the action under the hood. It can only be returned if the request has been accepted, but the action has not been put into effect yet.\nWhoa, okay, so where now?\nAre we overthinking it? Just like in most of the cases where computer science and engineering is involved - it depends. You could say that it\u0026rsquo;s easy to keep all of this simple, but often we have to be careful. After all, we don\u0026rsquo;t want to be lazy and oversimplify our APIs.\nLet\u0026rsquo;s take a tiny example - an API for a blog CMS. We will look at a resource, namely the /authors resource. This means that, we will have the following endpoints available:\nGET /authors # returns a collection of authors GET /authors/:id # returns an author with the ID of :id POST /authors # create an author PUT /authors/:id # create/update an author DELETE /authors/:id # destroy an author So, we are interested in the behaviour of the last endpoint, DELETE /authors/:id. When a request is succesfully fulfilled on this endpoint, the record which was identified by the :id param is destroyed. Since the request is idempotent, it means that you can freely request to delete a resource multiple times, but the effect on the system will be the same - the resource will not be present.\nIn most of the cases, the REST APIs that we use are level 3. This means that usually we have couple of options on how to respond to this request, HTTP 204, or HTTP 200, which we already discussed at the begining of this article. But, what happens if you are building a level 4 REST API?\nHandling the state in the client If you have a hypermedia API, things can get a little bit more complex. For those of you that don\u0026rsquo;t know what hypermedia APIs, I recommend reading my previous article about REST APIs - \u0026ldquo;Sprinkle some HATEOAS on your Rails APIs\u0026rdquo;. It covers all of Fielding\u0026rsquo;s REST levels and explains them thoroughly. After you get a grasp of hypermedia APIs, you can come back to this to more easily understand the issue at hand.\nHypermedia clients usually have to be a little bit smarter, due to the fact that the APIs they use are smarter. This means that when we update the state of the hypermedia API\u0026rsquo;s system, the client should be aware of the state change. In more concrete wording - when we delete a resource, the client must know that the resource does not exist anymore on the server side.\nWhat does that mean for our API? Well, remember the DELETE /authors/:id endpoint? If a request to that endpoint returns an HTTP 204 (which explicitly states that the reponse body is empty), then our clients need to know that the nested resources might be deleted because there might bea cascading delete.\nFor example, if the DELETE /authors/:id request also removes all of the posts that were written by an author, the client might still think that the posts are available. This means that the client will allow a request to GET /authors/:id/posts/, and the API needs to know to respond with an appropriate response and HTTP status. But, will any of the aforementioned statuses cut it in this case? You might think that even HTTP 404 would do it, but is it semantically correct?\nSure, HTTP 404 states that the resource is not found, but in cases like this we actually want to inform the consumer that there was something there before, but not anymore. This means that the best HTTP status code in these cases is HTTP 410:\n HTTP 410 GONE The target resource is no longer available at the origin server and that this condition is likely to be permanent.\n HTTP 410 will inform the consumer and the client that there was something there before, but now it\u0026rsquo;s gone (hence the status code). This will be semantically much more correct, but it will add implementation implications to the API itself. It means that the API will have to know that a resource has existed in a certain place. This means that records might have to be flagged as deleted, but not actually deleted and so on.\nAs you can see, the complexity that hypermedia APIs add to the client can be big, and both the client and the API have to be very smartly built to allow proper usage and leverage of hypermedia.\nIn closing As we some in our tiny examples, although things can most often look trivial, if we want to have semantically correct APIs, we need to be very careful of every aspect of our API. HTTP statuses, although oftern perceived as trivial, if applied correctly add a lot of power to our APIs and the clients.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/when-you-delete-an-api-resource/","summary":"Have you ever found yourself publishing an API, either an internal or a public one? Have your ever heard from the consumers of those same APIs back? Are they happy about the functionality of your APIs and their design? You already know, there is no perfect design, but API design has to be taken very seriously. Why? Because evolving and changing APIS is hard and time consuming.\nImagine you are on a team in a company, that has set off to design a company-wide API guideline and a blueprint.","title":"What happens when you DELETE a resource?"},{"content":"REST as a concept was introduced by Roy Fielding in his doctoral thesis, named Architectural Styles and the Design of Network-based Software Architectures. 16 years later, REST as an architecture is the most widely accepted way to design and build APIs. I am sure we have all heard about it, and most of us think we are building actual RESTful APIs. But, are we?\nLet\u0026rsquo;s remind ourselves what REST is and then continue on something else that supplements REST, called HATEOAS.\nSo, what was REST again? I was thinking of a good way to explain this, but this gem by Ryan Tomako named How I Explained REST to My Wife is the best explanation of REST I have seen so far.\nOverall, REST (an acronym for REpresentational State Transfer) is an architecture over which the Internet is built upon. The easiest way to explain REST is, in my opinion, the Richardson Maturity Model. Here, we will not go in much depth, but if you want to learn RMM in more depth, I recommend reading Richardson Maturity Model, steps toward the glory of REST written by Martin Fowler.\nThe RMM explains REST in four levels:\n Use a protocol to do remote procedure calls (RPC). Introduce Resources HTTP Verbs Hypermedia Controls  Let\u0026rsquo;s deconstruct all of these levels briefly.\nLevel 1 Level one basically states that we need to use a protocol (HTTP) to execute procedure calls on some remote location (a server). This also means that we will not use any of the mechanism that the protocol provides, but we will just use it as a tunnel to send the requests and responses.\nLevel 2 Level two is something very familiar to all of us, I am sure. Resources. Back in the day, when I was probably still in high school, RPC worked by communicating with a single endpoint on a server. This is called a \u0026ldquo;service endpoint\u0026rdquo;.\nBy implementing resources in an API, we provide multiple endpoints that will represent the resources. This means that instead of having one single multipurpose endpoint, we have an endpoint for every resource that the API exposes.\nLevel 3 With level 1 and level 2 the mechanisms of the protocol were skipped, because we think only about tunneling our calls instead of fully utilising the protocol. Level 3 takes this to the next level (pun intended) and states that any RESTful service needs to utilise HTTP verbs so clients can interact with resources.\nIf you are coming from Rails land, I am sure you already know this - there\u0026rsquo;s a big difference between GET, POST, PUT, PATCH and DELETE. Sure, you could handle these in various ways in your backend, but this is where Rails shines - it strongly encourages you to comply to REST.\nIf you do not obey Level 3 of the RMM, you could have a different endpoint for every action on the API side. For example, if you had a Pet resource, to create a new entry you could use a /pets/create or a /pets/update to update it. By utilising Level 3, when HTTP verbs come into play, you would use something that Rails makes super easy: GET /pets/:id to get a Pet, POST /pets to create a new Pet or PATCH /pets to update one.\nLevel 4 Now, while Rails does a great job to make you write RESTful APIs, Level 4 is something that falls onto you, the programmer, to implement. This is something that most of us don\u0026rsquo;t follow and we, as a community, still haven\u0026rsquo;t find the best way to accomplish.\nHypermedia Controls is REST\u0026rsquo;s \u0026ldquo;holy grail\u0026rdquo;, and the ultimate level of \u0026ldquo;RESTfulness\u0026rdquo;. It states that when an API is at level four, it\u0026rsquo;s clients can request resources in a specific data format and can navigate throughout the API by using Hypermedia Controls.\nIf you find this confusing, let\u0026rsquo;s take a step back and think about browsers and websites. When you use a website you usually know only the entry point, in the form of domainname.tld, like ieftimov.com or google.com. Then, by interacting the website via your browser you navigate throughout the different pages it has. Well, navigating is done by clicking on links, right? Imagine a website that instead of having links makes your remember every URL on the website and you have to type it in manually. Worst website ever!\nHaving this in mind, the idea of Hypermedia Controls means that a resource should provide links, so a client that consumes the resource can navigate through and interact with it without knowing any other endpoint except the entry point. Just like normal websites - the page provides you with the links so you can interact with it.\nWe will get into the format of the JSON responses that HATEOAS APIs return in a bit, but first we will look at another important mechanism of HATEAOS - content negotiation.\nContent negotiation Content negotiation is a mechanism embedded into HTTP that allows web services to serve different versions (or formats) of documents. Or in REST terminology, resources. This is achieved by the Accept group of HTTP headers. For example, when requesting a web page the user agent (the browser) sends these (or similar) headers, depending on the browser:\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 Accept-Encoding: gzip, deflate, sdch, br Accept-Language: en-US,en;q=0.8 This tells the server that the user agent can accept the document in a text/html, compressed with one of the specified compression schemes, formatted in en-US (US English) language.\nIf we go back to APIs, Rails does a very good job in content negotiation. When we are building apps nowadays, we usually make sure our resources have a HTML, JSON and (maybe) an XML representation. I am sure all of us have seen this:\nrespond_to :html, :json, :xml def index @pets = Pet.all respond_with(@pets) end Or maybe the older version of this code:\ndef index @pets = Pet.all respond_to do |format| format.html format.json { render :json =\u0026gt; @pets } format.xml { render :xml =\u0026gt; @pets } end end This tells our index action to allow three types of content format are requested, via content negotiation. HTML, JSON and XML are in fact Media (or MIME) types.\nIf you look at the example headers, you can notice the q parameter. This is called a Quality Value and it is what makes one content type more important than another. In other words, the q parameter adds a relative weight to the preference for that associated kind of content.\nFor example, let\u0026rsquo;s say we have the following Accept header:\nAccept: application/json; q=0.5, application/xml; q=0.001 This tells the server that the client prefers JSON content type much more than XML. If the q value is not specified, then the value is defaulted to 1. You can read more about content negotiation in RFC 7231.\nHATEOAS So what is HATEOAS? It is an acronym, just like REST, which translates to Hypermedia As The Engine Of Application State. Whoa, what a mouthful, right?\nLike we mentioned, Level 4 of the RMM states that an API should provide hypermedia controls to navigate in and interact with. But, what does HATEOAS have to do with this? Well, think about this - REST means Representational State Transfer while HATEOAS means Hypermedia As The Engine Of Application State. If you look just as the names, it makes sense that HATEOAS is a mechanism of REST. It all revolves around application state and state transitions.\nToo complex? Let\u0026rsquo;s see an example of a usual JSON representation of a resource, in this case, my user somewhere on a server:\ncurl http://awesomeapi.com/users/1 { \u0026#34;user\u0026#34;: { \u0026#34;first_name\u0026#34;: \u0026#34;Ilija\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Eftimov\u0026#34;, \u0026#34;age\u0026#34;: 25 } } Simple enough. Now, when we apply HATEOAS to our representations of resources, it should look something like this:\n{ \u0026#34;user\u0026#34;: { \u0026#34;first_name\u0026#34;: \u0026#34;Ilija\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Eftimov\u0026#34;, \u0026#34;age\u0026#34;: 25, \u0026#34;links\u0026#34;: [ { \u0026#34;rel\u0026#34;: \u0026#34;self\u0026#34;, \u0026#34;href\u0026#34;: \u0026#34;http://awesomeapi.com/users/1\u0026#34; }, { \u0026#34;rel\u0026#34;: \u0026#34;roles\u0026#34;, \u0026#34;href\u0026#34;: \u0026#34;http://awesomeapi.com/users/1/roles\u0026#34; } ] } } By providing the links we allow the clients to use hypermedia (in our case, JSON) as the engine (list of available actions) of our application state (changing the data on the API side). The idea here is that there should be only one entry point to an API, or to a resource, and that the representation of the resource should include all of the actions that can be executed on this resources.\nThis means that a consumer of the API can take use the self attribute of the User resource, and consider this the endpoint where it can execute actions on it. By knowing that the API is RESTful, the client knows how to update the resource:\ncurl -X \u0026#34;PUT\u0026#34; -d \u0026#34;{ \u0026#39;age\u0026#39;: 26 }\u0026#34; http://awesomeapi.com/users/1 Also, it knows how to delete the resource:\ncurl -X \u0026#34;DELETE\u0026#34; http://awesomeapi.com/users/1 Furthermore, if it wants to see all of the roles for this user, it can execute a GET request to the roles relation of the user:\ncurl http://awesomeapi.com/users/1/roles As you can see, by putting HATEOAS in the mix, clients can interact with resources just by getting the URIs from the resources and by assuming that the API is level three RESTful (utilises HTTP verbs).\nHATEOAS Serializers How can we make our Rails API implement Level 4 of RMM? Let\u0026rsquo;s see an example.\nOur API is part of a blog CMS. It has an Author model, which has a one-to-many association with an Article model. This means that, one Author can have multiple Article.\nThe Author model:\n# == Schema Information # # Table name: authors # # id :integer not null, primary key # first_name :string # last_name :string # created_at :datetime not null # updated_at :datetime not null # class Author \u0026lt; ApplicationRecord has_many :articles end And the Article model:\n# == Schema Information # # Table name: articles # # id :integer not null, primary key # author_id :integer # title :string # body :text # created_at :datetime not null # updated_at :datetime not null # class Article \u0026lt; ApplicationRecord belongs_to :author end Our routes look like the following:\nRails.application.routes.draw do resources :authors do resources :articles end end Finally, we will have serializers for both, the Article and the Author model. For this example, we will use Active Model Serializers.\nAuthor serializer All of the Author objects will be serialized by the AuthorSerializer. Let\u0026rsquo;s add the required attributes first to the serializer, and we can talk about extension afterwards.\nThe AuthorSerializer class will look like this:\n# == Schema Information # # Table name: authors # # id :integer not null, primary key # first_name :string # last_name :string # created_at :datetime not null # updated_at :datetime not null # class AuthorSerializer \u0026lt; ActiveModel::Serializer attributes :id, :first_name, :last_name, :created_at, :updated_at has_many :articles type :author end Super simple! I will leave the annotations in, to keep the context of the data visible to us throughout this short example. In my everyday work, I usually consult with the schema file if I forget the shape of the data instead of adding annotations.\nLet\u0026rsquo;s try sending a GET /authors request and see what the data looks like. For reference, this is the implementation of the index action in the AuthorsController:\nclass AuthorsController \u0026lt; ApplicationController def index render json: Author.all end end curl http://localhost:3000/authors This request will return the following JSON:\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;first_name\u0026#34;: \u0026#34;ilija\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;eftimov\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34;, \u0026#34;articles\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;Lorem ipsum\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2016-06-25T22:25:51.874Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2016-06-25T22:25:51.874Z\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;title\u0026#34;: \u0026#34;A princess of Mars\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;His reference to the great games of which I had heard so much while among the Tharks convinced me that I had but jumped from purgatory into gehenna. After a few more words with the female, during which she assured him that I was now fully fit to travel, the jed ordered that we mount and ride after the main column. I was strapped securely to as wild and unmanageable a thoat as I had\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34; } ] } ] Since my database has only one Author instance, it returns only that one. Also, the Author has two associated Article instances, so the serializer includes them in the response.\nAdding links to our serializer Now we have our serializer working. The next step is to extend it with links. This is quite trivial to do using Active Model Serializers - we need to add a new links attribute to the serializer, and provide the implementation of the attribute (which will be a method in fact) in the class:\n# == Schema Information # # Table name: authors # # id :integer not null, primary key # first_name :string # last_name :string # created_at :datetime not null # updated_at :datetime not null # class AuthorSerializer \u0026lt; BaseSerializer attributes :id, :first_name, :last_name, :created_at, :updated_at, :links has_many :articles type :author def links [ { rel: :self, href: author_path(object) } ] end end As you can see, the implementation is quite simple. We add a new attribute called links, and the method just returns an array of hashes. For starters, we will have only one - the self link which will point to the resource whose representation we are seeing.\nBut, if you execute the curl request again, you will gen an error, something like:\n#\u0026lt;NoMethodError: undefined method `author_path\u0026#39; for #\u0026lt;AuthorSerializer:0x007fe251b4c450\u0026gt;\u0026gt; This occurs because Rails' route helpers are not included in the scope of the serializers. This is easily fixable by including them to the serializer:\nclass AuthorSerializer \u0026lt; ActiveModel::Serializer include Rails.application.routes.url_helpers # *snip* end If we execute the curl request again now, we will see the links in the JSON:\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;first_name\u0026#34;: \u0026#34;ilija\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;eftimov\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34;, \u0026#34;links\u0026#34;: [ { \u0026#34;rel\u0026#34;: \u0026#34;self\u0026#34;, \u0026#34;href\u0026#34;: \u0026#34;/authors/1\u0026#34; } ], \u0026#34;articles\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;Lorem ipsum\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2016-06-25T22:25:51.874Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2016-06-25T22:25:51.874Z\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;title\u0026#34;: \u0026#34;A princess of Mars\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;His reference to the great games of which I had heard so much while among the Tharks convinced me that I had but jumped from purgatory into gehenna. After a few more words with the female, during which she assured him that I was now fully fit to travel, the jed ordered that we mount and ride after the main column. I was strapped securely to as wild and unmanageable a thoat as I had\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34; } ] } ] Great stuff! We added some HATEOAS to our resources.\nSpecifications Before we continue to add any more hypermedia to our resources, we need to put some thought into this. As you can see, we went on to implement the links attribute to the serializer without any thought. Sure, you might say, I am the creator of the API and I will structure the responses of the API as I please.\nTrue, you are the author of the API, but that statement is false. Imagine if all of us thought of a way to implement hypermedia in a different way? Every single API would be different in it\u0026rsquo;s hypermedia controls and it would be a hell to find your way around.\nWell, the sad part is that we still don\u0026rsquo;t know how to do HATEOAS. Or better said, we still don\u0026rsquo;t know the best way to do HATEOAS. That is why, people have tried to create specifications, which have been somewhat adopted.\nHAL From HAL\u0026rsquo;s documentation:\n HAL is a simple format that gives a consistent and easy way to hyperlink between resources in your API.\n As you can see, the motivation behind HAL is to create an easy and consistent way to add hypermedia controls. Just like any other specification, HAL provides a set of conventions for expressing hyperlinks in either JSON or XML.\nThis is an example of a JSON that applies the HAL specification:\n{ \u0026#34;_links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/orders\u0026#34; }, \u0026#34;curies\u0026#34;: [{ \u0026#34;name\u0026#34;: \u0026#34;ea\u0026#34;, \u0026#34;href\u0026#34;: \u0026#34;http://example.com/docs/rels/{rel}\u0026#34;, \u0026#34;templated\u0026#34;: true }], \u0026#34;next\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/orders?page=2\u0026#34; }, \u0026#34;ea:find\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/orders{?id}\u0026#34;, \u0026#34;templated\u0026#34;: true }, \u0026#34;ea:admin\u0026#34;: [{ \u0026#34;href\u0026#34;: \u0026#34;/admins/2\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Fred\u0026#34; }, { \u0026#34;href\u0026#34;: \u0026#34;/admins/5\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Kate\u0026#34; }] }, \u0026#34;currentlyProcessing\u0026#34;: 14, \u0026#34;shippedToday\u0026#34;: 20, \u0026#34;_embedded\u0026#34;: { \u0026#34;ea:order\u0026#34;: [{ \u0026#34;_links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/orders/123\u0026#34; }, \u0026#34;ea:basket\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/baskets/98712\u0026#34; }, \u0026#34;ea:customer\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/customers/7809\u0026#34; } }, \u0026#34;total\u0026#34;: 30.00, \u0026#34;currency\u0026#34;: \u0026#34;USD\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;shipped\u0026#34; }, { \u0026#34;_links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/orders/124\u0026#34; }, \u0026#34;ea:basket\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/baskets/97213\u0026#34; }, \u0026#34;ea:customer\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/customers/12369\u0026#34; } }, \u0026#34;total\u0026#34;: 20.00, \u0026#34;currency\u0026#34;: \u0026#34;USD\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;processing\u0026#34; }] } } JSON API JSON API, just like HAL is:\n a specification for how a client should request that resources be fetched or modified, and how a server should respond to those requests.\n It was was originally drafted by Yehuda Katz in 2013. This first draft was extracted from the JSON transport implicitly defined by Ember Data’s REST adapter. From there on, it picked up some popularity, but I cannot say with certainty that it\u0026rsquo;s the de facto API specification.\nThis is an example of a JSON that applies the JSON API specification:\n{ \u0026#34;data\u0026#34;: [{ \u0026#34;type\u0026#34;: \u0026#34;articles\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;JSON API paints my bikeshed!\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;The shortest article. Ever.\u0026#34;, \u0026#34;created\u0026#34;: \u0026#34;2015-05-22T14:56:29.000Z\u0026#34;, \u0026#34;updated\u0026#34;: \u0026#34;2015-05-22T14:56:28.000Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;author\u0026#34;: { \u0026#34;data\u0026#34;: {\u0026#34;id\u0026#34;: \u0026#34;42\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;people\u0026#34;} } } }], \u0026#34;included\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;people\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;42\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;age\u0026#34;: 80, \u0026#34;gender\u0026#34;: \u0026#34;male\u0026#34; } } ] } Other standards As you can imagine, people have tried to create a good JSON standard for quite some time. Some of the more popular specs are JSON for Linking Data, also known as JSON-LD; Collection+JSON and SIREN.\nJSON API and Active Model Serializers Since JSON API is picking up momentum and Active Model Serializers has a very good integration of it, we will stick to it and carry on with the implementation. Active Model Serializers on a high-level works through two parts: serializers and adapters. From the documentation:\n Serializers describe which attributes and relationships should be serialized. Adapters describe how attributes and relationships should be serialized.\n To get our JSON serialized in the JSON API format, we need to use a different adapter called, believe it or not, :json_api. Personally, I prefer to do this type of configuration in an initializer file:\n# config/initializers/active_model_serializers.rb ActiveModelSerializers.config.adapter = :json_api By setting the adapter to :json_api, our API will produce and consume JSON formatted in the JSON API spec. If we execute the same API call that we did earlier, we will get a newly formatted JSON:\n{ \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;first-name\u0026#34;: \u0026#34;ilija\u0026#34;, \u0026#34;last-name\u0026#34;: \u0026#34;eftimov\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;articles\u0026#34;: { \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34; } ] } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1\u0026#34; } } } ] } As you can notice, the JSON that we get back has a completely different structure compared to what we have before. The reason is that the JSON API adapter that we use now formats the JSON in the JSON API Spec format.\nAnother cool thing about the JSON API adapter is that it allows us to specify links very explicitly, with a very nice DSL:\nclass AuthorSerializer \u0026lt; ActiveModel::Serializer attributes :id, :first_name, :last_name, :created_at, :updated_at has_many :articles type :author link :self do href author_path(object) end end Also, we do not have to specify the links as an attribute and we can remove the include line that mixed-in Rails' url helpers in our serializer. If we call the /authors endpoint with a GET request again, we will see an extended JSON, that again complies with the JSON API Spec:\n{ \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;first-name\u0026#34;: \u0026#34;ilija\u0026#34;, \u0026#34;last-name\u0026#34;: \u0026#34;eftimov\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;articles\u0026#34;: { \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34; } ] } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1\u0026#34; } } } ] } Including additional resources Since AMS is an awesome gem, it allows you to include additional resources by including them in the controllers:\nclass AuthorsController \u0026lt; ApplicationController def index render json: Author.all, include: \u0026#39;articles\u0026#39; end end By including the Article association of on the Author model, we are able to extend the JSON result with the associated articles for each of the users:\n{ \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;first-name\u0026#34;: \u0026#34;ilija\u0026#34;, \u0026#34;last-name\u0026#34;: \u0026#34;eftimov\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;articles\u0026#34;: { \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34; } ] } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1\u0026#34; } } } ], \u0026#34;included\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Lorem ipsum\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-25T22:25:51.874Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-25T22:25:51.874Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;author\u0026#34;: { \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34; } } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1/articles/1\u0026#34; } } }, { \u0026#34;id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;A princess of Mars\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;His reference to the great games of which I had heard so much while among the Tharks convinced me that I had but jumped from purgatory into gehenna. After a few more words with the female, during which she assured him that I was now fully fit to travel, the jed ordered that we mount and ride after the main column. I was strapped securely to as wild and unmanageable a thoat as I had\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;author\u0026#34;: { \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34; } } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1/articles/2\u0026#34; } } } ] } Although this is quite nice, beware that this introduces N+1 queries for every resource that we fetch. That\u0026rsquo;s why, usually index actions return only the requested resources, while show actions tend to include some additional resources:\nclass AuthorsController \u0026lt; ApplicationController def index render json: Author.all end def show author = Author.find(params[:id]) render json: author, include: :articles end end This will add all of the articles found for the author that we requested:\n{ \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;first-name\u0026#34;: \u0026#34;ilija\u0026#34;, \u0026#34;last-name\u0026#34;: \u0026#34;eftimov\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-25T20:52:12.804Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;articles\u0026#34;: { \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34; } ] } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1\u0026#34; } } }, \u0026#34;included\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Lorem ipsum\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Lorem ipsum dolor sit amet\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-25T22:25:51.874Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-25T22:25:51.874Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;author\u0026#34;: { \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34; } } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1/articles/1\u0026#34; } } }, { \u0026#34;id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;A princess of Mars\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;His reference to the great games of which I had heard so much while among the Tharks convinced me that I had but jumped from purgatory into gehenna. After a few more words with the female, during which she assured him that I was now fully fit to travel, the jed ordered that we mount and ride after the main column. I was strapped securely to as wild and unmanageable a thoat as I had\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;author\u0026#34;: { \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34; } } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1/articles/2\u0026#34; } } } ] } As you can notice, because we supplied the has_many association in the serializer, AMS knows to utilise the correct serializer for each of the included resources. This adds the same structure to the included resources and the requested resource, which makes the result consistent and parsing this JSON much easier.\nNavigating resources Now, to actually see how easy it is to navigate through resources, let\u0026rsquo;s implement the ArticlesController#show action as well:\nclass ArticlesController \u0026lt; ApplicationController def show article = Article.find_by(author_id: params[:author_id], id: params[:id]) render json: article end end Super simple - we find the Article by the author_id and the id params and render it as a JSON. If we call GET /authors/1/articles/2, we will get the JSON API representation of the Article object:\n{ \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;article\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;A princess of Mars\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;His reference to the great games of which I had heard so much while among the Tharks convinced me that I had but jumped from purgatory into gehenna. After a few more words with the female, during which she assured him that I was now fully fit to travel, the jed ordered that we mount and ride after the main column. I was strapped securely to as wild and unmanageable a thoat as I had\u0026#34;, \u0026#34;created-at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34;, \u0026#34;updated-at\u0026#34;: \u0026#34;2016-06-26T00:20:09.388Z\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;author\u0026#34;: { \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;author\u0026#34; } } }, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;/authors/1/articles/2\u0026#34; } } } } If you use Postman, which I really enjoy using, or any other API browser to test the endpoints you could see how easy it is to navigate the resources:\nJust link in the web browser, you know the entry point localhost:3000/authors. From there you can click on the links property of the Author and get the single Author resource:\nBy seeing the resource with all of it\u0026rsquo;s included resources, then you can click on any of the links on the included Article resources, and see their attributes in JSON format:\nThis is what essentially HATEOAS means - navigating and interacting with resources via the endpoints that are provided in the JSON representation of the resources.\nOutro As you can see, to understand and learn what Hypermedia As The Engine Of Application State is, there is quite a bit of context that we need to get in our heads. Although all of this sometimes can appear as quite complex, Rails makes implementing HATEOAS APIs quite easy, as you could see in the examples. Sure, there is more to hypermedia controls, but these examples should be more than enough to get your feet wet.\nAlso, the HATEOAS concept seems quite complex on the surface, but when you deconstruct it it\u0026rsquo;s quite simple, because we have already seen the same behaviour in web browsers. The issue of why it seems quite complex is because we haven\u0026rsquo;t even thought about normal web sites like RESTful APIs, and vice-versa.\nIf you want to see the actual implementation of the endpoints that we worked with in this article, you can check this repo on Github.\nAdditional reading  Web Linking - RFC 5988 Haters gonna HATEOAS Richardson Maturity Model, steps toward the glory of REST What is the Richardson Maturity Model? Media type Content negotiation  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/sprinkle-some-hateoas-on-rails-apis/","summary":"REST as a concept was introduced by Roy Fielding in his doctoral thesis, named Architectural Styles and the Design of Network-based Software Architectures. 16 years later, REST as an architecture is the most widely accepted way to design and build APIs. I am sure we have all heard about it, and most of us think we are building actual RESTful APIs. But, are we?\nLet\u0026rsquo;s remind ourselves what REST is and then continue on something else that supplements REST, called HATEOAS.","title":"Sprinkle some HATEOAS on your Rails APIs"},{"content":"The web, as we all know, is driven by APIs. Since the rise of mobile applications and the JavaScript driven single-page applications, APIs became even more popular, as a unified way for the clients to communicate with the back-end. Most of the companies use internal APIs for different purposes. Some use them to expose resources, data or behaviour. Others, use them for authentication and authorisation, some do it for controlling the hardware layer with smart implementations under the hood. Overall, APIs are enablers that allow various clients to utilise the same back-end logic.\nAs we all know, banging some endpoints out of your head on the fly is rather easy. Maybe that approach will cut it for your internal API. Most probably not, but you could find your way around it. But, what if you wanted to expose a public API for your product, just like Facebook, Twitter, GitHub and a load of other companies do?\nThe design process APIs need consistent and stable design. That means that, once an API is released and clients start using it, breaking changes are a no-go. Even if you want to provide backwards compatibility for (otherwise a breaking) change, it will be a big hassle to pull off.\nThat means when building APIs we need to think about proper design. Yes, way before we put any code in, we have to think about various things. I am sure some of you find this obvious, but is it that obvious? And even then, how can we actually do it?\nAn API design means that we need to take various steps to achieve a well though out design before we have any code in place. We need to think about versioning, headers, response format, caching. We need to think about filtering, sorting and pagination of resources. Returning useful meta information, using appropriate HTTP verbs, security, authentication and what not. Since an API has so many moving parts, just putting some endpoints in place without putting (a lot of) thought into them will not do the trick.\nOh, and what about REST?\nThinking about REST REST as a concept is a really neat way to represent state and resources, while having a very intuitive design. REST means that your API has to be separated in logical resources. These resources then can be manipulated via HTTP requests, by using the appropriate methods. You know, whether a request uses the GET or the POST HTTP method has a big difference, for a good reason.\nAll of these things put together mean that designing an API has to be taken very seriously and writing documentation and/or blueprints is a very nice step towards a great API design.\nWriting a blueprint If you got so far, I assume that you agree with my point. So, how can we improve our workflow?\nWell, although I often get the \u0026ldquo;hack-n-slash\u0026rdquo; urge, I believe that APIs have to be done with a design-first approach. You can compare it to tests in test-driven development.\nEvery API has to have a contract before it is developed. This is where tools like API blueprint come in handy. API Blueprint is a way (or syntax) to define and design APIs in a standardised manner. This means that by writing a special flavour of markdown, a team (or teams) of developers can collaborate to design APIs to the best of their knowledge.\nBlueprints allow developers to define metadata, resource groups, resources, actions and so on. You can define requests and responses in various formats (like XML and JSON), specify request and response headers.\nLet\u0026rsquo;s see an small example of an API blueprint.\nFORMAT: 1A HOST: https://polls.apiblueprint.org/ # Polls  Polls is a simple web service that allows consumers to view polls and vote in them. # Polls API Root [/]  This resource does not have any attributes. Instead it offers the initial API affordances in the form of links in the JSON body. It is recommended to follow the “url” link values or Link headers to get to resources instead of constructing your own URLs to keep your client decoupled from implementation details. ## Retrieve the Entry Point [GET]  + Response 200 (application/json) { \u0026#34;questions_url\u0026#34;: \u0026#34;/questions\u0026#34; } ## Group Question  Resource related to questions in the API. ## Question [/questions/{question_id}]  A Question object has the following attributes. - question - published_at - url - choices (an array of Choice objects). + Parameters + question_id (required, number, `1`) ... ID of the Question in form of an integer ### View a question detail [GET]  + Response 200 (application/json) { \u0026#34;question\u0026#34;: \u0026#34;Favourite programming language?\u0026#34;, \u0026#34;published_at\u0026#34;: \u0026#34;2014-11-11T08:40:51.620Z\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;/questions/1\u0026#34;, \u0026#34;choices\u0026#34;: [ { \u0026#34;choice\u0026#34;: \u0026#34;Swift\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;/questions/1/choices/1\u0026#34;, \u0026#34;votes\u0026#34;: 2048 }, { \u0026#34;choice\u0026#34;: \u0026#34;Python\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;/questions/1/choices/2\u0026#34;, \u0026#34;votes\u0026#34;: 1024 }, { \u0026#34;choice\u0026#34;: \u0026#34;Objective-C\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;/questions/1/choices/3\u0026#34;, \u0026#34;votes\u0026#34;: 512 }, { \u0026#34;choice\u0026#34;: \u0026#34;Ruby\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;/questions/1/choices/4\u0026#34;, \u0026#34;votes\u0026#34;: 256 } ] } As you can notice, the API blueprint starts with the format and the host where the API is located. Then, it describes resource groups, like Polls, and endpoints like Polls API Root [/]. Then, every endpoint is described by providing the appropriate HTTP verb, with the description and the request and response body.\nWhere\u0026rsquo;s the value? By having a blueprint of an endpoint, we create a contract to which our API has to oblige. This is very useful, since we provide ground rules and high-level overview of our API, but still we have technical and design decisions easily visible.\nThink about this case - there\u0026rsquo;s an API that for some endpoints has to provide metadata. Great, nothing out of the ordinary. A valid question is, what will the metadata look like? Usually, metadata contains a cursor, or in other words, pagination data like page, per_page, or limit and offset. Almost always it contains the total number of objects that the API contains of the requested resource. Often, it contains the attribute that we order by and the ordering direction. In JSON, that would looks something like this:\n{ \u0026#34;meta\u0026#34;: { \u0026#34;limit\u0026#34;: 10, \u0026#34;offset\u0026#34;: 20, \u0026#34;order_by\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;order_dir\u0026#34;: \u0026#34;desc\u0026#34;, \u0026#34;total\u0026#34;: 200 } } But, will this be useful? Sure it will, but are we missing any data here? Maybe you would like to provide the locale as part of the metadata? By leaving these questions unanswered, you are immediately adding \u0026ldquo;design debt\u0026rdquo; to your API. This means that, if a client needs the locale, you will have to change the contract of the API itself, for all endpoints.\nBy taking a step back while designing the API, we can describe our metadata in a blueprint. This allows us to see in advance how our API responses will look like and we can have a meaningful discussion with our colleagues about it. That is why, these sort of decisions have to be documented. Imagine changing the metadata structure on a live API, for example, removing or changing the name of an attribute of the metadata - most (if not all) clients that use it will break.\nExploring an API Another very important side-effect of using an API blueprint is explorability. To discover an API means that you can test and use the endpoints via a tool or your browser. It means that the consumer can see the data coming in and out of the API.\nTo do this, the consumer will have to know the location, the endpoints, the data format, parameters, headers and whatnot. Simply said, the consumer needs a detailed API documentation.\nResources Even if we have our endpoints thought out, we have to remember that if we are building a REST API we need to think about resources. \u0026ldquo;Sure\u0026rdquo;, you might think, \u0026ldquo;we will replicate the database model in our API\u0026rdquo;. Are you sure you want and (more importantly) need this?\nAlthough REST APIs expose resources, APIs also expose behaviour. You have to ask yourself \u0026ldquo;what behaviour I want to give to the consumers\u0026rdquo; and \u0026ldquo;what are the resources that this behaviour will expose\u0026rdquo;. To do this, API blueprint has a very neat tool called MSON. MSON is an acronym for \u0026ldquo;Markdown Syntax for Object Notation\u0026rdquo; and it is a way to represent data structures in markdown.\nWhile we describe our API endpoints in a blueprint, we also need to describe the data objects that will be returned. For example, if we have a Product object we can describe it as follows:\n# Product A product from Acme\u0026#39;s catalog ## Properties  - id: 1 (number, required) - The unique identifier for a product - name: A green door (string, required) - Name of the product - price: 12.50 (number, required) - tags: home, green (array[string]) As you can see, it is quite trivial to write and to read. A Product has a description and properties. The properties is a list of items, with a name, type, presence and a description. By looking at this MSON file, we can see that our JSON representation of this object will look like:\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;A green door\u0026#34;, \u0026#34;price\u0026#34;: 12.50, \u0026#34;tags\u0026#34;: [ \u0026#34;home\u0026#34;, \u0026#34;green\u0026#34; ] } By knowing what our endpoints return and what these objects look, we can easily explore our API. There is less friction and no \u0026ldquo;guess work\u0026rdquo; - you just know what to call and what the call will return.\nIf you would like to read more about MSON, I recommend checking their short tutorial. It demostrates more cool features, like inheritance, nesting and so on.\nEveryday exploring This is what an API blueprint can provide. You can take your API blueprint file and convert it to a Postman collection. You can in fact use the awesome API Transformer tool and convert it to any format you want.\nFor example, let\u0026rsquo;s imagine we have the following API Blueprint ready for one of our APIs:\nFORMAT: 1A HOST: http://coconut-api.apiblueprint.org/ # Coconut API API for all Coconut actions ## Account [/api/v1/accounts/{account_id}] Exposes the `Account` resource. ### Fetch Account [GET] Fetch Account data + Parameters + account_id (number) - ID of the Account in the form of an integer + Response 200 (application/json) { \u0026#34;id\u0026#34;: 123, \u0026#34;first_name\u0026#34;: \u0026#34;Ilija\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Eftimov\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;foo@bar.com\u0026#34;, \u0026#34;uuid\u0026#34;: 0beec7b5ea3f0fdbc95d0dd47f3c5bc275da8a33 } The output of the API Transformer can be a Swagger JSON file:\n{ \u0026#34;swagger\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;info\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Coconut API\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;TODO: Add a description\u0026#34;, \u0026#34;license\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;MIT\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://github.com/gruntjs/grunt/blob/master/LICENSE-MIT\u0026#34; } }, \u0026#34;host\u0026#34;: \u0026#34;coconut-api.apiblueprint.org\u0026#34;, \u0026#34;basePath\u0026#34;: \u0026#34;/\u0026#34;, \u0026#34;securityDefinitions\u0026#34;: {}, \u0026#34;schemes\u0026#34;: [ \u0026#34;http\u0026#34; ], \u0026#34;consumes\u0026#34;: [ \u0026#34;application/json\u0026#34; ], \u0026#34;produces\u0026#34;: [ \u0026#34;application/json\u0026#34; ], \u0026#34;paths\u0026#34;: { \u0026#34;/api/v1/accounts/{account_id}\u0026#34;: { \u0026#34;get\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Fetch Account data\u0026#34;, \u0026#34;operationId\u0026#34;: \u0026#34;Fetch Account_\u0026#34;, \u0026#34;produces\u0026#34;: [ \u0026#34;application/json\u0026#34; ], \u0026#34;parameters\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;account_id\u0026#34;, \u0026#34;in\u0026#34;: \u0026#34;path\u0026#34;, \u0026#34;required\u0026#34;: true, \u0026#34;x-is-map\u0026#34;: false, \u0026#34;type\u0026#34;: \u0026#34;number\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;double\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;ID of the Account in the form of an integer\u0026#34; } ], \u0026#34;responses\u0026#34;: { \u0026#34;200\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;schema\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34; } } } } } } } Since Postman has the ability to import Swagger JSON, you can get the actual endpoint in your Postman and you can immediately fire requests away. Here is how my actual Postman looks like after importing the JSON above:\nAdditionally, you can use full blown explorers like Apiary that will put your blueprint on steroids. It will provide various examples on how to send requests to the API, with a mock server, live editor and documentation style page. You can see the API blueprint from above on Apiary here.\nLast but very important, you can use tools like swagger-codegen to dynamically generate an API client by feeding it your Swagger Resource Declaration (the JSON file from above).\nYou can see all of the tools that API Blueprint has currently available and how you can fit it into your workflow.\nOutro As you can see, there are plenty of design questions that we as developers have to answer. Sure, we take pride and have passion for what we do, but often we resort to hacking some endpoints before thinking about them. But if we document and design our APIs before we start building them, we will sleep better knowing that our clients will function well. And as enablers, a non-functioning client means a broken API. Or a broken design.\nAlso, the vast choice of tools that work with API Blueprints can completely change the way you build your APIs (and their clients). You can even generate real code out of the API Blueprint, by converting it to Swagger JSON first. All of this seems unreal, but once you get it in your workflow you can immediately feel the benefits. I mean, who doesn\u0026rsquo;t like documentations on steroids, request examples, mock servers for free, automatic generation of API clients and so on?\nOr, you can just bang out those couple of endpoints you need. The choice is yours.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/practicality-designing-describing-apis/","summary":"The web, as we all know, is driven by APIs. Since the rise of mobile applications and the JavaScript driven single-page applications, APIs became even more popular, as a unified way for the clients to communicate with the back-end. Most of the companies use internal APIs for different purposes. Some use them to expose resources, data or behaviour. Others, use them for authentication and authorisation, some do it for controlling the hardware layer with smart implementations under the hood.","title":"The practicality of designing and describing your APIs"},{"content":"Starting a greenfield application everyday is nearly impossible, especially in your daily job. In fact, most of us are facing (somewhat) legacy codebases on a daily basis, and regaining the context of why some feature, or line of code exists in the codebase is very important. This is where git, the distributed version control system, is invaluable. Let\u0026rsquo;s dive in and see how we can use our git history and easily navigate through it.\nGit history First and foremost, what is git history? As the name says, it is the commit history of a git repo. It contains a bunch of commit messages, with their authors' name, the commit hash and the date of the commit. The easiest way to see the history of a git repo, is the git log command.\nSidenote: For the purpose of this post, we will use Ruby on Rails' repo, the master branch. The reason behind this is because Rails has a very good git history, with nice commit messages, references and explanations behind every change. Given the size of the codebase, the age and the number of maintainers, it\u0026rsquo;s certainly one of the best repositories that I have seen. Of course, I am not saying there are no other repositories built with good git practices, but this is one that has caught my eye.\nSo back to Rails' repo. If you run git log in the Rails' repo, you will see something like this:\ncommit 66ebbc4952f6cfb37d719f63036441ef98149418 Author: Arthur Neves \u0026lt;foo@bar.com\u0026gt; Date: Fri Jun 3 17:17:38 2016 -0400 Dont re-define class SQLite3Adapter on test We were declaring in a few tests, which depending of the order load will cause an error, as the super class could change. see https://github.com/rails/rails/commit/ac1c4e141b20c1067af2c2703db6e1b463b985da#commitcomment-17731383 commit 755f6bf3d3d568bc0af2c636be2f6df16c651eb1 Merge: 4e85538 f7b850e Author: Eileen M. Uchitelle \u0026lt;foo@bar.com\u0026gt; Date: Fri Jun 3 10:21:49 2016 -0400 Merge pull request #25263 from abhishekjain16/doc_accessor_thread [skip ci] Fix grammar commit f7b850ec9f6036802339e965c8ce74494f731b4a Author: Abhishek Jain \u0026lt;foo@bar.com\u0026gt; Date: Fri Jun 3 16:49:21 2016 +0530 [skip ci] Fix grammar commit 4e85538dddf47877cacc65cea6c050e349af0405 Merge: 082a515 cf2158c Author: Vijay Dev \u0026lt;foo@bar.com\u0026gt; Date: Fri Jun 3 14:00:47 2016 +0000 Merge branch \u0026#39;master\u0026#39; of github.com:rails/docrails Conflicts: guides/source/action_cable_overview.md commit 082a5158251c6578714132e5c4f71bd39f462d71 Merge: 4bd11d4 3bd30d9 Author: Yves Senn \u0026lt;foo@bar.com\u0026gt; Date: Fri Jun 3 11:30:19 2016 +0200 Merge pull request #25243 from sukesan1984/add_i18n_validation_test Add i18n_validation_test commit 4bd11d46de892676830bca51d3040f29200abbfa Merge: 99d8d45 e98caf8 Author: Arthur Nogueira Neves \u0026lt;foo@bar.com\u0026gt; Date: Thu Jun 2 22:55:52 2016 -0400 Merge pull request #25258 from alexcameron89/master [skip ci] Make header bullets consistent in engines.md commit e98caf81fef54746126d31076c6d346c48ae8e1b Author: Alex Kitchens \u0026lt;foo@bar.com\u0026gt; Date: Thu Jun 2 21:26:53 2016 -0500 [skip ci] Make header bullets consistent in engines.md As you can see, the git log shows the commit hash, the author and his email and the date of when the commit was created. Of course, git being super customisable, it allows you to customise the output format of the git log command. Let\u0026rsquo;s say, we want to just see the first line of the commit message, we could run git log --oneline, which will produce a more compact log:\n66ebbc4 Dont re-define class SQLite3Adapter on test 755f6bf Merge pull request #25263 from abhishekjain16/doc_accessor_thread f7b850e [skip ci] Fix grammar 4e85538 Merge branch \u0026#39;master\u0026#39; of github.com:rails/docrails 082a515 Merge pull request #25243 from sukesan1984/add_i18n_validation_test 4bd11d4 Merge pull request #25258 from alexcameron89/master e98caf8 [skip ci] Make header bullets consistent in engines.md 99d8d45 Merge pull request #25254 from kamipo/fix_debug_helper_test 818397c Merge pull request #25240 from matthewd/reloadable-channels 2c5a8ba Don\u0026#39;t blank pad day of the month when formatting dates 14ff8e7 Fix debug helper test To see all of the git log options, I recommend checking out manpage of git log, available in your terminal via man git-log or git help log. A tip: if git log is a bit scarse or complicated to use, or maybe you are just bored, I recommend checking out various git GUIs and command line tools. In the past I\u0026rsquo;ve used GitX which was very good, but since the command line feels like home to me, after trying tig I\u0026rsquo;ve never looked back.\nFinding Nemo So now, since we know the bare minimum of the git log command, let\u0026rsquo;s see how we can explore the history more effectively in our everyday work.\nLet\u0026rsquo;s say, hypothetically, we are suspecting an unexpected behaviour in the String#classify method and we want to find how and where it has been implemented.\nOne of the first commands that you can use, to see where the method is defined, is git grep. Simply said, this command prints out lines that match a certain pattern. Now, to find the definition of the method, it\u0026rsquo;s pretty simple - we can grep for def classify and see what we get:\n➜ git grep \u0026#39;def classify\u0026#39; activesupport/lib/active_support/core_ext/string/inflections.rb: def classify activesupport/lib/active_support/inflector/methods.rb: def classify(table_name) tools/profile: def classify Now, although we can already see where our method is created, we are not sure on which line it is. If we add the -n flag to our git grep command, git will provide the line numbers of the match:\n➜ git grep -n \u0026#39;def classify\u0026#39; activesupport/lib/active_support/core_ext/string/inflections.rb:205: def classify activesupport/lib/active_support/inflector/methods.rb:186: def classify(table_name) tools/profile:112: def classify Much better, right? Having the context in mind, we can easily figure out that the method that we are looking for lives in activesupport/lib/active_support/core_ext/string/inflections.rb, on line 205. The classify method, in all of it\u0026rsquo;s glory looks like this:\n# Creates a class name from a plural table name like Rails does for table names to models. # Note that this returns a string and not a class. (To convert to an actual class # follow +classify+ with +constantize+.) # # \u0026#39;ham_and_eggs\u0026#39;.classify # =\u0026gt; \u0026#34;HamAndEgg\u0026#34; # \u0026#39;posts\u0026#39;.classify # =\u0026gt; \u0026#34;Post\u0026#34; def classify ActiveSupport::Inflector.classify(self) end Although the method we found is the one we usually call on Strings, it invokes another method on the ActiveSupport::Inflector, with the same name. Having our git grep result available, we can easily navigate there, since we can see the second line of the result being activesupport/lib/active_support/inflector/methods.rb on line 186. The method that we are are looking for is:\n# Creates a class name from a plural table name like Rails does for table # names to models. Note that this returns a string and not a Class (To # convert to an actual class follow +classify+ with #constantize). # # classify(\u0026#39;ham_and_eggs\u0026#39;) # =\u0026gt; \u0026#34;HamAndEgg\u0026#34; # classify(\u0026#39;posts\u0026#39;) # =\u0026gt; \u0026#34;Post\u0026#34; # # Singular names are not handled correctly: # # classify(\u0026#39;calculus\u0026#39;) # =\u0026gt; \u0026#34;Calculus\u0026#34; def classify(table_name) # strip out any leading schema name camelize(singularize(table_name.to_s.sub(/.*\\./, \u0026#39;\u0026#39;.freeze))) end Boom! Given the size of Rails, finding this should not take us more than 30 seconds with the help of git grep.\nSo, what changed last? Now, since we have the method available, we need to figure out what were the changes that this file has gone through. The since we know the correct file name and line number, we can use git blame. This command shows what revision and author last modified each line of a file. Let\u0026rsquo;s see what were the latest changes made to this file:\ngit blame activesupport/lib/active_support/inflector/methods.rb Whoa! Although we get the last change of every line in the file, we are more interested in the specific method (lines 176 to 189). Let\u0026rsquo;s add a flag to the git blame command, that will show the blame of just those lines. Also, we will add the -s (suppress) option to the command, to skip the author names and the timestamp of the revision (commit) that changed the line:\ngit blame -L 176,189 -s activesupport/lib/active_support/inflector/methods.rb 9fe8e19a 176) # Creates a class name from a plural table name like Rails does for table 5ea3f284 177) # names to models. Note that this returns a string and not a Class (To 9fe8e19a 178) # convert to an actual class follow +classify+ with #constantize). 51cd6bb8 179) # 6d077205 180) # classify(\u0026#39;ham_and_eggs\u0026#39;) # =\u0026gt; \u0026#34;HamAndEgg\u0026#34; 9fe8e19a 181) # classify(\u0026#39;posts\u0026#39;) # =\u0026gt; \u0026#34;Post\u0026#34; 51cd6bb8 182) # 51cd6bb8 183) # Singular names are not handled correctly: 5ea3f284 184) # 66d6e7be 185) # classify(\u0026#39;calculus\u0026#39;) # =\u0026gt; \u0026#34;Calculus\u0026#34; 51cd6bb8 186) def classify(table_name) 51cd6bb8 187) # strip out any leading schema name 5bb1d4d2 188) camelize(singularize(table_name.to_s.sub(/.*\\./, \u0026#39;\u0026#39;.freeze))) 51cd6bb8 189) end The output of the git blame command now shows all of the file lines and their respective revisions. Now, to see a specific revision, or in other words, what each of those revisions changed, we can use the git show command. When supplied a revision hash (like 66d6e7be) as an argument, it will show you the full revision, with the author name, timestamp and the whole revision in it\u0026rsquo;s glory. Let\u0026rsquo;s see what actually changed at the latest revision that changed line 188:\ngit show 5bb1d4d2 Whoa! Did you test that? If you didn\u0026rsquo;t, it\u0026rsquo;s an awesome commit by Schneems that made a very interesting performance optimization by using frozen strings, which makes sense in our current context. But, since we are on this hypothetical debugging session, this doesn\u0026rsquo;t tell much about our current problem. So, how can we see what changes has our method under investigation gone through?\nSearching the logs Now, we are back to the git log. The question is, how can we see all the revisions that the classify method went under?\nThe git log command is quite powerful, because it has a rich list of options to apply to it. We can try to see what the git log has stored for this file, using the -p options, which means show me the patch for this entry in the git log:\ngit log -p activesupport/lib/active_support/inflector/methods.rb This will show us a big list of revisions, for every revision of this file. But, just like before, we are interested in the specific file lines. Let\u0026rsquo;s modify the command a bit, to show us what we need:\ngit log -L 176,189:activesupport/lib/active_support/inflector/methods.rb The git log command accepts the -L option, which takes the lines range and the filename as arguments. The format might be a bit weird for you, but it translates to:\ngit log -L \u0026lt;start-line\u0026gt;,\u0026lt;end-line\u0026gt;:\u0026lt;path-to-file\u0026gt; When we run this command, we can see the list of revisions for these lines, which will lead us to the first revision that created the method:\ncommit 51xd6bb829c418c5fbf75de1dfbb177233b1b154 Author: Foo Bar \u0026lt;foo@bar.com\u0026gt; Date: Tue Jun 7 19:05:09 2011 -0700 Refactor diff --git a/activesupport/lib/active_support/inflector/methods.rb b/activesupport/lib/active_support/inflector/methods.rb --- a/activesupport/lib/active_support/inflector/methods.rb +++ b/activesupport/lib/active_support/inflector/methods.rb @@ -58,0 +135,14 @@ + # Create a class name from a plural table name like Rails does for table names to models. + # Note that this returns a string and not a Class. (To convert to an actual class + # follow +classify+ with +constantize+.) + # + # Examples: + # \u0026#34;egg_and_hams\u0026#34;.classify # =\u0026gt; \u0026#34;EggAndHam\u0026#34; + # \u0026#34;posts\u0026#34;.classify # =\u0026gt; \u0026#34;Post\u0026#34; + # + # Singular names are not handled correctly: + # \u0026#34;business\u0026#34;.classify # =\u0026gt; \u0026#34;Busines\u0026#34; + def classify(table_name) + # strip out any leading schema name + camelize(singularize(table_name.to_s.sub(/.*\\./, \u0026#39;\u0026#39;))) + end Now, look at that - it\u0026rsquo;s a commit from 2011. Practically, git allows us to travel back in time. This is a very good example of why a proper commit message is paramount to regain context, because from the commit message we cannot really regain context of how this method came to be. But, on the flip side, you should never ever get frustrated about it, because you are looking at someone that basically gives away his time and energy for free, doing open source work.\nComing back from that tangent, we are not sure how the initial implementation of the classify method came to be, given that the first commit is just a refactor. Now, if you are thinking something within the lines of \u0026ldquo;but maybe, just maybe, the method was not on the line range 176 to 189, and we should look more broadly in the file\u0026rdquo;, you are very correct. The revision that we saw said \u0026ldquo;Refactor\u0026rdquo; in it\u0026rsquo;s commit message, which means that the method was actually there, but after that refactor it started to exist on that line range.\nSo, how can we confirm this? Well, believe it or not, git comes to the rescue again. The git log command accepts the -S option, which looks for the code change (additions or deletions) for the specified string as an argument to the command. This means that, if we call git log -S classify, we can see all of the commits that changed a line that contains that string.\nIf you call this command in the Rails repo, you will first see git slowing down a bit. But, when you realise that git actually parses all of the revisions in the repo to match the string, it\u0026rsquo;s actually super fast. Again, the power of git at your fingertips. So, to find the first version of the classify method, we can run:\ngit log -S \u0026#39;def classify\u0026#39; This will return all of the revisions where this method has been introduced or changed. If you were following along, the last commit in the log that you will see is:\ncommit db045dbbf60b53dbe013ef25554fd013baf88134 Author: David Heinemeier Hansson \u0026lt;foo@bar.com\u0026gt; Date: Wed Nov 24 01:04:44 2004 +0000 Initial git-svn-id: http://svn-commit.rubyonrails.org/rails/trunk@4 5ecf4fe2-1ee6-0310-87b1-e25e094e27de How cool is that? It\u0026rsquo;s the initial commit to Rails, made on a svn repo by DHH! This means that classify has been around since the beginning of (Rails) time. Now, to see the commit with all of it\u0026rsquo;s changes, we can run:\ngit show db045dbbf60b53dbe013ef25554fd013baf88134 Great, we got to the bottom of it. Now, by using the output from git log -S 'def classify' you can track the changes that have happened to this method, combined with the power of the git log -L command.\nUntil next time Sure, we didn\u0026rsquo;t really fix any bugs, because we were trying some git commands and following along the evolution of the classify method. But, nevertheless, git is a very powerful tool that we all must learn to use and to embrace. I hope this article gave you a little bit more knowledge of how useful git is.\nWhat are your favourite (or, most effective) ways of navigating through the git history?\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/learn-your-tools-navigating-git-history/","summary":"Starting a greenfield application everyday is nearly impossible, especially in your daily job. In fact, most of us are facing (somewhat) legacy codebases on a daily basis, and regaining the context of why some feature, or line of code exists in the codebase is very important. This is where git, the distributed version control system, is invaluable. Let\u0026rsquo;s dive in and see how we can use our git history and easily navigate through it.","title":"Learn your tools: Navigating your Git History"},{"content":"Recently, I have been building an API as part of my day job. Rails is a great framework to build APIs in, and it has been a joy so far. When building the responses of the API, it\u0026rsquo;s paramount to understand what HTTP statuses you should utilize, which will in return help the consumers by providing more meaningful responses.\nSure, you could always have a status property in the response JSON, which will be a human-readable status code. But, I would like you to think about HTTP status codes as a nice card on a present, with your beautiful handwriting and best wishes to whom the gift goes to. HTTP status code don\u0026rsquo;t just add more semantical correctness, but they also speak about the nature of the response.\nRails and statuses Ruby on Rails, being a great framework, adds a very nice layer of abstraction of the status codes, and allows the developers to easily use custom status codes in their responses. I am sure, at some point you have seen something like:\nrender json: @resource, status: 201 # Created While this might be sometimes redundant, the render method in Rails allows you to specify HTTP status codes for the response. But also, being very developer friendly, Rails allows you to do the same with \u0026ldquo;human readable\u0026rdquo; status codes:\nrender json: @resource, status: :created The two code samples are identical, they specify the HTTP 201 status code to the response. But, what are the available Rails status codes (as symbols) that you can use? And how does Rails actually do this?\nStatus codes The HTTP status codes list is a quite stable and static list. Although sometimes status codes are added to the list, once you learn it, keeping up to date is rather easy. The latest addition to this list is HTTP 451 - Unavailable For Legal Reasons. You can see the RFC where it was proposed here.\nSo, how does Rails knows how to create all of these symbols, so we can use them in our render methods? Well, what\u0026rsquo;s very interesting is that Rails actually doesn\u0026rsquo;t do much about this. It relies on Rack, which does all of this magic. In an irb session, type:\n\u0026gt;\u0026gt; Rack::Utils::HTTP_STATUS_CODES {100=\u0026gt;\u0026#34;Continue\u0026#34;, 101=\u0026gt;\u0026#34;Switching Protocols\u0026#34;, 102=\u0026gt;\u0026#34;Processing\u0026#34;, 200=\u0026gt;\u0026#34;OK\u0026#34;, 201=\u0026gt;\u0026#34;Created\u0026#34;, 202=\u0026gt;\u0026#34;Accepted\u0026#34;, 203=\u0026gt;\u0026#34;Non-Authoritative Information\u0026#34;, 204=\u0026gt;\u0026#34;No Content\u0026#34;, 205=\u0026gt;\u0026#34;Reset Content\u0026#34;, 206=\u0026gt;\u0026#34;Partial Content\u0026#34;, 207=\u0026gt;\u0026#34;Multi-Status\u0026#34;, 208=\u0026gt;\u0026#34;Already Reported\u0026#34;, 226=\u0026gt;\u0026#34;IM Used\u0026#34;, 300=\u0026gt;\u0026#34;Multiple Choices\u0026#34;, 301=\u0026gt;\u0026#34;Moved Permanently\u0026#34;, 302=\u0026gt;\u0026#34;Found\u0026#34;, 303=\u0026gt;\u0026#34;See Other\u0026#34;, 304=\u0026gt;\u0026#34;Not Modified\u0026#34;, 305=\u0026gt;\u0026#34;Use Proxy\u0026#34;, 307=\u0026gt;\u0026#34;Temporary Redirect\u0026#34;, 308=\u0026gt;\u0026#34;Permanent Redirect\u0026#34;, 400=\u0026gt;\u0026#34;Bad Request\u0026#34;, 401=\u0026gt;\u0026#34;Unauthorized\u0026#34;, 402=\u0026gt;\u0026#34;Payment Required\u0026#34;, 403=\u0026gt;\u0026#34;Forbidden\u0026#34;, 404=\u0026gt;\u0026#34;Not Found\u0026#34;, 405=\u0026gt;\u0026#34;Method Not Allowed\u0026#34;, 406=\u0026gt;\u0026#34;Not Acceptable\u0026#34;, 407=\u0026gt;\u0026#34;Proxy Authentication Required\u0026#34;, 408=\u0026gt;\u0026#34;Request Timeout\u0026#34;, 409=\u0026gt;\u0026#34;Conflict\u0026#34;, 410=\u0026gt;\u0026#34;Gone\u0026#34;, 411=\u0026gt;\u0026#34;Length Required\u0026#34;, 412=\u0026gt;\u0026#34;Precondition Failed\u0026#34;, 413=\u0026gt;\u0026#34;Payload Too Large\u0026#34;, 414=\u0026gt;\u0026#34;URI Too Long\u0026#34;, 415=\u0026gt;\u0026#34;Unsupported Media Type\u0026#34;, 416=\u0026gt;\u0026#34;Range Not Satisfiable\u0026#34;, 417=\u0026gt;\u0026#34;Expectation Failed\u0026#34;, 422=\u0026gt;\u0026#34;Unprocessable Entity\u0026#34;, 423=\u0026gt;\u0026#34;Locked\u0026#34;, 424=\u0026gt;\u0026#34;Failed Dependency\u0026#34;, 426=\u0026gt;\u0026#34;Upgrade Required\u0026#34;, 428=\u0026gt;\u0026#34;Precondition Required\u0026#34;, 429=\u0026gt;\u0026#34;Too Many Requests\u0026#34;, 431=\u0026gt;\u0026#34;Request Header Fields Too Large\u0026#34;, 500=\u0026gt;\u0026#34;Internal Server Error\u0026#34;, 501=\u0026gt;\u0026#34;Not Implemented\u0026#34;, 502=\u0026gt;\u0026#34;Bad Gateway\u0026#34;, 503=\u0026gt;\u0026#34;Service Unavailable\u0026#34;, 504=\u0026gt;\u0026#34;Gateway Timeout\u0026#34;, 505=\u0026gt;\u0026#34;HTTP Version Not Supported\u0026#34;, 506=\u0026gt;\u0026#34;Variant Also Negotiates\u0026#34;, 507=\u0026gt;\u0026#34;Insufficient Storage\u0026#34;, 508=\u0026gt;\u0026#34;Loop Detected\u0026#34;, 510=\u0026gt;\u0026#34;Not Extended\u0026#34;, 511=\u0026gt;\u0026#34;Network Authentication Required\u0026#34;} As you can see, the Rack::Utils::HTTP_STATUS_CODES is a Hash that has all of the HTTP status codes, with the corresponding messages. If you open the Rack::Utils documentation you can see how these are programmatically created, including the code that does the conversion. The status codes are pulled from this CSV file and are parsed using this piece of code:\nruby -ne \u0026#39;m = /^(\\d{3}),(?!Unassigned|\\(Unused\\))([^,]+)/.match($_) and puts \u0026#34;#{m[1]} =\u0026gt; \\x27#{m[2].strip}\\x27,\u0026#34;\u0026#39; Great. But, how do we get the symbolized versions of the status messages? Well, Rack does that for us as well. In an irb session, try this:\n\u0026gt;\u0026gt; Rack::Utils::SYMBOL_TO_STATUS_CODE {:continue=\u0026gt;100, :switching_protocols=\u0026gt;101, :processing=\u0026gt;102, :ok=\u0026gt;200, :created=\u0026gt;201, :accepted=\u0026gt;202, :non_authoritative_information=\u0026gt;203, :no_content=\u0026gt;204, :reset_content=\u0026gt;205, :partial_content=\u0026gt;206, :multi_status=\u0026gt;207, :already_reported=\u0026gt;208, :im_used=\u0026gt;226, :multiple_choices=\u0026gt;300, :moved_permanently=\u0026gt;301, :found=\u0026gt;302, :see_other=\u0026gt;303, :not_modified=\u0026gt;304, :use_proxy=\u0026gt;305, :temporary_redirect=\u0026gt;307, :permanent_redirect=\u0026gt;308, :bad_request=\u0026gt;400, :unauthorized=\u0026gt;401, :payment_required=\u0026gt;402, :forbidden=\u0026gt;403, :not_found=\u0026gt;404, :method_not_allowed=\u0026gt;405, :not_acceptable=\u0026gt;406, :proxy_authentication_required=\u0026gt;407, :request_timeout=\u0026gt;408, :conflict=\u0026gt;409, :gone=\u0026gt;410, :length_required=\u0026gt;411, :precondition_failed=\u0026gt;412, :payload_too_large=\u0026gt;413, :uri_too_long=\u0026gt;414, :unsupported_media_type=\u0026gt;415, :range_not_satisfiable=\u0026gt;416, :expectation_failed=\u0026gt;417, :unprocessable_entity=\u0026gt;422, :locked=\u0026gt;423, :failed_dependency=\u0026gt;424, :upgrade_required=\u0026gt;426, :precondition_required=\u0026gt;428, :too_many_requests=\u0026gt;429, :request_header_fields_too_large=\u0026gt;431, :internal_server_error=\u0026gt;500, :not_implemented=\u0026gt;501, :bad_gateway=\u0026gt;502, :service_unavailable=\u0026gt;503, :gateway_timeout=\u0026gt;504, :http_version_not_supported=\u0026gt;505, :variant_also_negotiates=\u0026gt;506, :insufficient_storage=\u0026gt;507, :loop_detected=\u0026gt;508, :not_extended=\u0026gt;510, :network_authentication_required=\u0026gt;511} As you can see, the Rack::Utils::SYMBOL_TO_STATUS_CODE constant contains all of the status codes as symbols. The documentation also shows the actual conversion, from HTTP_STATUS_CODES to SYMBOL_TO_STATUS_CODE:\nHash[*HTTP_STATUS_CODES.map { |code, message| [message.downcase.gsub(/\\s|-|\u0026#39;/, \u0026#39;_\u0026#39;).to_sym, code] }.flatten] Having all of this documentation in place, is rather easy to see how everything falls into place. Rails being a Rack app, can utilize everything that Rack provides, and this is just an example. But, how does Rails actually plugs this into its runtime and has the ability to understand what is the status code?\nA bit deeper Rails' source code, although very well documented and well structured, can still be overwhelming to someone that hasn\u0026rsquo;t spent enough time digging through. If you are a Ruby developer, I encourage you to spend some time around Rails' code - you will learn a lot, I promise you!\nSo, how does Rails know what status code to apply to the response, if you provide just the symbolized version on the status? Well, let\u0026rsquo;s start with Rails' class hierarchy, which is quite nice.\nOn the surface, or what we usually see as developers, the rendering is done in the controllers. If you open any of your applications' ApplicationController, you will see something like:\nclass ApplicationController \u0026lt; ActionController::Base ... end This means that all of our controllers are subclasses of the ActionController::Base class. If you open the source code of the ActionController::Base class, you will see some very interesting things, that can be quite informative. But for our use case, we are interested in the following:\nMODULES = [ AbstractController::Rendering, AbstractController::Translation, AbstractController::AssetPaths, Helpers, UrlFor, Redirecting, ActionView::Layouts, Rendering, Renderers::All, ConditionalGet, EtagWithTemplateDigest, Caching, MimeResponds, ImplicitRender, StrongParameters, Cookies, Flash, FormBuilder, RequestForgeryProtection, ForceSSL, Streaming, DataStreaming, HttpAuthentication::Basic::ControllerMethods, HttpAuthentication::Digest::ControllerMethods, HttpAuthentication::Token::ControllerMethods, # Before callbacks should also be executed the earliest as possible, so # also include them at the bottom. AbstractController::Callbacks, # Append rescue at the bottom to wrap as much as possible. Rescue, # Add instrumentations hooks at the bottom, to ensure they instrument # all the methods properly. Instrumentation, # Params wrapper should come before instrumentation so they are # properly showed in logs ParamsWrapper ] MODULES.each do |mod| include mod end This piece of code, actually includes all of these modules in the ActionController::Base class, which in return gives us all of the functionlities that our controllers have. Just look at the module names, like Redirecting, ActionView::Layouts, Rendering, Cookies, Flash and so on. Very self-explanatory, right?\nWell, the classes that we are interested in are AbstractController::Rendering and ActionController::Rendering. The first one is an abstract class, kind of like an interface, and the second one is the default implementation class, which contains all of the rendering mechanisms that Rails uses to render your response. When we call render in our controllers, we are executing the ActionController::Rendering#render method, which does couple of things for us: it normalizes the arguments, the options and then builds the body of the response. When it normalizes the arguments, deep inside the _normalize_render method, it contains these lines of code:\nif options[:status] options[:status] = Rack::Utils.status_code(options[:status]) end This piece of code, takes the :status option from our render call, and translates the symbol to an actual HTTP code. If we go back to Rack::Utils documentation, we can see the actual implementation of the status_code method:\n# File \u0026#39;lib/rack/utils.rb\u0026#39;, line 573 def status_code(status) if status.is_a?(Symbol) SYMBOL_TO_STATUS_CODE[status] || 500 else status.to_i end end Here\u0026rsquo;s how your status: :created gets translated to a status: 201. As you can see, although Rails' source is sometimes hard to digest, it\u0026rsquo;s very well done and navigating through it is not that hard.\nWhat about exceptions? So now we know how Rails does the expected rendering, which was created by us, developers. But, what happens when Rails hits an exception of some sort, but it still has to recover from it and return a proper HTTP status code to the client?\nAlthough at first you might expect some sort of a rescue block in ActionController::Metal class, this is not the case. Open any Rails app you have on your computer, and run in it\u0026rsquo;s root directory:\n➜ rake middleware use Rack::Sendfile use ActionDispatch::Static use ActionDispatch::LoadInterlock use ActiveSupport::Cache::Strategy::LocalCache::Middleware use Rack::Runtime use ActionDispatch::RequestId use Rails::Rack::Logger *use ActionDispatch::ShowExceptions* use ActionDispatch::DebugExceptions use ActionDispatch::RemoteIp use ActionDispatch::Reloader use ActionDispatch::Callbacks use ActiveRecord::Migration::CheckPending use ActiveRecord::ConnectionAdapters::ConnectionManagement use ActiveRecord::QueryCache use Rack::Head use Rack::ConditionalGet use Rack::ETag use ActionView::Digestor::PerRequestDigestCacheExpiry run YourApp::Application.routes Actually, the exceptions are handled in Rails' middleware, more specifically in the ActionDispatch::ShowExceptions middleware class. It wraps a group of exceptions and maps them to a specific status code. This is the code that does the mapping:\nmodule ActionDispatch class ExceptionWrapper cattr_accessor :rescue_responses @@rescue_responses = Hash.new(:internal_server_error) @@rescue_responses.merge!( \u0026#39;ActionController::RoutingError\u0026#39; =\u0026gt; :not_found, \u0026#39;AbstractController::ActionNotFound\u0026#39; =\u0026gt; :not_found, \u0026#39;ActionController::MethodNotAllowed\u0026#39; =\u0026gt; :method_not_allowed, \u0026#39;ActionController::UnknownHttpMethod\u0026#39; =\u0026gt; :method_not_allowed, \u0026#39;ActionController::NotImplemented\u0026#39; =\u0026gt; :not_implemented, \u0026#39;ActionController::UnknownFormat\u0026#39; =\u0026gt; :not_acceptable, \u0026#39;ActionController::InvalidAuthenticityToken\u0026#39; =\u0026gt; :unprocessable_entity, \u0026#39;ActionController::InvalidCrossOriginRequest\u0026#39; =\u0026gt; :unprocessable_entity, \u0026#39;ActionDispatch::ParamsParser::ParseError\u0026#39; =\u0026gt; :bad_request, \u0026#39;ActionController::BadRequest\u0026#39; =\u0026gt; :bad_request, \u0026#39;ActionController::ParameterMissing\u0026#39; =\u0026gt; :bad_request, \u0026#39;Rack::Utils::ParameterTypeError\u0026#39; =\u0026gt; :bad_request, \u0026#39;Rack::Utils::InvalidParameterError\u0026#39; =\u0026gt; :bad_request ) ... end end All of the exceptions that can occur in the request/response lifecycle are mapped to a specific status code, which will be returned by the middleware if an exception is rescued. You can see this functionality in ActionDispatch::ShowExceptions#call method, which invokes the render_exception method if an Exception is rescued:\ndef call(env) request = ActionDispatch::Request.new env @app.call(env) rescue Exception =\u0026gt; exception if request.show_exceptions? render_exception(request, exception) else raise exception end end def render_exception(request, exception) backtrace_cleaner = request.get_header \u0026#39;action_dispatch.backtrace_cleaner\u0026#39; wrapper = ExceptionWrapper.new(backtrace_cleaner, exception) status = wrapper.status_code request.set_header \u0026#34;action_dispatch.exception\u0026#34;, wrapper.exception request.set_header \u0026#34;action_dispatch.original_path\u0026#34;, request.path_info request.path_info = \u0026#34;/#{status}\u0026#34; response = @exceptions_app.call(request.env) response[1][\u0026#39;X-Cascade\u0026#39;] == \u0026#39;pass\u0026#39; ? pass_response(status) : response rescue Exception =\u0026gt; failsafe_error $stderr.puts \u0026#34;Error during failsafe response: #{failsafe_error}\\n#{failsafe_error.backtrace * \u0026#34;\\n\u0026#34;}\u0026#34; FAILSAFE_RESPONSE end Now, when the exception is being rendered, the ExceptionWrapper comes into the picture. It will wrap the exception, and return an appropriate status code, which is translated from the symbolized variant, to the number version, using:\ndef status_code self.class.status_code_for_exception(@exception.class.name) end The status_code method invokes the status_code_for_exception method, which converts the status code:\ndef self.status_code_for_exception(class_name) Rack::Utils.status_code(@@rescue_responses[class_name]) end And that\u0026rsquo;s about it. After that, the middleware stack is being executed in order to return the new response, with the exception and the proper HTTP status code attached.\nAfter all Although all of this Rails \u0026ldquo;magic\u0026rdquo; might be a bit much to digest at first, Rails' source code does quite a good job of explaining what is going on. And as you can see, there\u0026rsquo;s always something more than meets the eye. If you need to remember anything from this blogpost is that Rails does a very good (and interesting) job at handling HTTP status codes, to make your app\u0026rsquo;s responses semantically correct and client friendly.\nIf you got to this point - thanks so much for reading. I know it was a bit of a long journey, and I hope it was informative for you. Looking forward to reading your comments!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/how-rails-handles-status-codes/","summary":"Recently, I have been building an API as part of my day job. Rails is a great framework to build APIs in, and it has been a joy so far. When building the responses of the API, it\u0026rsquo;s paramount to understand what HTTP statuses you should utilize, which will in return help the consumers by providing more meaningful responses.\nSure, you could always have a status property in the response JSON, which will be a human-readable status code.","title":"How Rails handles status codes"},{"content":"Object-oriented programming and design is (or, was?) a revolutionary way of thinking and designing programs. It introduced classes, objects, inheritance, polymorphism and many other ways to think about programming. As an addition, some very smart folks identified some pitfalls and patterns that occur in object-oriented programming and put them in books. That\u0026rsquo;s how we got a list of general code smells, design patterns and refactoring patterns that we can use in our everyday work.\nBut, is it that simple? Unfortunately, some of the patterns look very similar on the surface, and have subtle differences. Also, the craft lies in applying these patterns, over learning them by heart. In the past, I\u0026rsquo;ve been always confused between the decorator pattern and the presenter pattern. And if you are (or used to be) confused by these, believe me - it\u0026rsquo;s normal. Even the naming is so similar, I would be surprised if someone new on the block is not confused. Let\u0026rsquo;s go over some examples and see what makes the similar, but different.\nDecorators If you think about these patterns in a hierarchical way, the decorator pattern would live on the top of the hierarchy. This means that, a presenter is kind of subpattern of the decorator pattern. The decorator is a general purpose pattern, whose role is to attach additional responsibilities to an object dynamically. While \u0026ldquo;dynamically attach additional responsibilities\u0026rdquo; might sounds fancy, feel free to think about it as \u0026ldquo;adding functionalities on the fly, when needed\u0026rdquo;. Also, the decorator pattern as a side-effect, provides a flexible alternative to subclassing.\nDecorating over subclassing Very often, when we have some hierarchy of classes, we use subclassing (inheritance) to add some specific functionality to our subclass, while sharing the inherited functionality from the superclass. In cases like this, the decorator pattern gives us the flexibility to apply a decorator (or more decorators) to a class, instead of creating a class hierarchy, to get additional (or more specific) functionality on the class.\nAlso, the downside of subclassing is that it\u0026rsquo;s static, which means it\u0026rsquo;s applied to a whole class. On the other hand, a decorator can be applied on runtime, meaning it will decorate the object when needed.\nExample Let\u0026rsquo;s see a small example of what a decorator might look like. Ruby makes defining decorators so flexible and easy, which makes it hard to choose which way to do it.\nOur base class will be a CoffeeMachine:\nclass CoffeeMachine attr_reader :price def initialize(price) @price = price end end Now, some coffee machines have a milk steamer attached. To make a SteamedMilkCoffeeMachineDecorator decorator, you can go couple of ways. The first one would be to make it a PORO:\nclass SteamedMilkCoffeeMachineDecorator def initialize(obj) @obj = obj end def price @obj.price + 300 end def can_steam_milk? true end end Basically, when the object is decorated, it will override the price method on the CoffeeMachine object, and it will also decorate a method can_steam_milk?. The downside of using this approach is that we will need to add some method_missing magic, because we want all of the methods that are not present on the decorator to be delegated to the decorated object.\nOr, we can use Ruby\u0026rsquo;s SimpleDelegator :\nclass SteamedMilkCoffeeMachineDecorator \u0026lt; SimpleDelegator def price super + 300 end def can_steam_milk? true end end This decorator will have the same functionality as the PORO decorator above, with the addition of delegating the methods, that are unknown to the decorator, to the wrapped object.\nUsing the decorator is plain simple:\ncoffee_machine = CoffeeMachine.new(500) with_steamer = SteamedMilkCoffeeMachineDecorator.new(coffee_machine) coffee_machine.price #=\u0026gt; 500 with_steamer.can_steam_milk? #=\u0026gt; true with_steamer.price #=\u0026gt; 800 If you would like to see a nice summary of decorator implementations, I would recommend you read Evaluating Alternative Decorator Implementations In Ruby by Dan Croak.\nThe Presenter pattern Now that we have a good grasp of the decorator pattern, let\u0026rsquo;s see what it is, and where the presenter pattern shines. As we mentioned in the beginning of this article, the presenter is a \u0026ldquo;subpattern\u0026rdquo; of the decorator. The main difference between them is how close they live to the view. Presenters live very close to the view layer, while decorators being very broad, can live near the business logic of your application.\nWithin a Rails application, presenters can be seen in various shapes. Most often, presenters are used to keep logic out of the views:\nclass Apartment attr_reader :area def initialize(sq_meters: sq_meters) @area = sq_meters end end class ApartmentPresenter \u0026lt; Decorator decorates :apartment def size if area \u0026lt; 30 \u0026#34;Small\u0026#34; elsif area \u0026lt; 50 \u0026#34;Cozy\u0026#34; elsif area \u0026lt; 80 \u0026#34;Big\u0026#34; else \u0026#34;Huge\u0026#34; end end end As you can tell, this example uses the very popular draper gem that enables easy creation of presenters. We can use our newly created presenter as:\napartment = ApartmentPresenter.new(Apartment.new(sq_meters: 75)) apartment.area #=\u0026gt; 75 apartment.size #=\u0026gt; \u0026#34;Big\u0026#34; With presenters like this, you can always simplify your views. Whatever the type of logic that you usually would put into helper methods, you can use presenters for it. Presenters are more object-oriented way to achieve the same goal.\nWrapping up If you think just a bit more broadly about decorators, you can see that basically decorators are the open/closed principle (the O, from the SOLID principles) put into practice. The open/closed principle states that a class should be open for extension, but closed for modification, which if applied in our context, easily paints the picture of how decorators extend classes.\nAs it usually goes, when something is easy to create, abusing it even easier. Gems like Draper allow us to create decorators without any hassle, so it\u0026rsquo;s pretty easy to create fat decorators or to use them in weird ways. Also, another thing to keep in mind is that although decorators help with applying SOLID principles to your code, the decorators themselves need to oblige to these principle at the same time.\nNevertheless, learning about the decorator pattern is a very useful addition to your design patterns toolbelt. Although at time using it in the proper manner can require some additional thinking (and maybe even prototyping), it can improve the flexibility of your design.\nAdditional reading These are some links that I would recommend you if you would like to learn more about the decorator pattern:\n Exhibit vs Presenter by Mike Pack Decorator Design Pattern at SourceMaking Rails Anti-Pattern: Fat Decorator by Jeroen Weeink Draper gem SimpleDelegator documentation  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/decorators-and-presenters/","summary":"Object-oriented programming and design is (or, was?) a revolutionary way of thinking and designing programs. It introduced classes, objects, inheritance, polymorphism and many other ways to think about programming. As an addition, some very smart folks identified some pitfalls and patterns that occur in object-oriented programming and put them in books. That\u0026rsquo;s how we got a list of general code smells, design patterns and refactoring patterns that we can use in our everyday work.","title":"A bit about decorators and presenters"},{"content":"Most of us use Git on a daily basis. We have all read a book (or part of a book) about Git, we learned how to do commits, track additions and removals, work with branches and so on. But, there\u0026rsquo;s so much more to Git than just committing your changes. In this post I am going to rant a bit about how we don\u0026rsquo;t utilise the power of our Git history, and how one can actually start doing it.\nWhat is history, actually? Well, you see, the word history comes from the Greek word \u0026ldquo;historia\u0026rdquo;, which means \u0026ldquo;inquiry, knowledge acquired by investigation\u0026rdquo;. The modern definition of history is \u0026ldquo;study of the past, particularly how it relates to humans\u0026rdquo;. So, while we have history books about what has happened to humans in the past, Git is the only tool we have to see the history of our source code.\nWhile in some parts, especially in the early years of humanity, history can be misguiding or unclear, the history of a codebase is very clear from the very beginning. Or is it? Think about this - if we could be able to go back in time, and watch every single thing happen and write all of these things down, how different would the world be? We would know all of the facts, instead of assumptions and relying on some manuscripts from thousands years ago.\nSo, when we are given the chance to start a new Git repo, and do the legendary initial commit, why don\u0026rsquo;t we care about what the history of the codebase will look like?\nCommit messages Picture this - you are writing this awesome feature at work, which will have a huge impact on the product. Of course, a high-impact feature almost always means high impact on the codebase. Thousands of deletions and additions, a huge diff, sits on a feature branch. The code has been well tested and it\u0026rsquo;s about to be merged in master. You press the button, and couple of minutes later it\u0026rsquo;s on production. Everyone on the team is monitoring the application and it seems that you\u0026rsquo;ve done a marvelous job. Time for beers, right? Of course!\nFast forward six months ahead, a bug pops out. You start debugging and see that there might be some edge case bug that it\u0026rsquo;s crazy hard to debug. After some debugging, you have to see when the \u0026ldquo;smelly\u0026rdquo; files were changed. You do:\ngit log -p /path/to/smelly/file While scrolling through the history you see your squashed merge commit from 6 months ago. You grab the commit hash, and do:\ngit show dc3730f72d46de2bffa62bc3e9203e4d0f4210c5 You say to yourself: \u0026ldquo;Oh, yes, I remember I did this. The deployment went so smooth without any bugs and we all felt like champions. Great, I should be able to find my way through this easily!\u0026rdquo;\nBut, can you?\nContext is king So great, you found your merge commit. But, how are you going to figure out the context of the diff? Why did some method\u0026rsquo;s signature change? What was wrong with the naming of that class that you had to change it to something else? Also, you added a new table and couple of polymorphic associations? Whoa, this must\u0026rsquo;ve been quite a bit of work. But only one sqashed merge commit.\nTough stuff right? There\u0026rsquo;s no way to regain the context easily. Well, this is where Git history should shine! While there are a ton of good articles on writing good commit messages, we usually go with \u0026ldquo;fixed a bug\u0026rdquo;, \u0026ldquo;typo\u0026rdquo; or \u0026ldquo;a very long commit message that actually doesn\u0026rsquo;t make sense\u0026rdquo;. Your repo\u0026rsquo;s history is there to help you regain context and understand a change that has been done by someone at a point of time. It\u0026rsquo;s easy as that. And there\u0026rsquo;s a plethora of options that can be applied to the git log command which can be very helpful in achieving that.\nSo, to make it easier for yourself and other people to regain context easily, be careful of what and how you commit.\nAn ideal history Let\u0026rsquo;s be frank - there\u0026rsquo;s no ideal history, but an optimal one is sure possible. If you would ask me, it falls down to two things: clean and concise commit messages and small diffs. If you can apply these two \u0026ldquo;methodologies\u0026rdquo; you can easily have an optimal Git history where you can easily regain context. And this is one of the powers of Git.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/git-history-is-underrated/","summary":"Most of us use Git on a daily basis. We have all read a book (or part of a book) about Git, we learned how to do commits, track additions and removals, work with branches and so on. But, there\u0026rsquo;s so much more to Git than just committing your changes. In this post I am going to rant a bit about how we don\u0026rsquo;t utilise the power of our Git history, and how one can actually start doing it.","title":"Git history is underrated"},{"content":"I don\u0026rsquo;t think that at this point Rubygems needs any introduction. Except if you have been living under a rock for the last 10 years or so. In that case, I think that you wouldn\u0026rsquo;t be here reading this blog. You would be having a problem understanding why someone would like to share what they are eating, or what they are doing at the moment. For the rest of you, have you heard that Rubygems is extensible? Let\u0026rsquo;s see how Rubygems does this, and how we can make our own Rubygem plugin.\nExtensibility Rubygems, since version 1.3.2 has the ability to load plugins installed in the gems collection or the $LOAD_PATH. This means that you can create a Ruby program that will extend Rubygems with your own logic. The best way to go about this is by packing it into a gem. It gets a bit of meta, I know. Basically, what I am saying is that you can have a gem which will extend Rubygems, when installed.\nNow, there are is a naming convention when it comes to plugins. They must be named rubygems_plugin and placed at the root of your gem’s #require_path. Plugins are discovered via Gem::find_files and then loaded. But, instead of dwelling into the theory, why don\u0026rsquo;t we go ahead and build one ourselves?\nTaken? No, not this guy!\nWe are going to keep it peaceful here, no guns, kidnappers and violence. We will continue talking about gems. Any time we want to create a new gem, we are in a need of a name. Let\u0026rsquo;s make a Rubygems plugin that will add a command to check if a gem name is available. The desired command will be:\ngem taken liam And the output can vary between\nThe gem name \u0026#39;liam\u0026#39; is taken. and\nIt will be yours. Oh yes. It will be yours. The gem name \u0026#39;liam\u0026#39; is available. And you guess it - the plugin\u0026rsquo;s name will be taken.\nSetting the foundations Let\u0026rsquo;s create a new gem, using the command:\nbundle new taken This will create a new barebones gem, called Taken:\ncreate taken/Gemfile create taken/.gitignore create taken/lib/taken.rb create taken/lib/taken/version.rb create taken/taken.gemspec create taken/Rakefile create taken/README.md create taken/bin/console create taken/bin/setup create taken/.travis.yml create taken/test/test_helper.rb create taken/test/taken_test.rb create taken/LICENSE.txt create taken/CODE_OF_CONDUCT.md Initializing git repo in /some/path/here/taken First, let\u0026rsquo;s do a bit of restructuring of our gem files and directories, before we start with writing some code. In the lib directory, we will need to add the rubygems_plugin.rb file, which will be picked up by Rubygems and will load our new command. Next, in the same directory, we will need to create a new directory with the name rubygems. Here, we will store all of the needed files for this particular Rubygems plugin.\nThis is what our lib directory should look like:\n➜ ls lib rubygems/ rubygems_plugin.rb That\u0026rsquo;s all. Let\u0026rsquo;s open the rubygems_plugin.rb and start writing our new command.\nDefining the new command First, in the plugin file we will need to register our new command. Rubygems has this utility class, called CommandManager. It registers and installs all the individual sub-commands supported by the gem command. If you would like to register a new command against the Gem::CommandManager instance, you need to do the following:\nrequire \u0026#34;rubygems/command_manager\u0026#34; Gem::CommandManager.instance.register_command(:taken) This will tell Rubygems that there\u0026rsquo;s a new command in town, called taken. This also expects that the command program will be stored in the lib/rubygems/commands/taken_command.rb file. Let\u0026rsquo;s create it!\nclass Gem::Commands::TakenCommand \u0026lt; Gem::Command end There are couple of key things when it comes to Rubygems plugins. The first would be that each command class should inherit from the Gem::Command class. If you look inside the actual source code of the Gem::Command class, you will notice the following comment:\n# Base class for all Gem commands. When creating a new gem command, # define #initialize, #execute, #arguments, #defaults_str, # #description and #usage (as appropriate)... This means that, in our new command we will need to implement the required methods. Let\u0026rsquo;s begin by adding the initialize method:\ndef initialize super(\u0026#34;taken\u0026#34;, \u0026#34;Checks if the gem name is taken.\u0026#34;) end Since our taken command will not need any special configurations, we can keep the initialize method short and sweet. As the first argument to the initializer, we pass the command name - in our case taken. The second argument is the short summary of the command.\nThe next method that we will need to override is the arguments methods. This method is pretty simple - it\u0026rsquo;s just used to provide details of the arguments that a command will take. In our case, that\u0026rsquo;s the gem name, whose name we would like to check. Our implementation of the method would look like:\ndef arguments # :nodoc: \u0026#34;GEMNAME gem name to check\u0026#34; end Next is the description method. All it does is return a string containing a longer description of what the command will do.\ndef description \u0026lt;\u0026lt;-EOF  The `taken` command gets all of the available gems names and check if a gem name is free or taken. EOF end These are the only methods that we need at the moment. The last one is the execute method, which will do all of the work in our new Rubygems command.\nImplementing execute This method will do most of the heavy lifting in our plugin. We can separate the flow of the command in couple of steps:\n Get the gem name from the command arguments, Throw some kind of an error if it\u0026rsquo;s blank or has multiple gem names, Fetch the latest list of gems, Find out if a gem with the name already exists, and Depending on the former step, inform the user for the result  First, let\u0026rsquo;s take the gem name from the command arguments. If you took a bit of a deeper look in the Gem::Command class, I am sure you\u0026rsquo;ve noticed the Gem::Command#get_one_gem_name method. This method will take care of the first two steps of the flow. The actual source code is the following:\n## # Get a single gem name from the command line. Fail if there is no gem name # or if there is more than one gem name given. def get_one_gem_name args = options[:args] if args.nil? or args.empty? then raise Gem::CommandLineError, \u0026#34;Please specify a gem name on the command line (e.g. gem build GEMNAME)\u0026#34; end if args.size \u0026gt; 1 then raise Gem::CommandLineError, \u0026#34;Too many gem names (#{args.join(\u0026#39;, \u0026#39;)}); please specify only one\u0026#34; end args.first end Nice and easy. Let\u0026rsquo;s add invoke this method in our execute method:\ndef execute gem_name = get_one_gem_name end The next step is to get the latest list of gems. Rubygems has a class called Gem::SpecFetcher, that handles metadata updates from remote gem repositories. Simply said, this class with retrieve gem specifications and allow you to work with them. Now, under the hood, the Gem::SpecFetcher uses a class called Gem::RemoteFetcher. This class handles communication with remote sources, like Rubygems.org. It knows how to fetch gem details and info.\nSince we would like to have our command to work with the gem specs, we need to introduce a fetcher to our execute method and utilize the Gem::SpecFetcher#detect method.\ndef execute gem_name = get_one_gem_name fetcher = Gem::SpecFetcher.fetcher spec_tuples = fetcher.detect do |name_tuple| gem_name == name_tuple.name end end The spec_tuples will be a collection of objects from the Gem::NameTuple class. If you open it\u0026rsquo;s source code, you can see that it\u0026rsquo;s a utility class that represents a gem, in a certain format. The explanation within the class is the following:\n# Represents a gem of name +name+ at +version+ of +platform+. These # wrap the data returned from the indexes. Since each Gem::NameTuple object has a name method, we compare the gem name that was provided by the user with the name from the gem spec. If it matches, that means that there\u0026rsquo;s already a gem with that name.\ndef execute gem_name = get_one_gem_name fetcher = Gem::SpecFetcher.fetcher spec_tuples = fetcher.detect do |name_tuple| gem_name == name_tuple.name end if name_free?(spec_tuples) $stdout.puts \u0026#34;It will be yours. Oh yes. It will be yours. The gem name \u0026#39;#{name}\u0026#39; is available.\u0026#34; else $stdout.puts \u0026#34;The gem name \u0026#39;#{name}\u0026#39; is taken.\u0026#34; end private def name_free?(spec) !spec.flatten.length.zero? end end This is it. We check if the the spec_tuples length is not zero and we show the user the appropriate message.\nBeyond the command If you have been following this small tutorial, I am sure you are starting to get an idea of how you can utilize Rubygems' API to build a plugin. You could pack all of this logic into a gem, add some tests and publish it. Then people can install the gem and use the newly created taken command.\nBut, this command is just scratching the surface of the possibilities that Rubygems offers. And as a side-win, the Rubygems code is really great. In the Git logs you can see names that are well respected in the Ruby community. You can learn how they\u0026rsquo;ve modeled their exceptions. Or maybe, how they do the security or the HTTP layer.\nHave you ever done any contributions to Rubygems? Or maybe you have written a Rubygems plugin? Or maybe, you would like to write one but you have run out of ideas? Hit me up in the comments!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/your-first-rubygem-plugin/","summary":"I don\u0026rsquo;t think that at this point Rubygems needs any introduction. Except if you have been living under a rock for the last 10 years or so. In that case, I think that you wouldn\u0026rsquo;t be here reading this blog. You would be having a problem understanding why someone would like to share what they are eating, or what they are doing at the moment. For the rest of you, have you heard that Rubygems is extensible?","title":"Write your first Rubygems plugin"},{"content":"Imagine you just woke up, took a shower and you immediately go to your coffee machine to make that strong, large, morning, double-shot, extra-spice-and-everything-nice cup of coffee. Sure, you go to the machine, press some buttons and the next thing you know, you are waiting for the coffee to start pouring into your cup. And then, something\u0026rsquo;s not right, and something starts to smell bad. A morning nightmare, right?\nNothing Works All the Time You know, most of the things in our daily lives do not work at 100%. The nice thing is that we never expect them to do that. Yeah, sure, if something breaks, like that coffee machine, it might give us a slight frustration (especially in the morning), but we won\u0026rsquo;t lose our shit to it. We usually either try to fix it, of course, by turning it off and on again. Or we just throw it away and buy a new thing. And as a side-win, it\u0026rsquo;s what drives our economy forward.\nBut what\u0026rsquo;s really frustrating for us developers is that software does an exceptionally good job of misbehaving. Now this is where things can get hairy. Our software is not always prepared for errors. In fact we usually think about our code as this bulletproof titanium brick that does not fail under any circumstances. But more then often, our bulletproof software can get nuked. Houston, we have a problem.\nHandling Exceptions What I really dislike about the whole culture in programming about exceptions, is that it\u0026rsquo;s being taught as this really unimportant thing. We study them briefly, usually one chapter in a book and we think we are done with it. Yeah, until we get hit by a \u0026ldquo;broken coffee machine\u0026rdquo; problem and then we try to deal with them.\nIn Ruby, we all know how to deal with exceptions. Sure, the syntax is nice:\nbegin # Some HTTP requests here... rescue Timeout::Error =\u0026gt; e Logger.debug \u0026#34;Timeout error:\u0026#34; Logger.debug e.message end We wrap the code that we suspect will fail in a begin \u0026amp; rescue blocks and we can properly handle the exceptions. Sure, this works well, but I would like you to focus on something else for this article - the exception class.\nWhat should we rescue? I am sure you have seen some piece of code where someone knew that an exception could be thrown, and that person thinks they\u0026rsquo;ve done a good job by rescuing Exception.\nbegin # Read a file # Parse the file # Send the parsed data to API rescue Exception =\u0026gt; e Logger.debug \u0026#34;Exceptions raised:\u0026#34; Logger.debug e.message end Right, all good? Sure, we could have done more with the rescue block, but at least we log the exceptions somewhere so we can more easily view them in the future. There\u0026rsquo;s a problem with this approach - you are essentially rescuing a metric ton of Ruby exceptions. And if this is a piece of code in a Rails application - the list is even longer. You are looking at couple of hundred exception types!\nAnd if you think that it\u0026rsquo;s fine, I have a question for you. Do you take the same measures/actions when your car:\n Has a blown up tire? The engine does not want to start? Door is frozen, because it\u0026rsquo;s freezing cold outside?  Of course you don\u0026rsquo;t. Fixing a blown tire by looking under the hood would be pretty silly, right? Well, it\u0026rsquo;s the same as software - whatever goes wrong we need to act accordingly, without generalisations.\nFor example, if a file will not open, there can be multiple reasons:\n Permissions Corrupt file The stream is prematurely closed, or was never opened File does not exist  Having all of these things in mind, we would need to write something like this:\nrequire \u0026#39;json\u0026#39; begin contents = File.read(\u0026#34;users.json\u0026#34;) JSON.parse(contents) rescue IOError =\u0026gt; e $stdout.puts e.message # rescue Errno::EACCES =\u0026gt; e $stdout.puts e.message $stdout.puts \u0026#34;Will try to fix permissions and retry...\u0026#34; system(\u0026#39;chmod +r users.json\u0026#39;) retry rescue Errno::ENOENT =\u0026gt; e $stdout.puts e.message # File does not exist exit(1) end Sure, this might seem a bit overcomplicated for most of the cases that you will see in your day job, but I think that it paints the picture well. Our software should know how to take care of different cases of misbehaviour.\nOutro As a rule of thumb, you should keep your rescues short and sweet. And very specific. You should think about in what ways your program can misbehave and how you can recover from that error. Sure, it definitely is not that easy, but if your throw couple of random values at your code in the tests, you can easily spot some of the misbehaviours.\nIn the end, I\u0026rsquo;ll leave you with this quote, from Betrand Meyer, from his book Object Oriented Software Construction:\n In practice, the rescue clause should be a short sequence of simple instructions designed to bring the object back to a stable state and to either retry the operation or terminate with failure.\n And if you want to learn more about exception handling in Ruby, I recommend Exceptional Ruby, by Avdi Grimm.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/you-cant-rescue-them-all/","summary":"Imagine you just woke up, took a shower and you immediately go to your coffee machine to make that strong, large, morning, double-shot, extra-spice-and-everything-nice cup of coffee. Sure, you go to the machine, press some buttons and the next thing you know, you are waiting for the coffee to start pouring into your cup. And then, something\u0026rsquo;s not right, and something starts to smell bad. A morning nightmare, right?\nNothing Works All the Time You know, most of the things in our daily lives do not work at 100%.","title":"You Can't Rescue Them All"},{"content":"We\u0026rsquo;ve all been at this point where we have bloated our classes with primitive values all over the place. Usually, we drop in primitive constants that, for whatever reason, we think that are a good fit to the class. Or sometimes, we just dump primitive values instead of small objects, thinking \u0026ldquo;it\u0026rsquo;s okay, it\u0026rsquo;s just an attribute in the class\u0026rdquo;. But, does it always make sense?\nThe problem Say we have a project for a finance journalist who wants us to automate his text editor to do some random fixes to his texts, on the fly. The automation is basically adding his name and date to the footer of the text that he\u0026rsquo;s writing, and to change currencies abbreviations to symbols. The good thing for us is that his editor is written in Ruby, and has the ability to add custom I/O streams to it\u0026rsquo;s I/O stack.\nSo, our specification for this I/O stream, is:\n limit text to no more than 10000 words append journalist name to end of article swap popular currency names abbreviations with symbols  After a bit of work, we come up with this quick hack for a I/O stream:\nrequire \u0026#39;stringio\u0026#39; class FinanceIO class MaximumLengthExceeded \u0026lt; StandardError; end MAX_WORDS = 10000 MIN_WORDS = 2000 AUTHOR_NAME = \u0026#34;John Smith\u0026#34; AUTHOR_EMAIL = \u0026#34;j.smith@nytimes.com\u0026#34; CURRENCIES = [ [\u0026#34;USD\u0026#34;, \u0026#34;$\u0026#34;], [\u0026#34;GBP\u0026#34;, \u0026#34;£\u0026#34;], [\u0026#34;JPY\u0026#34;, \u0026#34;¥\u0026#34;], [\u0026#34;CHF\u0026#34;, \u0026#34;₣\u0026#34;], [\u0026#34;EUR\u0026#34;, \u0026#34;€\u0026#34;], [\u0026#34;INR\u0026#34;, \u0026#34;₹\u0026#34;], [\u0026#34;GEN\u0026#34;, \u0026#34;¤\u0026#34;] # General currency sign ] def initialize @io = StringIO.new end def puts(arg) if @io.string.split(\u0026#34;\u0026#34;).length \u0026gt;= MAX_WORDS || @io.string.split(\u0026#34;\u0026#34;).length =\u0026lt; MIN_WORDS raise TextLengthExceeded.new(\u0026#34;The text must be within #{MIN_WORDS}and #{MAX_WORDS}words.\u0026#34;) else CURRENCIES.each do |abbrv, symbol| arg.gsub!(abbrv,symbol) end @io.puts(arg) end end def on_exit append_author end def method_missing(method_name, *args, \u0026amp;block) if @io.respond_to?(method_name) @io.send(method_name, *args) else super(method_name, *args, \u0026amp;block) end end private def append_author @io.puts(\u0026#34;\\n\u0026#34;) @io.puts(AUTHOR_NAME) @io.puts(\u0026#34;\\n\u0026#34;) @io.puts(AUTHOR_EMAIL) @io.puts(\u0026#34;\\n\u0026#34;) end end The FinanceIO class is a wrapper around a StringIO, which overrides a couple of methods, but relays any other method calls to the wrapped StringIO object. This allows us to do our work easily, while not breaking when any object of the I/O stack tries to call a built-in method on our object.\nLet\u0026rsquo;s break down the example. The MAX_WORDS and MIN_WORDS is a limitation that our client (the journalist) has been given by the newspaper he works for, or in other words, his articles cannot be loger than 10000 words. The AUTHOR_NAME constant is the name of our author. We don\u0026rsquo;t need to enable customization for this piece of data, because our client wanted to make our life easier by agreeing that he will not change his name any time soon. The AUTHOR_EMAIL constant is the author public email address. Next, the CURRENCIES constant is a two-dimensional array which contains the abbreviations and the symbols of the most popular currencies that the journalist uses while writing his finance articles.\nMost of the functionality described in the spec is done within the FinanceIO#puts method:\ndef puts(arg) if @io.string.split(\u0026#34;\u0026#34;).length \u0026gt;= MAX_WORDS || @io.string.split(\u0026#34;\u0026#34;).length =\u0026lt; MIN_WORDS raise TextLengthExceeded.new(\u0026#34;The text must be within #{@limitations.min_words}and #{@limitations.max_words}words.\u0026#34;) else CURRENCIES.each do |abbrv, symbol| arg.gsub!(abbrv,symbol) end @io.puts(arg) end end The puts method takes a string as an argument, and saves it to the stream. But, before it does that, it checks if the text is longer than 10000 words. If it is, it will raise an exception that the text editor will handle gracefully. If not, it will carry on to substitute any of the currency abbreviations in the text with the corresponding symbol.\nAlso, the FinanceIO#on_exit is a method which will append the author name in the footer of the text.\ndef on_exit append_author end This will get automatically invoked by the editor, as an callback before the journalist closes his editor.\nThis will surely work, and it complies with our imaginary text editor. Sure, it might be a bit dirty, but it does the trick. Now, a question to ourselves - what should we do about the data in the constants? There seems to be much behaviour in connection with these constants. Aside of that, it\u0026rsquo;s just plain data and it doesn\u0026rsquo;t really add too much noise to our class and the functionality is easy to follow\u0026hellip; right?\nThe Code Smell Well, sure, the fields don\u0026rsquo;t do much noise, but this is exactly the way of thinking that creates these code smells. You could argue that the FinanceIO class is pretty simple to follow, and you would be right. The problem lies in the practice, which will eventually bloat the class with so much \u0026ldquo;static\u0026rdquo; data, to a point of total confusion. Sure, our journalist could be happy with our hack, which is great, but he will surely come back one day with more specs for customizations. That\u0026rsquo;s what usually happy customers do - they return for more stuff.\nAlthough this code smell is not that dangerous at first, it will cause havoc in the near future. The Primitive Obsession code smell is one of the simplest ones. It can be spotted in classes where primitives are used to \u0026ldquo;simulate\u0026rdquo; types. This means that instead of separating a data type for the primitives, we keep some sort of a primitive value, whether it\u0026rsquo;s a string, or a number or an array of any values. As a next step, we usually add simple names to these primitive values (see our class above), and we keep on thinking that it is very clear what these values do.\nAnother occurance of this code smell is creating a \u0026ldquo;field simulation\u0026rdquo;. This happens when we add an array of primitive values to the class, which contains some data that is used in the class logic, somewhere.\nSure, three to five values are easy to track. What happens when you get to twenty? Thirty maybe? Yeah, I have seen some classes where these primitive values are all over the place, and let me tell you, it\u0026rsquo;s no fun!\nSo, how can we avoid and/or detect this code smell? Let\u0026rsquo;s see!\nRefactoring When it comes to refactoring this code smell, you can take multiple paths. For example, if you have a large variety of these primitives, you can always look for logical links between them. Another way is, if these primitive values are used as method parameters, we could introduce a parameter objects, or we could change arrays into objects as well. There are more forms of this code smell, but let\u0026rsquo;s tackle them one by one and see the approaches to refactoring.\nLogical linking Like we saw earlier, often these primitive values have some logial link between them. Although our list of primitives is not that long, you can see the logical link between AUTHOR_NAME and AUTHOR_EMAIL, right?\nSince the logical link between these two primitives and the FinanceIO#append_author method are easily noticable, we know that these two constants and the method should be grouped in some way. Here, we can refactor the values with an object, which will be called Author:\nclass Author attr_reader :first_name, :last_name, :email def initialize(first_name = \u0026#34;John\u0026#34;, last_name = \u0026#34;Smith\u0026#34;, email = \u0026#34;j.smith@nytimes.com\u0026#34;) @first_name = first_name @last_name = last_name @email = email end def full_name last_name + \u0026#34; \u0026#34; + first_name end end Pretty straight forward. Now, if you think about it, you can notice that the FinanceIO#append_author is basically the signature of the journalist. So, we can extract that method into our new Author class:\ndef signature %Q{ #{full_name}#{email}} end Now, having the behaviour and the values extracted to a separate class, we can refactor FinanceIO a bit:\nrequire \u0026#39;stringio\u0026#39; class FinanceIO class MaximumLengthExceeded \u0026lt; StandardError; end MAX_WORDS = 10000 MIN_WORDS = 2000 CURRENCIES = [ [\u0026#34;USD\u0026#34;, \u0026#34;$\u0026#34;], [\u0026#34;GBP\u0026#34;, \u0026#34;£\u0026#34;], [\u0026#34;JPY\u0026#34;, \u0026#34;¥\u0026#34;], [\u0026#34;CHF\u0026#34;, \u0026#34;₣\u0026#34;], [\u0026#34;EUR\u0026#34;, \u0026#34;€\u0026#34;], [\u0026#34;INR\u0026#34;, \u0026#34;₹\u0026#34;], [\u0026#34;GEN\u0026#34;, \u0026#34;¤\u0026#34;] # General currency sign ] def initialize @io = StringIO.new @author = Author.new end def puts(arg) if @io.string.split(\u0026#34;\u0026#34;).length \u0026gt;= MAX_WORDS || @io.string.split(\u0026#34;\u0026#34;).length =\u0026lt; MIN_WORDS raise TextLengthExceeded.new(\u0026#34;The text must be within #{MIN_WORDS}and #{MAX_WORDS}words.\u0026#34;) else CURRENCIES.each do |abbrv, symbol| arg.gsub!(abbrv,symbol) end @io.puts(arg) end end def on_exit @io.puts(@author.signature) end def method_missing(method_name, *args, \u0026amp;block) if @io.respond_to?(method_name) @io.send(method_name, *args) else super(method_name, *args, \u0026amp;block) end end end Much cleaner, right? We have the values and the behaviour extracted to a separate class, and the Author#signature method clearly shows that the behaviour revolving the author signature should be a part of the Author class.\nNow, since the first name, last name and email are set to default parameters on the Author#initialize method, we could go a step further and extract them to a DefaultAuthor subclass:\nclass DefaultAuthor \u0026lt; Author def initialize super(\u0026#34;John\u0026#34;, \u0026#34;Smith\u0026#34;, \u0026#34;j.smith@nytimes.com\u0026#34;) end end Having this class, we can easily customize our FinanceIO stream and use a non-default author just by tweaking the constructor by using dependency injection:\nclass FinanceIO # snipped.. def initialize(author = DefaultAuthor.new) @io = StringIO.new @author = author end # snipped.. end Replacing the array with\u0026hellip; something meaningful When we got to this step I assume you were wondering what we will do with the CURRENCIES two-dimensional array. Well, let\u0026rsquo;s disect the array a bit and see what we are actually dealing with.\nWell, just like the array name states, we are dealing with a bunch of currencies here, ergo, we need a Currency class to encapsulate the abbreviation and the symbol:\nclass Currency attr_reader :abbreviation, :symbol def initialize(abbreviation, symbol) @abbreviation = abbreviation @symbol = symbol end end So, how can we eliminate the array from the FinanceIO class and move it somewhere else? Let\u0026rsquo;s start moving the array step by step - first, by extracting it into the Currency class. We will move the collection and we will also add a utility method Currency.all which will return a collection of all the currencies, as Currency objects:\nclass Currency DEFAULT_CURRENCIES = [ [\u0026#34;USD\u0026#34;, \u0026#34;$\u0026#34;], [\u0026#34;GBP\u0026#34;, \u0026#34;£\u0026#34;], [\u0026#34;JPY\u0026#34;, \u0026#34;¥\u0026#34;], [\u0026#34;CHF\u0026#34;, \u0026#34;₣\u0026#34;], [\u0026#34;EUR\u0026#34;, \u0026#34;€\u0026#34;], [\u0026#34;INR\u0026#34;, \u0026#34;₹\u0026#34;], [\u0026#34;GEN\u0026#34;, \u0026#34;¤\u0026#34;] ] def self.all(currencies_list = DEFAULT_CURRENCIES) currencies_list.collect do |abbr, sym| new(abbr, sym) end end attr_reader :abbreviation, :symbol def initialize(abbreviation, symbol) @abbreviation = abbreviation @symbol = symbol end end Now, refactoring the FinanceIO#puts method should be straight forward:\ndef puts(arg) if @io.string.split(\u0026#34;\u0026#34;).length \u0026gt;= MAX_WORDS || @io.string.split(\u0026#34;\u0026#34;).length =\u0026lt; MIN_WORDS return MaximumLengthExceeded.new(\u0026#34;You\u0026#39;ve reached the maximum length.\u0026#34;) else Currency.all.each do |currency| arg.gsub!(currency.abbreviation, currency.symbol) end @io.puts(arg) end end Sure, this could work, but we still have a bit of polution in the Currency class. What we could do, instead of keeping the currencies as a constant, we could move them to a method, or better yet, move them to a new class, with a method that would return all of them:\nclass DefaultCurrencies def self.all [ [\u0026#34;USD\u0026#34;, \u0026#34;$\u0026#34;], [\u0026#34;GBP\u0026#34;, \u0026#34;£\u0026#34;], [\u0026#34;JPY\u0026#34;, \u0026#34;¥\u0026#34;], [\u0026#34;CHF\u0026#34;, \u0026#34;₣\u0026#34;], [\u0026#34;EUR\u0026#34;, \u0026#34;€\u0026#34;], [\u0026#34;INR\u0026#34;, \u0026#34;₹\u0026#34;], [\u0026#34;GEN\u0026#34;, \u0026#34;¤\u0026#34;] ] end end Then, adding this class as a depenency to the Currency class will be pretty easy. But also, uncoupling it will be also easy, if we decide to move these hardcoded primitive values to a database:\nclass Currency def self.all DefaultCurrencies.all.collect do |abbr, sym| new(abbr, sym) end end attr_reader :abbreviation, :symbol def initialize(abbreviation, symbol) @abbreviation = abbreviation @symbol = symbol end end With this step we have encapsulated our collection of data, and made it easy to replace in next iteration of our program. Our Currency class only depends on a class method, which would return a two-dimensional array with the currencies data. With this in place, we can come back to the FinanceIO class and polish it up.\nIntroducing a parameter object Let\u0026rsquo;s look at the state of our FinanceIO class now. The only leftovers from our refactoring are the MAX_WORDS and MIN_WORDS primitives. Their purpose is to limit the length of the text that the author can write. Let\u0026rsquo;s see how we can refactor it out of the class.\nIf you look at the FinanceIO#puts method, you can notice that these constants are used only as a parameter, to check if the length words are within the limit.\nHaving this in mind, we can extract a Parameter Object. Parameter objects are usually like containers for data that has same or similar role. Our limitation primitives are a nice example - they do not belong to the FinanceIO class, but their only purpose is to validate the input of the user. Let\u0026rsquo;s extract them out to a separate class:\nclass EditorialLimitations attr_reader :max_words, :min_words def initialize @max_words = 10000 @min_words = 2000 end def within?(text) text_length = words(text) text_length \u0026gt;= @min_words \u0026amp;\u0026amp; text_length =\u0026lt; @max_words end private def words(txt) txt.split(\u0026#34;\u0026#34;).length end end As you can see, by extracting this parameter object, we are even able to extract the logic which will validate the text of the journalist. Now, let\u0026rsquo;s use our newly created class in the program:\nrequire \u0026#39;stringio\u0026#39; class FinanceIO class MaximumLengthExceeded \u0026lt; StandardError; end def initialize @io = StringIO.new @author = Author.new @limitations = EditorialLimitations.new end def puts(arg) if @limitations.within?(io.string) Currency.all.each do |currency| arg.gsub!(currency.abbreviation, currency.symbol) end else raise TextLengthExceeded.new(\u0026#34;The text must be within #{@limitations.min_words}and #{@limitations.max_words}words.\u0026#34;) end @io.puts(arg) end def on_exit @io.puts(@author.signature) end def method_missing(method_name, *args, \u0026amp;block) if @io.respond_to?(method_name) @io.send(method_name, *args) else super(method_name, *args, \u0026amp;block) end end end As you can see, although there\u0026rsquo;s still a lot going on in the FinanceIO#puts method, it\u0026rsquo;s much easier to understand what\u0026rsquo;s going on. Also, if we would write tests around this code, testing would be much easier.\nOutro We could do more refactoring here, especially in the FinanceIO#puts method, but for the scope of this article we will stop there. I encourage you to carry on with refactoring the code, and writing some tests - practice makes it perfect, doesn\u0026rsquo;t it?\nUntil next time!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/primitive-obsession-ruby/","summary":"We\u0026rsquo;ve all been at this point where we have bloated our classes with primitive values all over the place. Usually, we drop in primitive constants that, for whatever reason, we think that are a good fit to the class. Or sometimes, we just dump primitive values instead of small objects, thinking \u0026ldquo;it\u0026rsquo;s okay, it\u0026rsquo;s just an attribute in the class\u0026rdquo;. But, does it always make sense?\nThe problem Say we have a project for a finance journalist who wants us to automate his text editor to do some random fixes to his texts, on the fly.","title":"Refactoring in Ruby: Primitive Obsession"},{"content":"Indexes in relational databases are a very imporatant feature, that reduce the cost of our lookup queries. In the last post on the basics of indexes in PostgreSQL, we covered the fundamentals and saw how we can create an index on a table and measure it\u0026rsquo;s impact on our queries. In this post, we will take a dive into the inner workings and some implmentation details of the most used index type in PostgreSQL - the B-Tree index.\nWhat is B-Tree? From Wikipedia\u0026rsquo;s page on B-Tree:\n In computer science, a B-tree is a self-balancing tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.\n Awesome, right? Basically, it\u0026rsquo;s a data structure that sorts itself. That\u0026rsquo;s why it\u0026rsquo;s self-balancing - it chooses it\u0026rsquo;s shape on it\u0026rsquo;s own.\n The B-tree is a generalization of a binary search tree in that a node can have more than two children. Unlike self-balancing binary search trees, the B- tree is optimized for systems that read and write large blocks of data.\n Unlike regular binary trees, the B-Tree can have multiple leaves, which it balances on it\u0026rsquo;s own. Also, it\u0026rsquo;s implementations are I/O optimized, which makes them suitable for database indexes.\n B-trees are a good example of a data structure for external memory. It is commonly used in databases and filesystems.\n Now, there\u0026rsquo;s plenty to know about B-Trees. Knowing how they work is pretty interesting, so let\u0026rsquo;s check it out.\nFunctionality As a disclaimer before we start with the B-Tree as a self-balancing data structure, I would like to inform you that there is a lot of CS theory about the B-Tree, which we will not cover in this section. For example, you might want to look first at binary trees, 23-trees and 234-trees before you dive into B-Trees. Nevertheless, what we will cover here will be sufficient for you to understand how the B-Tree index works.\nHaving that out of the way, think of a binary tree. In binary trees, each node can have a maximum of two children, hence the name - binary.\nA Binary TreeWell, a B-Tree is a tree where each node can have multiple children, or better said, a B-Tree can have N children. While in binary search trees each node can have one value, B-Trees have the concept of keys. Keys are like a list of values, that each of the nodes will hold.\nB-Trees also have the concept of order, where for B-Trees an order of 3 means that each non-leaf node of the tree can have a maximum of 3 children. Having that in mind, this means that each node can have two (3-1) keys.\nConfusing? Well, think about this: on a non-leaf node with keys 5, 10, you can add three nodes:\n one node, with values smaller than 5 one node, with values between 5 and 10 and one node, with values larger than 10  Let\u0026rsquo;s draw it out:\nThe most important thing about B-Trees is their balaning aspect. The concept revolves on the fact that each node has keys, like in the example above. The way B-Trees balance themselves is really interesting, and the keys are the most important aspect of this this functionality.\nBasically, whenever a new item (or, in our case, a number) is added, the B-Tree finds the appropriate place (or, node) for the item to go in. For example, if we want to add the number 6, the B-Tree will \u0026ldquo;ask the root node\u0026rdquo;, in what node should it push the number in. \u0026ldquo;Asking\u0026rdquo; is nothing more than comparing the new number with the keys of the node. Since the number 6 is larger then 5, but smaller then the number 10 (which are the root node keys), it will create a new node just below the root node:\nWith this mechanism, the B-Tree is always ordered and looking up a value in it is rather cheap. There are multiple implementations of B-Trees. For this post, it\u0026rsquo;s nice to know that PostgreSQL uses the B-Tree implementation of the \u0026ldquo;Lehman and Yao\u0026rsquo;s high-concurrency B-tree management algorithm\u0026rdquo;. You can read the actual paper here{:target=\u0026quot;_blank\u0026quot;}.\nBut, how is this relevant to the B-Tree indexes in PostgreSQL?\nB-Trees and PostgreSQL Indexes in PostgreSQL, simply put, are a replica of the data on the column(s) that is/are indexed. The only difference is in the data order - the replica of the data is sorted, which allows PostgreSQL to quickly find and retrieve the data. For example, when you search for a record in a table, where the column by which you are searching is indexed, the index decreases the cost of the query because PostgreSQL looks up in the index and can easily find the location of the data on disk.\nThe B-Tree data structure falls really nice into place, when you recall that the index is ordered. Under the hood, indexes are B-Trees, but really big ones. Due to the nature of the B-Tree data structure, whenever a new record is added on the indexed table it knows how to rebalance and keep the order of the records in it.\nLimitations Almost in all use cases, the power of indexes is noticable on large amounts of data. This means that the indexes will have to be as big as the actual data tables. Or does it?\nImagine if we are dealing with billions of records. This means that the index tables will have the billions of records stored in an ordered fashion. Okay, PostgreSQL could handle that. But, can you imagine how long would an INSERT command take? Adding the record in the data table will take really long, because the index will have to add the new record in the correct place, to keep the order of the indexes. Due to this limitation, the implementation of the B-Tree index keeps page files, which simply put, are nodes on a big B-Tree data structure.\nAlthough each index is a whole, this paging mechanism adds a separation of the data in the index, while still keeping the order. In that case, instead of dumping the whole index into memory just to add a single record, PostgreSQL finds the page where the new record should be added and writes the indexed value into it.\nMy explanation is quite abstract, but the aim of this article was to introduce the B-Tree data structure and how it falls into place with PostgreSQL. If you would like to read more details on the implementation, check Discovering the Computer Science Behind Postgres Indexes from Pat Shaughnessy. Actually, if I knew of the existence of his article before I started writing this article, I might have not even written it.\nUsing a B-Tree index Having the workings of B-Tree index aside, let\u0026rsquo;s see how to use it. The command to add an index to a column is:\nCREATE INDEX name ON table USING btree (column); Or, since the btree index is the default one, we can omit the USING part of the command:\nCREATE INDEX name ON table; This will create a BTree index on the name column in the table table.\nOutro In this article we took an overview on one of the most popular indexes in PostgreSQL. We saw what is the difference between Binary Search Trees and B-Trees, and how their behaviour translates into PostgreSQL. Take note, there is a ton of detail that I had to omit due to the length of the article and the target audience.\nLinks If you would like to dig in deeper into B-Tree, whether the index or the data structure, here are some useful links:\n Efficient Locking for Concurrent Operations on B-Trees B-Trees Anatomy of an SQL index B-Tree on Wikipedia  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/postgresql-indexes-btree/","summary":"Indexes in relational databases are a very imporatant feature, that reduce the cost of our lookup queries. In the last post on the basics of indexes in PostgreSQL, we covered the fundamentals and saw how we can create an index on a table and measure it\u0026rsquo;s impact on our queries. In this post, we will take a dive into the inner workings and some implmentation details of the most used index type in PostgreSQL - the B-Tree index.","title":"PostgreSQL Indexes: B-Tree"},{"content":"We have all heard about indexes. Yeah, that thing that it\u0026rsquo;s automatically added to the Primary Key column that enables fast data retrieval and stuff. Sure, but have you ever asked yourself if there are multiple types or implementations of indexes? Or maybe, what type of indexes your favourite RDBMS implements? In this blog post, we will take a step back to the beginning, exploring what indexes are, what is their role, types of indexes, metrics and so on. And all of this in PostgreSQL.\nWhat\u0026rsquo;s the Problem? When explaining indexes, everyone uses the phonebook analogy. The problem is that the phonebook analogy is so good, thinking of any other one is a waste of time. But, before we jump into indexes, we need to understand the problem that they solve.\nSo, think of a phonebook. The phonebook is a book with all of the names and phone numbers of the people in a city or a country. Now, let\u0026rsquo;s say we want to find John Doe\u0026rsquo;s phone number. Knowing that the phone book is alphabetically ordered we look for the page where the surname Doe is. There, we look for John and his phone number. Good, that is efficient enough for a phonebook.\nNow, imagine if our phonebook was not alphabetically sorted? Hell, right? We would need to go through all of the pages, reading every name in the phonebook, until we find our John Doe. This is called sequential searching. You go over all of the records, until you find the person whose phone number you are looking for.\nOne does not need to be a genius to understand that this is super inefficient. The problem with database tables is that the data in them is unordered. If we had a people table, containing all information about people, to lookup the person with the full name John Doe, we would need to execute:\nSELECT * FROM people WHERE first_name = \u0026#34;John\u0026#34; and last_name = \u0026#34;Doe\u0026#34;; Easy enough. But although this query is fast, under the hood, the database will hit every row of the table, until it finds the record it is looking for. I am sure your side-project won\u0026rsquo;t have this problem soon, but imagine a table with millions of records, without indexes. Data retrieval would take seconds, sometimes maybe minutes. Imagine waiting 30 seconds for a list of videos on YouTube?\nIntroducing Indexes I guess the phonebook example painted the picture well for you. Now, what\u0026rsquo;s interesting is that the phonebooks, actually have indexes. But, they are different. They are not like a book index, which shows what chapter starts on which page. Or maybe they do, I haven\u0026rsquo;t seen a phonebook in a while.\nClustered Indexes Nevertheless, indexes have different architectures/indexing methods. And the phonebook has a clustered index. Clustering means that the data is in a distinct order, resulting the row data to be stored in order. If this confuses you, think again about the phonebook - the records in the book are ordered alphabetically. Regardless of how simple this might seem to you, it\u0026rsquo;s a clustered index. The way the data is ordered (clusters) makes it really easy to search and find the needed phone number. So, a clustered index is an index which physically orders the data (the actual bits on disk) in a certain way, and when new data arrives it is saved in the same order.\nA caveat with the clustered indexes is that only one can be created on a given database table. That occurs due to their nature - they enforce a data order. Also, clustered indexes increase the write time, because when new data arrives, all of the data has to be rearranged. But on the bright side - they can greatly increase the reading speed of the table.\nTo summarize - clustered indexes order the data physically (on disk) in clusters.\nNon-clustered Indexes I know you guessed it - if there are clustered indexes, the opposite type has to exist. And you are right, non-clustered indexes are a thing. They are the type that we know to use most, but I guess not everyone knows how their implementation works.\nNon-clustered indexes are indexes that keep a separate ordering list that has pointers to the physical rows. It\u0026rsquo;s basically like a book index, it knows on what page a certain chapter starts and ends. Now, unlike the clustered index, a table can have many non-clustered indexes. But, the caveat with these indexes is that each new index will increase the time it takes to write new records.\nSo, to summarize - non-clustered indexes do not order the data physically, they just keep a list of the data order.\nIndexing effects So, after we covered the index architecture, we can explore how indexes work in PostgreSQL. But first things first - let\u0026rsquo;s play with some indexes.\nIndexes in PostgreSQL are manipulated via a set of commands. For this example, I will use a table with 1000 records, representing 1000 users. The table schema will look like this:\n+-------------------------------------------------+ | Table \u0026#34;public.users\u0026#34; | +-------------------------------------------------+ | Column | Type | Modifiers | +------------+------------------------+-----------+ | id | integer | not null | | first_name | character varying(60) | | | last_name | character varying(60) | | | email | character varying(120) | | | gender | character varying(6) | | | created_at | date | | +-------------------------------------------------+ |Indexes: | | \u0026#34;users_pkey\u0026#34; PRIMARY KEY, btree (id) | +-------------------------------------------------+ If you want to follow along with this tutorial, you can easily create this table with the following query:\nCREATE TABLE users ( id INT PRIMARY KEY, first_name VARCHAR(60), last_name VARCHAR(60), email VARCHAR(120), gender VARCHAR(6), created_at DATE ); Having the table now, we can dump any amount of data we want. I will use the following CSV file, which contains 1000 user records. Dumping the data in the table is easy using PostgreSQL\u0026rsquo;s COPY command. If you are unfamiliar with the command, check out my post which explains it in depth.\nIn our case, the actual command is:\nCOPY users ( id, first_name, last_name, email, gender, created_at ) FROM \u0026#39;/some/path/here/to/dummy-users.csv\u0026#39; DELIMITER \u0026#39;,\u0026#39;; /* Output: COPY 1000 */ Having the data in the database now, let\u0026rsquo;s see the real impact of the indexes.\nAnalyzing Queries PostgreSQL creates a query plan for each query it receives. When writing your queries, it is very important to choose the best query plan, which adheres to the query structure and the properties of the data. The query plans are really easy to produce in PostgreSQL. It comes with a really neat command called EXPLAIN, which shows the query plan, which contains all of the relevant info.\nFor example, let\u0026rsquo;s see the query plan for the query that returns all of the users:\nEXPLAIN SELECT * FROM users; This will return the following output:\nQUERY PLAN ---------------------------------------------------------- Seq Scan on users (cost=0.00..20.00 rows=1000 width=48) (1 row) As you can notice, this simple query requires a Sequential Scan, because there is no WHERE clause in it. This means that it will have to scan each row of the table and return it.\nIn the parentheses we notice couple of values. The cost is a range of arbitrary units (that closely resemble disk page fetches) - starting from the expected before the output phase can begin, to the estimated total cost of this query. Then, the numbers of rows output that were estimated by the query planner. Last, the width represents the average width of the rows, in bytes.\nLet\u0026rsquo;s add a WHERE clause to the query:\nSELECT * FROM users WHERE email = \u0026#39;phughes5m@nbcnews.com\u0026#39;; The query will return the user whose email is phughes5m@nbcnews.com . Perfect. Let\u0026rsquo;s EXPLAIN the query, and see its query plan:\nEXPLAIN SELECT * FROM users WHERE email = \u0026#39;phughes5m@nbcnews.com\u0026#39;; QUERY PLAN ---------------------------------------------------------- Seq Scan on users (cost=0.00..22.50 rows=1 width=48) Filter: ((email)::text = \u0026#39;phughes5m@nbcnews.com\u0026#39;::text) As you can see, although the WHERE clause was added, and the result set was reduced to only one row, the time didn\u0026rsquo;t go down. Actually, it increased. This happens because the query will issue a Sequential Scan on the table. Let\u0026rsquo;s see if adding an index to the email column will decrease the cost of the query.\nAdding an Index Adding an index in PostgreSQL is done via the CREATE INDEX command:\nCREATE INDEX \u0026lt;index name\u0026gt; ON \u0026lt;table name\u0026gt; USING \u0026lt;method\u0026gt;(\u0026lt;column name\u0026gt;); Or, in our specific case:\nCREATE INDEX email_idx ON users USING btree(email); After we run this command, let\u0026rsquo;s see a description of the table:\nTable \u0026#34;public.users\u0026#34; Column | Type | Modifiers ------------+------------------------+----------- id | integer | not null first_name | character varying(60) | last_name | character varying(60) | email | character varying(120) | gender | character varying(6) | created_at | date | Indexes: \u0026#34;users_pkey\u0026#34; PRIMARY KEY, btree (id) \u0026#34;email_idx\u0026#34; btree (email) You can see in the \u0026ldquo;Indexes\u0026rdquo; section, the new index appears. After we added the index, let\u0026rsquo;s see the query plan for the SELECT query:\nEXPLAIN SELECT * FROM users WHERE email = \u0026#39;phughes5m@nbcnews.com\u0026#39;; QUERY PLAN ---------------------------------------------------------------------- Index Scan using email_idx on users (cost=0.28..8.29 rows=1 width=48) Index Cond: ((email)::text = \u0026#39;phughes5m@nbcnews.com\u0026#39;::text) Whoa! The projected query cost dropped from the original 22.50 to 8.29. So, what changed? As you can notice, instead of a Sequential Scan, now PostgreSQL will issue a Index Scan. We won\u0026rsquo;t go into details here, because types and approaches of scanning is topic for another blogpost. Simply said, Postgres will issue a scan based on the indexes, therefore finding the exact location of the user that we are looking for and returning it. This is a much cheaper operation then using a sequential scan.\nSequential isn\u0026rsquo;t Always the Worst Let\u0026rsquo;s see a different example. Let\u0026rsquo;s say, we want to return all of the users that have the id between 100 and 200:\nEXPLAIN SELECT * FROM users WHERE id \u0026gt; 100 AND id \u0026lt; 200; QUERY PLAN ---------------------------------------------------------------------- Index Scan using users_pkey on users (cost=0.28..11.28 rows=100 width=48) Index Cond: ((id \u0026gt; 100) AND (id \u0026lt; 200)) (2 rows) Looks about right, right? It uses a Index Scan, with an Index Cond(itional) searching for all ids between 100 and 200. Good enough.\nHow about we try to return all users with ids between 200 and 800?\nEXPLAIN SELECT * FROM users WHERE id \u0026gt; 200 AND id \u0026lt; 800; QUERY PLAN ------------------------------------------------------- Seq Scan on users (cost=0.00..25.00 rows=600 width=48) Filter: ((id \u0026gt; 200) AND (id \u0026lt; 800)) (2 rows) Hold on, what happened here? Although there is an index on the primary key column, PostgreSQL decides that doing a sequential scan on the user table is more performant than an index scan. An index scan would require finding 600 indexes and returning each and every one of those records whose index were found. On the other hand, a sequential scan would just go over each of the records and filter out the unwanted rows.\nSo, although this is a contrived example, you can see in some situations an index scan will not be as performant as a sequential scan.\nCareful Usage Indexes are a powerful way to improve the performance of your tables, but they have to be used carefully. Often, indexes can actually stand in the way of your queries, if not used properly.\nNext time we will see what are the index types in PostgreSQL and how we can leverage them.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/postgresql-indexes-first-principles/","summary":"We have all heard about indexes. Yeah, that thing that it\u0026rsquo;s automatically added to the Primary Key column that enables fast data retrieval and stuff. Sure, but have you ever asked yourself if there are multiple types or implementations of indexes? Or maybe, what type of indexes your favourite RDBMS implements? In this blog post, we will take a step back to the beginning, exploring what indexes are, what is their role, types of indexes, metrics and so on.","title":"PostgreSQL Indexes: First Principles"},{"content":"Reactive Programming is a very interesting programming paradigm that I started pondering with last week, which ended up in an article on this blog. Today, I will show you how you can write a very simple weather widget with reactive programming, using RxJS. Or, in other words, how to do HTTP calls in reactive programming fashion.\nRxJS RxJS is an acronym for Reactive Extensions for JavaScript. Simply put, it is a set of libraries to do asynchronous and event-based programming using observable collections and iterators. Simple as that. If you are interested in diving into RxJS, which I recommend, you can start with the README. It has plenty of informations and links that you can use to learn Rx.\nThe UI After getting (some of) the RxJS syntax and functions under my belt, I tried to go on and implement something super simple. In the past, I have worked with the Open Weather Map\u0026rsquo;s API, so I said to myself, let\u0026rsquo;s build a simple weather widget.\nThe widget that we will be building will look like this:\nThis is the default (start) state of the widget. The other state is when the used populates the input field with his location. Then, the widget fetches the weather data and shows it:\nVery simple, but sufficient for the purpose of this article. As a sidenote, I will not cover the HTML/CSS part of the widget, as it is quite simple and it\u0026rsquo;s beside the point of this article.\nThe code We will use the part of the Open Weather Map API which returns the current weather for a location. First, in our code, we will need to define the endpoint and the API_KEY (to get yours, just register).\nAlso, make sure you include RxJS in your project, whether via a simple \u0026lt;script\u0026gt;\u0026lt;/script\u0026gt; tag in your HTML file, or via any package manager that you prefer. We will use the ES6/Babel syntax in this article.\nconst API_KEY = \u0026#34;YOUR_API_KEY_HERE\u0026#34;; const API_URL = `http://api.openweathermap.org/data/2.5/weather?appid=${API_KEY}`; Easy as that. Next, we will need to get both of the DOM elements that we need to work with - the input field and the text paragraph where the temperature will be shown:\nvar weatherText = document.querySelector(\u0026#39;#weather\u0026#39;); var searchInput = document.querySelector(\u0026#39;#location-input\u0026#39;); Now, this is where Rx kicks in. We want to grab the keyup event on the input field and kick off a HTTP request after it. This is achievable via the Rx.Observable.fromEvent function, which takes the DOM element and event type as arguments:\nRx.Observable.fromEvent(element, \u0026#39;event-type\u0026#39;); Or, in our specific case, we want to grab the keyup event on the searchInput DOM element:\nvar searchInputSource = Rx.Observable .fromEvent(searchInput, \u0026#39;keyup\u0026#39;) .debounce(500); As you can see, this is really easy with RxJS. As a UX nicety, we use the debounce function, which will make RxJS register events 500ms after the last one is done. Any intermediary events will be rejected. The searchInputSource will be the event source stream. From there, we will map our events, build our request streams and send the HTTP requests to the API.\nvar requestOnFindStream = searchInputSource.map(ev =\u0026gt; { return API_URL + \u0026#34;\u0026amp;q=\u0026#34; + ev.target.value; }); Now, this section of the code will map all of the events coming through the searchInputSource and build the full request API URLs. At the end of the API_URL it will append a query string with the location specified in the input field.\nvar responseStream = requestOnFindStream .flatMap(requestUrl =\u0026gt; { return Rx.Observable.fromPromise($.getJSON(requestUrl)); }) .map(response =\u0026gt; convertToCelsius(response.main.temp)) .startWith(0); Now, here\u0026rsquo;s where all of the magic happens. On the requestOnFindStream we apply the flatMap function, whose role here is to build a stream of new streams. I know, this looks confusing, but bear with me.\nIn the flatMap function, we wrap any incoming requestUrl from the requestOnFindStream and we create a new Rx.Observable from a jQuery promise. Later on, when we subscribe on the observable (the responseStream), the promise will be invoked and the data will pass through all of the chained functions.\nAfter the flatMap, we map all of the responses that we will get from the resolved promise and we use the convertToCelsius function:\nfunction convertToCelsius(kelvin) { return (kelvin - 273.15).toFixed(1); } The function is rather simple - it converts Kelvin degrees from Celsius degrees. After that, we return only the converted temperature from the response body. At the end, the startWith functions just sets a default value for the responseStream, so instead of showing a blank widget, we show 0 degrees temperature.\nAs a last step, we need to subscribe to the requestStream:\nresponseStream.subscribe(temp =\u0026gt; { weatherText.innerHTML = `${temp}°C`; }); This is rather simple - we subscribe to the data stream and set a callback. The callback will be invoked any time we get any data through the stream. It will only update the HTML on the widget, showing the temperature to the user.\nIf you want to see the source of and/or play with this widget, here it is.\nOutro Although Reactive Programming requires a bit of a mindset switch, I found that programming in the paradigm is quite interesting and challenging. If you want to dig deeper, I would recommend heading over to Egghead.io and checking their courses on Reactive Programming. Also, if you are interested in Reactive Programming with Ruby, check my latest post on RxRuby.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/build-weather-widget-rxjs/","summary":"Reactive Programming is a very interesting programming paradigm that I started pondering with last week, which ended up in an article on this blog. Today, I will show you how you can write a very simple weather widget with reactive programming, using RxJS. Or, in other words, how to do HTTP calls in reactive programming fashion.\nRxJS RxJS is an acronym for Reactive Extensions for JavaScript. Simply put, it is a set of libraries to do asynchronous and event-based programming using observable collections and iterators.","title":"Building a Weather Widget using RxJS"},{"content":"Reactive Programming is a relatively new and interesting programming paradigm that has picked up quite a bit of popularity lately. Out of curiosity, I did a bit of research over the weekend. In this blog post I will summarize what I learned and try to explain what RP to any novice out there. Also, I show you how to use the Reactive Extensions for Ruby. Let\u0026rsquo;s dive in!\nThe Motivation I rarely have strong opinions, but I really think that to understand anything in life, you need to understand the motivation behind it. In this case, to understand what Reactive Programming is, we need to see what problems it is solving.\nAll of the programming paradigms that we know of at this point of time are invented more than 20 years ago. Yes, even functional programming. In fact, it was invented like 60 years ago. The problem is, just like with anything that evolves, priorities change.\nIn our case, the internet happened. Sure, +20 years ago the internet did exist, but it had less users then the count of views that a popular video on YouTube has today. Going forward 15-10 years ago, the internet grew enough, so we felt the need for a ton of data processing and asynchronous behaviour.\nApplications needs have changed, from poll-based to full reactive applications, where the data is pushed to us. Each time, we\u0026rsquo;re adding more complexity, more data, and asynchronous behavior to our applications. So, reactive programming is a way to manage all of that complexity, mindset switch included.\nComposition The word invented might hurt someone\u0026rsquo;s ears. At the low level, the paradigm is basically a construct of two design patterns that have been around for more then 20 years. Actually, one of the most popular design patterns book, the Gang of Four book, covers these two design patterns: the Iterable and the Observer patterns. These two patterns are behavioral design patterns, which characterize the interaction and responsibility of objects and classes.\nIterator Taken from the GoF book:\n The key idea in this pattern (the Iterator) is to take the responsibility for access and traversal out of the list object and put it into an iterator object. The Iterator class defines an interface for accessing the list\u0026rsquo;s elements. An iterator object is responsible for keeping track of the current element; that is, it knows which elements have been traversed already.\n Sounds familiar? I am sure it does. Ruby\u0026rsquo;s Enumerable module does just that, it returns an enumerator, which encapsulates the data and the traversal methods. Okay, let\u0026rsquo;s keep this short then - an iterator in Ruby is an instance of a class that includes the Enumerable module. Which, it\u0026rsquo;s pretty much any collection.\nObserver The observer pattern is a design pattern in which an object, called the subject, maintains a list of its dependents, called observers, and notifies them automatically of any state changes, usually by calling one of their methods. Usually, it\u0026rsquo;s used to implement distributed event handling systems.\nBasically, the subjects are the objects that send the messages to the objects that observe the subjects (damn!). The subjects push the messages to the observers, which is why this is called the Observer Pattern.\nRuby ships with the Observable module in it\u0026rsquo;s standard library, which provides a simple mechanism for one object (subject) to inform a set of subscribers (observers) of any state change.\nReactive Programming Now that we have an understanding of both, the Iterator and the Observer patterns, it\u0026rsquo;s time for the Reactive Programming paradigm.\nAccording to the Reactive Manifesto, Reactive Systems are: Responsive, Resilient, Elastic and Message Driven. I don\u0026rsquo;t know about you, but these type of definitions confuse me a lot. In the way that I understand the Reactive Manifesto, Reactive Systems are asynchronous, fault tolerant, scalable and they communicate with non-blocking message-passing.\nBut, what interests us is the implementation, especially in Ruby. Would you be surprised if I tell you that on the surface, the reactive programming paradigm is basically an abstraction on top of the the Observer pattern in combination with the Iterator pattern?\nDon\u0026rsquo;t believe me? Let\u0026rsquo;s see a few examples.\nReactive Extensions From the README:\n The Reactive Extensions for Ruby (or, RxRuby) is a set of libraries to compose asynchronous and event-based programs using observable collections and Enumerable module style composition in Ruby.\n There, told ya? RxRuby is a library, which does all of the abstractions for us, so we can easily start with Reactive Programming in Ruby. Neat, eh?\nObservables Let\u0026rsquo;s see how RxRuby works, in it\u0026rsquo;s simplest form.\nRxRuby::Observable.just(42) A RxRuby::Observable is just a stream. A stream is a subject (or, an object) that you can subscribe to (or, observe). Now, the RxRuby:Observable module itself doesn\u0026rsquo;t do anything, unless we invoke a method on it. Let\u0026rsquo;s carry on with the example:\nstream = RxRuby::Observable.just(42) stream.subscribe {|num| puts \u0026#34;We received: #{num}\u0026#34; } What do you think will happen here? Let\u0026rsquo;s break it down. The object that we receive is a just the number 42, wrapped as an observable. Since the observable implements (most of) the Enumerable methods, we can do anything with it. But, to avoid any complication in this example, we will just subscribe to the observable and pass in a lambda. The lambda will be invoked on everytime the stream pushes any data (or, in this case, just once).\nThe output of the example will be:\nWe received 42. Observing on an array Now, since we have a lot of the methods from the Enumerable mixin available, let\u0026rsquo;s do something with an array. There\u0026rsquo;s two ways of working with arrays in RxRuby: via ranges and via plain arrays.\nVia ranges:\nRxRuby::Observable.range(1,10) .select {|num| num.even? } .sum .subscribe {|s| puts \u0026#34;The sum of the even numbers from 1 to 10 is: #{s}\u0026#34; } This will return: The sum of the even numbers from 1 to 10 is: 30\nLet\u0026rsquo;s break it down. First, we create an observable range, with the numbers from 1 to 10. Then, we invoke select on the observable, with a lambda as a parameter. The lambda takes each number of the range as a parameter, and filters all even numbers from the observable, returning a new observable. Then, we invoke sum on it, which sums all of the even numbers.\nAt the end, we subscribe on the observable that sum returns. By subscribing we basically \u0026ldquo;watch over\u0026rdquo; the observable (or, the stream of data) and invoke the lambda that we pass as an argument to the subscribe. Any time the observable pushes any data, it will go through this \u0026ldquo;funnel\u0026rdquo; and invoke the last lambda at the end, which will print out the message. the observables push any data we\nDoing this via arrays is very similar:\narr = Array(1..10) RxRuby::Observable.from_array(arr) .select {|num| num.even? } .sum .subscribe {|s| puts \u0026#34;The sum of the even numbers from 1 to 10 is: #{s}\u0026#34; } This snippet will also return the same message at the end. The only difference here is that we create an observable from an array.\nMore RxRuby The documentation on RxRuby is still scarce, but fortunately for us there are a lot of examples in the Github repo.\nAlso, I have ported the RxJS Koans to Ruby, for easier learning of the library. RxRuby Koans is still a bit unstable, but it should give you a nice overview RxRuby\u0026rsquo;s methods/objects.\nThe future I am not sure what the future holds for RxRuby, but it seems that reactive programming is here to stay. Netflix has built quite a big architecture built on the Reactive Systems paradigm. Also, the Reactive JavaScript community is super vibrant, unlike the Ruby community. But, let\u0026rsquo;s hope for the best!\nAs for me - I am looking for anyone that\u0026rsquo;s proficient with RxRuby, to review my RxRuby Koans, so we can get it moving somewhere.\nNotes Some links I used while writing this article, that you might find interesting:\n The introduction to Reactive Programming you\u0026rsquo;ve been missing Overview of Reactive Programming What is Reactive Programming? The 7 Ways to Wash Dishes and the Case for Message-driven Reactive Systems RxRuby RxJSKoans  Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/reactive-programing-rxruby/","summary":"Reactive Programming is a relatively new and interesting programming paradigm that has picked up quite a bit of popularity lately. Out of curiosity, I did a bit of research over the weekend. In this blog post I will summarize what I learned and try to explain what RP to any novice out there. Also, I show you how to use the Reactive Extensions for Ruby. Let\u0026rsquo;s dive in!\nThe Motivation I rarely have strong opinions, but I really think that to understand anything in life, you need to understand the motivation behind it.","title":"Understanding Reactive Programming with RxRuby"},{"content":"Recently I started tackling refactoring in Ruby with my blog posts. It seems that it\u0026rsquo;s one of the most popular topics that people would like to read about, so here I am with another installment of refactoring in Ruby. This time, we will see if it\u0026rsquo;s the right time and place for a Builder\u0026hellip; whatever that means.\nJust a bit of backstory In my last post on refactoring in Ruby, I covered how to detect and refactor the long parameters code smell. It stirred up quite a discussion in the comments, but also, on my Skype chat. So, a colleague of mine, who I respect a lot, mentioned that eliminating the long parameters lists can be done via the builder pattern. I won\u0026rsquo;t go into too much detail of how the discussion went, but I\u0026rsquo;ll tell you that we had a bit of a disagreement.\nEventually we shared some thoughts and got on the same page. So, in this blog post I would like to show you what is the Builder Pattern and what\u0026rsquo;s a good place to use it.\nThe basics First, the basics - what is the Builder Pattern? The builder pattern is an object creation design pattern. This means that the code produced when following this pattern will create objects of certain class(es).\nNow, the key thing to the Builder Pattern, which differentiates it from the Factory pattern, is it\u0026rsquo;s purpose. The Builder pattern is used to apply any sort of configuration on object creation.\nThis pattern also allows finer control over the object creation. Via the builder\u0026rsquo;s interface we create an uniformed way of object creation, instead of dealing with complex flows of creating an object (which often can be a composite).\nLong parameters lists Now, back to that topic on the long parameters lists code smell. Does it make sense to apply the Builder pattern to this type of a code smell? Well, it seems like it does, but only to a special type of methods - constructors!\nIf you know just a bit of OOP, you know that constructors are the methods which are invoked when an object is being created. Now, if a constructor has a long list of parameters, that usually means that it is doing quite a bit of configuration of the object itself.\nTake a look at this example:\nclass Touchscreen # Some nice things a touch screen can do... end class CPU # Power... unlimited power! #StarWars end class RAM # Yeah! end class Smartphone attr_accessor :model, :screen, :cpu, :ram, :memory, :os def initialize(model = nil, screen = nil, cpu = nil, ram = nil, memory = nil, os = nil) @model = model @screen = screen @cpu = cpu @ram = ram @memory = memory @os = os end end This is quite simlpe, but it implies that you will need to create objects from the CPU and Touchscreen classes, before you create a Smartphone object. It means that you need some configuration done before you can create an actual Smartphone.\nAs you can see, a big parameters lists can lead to confusion. If in the source code of the application you will only create Smartphone objects couple of times, then refactoring this is an overkill. But, if the class with the long parameters list in the constructor is used often, then streamlining the object creation will be an immediate win.\nBefore applying the Builder Pattern here, we need to detect some patterns in our code. By code, I mean production code and tests. If you often find yourself forgetting to create a CPU object before assigning it to a Smartphone, then a builder can help with all of that. Basically, a builder should have utility methods that will make the configuration of these objects easier.\nclass SmartphoneBuilder def initialize @smartphone = Smartphone.new end def set_model(model) @smartphone.model = model end def add_processor(speed) @smartphone.cpu = CPU.new(speed) end def add_touchscreen(size) @smartphone.screen = Touchscreen.new(size) end def add_ram(amount) @smartphone.ram = RAM.new(amount) end def add_memory(amount) @smartphone.memory = amount end def set_os(os) @smartphone.os = os end def smartphone obj = @smartphone.dup @smartphone = Smartphone.new return obj end end Having these methods in our SmartphoneBuilder class will improve the object creation flow. Take this dummy code for a comparison.\nBefore:\nclass Order attr_accessor :products def initialize @products = [] end end class OrderTest \u0026lt; Minitest::Test def test_contains_multiple_products order = Order.new 5.times do order.products \u0026lt;\u0026lt; Smartphone.new(\u0026#34;Apple iPhone 6S\u0026#34;, 4.7, 1.84, 2048, 16384, :ios) end assert_equal 5, order.products.length # Sanity check assert_equal \u0026#34;Apple iPhone 6S\u0026#34;, order.products.last.model end end Just writing the line\norder.products \u0026lt;\u0026lt; Smartphone.new(\u0026#34;Apple iPhone 6S\u0026#34;, 4.7, 1.84, 2048, 16384, :ios) takes effort, because it\u0026rsquo;s nearly impossible to remember the order of the parameters. Meta-note: When I was writing the example, I had to copy-paste the initializer arguments and fill them up one-by-one, so I don\u0026rsquo;t mix them up.\nNow, writing the same test with the builder:\nclass OrderTest \u0026lt; Minitest::Test def test_contains_multiple_products order = Order.new smartphone_builder = SmartphoneBuilder.new 5.times do smartphone_builder.set_model(\u0026#34;Apple iPhone 6S\u0026#34;) smartphone_builder.add_touchscreen(4.7) smartphone_builder.add_processor(1.84) smartphone_builder.add_ram(2048) smartphone_builder.add_memory(16384) smartphone_builder.set_os(:ios) order.products \u0026lt;\u0026lt; smartphone_builder.smartphone end assert_equal 5, order.products.length # Sanity check assert_equal \u0026#34;Apple iPhone 6S\u0026#34;, order.products.last.model end end As you can see, although the example is quite contrived, introducing the builder pattern comes in handy. Sure, the second code example might be more verbose, but on the other hand it\u0026rsquo;s super clear and very hard to get confused by it. There are a ton of other situations where one could use the builder pattern, but in this case it plays nicely when eliminating this code smell.\nEdited, 16th of January, 2016:\nAdditionally, thanks to couple of readers and colleagues, who I thank a ton for weighing in, a very interesting and approach to builders is using a building block. The usage would look like:\nclass OrderTest \u0026lt; Minitest::Test def test_contains_multiple_products order = Order.new 5.times do smartphone = SmartphoneBuilder.build do |builder| builder.set_model(\u0026#34;Apple iPhone 6S\u0026#34;) builder.add_touchscreen(4.7) builder.add_processor(1.84) builder.add_ram(2048) builder.add_memory(16384) builder.set_os(:ios) end order.products \u0026lt;\u0026lt; smartphone end assert_equal 5, order.products.length # Sanity check assert_equal \u0026#34;Apple iPhone 6S\u0026#34;, order.products.last.model end end As you can see, this looks super nice, which is half the reason I agreed to add this to the post after it was published. The other half is usefulness, obviously. The implementation of the block-style builder:\nclass SmartphoneBuilder def self.build builder = new yield(builder) builder.smartphone end def initialize @smartphone = Smartphone.new end def set_model(model) @smartphone.model = model end def add_processor(speed) @smartphone.cpu = CPU.new(speed) end def add_touchscreen(size) @smartphone.screen = Touchscreen.new(size) end def add_ram(amount) @smartphone.ram = RAM.new(amount) end def add_memory(amount) @smartphone.memory = amount end def set_os(os) @smartphone.os = os end def smartphone obj = @smartphone.dup @smartphone = Smartphone.new return obj end end By implementing the SmartphoneBuilder.build method, we expose the additional block-style variant of the builder, so the user can choose between the good-looking block building or the not-so-good-looking non-block-style version.\n(Over) Validation Earlier we agreed that as an object creational patten, the Builder comes into play when there\u0026rsquo;s some configuration heavy lifting when creating objects. Well, another place where a Builder might fit in nicely is validation-on-creation.\nThere have been plenty of cases where we want to make sure that the data that is passed in on object creation is valid. Like, a smartphone without a touchscreen is not really a smartphone, is it? Well, at least for now.\nAnyway, the Builder Pattern comes nicely into play when we want to deal with validation. Since the data is pushed into the object in it\u0026rsquo;s constructor, the most logical place to do the validation is there, in the constructor:\nclass Smartphone attr_accessor :model, :screen, :processor, :ram, :memory def initialize(model, screen_size, processor_freq, ram, memory, os) raise \u0026#34;Smartphone model required\u0026#34; if model.empty? raise \u0026#34;Screen size required\u0026#34; if screen_size.empty? raise \u0026#34;Processor Frequency required\u0026#34; if processor_freq.empty? raise \u0026#34;RAM required\u0026#34; if ram.empty? raise \u0026#34;Memory required\u0026#34; if memory.empty? raise \u0026#34;OS required\u0026#34; if os.empty? @model = model @screen = Touchscreen.new(screen_size) @cpu = CPU.new(processor_freq) @ram = ram @memory = memory @os = os end end Sure, this bloats the initializer, so we could extract the validation into a separate method:\nclass Smartphone attr_accessor :model, :screen, :processor, :ram, :memory def initialize(model, screen_size, processor_freq, ram, memory, os) validate_parameters!(model, screen_size, processor_freq, ram, memory, os) @model = model @screen = Touchscreen.new(screen_size) @cpu = CPU.new(processor_freq) @ram = ram @memory = memory @os = os end private def validate_parameters!(*p) model, screen_size, processor_freq, ram, memory, os = *p raise \u0026#34;Smartphone model required\u0026#34; if model.nil? raise \u0026#34;Screen size required\u0026#34; if screen_size.nil? raise \u0026#34;Processor Frequency required\u0026#34; if processor_freq.nil? raise \u0026#34;RAM required\u0026#34; if ram.nil? raise \u0026#34;Memory required\u0026#34; if memory.nil? raise \u0026#34;OS required\u0026#34; if os.nil? end end But, what would happen if we need to validate the CPU frequency? There isn\u0026rsquo;t really a CPU with a working frequency of 0 GHz, right? Or, maybe, validating the Operating System?\nclass Smartphone VALID_OS = [:ios, :android, :windows, :blackberry, :firefox, :tizen, :ubuntu] attr_accessor :model, :screen, :processor, :ram, :memory def initialize(model, screen_size, processor_freq, ram, memory, os) validate_parameters!(model, screen_size, processor_freq, ram, memory, os) validate_os!(os) @model = model @screen = Touchscreen.new(screen_size) @cpu = CPU.new(processor_freq) @ram = ram @memory = memory @os = os end private def validate_parameters!(*p) model, screen_size, processor_freq, ram, memory, os = *p raise \u0026#34;Smartphone model required\u0026#34; if model.nil? raise \u0026#34;Screen size required\u0026#34; if screen_size.nil? raise \u0026#34;Processor Frequency required\u0026#34; if processor_freq.nil? raise \u0026#34;RAM required\u0026#34; if ram.nil? raise \u0026#34;Memory required\u0026#34; if memory.nil? raise \u0026#34;OS required\u0026#34; if os.nil? end def validate_os!(os) unless VALID_OS.include?(os) raise \u0026#34;Invalid Operating System: #{os}\u0026#34; end end end This adds additional weight on the Smartphone class. One option to reduce the complexity in the class would be to move this logic to a validator class. But, since all of this logic is related to the configuration of a Smartphone object on creation, moving the logic to the SmarphoneBuilder will ensure that the objects are always safely configurated.\nLet\u0026rsquo;s refactor the Smartphone class and move the validation logic to the SmartphoneBuilder:\nclass Smartphone attr_accessor :model, :screen, :processor, :ram, :memory def initialize(model, screen_size, processor_freq, ram, memory, os) @model = model @screen = Touchscreen.new(screen_size) @cpu = CPU.new(processor_freq) @ram = ram @memory = memory @os = os end end First, we remove all of the validaton logic from the Smartphone class. The next step is to find the perfect spot for the logic in the SmartphoneBuilder class:\nclass SmartphoneBuilder VALID_OS = [:ios, :android, :windows, :blackberry, :firefox, :tizen, :ubuntu] attr_reader :smartphone def initialize @smartphone = Smartphone.new end def add_memory(gbs) validate_presence!(\u0026#34;Memory\u0026#34;, gbs) @smartphone.memory = gbs end def add_ram(gbs) validate_presence!(\u0026#34;RAM\u0026#34;, gbs) @smartphone.ram = gbs end def add_screen(screen_size) validate_presence!(\u0026#34;Screen size\u0026#34;, screen_size) @smartphone.screen = Touchscreen.new(screen_size) end def set_model(model) validate_presence!(\u0026#34;Model\u0026#34;, model) @smartphone.model = model end def add_processor(cpu_freq) validate_presence!(\u0026#34;Processor Speed\u0026#34;, cpu_freq) @smartphone.cpu = CPU.new(cpu_freq) end def set_os(os) validate_presence!(\u0026#34;Operating System\u0026#34;, os) validate_os!(os) @smartphone.os = os end def smartphone @smartphone end private def validate_presence!(attr_name, attr_value) raise \u0026#34;#{attr_name}is required.\u0026#34; if attr_value.nil? end def validate_os!(os) unless VALID_OS.include?(os) raise \u0026#34;Invalid Operating System: #{os}\u0026#34; end end end As you can see, whenever we set any property on the builder, it validates the configuration and raises an error if the configuration is broken. In this way, the Builder Pattern gives us the security that we will always get valid and sane objects out of it. Let\u0026rsquo;s say, we want to make sure that the phone memory must be between 1GB and 64GBs, by adding additional validation:\nclass SmartphoneBuilder VALID_OS = [:ios, :android, :windows, :blackberry, :firefox, :tizen, :ubuntu] attr_reader :smartphone def initialize @smartphone = Smartphone.new end def add_memory(gbs) validate_presence!(\u0026#34;Memory\u0026#34;, gbs) validate_memory!(gbs) @smartphone.memory = gbs end def add_ram(gbs) validate_presence!(\u0026#34;RAM\u0026#34;, gbs) @smartphone.ram = gbs end def add_screen(screen_size) validate_presence!(\u0026#34;Screen size\u0026#34;, screen_size) @smartphone.screen = Touchscreen.new(screen_size) end def set_model(model) validate_presence!(\u0026#34;Model\u0026#34;, model) @smartphone.model = model end def add_processor(cpu_freq) validate_presence!(\u0026#34;Processor Speed\u0026#34;, cpu_freq) @smartphone.cpu = CPU.new(cpu_freq) end def set_os(os) validate_presence!(\u0026#34;Operating System\u0026#34;, os) validate_os!(os) @smartphone.os = os end def smartphone @smartphone end private def validate_memory!(gigabytes) unless gigabytes.between?(1, 64) raise \u0026#34;The memory must be between 1GB and 64GBs\u0026#34; end end def validate_presence!(attr_name, attr_value) raise \u0026#34;#{attr_name}is required.\u0026#34; if attr_value.nil? end def validate_os!(os) unless VALID_OS.include?(os) raise \u0026#34;Invalid Operating System: #{os}\u0026#34; end end end As you can see, adding more validation rules in the builder allows us to always get valid objects, forever and ever.\nOutro In this post we\u0026rsquo;ve covered, in my opinion, two of most popular cases where a builder pattern can come in handy.\nAs a general rule, when you think of applying this pattern, look for places in your code where confusion appears. Also, a good smell is a lot of configuration overhead. In these places, you might find this pattern useful.\nI am sure you might find other situations where you can apply this pattern. I would love to learn of new places where this pattern can be used, so please share your experience with me in the comments section below.\nThanks for reading!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/refactoring-builder-pattern/","summary":"Recently I started tackling refactoring in Ruby with my blog posts. It seems that it\u0026rsquo;s one of the most popular topics that people would like to read about, so here I am with another installment of refactoring in Ruby. This time, we will see if it\u0026rsquo;s the right time and place for a Builder\u0026hellip; whatever that means.\nJust a bit of backstory In my last post on refactoring in Ruby, I covered how to detect and refactor the long parameters code smell.","title":"Refactoring in Ruby: The right place for a Builder?"},{"content":"In the last couple of years, we have seen a lot of development in the devops field. It’s becoming much easier for developers to provision servers and deploy their applications on those servers just with a couple of key strokes. Since the start of the SaaS and PaaS products (even before we knew them as that), we have seen a vast number of companies and communities try to make our lives easier by developing smart tools that will fit into our workflow seamlessly.\nAs a side effect, or perhaps intentionally, we’ve also seen the open-source community create tools to not just make the workflow easier but to cut costs and enable us to make great software without thinking about the costs of the hardware.\nAmazon with its huge selection of web services (AWS) and the like have made our lives much easier when it comes to incorporating infrastructure and tools in the cloud. Then there are Chef and Puppet that made provisioning servers a breeze. Then came containerization in the form of Docker, although some would argue that containers, or at least the idea around them, existed well before Docker came along.\nRead the rest of the blog post on Codeship\u0026rsquo;s Blog.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/running-rails-app-deis/","summary":"In the last couple of years, we have seen a lot of development in the devops field. It’s becoming much easier for developers to provision servers and deploy their applications on those servers just with a couple of key strokes. Since the start of the SaaS and PaaS products (even before we knew them as that), we have seen a vast number of companies and communities try to make our lives easier by developing smart tools that will fit into our workflow seamlessly.","title":"Running a Rails Application on Deis"},{"content":"Ruby is a really clear and expressive language, but we developers sure know how to make a mess. Even when you think your classes are nicely written and tested, things can still get out of hand. I am pretty sure you\u0026rsquo;ve heard one (or more) of your more experienced colleagues/mentors tell you that \u0026ldquo;something is smelly\u0026rdquo; in the code. Well, in this article we will cover one of the simplest code smells\n long parameters lists in your method signatures.  Code Smells First, what are code smells? According to the Wikipedia article on Code smell:\n Code smell, also known as bad smell, in computer programming code, refers to any symptom in the source code of a program that possibly indicates a deeper problem.\n Another very imporant point is this:\n Code smells are usually not bugs—they are not technically incorrect and do not currently prevent the program from functioning. Instead, they indicate weaknesses in design that may be slowing down development or increasing the risk of bugs or failures in the future. Bad code smells are an important reason for technical debt.\n These couple of sentences explain what code smells are very nicely. If you would like to know more, I encourage you to head over to the Wikipedia article.\nNow, back to our code smell - long parameters list.\nLong Parameters Lists This code smell is quite easy to detect - just look for methods with 3, 4 or more parameters. Now, while to some of you this might be okay, let\u0026rsquo;s see why this is an actual code smell.\nclass Person def initialize(first_name, last_name, age, sex, height, weight) @first_name = first_name @last_name = last_name @age = age @sex = sex @height = height @weight = weight end end Just creating a new object of the Person class can lead to bugs. For example, it\u0026rsquo;s really easy to mix up the height and weight, also the first and last name. Then, just reading the signature of the initializer is super hard. And even if this long of an initializer signature can be acceptable to you, imagine doing this for any other method that you do not invoke that often.\nTake this for example:\nclass Invitation def self.deliver!(first_name, last_name, email, date, time, venue, dress_code) Invitation.create(to: \u0026#34;#{first_name}#{last_name}\u0026#34;, email: email) UserMailer.invitation(first_name, last_name, date, time, venue, dress_code) end end I hope that this paints the picture well that long paratemeters lists can lead to bugs and confusion. So, how do we refactor them?\nReplace Parameter with Method Call One refactoring pattern that could help us here is the Replace Parameter with Method Call pattern. Let\u0026rsquo;s take this as an example:\nclass Discount def initialize(store, price, quantity) @store = store @price = price @quantity = quantity end def effective_cost base_price = @quantity * @price discount = @store.seasonal_discount apply(base_price, discount) end def apply(base_price, discount) base_price - discount end end As you can see, we use the Discount#effective_cost method to calculate a discounted price. Now, the problem lies where we need to pass in the discount as parameter to the Discount#apply method. Instead of doing that, we can reduce the parameters list of the apply method to one.\nThis can be achieved by substituting the parameter with a method call and pushing the logic of retrieving the discount down to the apply method:\nclass Discount def initialize(store, price, quantity) @store = store @price = price @quantity = quantity end def effective_cost base_price = @quantity * @price calculate_effective_cost(base_price) end def apply(base_price) discount = @store.seasonal_discount base_price - discount end end As you can see, by refactoring the parameter into to a method call, we reduced the number of parameters and made the method signatures much cleaner.\nPreserving a Whole Object Now, using the same example, let\u0026rsquo;s take a look at another refactoring pattern - the Preserve Whole Object pattern. The example that we will use is the refactored version of the code from the last section:\nclass Discount def initialize(store, price, quantity) @store = store @price = price @quantity = quantity end def effective_cost base_price = @quantity * @price calculate_effective_cost(base_price) end def apply(base_price) discount = @store.seasonal_discount base_price - discount end end Preserve Whole Object states that instead of passing raw data as parameters, one can send the same data encapsulated in an object. Let\u0026rsquo;s see how this pattern can improve our code:\nFirst, instead of passing in the price and the quantity as separate data, we can introduce a new object to our program - a Order. The Order will hold the price of the product and the quantity that was ordered.\nclass Order attr_reader :price, :quantity def initialize(product, quantity) @price = product.price @quantity = quantity end end Then, in the initializer of our Discount class, instead of passing in the raw data we will pass an Order object as a parameter:\nclass Discount def initialize(store, order) @store = store @order = order end def effective_cost base_price = @order.quantity * @order.price calculate_effective_cost(base_price) end def calculate_effective_cost(base_price) discount = @store.seasonal_discount base_price - discount end end As you can see, by taking this step, the list of parameters in the initializer of the Discount class fell down from three to two.\nIntroduce Parameter Object pattern Another way of getting rid of long parameters lists is the Introduce Parameter Object pattern. The pattern basically states that when a certain list of parameters has a solid logical link between them, it is a good practice to wrap them in a data structure/object. This will make the code more testable and will improve it\u0026rsquo;s readibility.\nPersonally, I would enforce using this pattern if the parameters are being repeated in multiple places/classes/methods.\nFor this section, we will change the example. We will use a Invoice class which has an issue date and a due date:\nclass Invoice def self.deliver(issue_date, due_date) # Deliver the invoice here somehow... end def self.store(issue_date, due_date) # Store the invoice here somehow... end end Now, since we have a logical link between the parameters here (and duplication in the same time), we can extract the issue_date and due_date into a DateRange object:\nclass DateRange def initialize(start_date, end_date) @start_date = start_date @end_date = end_date end def started? Date.today \u0026gt; @start_date end def ended? Date.today \u0026gt; @end_date end end As you can see, we have made the DateRange class as a general purpose class for any other date ranges. Now, instead of passing the dates separately as parameters, we can pass in a DateRange object in the Invoice class:\nclass Invoice def self.deliver(date_range) if date_range.ended? # Deliver with a warning notice else # Just deliver the invoice end end def self.store(date_range) if date_range.started? # Store the invoice here somehow... end end end As you can see, this allows us to easily modify the behaviour of the methods in the Invoice class, adding points to readibility and testability of the methods. Also, the DateRange class is dead-easy to test at this point.\nTaking a step back The three patterns we covered in this article are a nice way to remove the code smell around long parameters lists. I guess that some of them are just an intuitive way to remove the code smell to some. If that is so - great, you do not have to see them as patterns. If not - not a big deal, always look for logical links in the parameters and try to encapsulate the data in some way. With a bit of practice, you can easily apply these patterns on your own.\nHope you enjoyed this refactoring article. If you would like to learn more about refactoring, check out the article on the Extract Class refactoring pattern.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/refactoring-smelly-parameters-lists/","summary":"Ruby is a really clear and expressive language, but we developers sure know how to make a mess. Even when you think your classes are nicely written and tested, things can still get out of hand. I am pretty sure you\u0026rsquo;ve heard one (or more) of your more experienced colleagues/mentors tell you that \u0026ldquo;something is smelly\u0026rdquo; in the code. Well, in this article we will cover one of the simplest code smells","title":"Refactoring in Ruby: Smelly Parameters Lists"},{"content":"There are a lot of refactoring patterns available out there for us. I assume that most of us use these patterns, at certain times without being aware that those refactoring steps are defined as a pattern in the past. In this post, I will take you through an example of refactoring Ruby code with the Extract Class pattern by using Test-Driven Development.\nLet\u0026rsquo;s dive in!\nWhat went wrong at the test? Say we are professors in university and we compile a CSV file with our students' grades. Some of them are good, some are not that good. We want to have a small informal meeting with the students that did not pass the exam, in a classroom and review the tests and discuss what went wrong. Given that there are a lot of students in our class, writing an email for each of the students is painful. Well, good we are programming professors, so we can write our own little program to automate sending those emails:\nrequire \u0026#39;csv\u0026#39; require \u0026#39;mail\u0026#39; class Parser def initialize(file_path) @file_path = file_path end def parse! CSV.foreach(@file_path, headers: true) do |row| if failed_test?(row[\u0026#34;points\u0026#34;]) Mail.deliver do to row[\u0026#34;email\u0026#34;] from \u0026#39;John Doe \u0026lt;john@doe.com\u0026gt;\u0026#39; subject \u0026#39;Post exam meeting invitation\u0026#39; body failed_exam_body(row[\u0026#34;first_name\u0026#34;], row[\u0026#34;points\u0026#34;]) end else Mail.deliver do to row[\u0026#34;email\u0026#34;] from \u0026#39;John Doe \u0026lt;john@doe.com\u0026gt;\u0026#39; subject \u0026#39;Exam results\u0026#39; body passed_exam_body(row[\u0026#34;first_name\u0026#34;], row[\u0026#34;points\u0026#34;]) end end end end private def failed_test?(points) points \u0026lt; 50 end def failed_exam_body(student_name, points) %Q{ Hi #{student_name}, On the exam last week you got #{points}points. It seems to me that you ran into some problems with it so I would like to invite you to a meeting in classrom 201, tomorrow at 2PM. Regards, Prof. John Doe } end def passed_exam_body(student_name, points) %Q{ Hi #{student_name}, On the exam last week you got #{scored_points}points. Congratulations, Prof. John Doe } end end As you can see, it\u0026rsquo;s quite a simple class. It takes a CSV file path and parses it. For each row it checks if the points are less then the minimum amount to pass the exam. If so, then a customised email is sent to each of the students.\nNow, if we take a moment to think about the design of this class, there\u0026rsquo;s a question that we can ask ourselves: what does this class do? Although the question is simple, the answer can reveal something very interesting.\nThe class parses a CSV file and sends an email to each of the students that failed the test. You see, the word \u0026ldquo;and\u0026rdquo; is bolded because it points out to a code smell - violation of the Single Responsibility Principle. If you don\u0026rsquo;t know what SRP is, I recommend you check out my blog post on SOLID principles.\nSo, how can we refactor our class? Well, one of the options is using the Extract Class pattern. Let\u0026rsquo;s check it out.\nExtract Class pattern This pattern falls into a group of patterns that are used for moving features (or functionalities) between objects. The benefit of this refactor is to make your classes adhere to the SRP. Classes that adhere to the SRP are much easier to understand and expand onto.\nNow, back to the design of the class. Since we agreed that it breaks the SRP, we need to decide which functionality we will move out into a new class. For our example, we will let the Parser class just parse the CSV, while we will create a new class called Exam which will contain all of the data and behaviour around the exam data that we parse from the CSV. After that, we will create a Mailer class, whose role will be just to send the email.\nWith that, we will have three classes into play - all having just one responsibility, whether is representing an Exam, parsing a CSV or sending emails.\nThe first step will be to wish the interface of the Exam and Mailer classes and use them in the Parser class. This is called \u0026ldquo;programming by wishful thinking\u0026rdquo;.\n# parser.rb require \u0026#39;csv\u0026#39; class Parser def initialize(file_path) @file_path = File.expand_path(file_path) end def parse! CSV.foreach(@file_path, headers: true) do |row| exam = Exam.new(row) if exam.failed? ExamMailer.failed!(exam) else ExamMailer.passed!(exam) end end end end Parser.new(\u0026#34;grades.csv\u0026#34;).parse! Good. As you can see, we\u0026rsquo;ve added the new classes in Parser#parse! method which radically simplified the readiness and simplicity of it. Since we now have the classes in place, let\u0026rsquo;s take a step back and use TDD to create these classes.\nIntroducing the Exam As we said before, the Exam class will hold the data and represent the behaviour of an exam. But what does that mean? Well, simply put, it will have methods that will decide if an exam is failed based on the data (points). Let\u0026rsquo;s TDD our way through this and write some tests before we implement the class:\n# exam_test.rb class ExamTest \u0026lt; Minitest::Test def test_it_can_be_failed exam = Exam.new({ \u0026#39;points\u0026#39; =\u0026gt; \u0026#39;20\u0026#39; }) assert exam.failed? end def test_it_can_be_passed exam = Exam.new({ \u0026#39;points\u0026#39; =\u0026gt; \u0026#39;51\u0026#39; }) assert exam.passed? end end I assume the tests are quite self explanatory. The constructor will take a hash as an argument and extract the points from it. Then the Exam#passed? and Exam#failed? methods will check if the exam is passed or failed. The rule here is that an exam is failed if it has less than 50 points scored. Let\u0026rsquo;s implement this:\n# exam.rb class Exam attr_reader :scored_points def initialize(entry) @scored_points = entry[\u0026#39;points\u0026#39;].to_i end def failed? @scored_points \u0026lt; 50 end def passed? !failed? end end Really easy, right? If we run the tests, they will pass. Additionally we will need the exam to contain the data for the student which has taken the exam. Some of you might think that a student should be a separate object and I would say that you are right. Also, others might say that there can be separate classes for a failed and passed exams.\nBut, for this example we can keep it really simple. Let\u0026rsquo;s add some tests for the attribute readers:\nclass ExamTest \u0026lt; Minitest::Test def test_student_name student_name = \u0026#39;Ilija\u0026#39; exam = Exam.new({ \u0026#39;first_name\u0026#39; =\u0026gt; student_name }) assert_equal student_name, exam.student_name end def test_student_email student_email = \u0026#39;ile@eftimov.net\u0026#39; exam = Exam.new({ \u0026#39;email\u0026#39; =\u0026gt; student_email }) assert_equal student_email, exam.student_email end def test_failure exam = Exam.new({ \u0026#39;points\u0026#39; =\u0026gt; \u0026#39;20\u0026#39; }) assert exam.failed? end def test_success exam = Exam.new({ \u0026#39;points\u0026#39; =\u0026gt; \u0026#39;51\u0026#39; }) assert exam.passed? end end Implementing these methods is quite easy as well:\nclass Exam attr_reader :student_name, :student_email, :scored_points def initialize(entry) @student_name = entry[\u0026#39;first_name\u0026#39;] @student_email = entry[\u0026#39;email\u0026#39;] @scored_points = entry[\u0026#39;points\u0026#39;].to_i end def failed? @scored_points \u0026lt; 50 end def passed? !failed? end end That is our Exam class with all of it\u0026rsquo;s glory. Did you think about what we did in this step? Really simple stuff - noticing that there is room for a class to encapsulate all of the required data so it can answer to the question \u0026ldquo;is this exam failed or not?\u0026rdquo;. We first wished what the interfaces of our classes should be and then we created the first class, using TDD.\nThis is the Extract Class pattern at it\u0026rsquo;s core - reducing complexity and improving readibility by extracting data and behaviour to a new class.\nThat would be it at this moment. The Exam holds enough behaviour and data so we can continue with the other classes.\nBuilding the mailer The next step is the ExamMailer. The mailer should contain only the behaviour required to send the emails - nothing else. As we decided in the first step, the mailer will have two methods: ExamMailer.passed! and ExamMailer.failed!. The mailer class will use the Mail gem to send emails.\nLet\u0026rsquo;s write some tests around them first and implement them after:\nMail.defaults do delivery_method :test end class MailerTest \u0026lt; Minitest::Test def setup Mail::TestMailer.deliveries.clear @student_mail = \u0026#39;john@doe.com\u0026#39; @student_name = \u0026#39;John\u0026#39; end def test_failed_exam_mail points = \u0026#39;49\u0026#39; exam = Exam.new({ \u0026#39;points\u0026#39; =\u0026gt; points, \u0026#39;email\u0026#39; =\u0026gt; @student_mail, \u0026#39;first_name\u0026#39; =\u0026gt; @student_name }) ExamMailer.failed!(exam) mail = Mail::TestMailer.deliveries.first assert_equal @student_mail, mail.to.first assert_equal \u0026#34;Post exam meeting invitation\u0026#34;, mail.subject assert_match /you got #{points}points/i, mail.body.raw_source end def test_passed_exam_mail points = \u0026#39;50\u0026#39; exam = Exam.new({ \u0026#39;points\u0026#39; =\u0026gt; points, \u0026#39;email\u0026#39; =\u0026gt; @student_mail, \u0026#39;first_name\u0026#39; =\u0026gt; @student_name }) ExamMailer.passed!(exam) mail = Mail::TestMailer.deliveries.first assert_equal @student_mail, mail.to.first assert_equal \u0026#34;Exam results\u0026#34;, mail.subject assert_match /you got #{points}points/i, mail.body.raw_source end end Now, there\u0026rsquo;s a bit of boilerplate code here, which deals with the Mail gem. In the beginning of the file, we set the delivery method of the Mail gem to be :test. This means that the gem will hold all of the emails that are sent in memory, without trying to make an actual delivery. Also, in our setup method we invoke the Mail::TestMailer.deliveries.clear method, which clears the deliveries collection before running each test. This is done so we have a fresh collection of sent emails for each test, which helps with avoiding any confusion.\nAs you can notice in the tests, we assert on the recipient email, on the e-mail subject and on the e-mail body. With this step, we want to make sure that the most essential parts of the e-mail (recipient, body and subject) are correct.\nExtracting the mailer logic from the initial script to a new mailer class is rather simple:\nrequire \u0026#39;mail\u0026#39; class ExamMailer def self.failed!(exam) new(exam).failed! end def self.passed!(exam) new(exam).passed! end def initialize(exam) @exam = exam end def failed! send_mail!(\u0026#39;Post exam meeting invitation\u0026#39;, failed_exam_email_body) end def passed! send_mail!(\u0026#39;Exam results\u0026#39;, passed_exam_email_body) end private def send_mail!(subject, body) mail = Mail.new mail.to = @exam.student_email mail.from = \u0026#39;John Doe \u0026lt;john@doe.com\u0026gt;\u0026#39; mail.subject = subject mail.body = body mail.deliver end def passed_exam_email_body %Q{ Hi #{@exam.student_name}, On the exam last week you got #{@exam.scored_points}points. Congratulations, Prof. John Doe } end def failed_exam_email_body %Q{ Hi #{@exam.student_name}, On the exam last week you got #{@exam.scored_points}points. It seems to me that you ran into some problems with it so I would like to invite you to a group meeting in classrom 201, tomorrow at 2PM. Regards, Prof. John Doe } end end Most of the magic lies within the send_mail! method. It builds a new Mail object and delivers it.\nAs you saw in this step, we extracted the mailing logic from the script to a new well-defined class. The next (and last step) is reviewing the original Parser class and pondering a bit with it.\nBack to the parser After we did all of the hard work around extracting two new classes and writing tests for them, it is time to take a look at the Parser class. I would say that improving it further would be over-engineering it, at least in the scope of this article. The only thing that I would like us to think about is the name of the class. Does Parser do it?\nThis is quite subjective and I would guess some of you wouldn\u0026rsquo;t agree with me, but in my mind the Parser is quite broad term. In this instance, I think that Grader is a better name for it.\nTaking a step back As you could see in this article, there\u0026rsquo;s quite a bit of work around refactoring existing code. There are more than a two dozen patterns around refactoring, with Extract Class being one of the simplest ones. Having this said, I would like to ask you a question:\nDo you really need to think in patterns? Do we really need to have a \u0026ldquo;predefined sequence of steps\u0026rdquo; to make our code better?\nI think that it\u0026rsquo;s not really about applying a certain pattern, it\u0026rsquo;s more about caring about the design of the code and writing tests for it. As a rule of thumb, I always try to think about the five SOLID principles when writing my code. And when you are refactoring - understand the motivation and the context behind the code that you are refactoring, without focusing on which pattern you will apply.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/tdd-extract-class/","summary":"There are a lot of refactoring patterns available out there for us. I assume that most of us use these patterns, at certain times without being aware that those refactoring steps are defined as a pattern in the past. In this post, I will take you through an example of refactoring Ruby code with the Extract Class pattern by using Test-Driven Development.\nLet\u0026rsquo;s dive in!\nWhat went wrong at the test?","title":"Refactoring in Ruby: TDD your way through Extract Class"},{"content":"Ruby on Rails as a framework does a lot of things for us developers. We get a very customizable middleware stack, great routing system, very expressive ORM, helpful modules with great utility methods in them and so on. But in Rails there\u0026rsquo;s more than meets the eye. It does some great things that we just take for granted or on occasions we don\u0026rsquo;t even know they exist.\nSome of these features are TLS redirection, secure cookies and HTTP Strict Transport Security (HSTS). Let\u0026rsquo;s dive in into the Rails middleware stack and see what these things mean and what benefits they provide.\nHTTP Strict Transport Security According to Wikipedia:\n HTTP Strict Transport Security (HSTS) is a web security policy mechanism which helps to protect secure HTTPS websites against downgrade attacks and cookie hijacking. It allows web servers to declare that web browsers (or other complying user agents) should only interact with it using secure HTTPS connections and never via the insecure HTTP protocol. HSTS is an IETF standards track protocol and is specified in RFC 6797.\nThe HSTS Policy is communicated by the server to the user agent via an HTTP response header field named \u0026ldquo;Strict-Transport-Security\u0026rdquo;. HSTS Policy specifies a period of time during which the user agent shall access the server in a secure-only fashion.\n This is a short and nice summary of HSTS. The Internet Engineering Task Force (IETF) have solved the problem by making web servers send a HTTP response header which will make the browsers use HTTPS over HTTP when requesting any of the resources on that particular web server.\nIf you take a deeper look, into the Request for Comments (RFC) No. 6797 where HSTS was proposed, you will see this:\n 2.3. Threat Model\nHSTS is concerned with three threat classes: passive network attackers, active network attackers, and imperfect web developers. However, it is explicitly not a remedy for two other classes of threats: phishing and malware. Threats that are addressed, as well as threats that are not addressed, are briefly discussed below.\n It\u0026rsquo;s a good thing that the IETF and the Rails core developers know that we are imperfect (read: lazy), so they have our backs. *wink emoji*\nSince we got the basics right, let\u0026rsquo;s look at the structure of the HSTS header:\nStrict-Transport-Security: max-age=31536000; includeSubdomains; preload\nIt is composed of three directives: max-age, includeSubdomains and preload. The max-age directive tells the browser that this is the duration of time for which HSTS will be active for the domain. The includeSubdomains directive is quite self-explanatory: it tells the browser that HSTS will be active for all subdomains. The last one, preload, is created by the Chrome security team. It\u0026rsquo;s purpose is to create a list of domains that will be preloaded to Chrome, so Chrome knows that HSTS will be preloaded for the given domain. Later, this preloading mechanism got incorporated to Firefox, Safari and Internet Explorer. This allows HSTS to kick in even for the first visit of the website.\nSecure cookies Cookies, the ones that browsers consume, have multiple values and flags on them. Here\u0026rsquo;s a screenshot of someone\u0026rsquo;s cookies as shown in the Chrome Developer Tools:\nAs you can see in the screenshot, a cookie has a name, a value, the domain (or owner), the path, expiry date/time, it\u0026rsquo;s size, the HttpOnly flag, the Secure flag and the First-Party field. For the purpose of this article, we are only interested in the Secure flag.\nThe secure flag tells the browser that it can send this cookie to the owner only via HTTPS. This protects the user when under a Man in the middle (MITM) attack. Basically, if someone steals the session cookie from the user, it will always be encrypted with SSL/TLS so it will be unusable for the attacker.\nSSL/TLS Redirection In comparison to HSTS and Secure Cookies this is a really simple security mechanism. Rails has the ability to redirect clients accessing it from HTTP to HTTPS. Think of it in this way - if the proper configuration is set, it will check if the request comes via HTTPS. If not, it redirects the client to the same URL, just via HTTPS. Simple as that.\nBack to Rails Now, how does Rails implement these mechanisms? Think about this: when we are fetching/building the data for the response, whether it\u0026rsquo;s XML, JSON or HTML, we rarely do anything with the response headers. We usually render some document/data and we let Rails take care of the rest. So, there has to be some configuration where we can turn on TLS redirection, secure cookies and HSTS.\nRails configuration can be found in multiple places. If it\u0026rsquo;s configuration per environment, it\u0026rsquo;s usually config/\u0026lt;environment\u0026gt;.rb. If it\u0026rsquo;s general configuration - config/application.rb. Other times, it can be in config/initializers. It very much depends on what part of the application you want to configure.\nBy default Rails has some configurations set up for us. For example, when a brand new Rails application is generated, in the config/production.rb file you can see the following lines:\n# Force all access to the app over SSL, use Strict-Transport-Security, # and use secure cookies. config.force_ssl = true As you can notice in the comment, this is the line that enables all these security mechanisms. Quite self-descriptive, the attribute is called force_ssl. For production environment, this is set to true by default. Let\u0026rsquo;s see how this actually works under the hood.\nWhere does it do it? Searching through the Rails source code, starting from the Rails::Application::Configuration where I noticed that the force_ssl configuration is set to false by default. But, this was a dead end - it was only the Rails configuration object, nothing else.\nSearching on for the force_ssl property, I ran into Rails::Application::DefaultMiddlewareStack (source). In the #build_stack method I noticed that when Rails is booting up, it decides if the Rails::Application::ActionDispatch::SSL middleware should be pushed onto the middleware stack. This was the obvious place to look, so let\u0026rsquo;s open that class.\nEnforcing TLS/SSL and HSTS In the Rails::Application::ActionDispatch::SSL there\u0026rsquo;s the build_hsts_header method:\ndef build_hsts_header(hsts) value = \u0026#34;max-age=#{hsts[:expires].to_i}\u0026#34; value \u0026lt;\u0026lt; \u0026#34;; includeSubDomains\u0026#34; if hsts[:subdomains] value \u0026lt;\u0026lt; \u0026#34;; preload\u0026#34; if hsts[:preload] value end It is being called from the #initialize method, which is where an object from the middleware class is created:\ndef initialize(app, redirect: {}, hsts: {}, **options) @app = app if options[:host] || options[:port] ActiveSupport::Deprecation.warn \u0026lt;\u0026lt;-end_warning.strip_heredoc  The `:host` and `:port` options are moving within `:redirect`: `config.ssl_options = { redirect: { host: …, port: … }}`. end_warning @redirect = options.slice(:host, :port) else @redirect = redirect end @hsts_header = build_hsts_header(normalize_hsts_options(hsts)) end The #build_hsts_header method takes a normalized hash of HSTS options and builds the header based on the values in the hash. This all takes effect in the #call method:\ndef call(env) request = Request.new env if request.ssl? @app.call(env).tap do |status, headers, body| set_hsts_header! headers flag_cookies_as_secure! headers end else redirect_to_https request end end After the HSTS header is added to the request, it is passed down onto the rest of the middleware stack.\nSecuring the cookies Securing the cookies is done in the same module. The flag_cookies_as_secure! method looks for the Set-Cookie header in the request and appends the secure property to the Set-Cookie header if needed.\ndef flag_cookies_as_secure!(headers) if cookies = headers[\u0026#39;Set-Cookie\u0026#39;.freeze] cookies = cookies.split(\u0026#34;\\n\u0026#34;.freeze) headers[\u0026#39;Set-Cookie\u0026#39;.freeze] = cookies.map { |cookie| if cookie !~ /;\\s*secure\\s*(;|$)/i \u0026#34;#{cookie}; secure\u0026#34; else cookie end }.join(\u0026#34;\\n\u0026#34;.freeze) end end For reference, this is what the Set-Cookie header looks like:\nSet-Cookie: cookie-name=cookie-value-here; path=/; expires=Fri, 01 Jan 2016 00:00:00 -0000; secure; HttpOnly This will tell the browser that the cookie should be secured and sent only via HTTPS. Just like the HSTS header, the secure cookies header is attached to the request in the #call method (which you can see above).\nNote: do not confuse the secure directive with the HttpOnly directive.\nTLS redirection Another feature of Rails is the so-called \u0026ldquo;TLS redirection\u0026rdquo;. It\u0026rsquo;s workings are quite simple - whenever you have force_ssl set to true, it will redirect all of the HTTP traffic to HTTPS. Again, the Rails::Application::ActionDispatch::SSL middleware class is responsible for this behaviour of Rails, more specifically the redirect_to_https method, which invokes the https_location_for method:\ndef redirect_to_https(request) [ @redirect.fetch(:status, 301), { \u0026#39;Content-Type\u0026#39; =\u0026gt; \u0026#39;text/html\u0026#39;, \u0026#39;Location\u0026#39; =\u0026gt; https_location_for(request) }, @redirect.fetch(:body, []) ] end def https_location_for(request) host = @redirect[:host] || request.host port = @redirect[:port] || request.port location = \u0026#34;https://#{host}\u0026#34; location \u0026lt;\u0026lt; \u0026#34;:#{port}\u0026#34; if port != 80 \u0026amp;\u0026amp; port != 443 location \u0026lt;\u0026lt; request.fullpath location end As you can notice, redirect_to_https rebuilds a response which will have the same Content-Type and body, but the Location and HTTP Status will be different.\nIn it\u0026rsquo;s core, the middleware just wraps the incoming request and checks if it\u0026rsquo;s SSL/TLS based. If not, it redirects the web client to the same resource on the server, just via HTTPS.\nOutro As we saw in this article, Rails does some magic under the hood for us. It\u0026rsquo;s really great that we all get these great benefits without even bothering to set them up. Although we get them by default, it\u0026rsquo;s good to know what happens with our application under the hood.\nI hope this article was fun to read and informative for you. Do you have a favourite \u0026ldquo;hidden\u0026rdquo; functionality of Rails that not many of us know? Please share your thoughts with me in the comments section below.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/rails-tls-hsts-cookies/","summary":"Ruby on Rails as a framework does a lot of things for us developers. We get a very customizable middleware stack, great routing system, very expressive ORM, helpful modules with great utility methods in them and so on. But in Rails there\u0026rsquo;s more than meets the eye. It does some great things that we just take for granted or on occasions we don\u0026rsquo;t even know they exist.\nSome of these features are TLS redirection, secure cookies and HTTP Strict Transport Security (HSTS).","title":"Rails, Secure Cookies, HSTS and friends"},{"content":"Most of us write some Rake tasks and completely forget about them. In fact, we rarely give any love to our Rake tasks. Well, I think it\u0026rsquo;s time we change that. Let\u0026rsquo;s see why and how we can test our Rake tasks.\nBut, why? Yes, it\u0026rsquo;s a legit question. You can always say \u0026ldquo;I already tested my classes!\u0026rdquo;. But, there are couple of reasons why you should always test your Rake tasks:\n Rake tasks is code. And all code should be tested. Rake tasks can use any part of your app. Models, service classes and what not. If one of the classes that the Rake task relies on changes, you have to know if it will break it. Rake tasks can do heavy lifting. Perhaps you have a cron on Heroku that runs an email campaign that calls a Rake task. Or you generate reports with a Rake task. This is important and you need to know if it actually works. Forgetting about your Rake tasks is easy. Or, if you inherit a codebase it\u0026rsquo;s easy to not even notice them when beginning the project. Rake tasks are code as well and breaking it is easy.  So, yeah, test your Rake tasks!\nThe Rake task For our example application, let\u0026rsquo;s imagine we have an application where users can register. But, just like with most of the websites online, people sometimes register but they do not finish the registration process. Often, the database can be polluted with records of unfinished user registration.\nThe application has a Rake task that deletes users that haven\u0026rsquo;t finished their registration process.\n# lib/tasks/users/remove_unconfirmed.rb namespace :users do desc \u0026#34;Delete users that have not finished the registration process\u0026#34; task :remove_unconfirmed do User.unconfirmed.each {|user| user.delete } end end This task is run with as a cron job. Let\u0026rsquo;s see how we can test it.\nLately, I prefer testing with Minitest. I like it because it\u0026rsquo;s really tiny, quite verbose, magic-less and it\u0026rsquo;s pure Ruby. Now, since Test::Unit is basically syntactic-sugar on top of Minitest, I will show you how to test the Rake task with it.\nIntegration test We will take for granted that the User model and the UserMailer are already tested. Our next objective is to test this Rake task. We will need one test for this task - it will check that the task deletes the unconfirmed user. This is basically an integration test that will work with actual records in the database.\nWhenever you are testing Rake tasks, you need to load the tasks from the Rails application itself. Note that in your tests you should change MyApplication to the name of your application.\nThe test will look like this:\n# test/lib/user_notify_test.rb require \u0026#39;test_helper\u0026#39; class RemoveUnconfirmedTaskTest \u0026lt; ActiveSupport::TestCase setup do @confirmed_user = User.create(email: \u0026#34;john@appleseed.com\u0026#34;, confirmed_at: Time.now) @unconfirmed_user = User.create(email: \u0026#34;jane@doe.com\u0026#34;, confirmed_at: nil) MyApplication::Application.load_tasks Rake::Task[\u0026#39;users:remove_unconfirmed\u0026#39;].invoke end test \u0026#34;unconfirmed user is deleted\u0026#34; do assert_nil User.find_by(email: \u0026#34;jane@doe.com\u0026#34;) end test \u0026#34;confimed user is not deleted\u0026#34; do assert_equal @confimed_user, User.find_by(email: \u0026#34;john@appleseed.com\u0026#34;) end end Now, in the setup step, we create two users - one which will be confirmed and one unconfirmed. Then, we load the tasks from the application. This is done by adding:\nMyApplication::Application.load_tasks This task basically requires rake and loads each file in the lib/tasks path. You can see it\u0026rsquo;s source here. Next, we invoke the task itself. We do this by adding this in our test:\nRake::Task[\u0026#39;users:remove_unconfirmed\u0026#39;].invoke This line locates the task by it\u0026rsquo;s name and returns a Rake::Task object. Then, we call invoke on it, which executes the task. After that we make assertions on the data in the database, expecting the unconfirmed user to be removed from the database.\nUnit test Another approach at testing this is exctracting the logic from the Rake task to a utility class. Then, we would call the method from the class that contains the logic in the Rake task.\nLet\u0026rsquo;s create a UserRemoval class, with a class method called remove_unconfirmed.\nclass UserRemoval def self.remove_unconfirmed! User.unconfirmed.each {|user| user.delete } end end Then, our Rake task would look like:\n# lib/tasks/users/remove_unconfirmed.rb namespace :users do desc \u0026#34;Delete users that have not finished the registration process\u0026#34; task :remove_unconfirmed do UserRemoval.remove_unconfirmed! end end Since all of the logic in the rake task is contained in another class, we can test the class itself, instead of testing the task. This is quite trivial, since we can pretty much use the same test, with some small changes.\nThe test would look like this:\n# test/lib/user_notify_test.rb require \u0026#39;test_helper\u0026#39; class UserRemovalTest \u0026lt; ActiveSupport::TestCase setup do @confirmed_user = User.create(email: \u0026#34;john@appleseed.com\u0026#34;, confirmed_at: Time.now) @unconfirmed_user = User.create(email: \u0026#34;jane@doe.com\u0026#34;, confirmed_at: nil) UserRemoval.remove_unconfirmed! end test \u0026#34;unconfirmed user is deleted\u0026#34; do assert_nil User.find_by(email: \u0026#34;jane@doe.com\u0026#34;) end test \u0026#34;confimed user is not deleted\u0026#34; do assert_equal @confimed_user, User.find_by(email: \u0026#34;john@appleseed.com\u0026#34;) end end As you can notice, the test is basically the same, without loading/invoking the Rake task. Instead, we just call the UserRemoval.remove_unconfirmed! method.\nNow, we could stub out the calls to the database and isolate the tests from database IO, but I usually prefer to do these cheap tests with real databse records.\nOutro Now, I know that this is quite a beginner tutorial on testing Rake tasks and I am sure it didn\u0026rsquo;t rock the world of someone adept at Ruby and testing. But, I have been asked on couple of occasions about this and have seen some questions on Stack Overflow about it so I figured it would be nice to document it somewhere.\nWhat do you think about testing Rake tasks? Do you test them? If you do, do you write integration tests or maybe you prefer unit tests with mocks? Or, maybe you take another approach?\nLet me know in the comments!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/test-rake-tasks/","summary":"Most of us write some Rake tasks and completely forget about them. In fact, we rarely give any love to our Rake tasks. Well, I think it\u0026rsquo;s time we change that. Let\u0026rsquo;s see why and how we can test our Rake tasks.\nBut, why? Yes, it\u0026rsquo;s a legit question. You can always say \u0026ldquo;I already tested my classes!\u0026rdquo;. But, there are couple of reasons why you should always test your Rake tasks:","title":"Why and how to test Rake tasks in your Rails application"},{"content":"Elixir is a really cool language. Although I do not have much experience with it (yet), I am always trying to build interesting stuff with it and learn the built-in tools. In this blog post I decided to show you how to build a self-contained command line application with Elixir, with some help from escript.\nEscript Erlang and Elixir have this cool thing called escript. It\u0026rsquo;s basically a tool that compiles an Elixir app that you have as a command line application.\nFrom Elixir\u0026rsquo;s documentation on escript:\n An escript is an executable that can be invoked from the command line. An escript can run on any machine that has Erlang installed and by default does not require Elixir to be installed, as Elixir is embedded as part of the escript.\n  This task guarantees the project and its dependencies are compiled and packages them inside an escript.\n What is really interesting is that escript will build your Elixir CLI application and create an executable. The executable will only require Erlang to be able to run on any machine. It will not need Elixir because it will be contained in the executable it builds.\neight_ball wrapped in escript Now, instead of going at length of building a tiny example Elixir application, I will use the eight_ball application that we built in the Write and publish your first Elixir library post. If you haven\u0026rsquo;t read it yet you can click on the link above, read the step-by-step tutorial and come back to this post once you are done.\nThe application is quite simple. It\u0026rsquo;s a module which has only one function EightBall.ask/1. It takes a question as an argument and returns the answer. Let\u0026rsquo;s use escript to build a command line application from this Elixir application.\nAdding escript to the application If you want to follow along, you can find the repo here.\nIn the mix.exs file, we need to make an addition:\ndefmodule EightBall.Mixfile do use Mix.Project def project do [app: :eight_ball, version: \u0026#34;0.0.1\u0026#34;, elixir: \u0026#34;~\u0026gt; 1.0\u0026#34;, build_embedded: Mix.env == :prod, start_permanent: Mix.env == :prod, escript: [main_module: EightBall.CLI], # \u0026lt;- this line deps: deps, package: package ] end # ... end The line we added will tell escript that the main module where the main/1 function will be placed is EightBall.CLI. If you are wondering what main/1 function, think of it in this way: the main/1 function is the function that will be an entry point for the command line application.\nEightBall.CLI Since the EightBall.CLI module doesn\u0026rsquo;t exist, let\u0026rsquo;s create it:\ndefmodule EightBall.CLI do def main(args) do end end As you can see, the module contains the main/1 function wich will take the command line arguments map as an argument. Now, to make any sense of the arguments, we need to use the OptionParser module which comes with Elixir. The OptionParser (docs) module contains functions which can parse the command line arguments.\nIf I were to wish the syntax of the arguments of the command line application, I\u0026rsquo;d like to see something like:\neight_ball --question \u0026#34;Is Elixir great?\u0026#34; or\neight_ball -q \u0026#34;Is Elixir great?\u0026#34; So, let\u0026rsquo;s use OptionParser and make -q/--question an argument:\ndefmodule EightBall.CLI do def main(argv) do {options, _, _} = OptionParser.parse(argv, switches: [question: :string], ) IO.inspect options end end The main/1 function will parse arguments and build meaningful tagged lists that we can use. At this time, the main/1 function will only show the options that have been parsed. We will add some meaningful logic later.\nFirst, let\u0026rsquo;s build the executable with escript. To build the executable, in the project root we need to run:\nmix escript.build This will compile the Elixir application and build an escript executable.\n➜ eight_ball git:(master) ✗ mix escript.build Compiled lib/eight_ball/cli.ex Generated eight_ball app Generated escript eight_ball with MIX_ENV=dev If you check the contents of the root path of the eight_ball project, you will see an eight_ball executable. To use it, type:\n./eight_ball --question \u0026#34;Is Elixir great?\u0026#34; And you will get the following output:\n➜ eight_ball git:(master) ✗ ./eight_ball -q \u0026#34;Is Elixir great?\u0026#34; [question: \u0026#34;Is Elixir great?\u0026#34;] Voila! We can see the parsed command line arguments.\nWiring it up Now, let\u0026rsquo;s use the EightBall.ask/1 function in the CLI app. In the EightBall::CLI.main/1 function, add the following code:\ndefmodule EightBall.CLI do def main(opts) do {options, _, _} = OptionParser.parse(opts, switches: [question: :string], aliases: [q: :question] # makes \u0026#39;-q\u0026#39; an alias of \u0026#39;--question\u0026#39; ) try do IO.puts EightBall.ask(options[:question]) rescue e in RuntimeError -\u0026gt; e IO.puts e.message end end end In the try/rescue block we send the question string to the ask/1 function and rescue from a RuntimeError. This error can be triggered by EightBall::QuestionValidator which validates the input string. If the input is not a question, it will throw an error:\n Question must be a string, ending with a question mark.\n If our command line application rescues this error, it will output the error message.\nBuilding the CLI application Now, the last step of building the command line application is invoking escript. With Elixir, as we saw earlier, it\u0026rsquo;s super easy to invoke esciprt via mix:\nmix escript.build If you are following along, the output of the command should be similar to this:\n➜ eight_ball git:(master) ✗ mix escript.build Compiled lib/eight_ball.ex Generated eight_ball app Generated escript eight_ball with MIX_ENV=dev This will create a command line application, with the same filename as the main module. In our case, this will be just eight_ball. Now, if one would open the executable, there will be a ton of non-readable code. This is due to the fact that the code you will see is Erlang VM bytecode.\nWhile the code is unreadable, the awesome thing is that you can send this command line application to anyone that has just Erlang installed on her/his machine. Elixir itself is embedded in the file, so the only dependency is Erlang. Isn\u0026rsquo;t that cool?\nNow, if we run the app:\n➜ eight_ball git:(master) ✗ ./eight_ball --question \u0026#34;Is Elixir awesome?\u0026#34; Outlook good Or\n➜ eight_ball git:(master) ✗ ./eight_ball --question \u0026#34;Is Elixir awesome\u0026#34; Question must be a string, ending with a question mark. Outro Thanks for following along this post. I hope you learn something and you consider it a time well spent. Have you built anything interesting with Elixir? Share it with me in the comments, I would love to check it out!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/writing-elixir-cli-apps/","summary":"Elixir is a really cool language. Although I do not have much experience with it (yet), I am always trying to build interesting stuff with it and learn the built-in tools. In this blog post I decided to show you how to build a self-contained command line application with Elixir, with some help from escript.\nEscript Erlang and Elixir have this cool thing called escript. It\u0026rsquo;s basically a tool that compiles an Elixir app that you have as a command line application.","title":"Writing command line apps with Elixir"},{"content":"Learn how to integrate Minitest into your Ruby project and reap the benefits of test-driven development.\nRead the article here.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/getting-started-with-minitest/","summary":"Learn how to integrate Minitest into your Ruby project and reap the benefits of test-driven development.\nRead the article here.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","title":"Getting Started with Minitest"},{"content":"Mixins in Ruby are a very powerful feature. But knowing how to test them sometimes is not so obvious, especially to beginners. I think that this comes from mixins' nature - they get mixed into other classes. So, if you think that there is a lot to testing mixins and you easily get overwhelmed by it - take it easy, it\u0026rsquo;s not that hard.\nLet\u0026rsquo;s see how easy it is to test mixins, with some help from the lovely Minitest.\nMixins When writing Ruby, we usually write two types of mixins. The first one is a coupled mixin, and the other, well.. uncoupled.\nUncoupled mixins Uncoupled mixins are the ones whose methods do not depend on the implementation of the class where they will get mixed in.\nQuick example:\nmodule Speedable def speed \u0026#34;This car runs super fast!\u0026#34; end end class PetrolCar include Speedable def fuel \u0026#34;Petrol\u0026#34; end end class DieselCar include Speedable def fuel \u0026#34;Diesel\u0026#34; end end In irb:\n\u0026gt;\u0026gt; p = PetrolCar.new =\u0026gt; #\u0026lt;PetrolCar:0x007fc332cc4be0\u0026gt; \u0026gt;\u0026gt; p.speed =\u0026gt; \u0026#34;This car runs super fast!\u0026#34; \u0026gt;\u0026gt; p.fuel =\u0026gt; \u0026#34;Petrol\u0026#34; \u0026gt;\u0026gt; d = DieselCar.new =\u0026gt; #\u0026lt;DieselCar:0x007fc332cae2f0\u0026gt; \u0026gt;\u0026gt; d.speed =\u0026gt; \u0026#34;This car runs super fast!\u0026#34; \u0026gt;\u0026gt; d.fuel =\u0026gt; \u0026#34;Diesel\u0026#34; As you can see, the speed method in the Speedable mixins does not depend on any other methods. In other words, it\u0026rsquo;s self-contained.\nTesting uncoupled mixins When it comes to testing uncoupled mixins, it\u0026rsquo;s quite trivial. There are two main strategies that you can use, by extending the singleton class of an object or by using a dummy class.\nLet\u0026rsquo;s see the first one.\nclass FastCarTest \u0026lt; Minitest::Test def setup @test_obj = Object.new @test_obj.extend(Speedable) end def test_speed_reported assert_equal \u0026#34;This car runs super fast!\u0026#34;, @test_obj.speed end end As you can see, we instantiate an object of the Object class which is just an empty, ordinary object that doesn\u0026rsquo;t do anything. Then, we extend the object singleton class with the Speedable module which will mix the speed method in. Then, in the test, we assert that the method will return the expected output.\nThe second strategy is the \u0026ldquo;dummy class\u0026rdquo; strategy:\nclass DummyTestClass include Speedable end class FastCarTest \u0026lt; Minitest::Test def test_speed_reported dummy = DummyTestClass.new assert_equal \u0026#34;This car runs super fast!\u0026#34;, dummy.speed end end As you can see, we create just a dummy class, specific only for this test file. Since the FastCar mixin is mixed in, the DummyTestClass will have the speed method as an instance method. Then, in the test, we just create a new object from the dummy class and assert on the dummy.speed method.\nCoupled mixins Coupled mixins are the ones whose methods depend on the implementation of the class where they will be mixed in. Or, the oposite of uncoupled mixins.\nLet me show you a quick example:\nmodule Reportable def report \u0026#34;This car runs on #{fuel}.\u0026#34; end end class PetrolCar include Reportable def fuel \u0026#34;petrol\u0026#34; end end class DieselCar include Reportable def fuel \u0026#34;diesel\u0026#34; end end Now, if we try our classes in irb:\n\u0026gt;\u0026gt; pcar = PetrolCar.new =\u0026gt; #\u0026lt;PetrolCar:0x007fda3403bba8\u0026gt; \u0026gt;\u0026gt; pcar.report =\u0026gt; \u0026#34;This car runs on petrol.\u0026#34; \u0026gt;\u0026gt; dcar = DieselCar.new =\u0026gt; #\u0026lt;DieselCar:0x007fda3318a320\u0026gt; \u0026gt;\u0026gt; dcar.report =\u0026gt; \u0026#34;This car runs on diesel.\u0026#34; You see, the implementation of the Reportable#report method relies on (or, is coupled to) the implementation of the DieselCar and PetrolCar classes. If we mixed in the Reportable mixin in a class that does not have the fuel method implemented, we would get an error when calling the report method.\nTesting coupled mixins When it comes to coupled mixins, testing can get just a tad bit harder. Again, the same two strategies.\nclass ReportableTest \u0026lt; Minitest::Test def setup @test_obj = Object.new @test_obj.extend(Reportable) class \u0026lt;\u0026lt; @test_obj def fuel \u0026#34;diesel\u0026#34; end end end def test_speed_reported assert_equal \u0026#34;This car runs on diesel.\u0026#34;, @test_obj.report end end Now, you can see, it gets a bit hairy when we open the singleton class of the @test_obj and we add the fuel method, so our coupled mixin can work. But, otherwise, it\u0026rsquo;s quite straight forward.\nThe approach that I prefer is using the dummy class because it\u0026rsquo;s much more explicit.\nclass DummyCar include Reportable def fuel \u0026#34;gasoline\u0026#34; end end class ReportableTest \u0026lt; Minitest::Test def test_fuel_reported dummy = DummyCar.new assert_equal \u0026#34;This car runs on gasoline.\u0026#34;, dummy.report end end Now, this is cleaner. We create a DummyCar class where we mix the Reportable mixin and we define the fuel method. Then, in the test, we just create a DummyCar object and we assert for the value of the report method. Remember, we are doing this only because we want to test the mixin. If we were to test any of the classes, there would be no point in doing this.\nAs you can see, it\u0026rsquo;s quite simple to test these mixins with plain-old Ruby. I guess it\u0026rsquo;s worth mentioning that these examples are very simple and you might run into more complex mixins that need testing in the future. But, when testing mixins, these strategies will still work. Just don\u0026rsquo;t get owerwhelmed and take it step-by-step.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-mixins-minitest/","summary":"Mixins in Ruby are a very powerful feature. But knowing how to test them sometimes is not so obvious, especially to beginners. I think that this comes from mixins' nature - they get mixed into other classes. So, if you think that there is a lot to testing mixins and you easily get overwhelmed by it - take it easy, it\u0026rsquo;s not that hard.\nLet\u0026rsquo;s see how easy it is to test mixins, with some help from the lovely Minitest.","title":"Testing Ruby Mixins with Minitest in isolation"},{"content":"Phoenix is a really powerful and customizable framework. One of it\u0026rsquo;s small but important configurations is filtering custom params from the logs. I am sure that this will be more interesting to beginner than experienced developers, but nevertheless, let\u0026rsquo;s see what\u0026rsquo;s the motivation behind this and how to do it in Phoenix.\nMotivation First, I\u0026rsquo;d like you to understand the motivation behind this and why this is useful. Think about it. Our applications usually have login credentials, i.e. username and password. In our databases, we almost always keep the username in plain text, while the password is encryped with some sort of a hashing algorithm.\nWhile logging events is a very nice, although simple, feature of any web framework (or, most of the software in the world), it can be a security flaw if not configured properly. Logs enable us, the people that build and maintain the software, to see how our application is behaving. It\u0026rsquo;s logging all sorts of information. All of the logs are stored on the hard drive of the server that\u0026rsquo;s running the application.\nSo, it we are storing the passwords in the databases as hashes, why would we want the logs to contain any login credentials in plain text? This is quite a security flaw. If someone gains access to the logs, they\u0026rsquo;ll have access to a lot of user credentials.\nIn practice All of the web frameworks (that I\u0026rsquo;ve seen/tried/used) filter the password and password_confirmation params in their logs. But, what if you are building an API? For example, what if the user needs to supply an API_KEY param with every request? We wouldn\u0026rsquo;t want the key to be stored in the logs in plain text.\nCustom params filters come into play here. Phoenix allows us to customize the list of filtered params from the logs. This is easily achived by adding:\nconfig :phoenix, :filter_parameters, [\u0026#34;password\u0026#34;, \u0026#34;api_key\u0026#34;] Now, there are two things to keep in mind. The first is to decide in which environment(s) we want the filtering to be applied. For example, if we want this to happen only in production environment, this line needs to be added in the config/prod.exs file. In case we need filtering in all environments, it should be added in the config/config.exs file.\nThe second thing is to understand that by adding this line, the default filters are overriden. This means that if we leave out \u0026quot;password\u0026quot; from the list, it will not be filtered, although it\u0026rsquo;s a default configuration.\nHope this clears up filtering params from the logs in Phoenix. If you have any questions or feedback, feel free to join the discussion below!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/filter-params-phoenix/","summary":"Phoenix is a really powerful and customizable framework. One of it\u0026rsquo;s small but important configurations is filtering custom params from the logs. I am sure that this will be more interesting to beginner than experienced developers, but nevertheless, let\u0026rsquo;s see what\u0026rsquo;s the motivation behind this and how to do it in Phoenix.\nMotivation First, I\u0026rsquo;d like you to understand the motivation behind this and why this is useful. Think about it.","title":"Filter request params from Phoenix logs"},{"content":"Elixir\u0026rsquo;s built in testing library is called ExUnit. It\u0026rsquo;s a proper testing framework, which, although simple, gives the developers a lot of power and flexibility. If you come from Ruby land, I am sure you\u0026rsquo;ve been in a position where you want to set a certain test to be skipped. For example, RSpec in Ruby does it with the pending method. Let\u0026rsquo;s see how we can customize our test suite so ExUnit can skip over tests in our test suite.\nTags ExUnit comes with this neat feature called tags. Tags are basically module variables in the test module. In the context of the test, you can think of them as annotations. So, by tagging a test, the value of the tag can be used in the test itself, by passing the context.\ndefmodule FileTest do # Changing directory cannot be async use ExUnit.Case, async: false setup context do # Read the :cd tag value if cd = context[:cd] do prev_cd = File.cwd! File.cd!(cd) on_exit fn -\u0026gt; File.cd!(prev_cd) end end :ok end @tag cd: \u0026#34;fixtures\u0026#34; test \u0026#34;reads utf-8 fixtures\u0026#34; do File.read(\u0026#34;hello\u0026#34;) end end Now, how can we utilize tags to get RSpec\u0026rsquo;s pending funcionality in ExUnit?\nRunning tests by tag Running tests by tag is really simple in ExUnit. Basically, ExUnit has the ability to skip/include any test by it\u0026rsquo;s tag.\nFor example, let\u0026rsquo;s say you have tagged couple of tests that are brittle:\ndefmodule SomeTest do use ExUnit.Case, async: false @tag :brittle test \u0026#34;some brittle code\u0026#34; do # test here... end end Now, you can run only the tests with the brittle tag, by executing:\nmix test test/some_test.exs --include brittle Having this in mind, let\u0026rsquo;s introduce a custom tag of ours so we can make our tests pending.\nCustom tags Although the word \u0026ldquo;custom\u0026rdquo; used in programming often means something complicated done from scracth by the programmer, in this case it\u0026rsquo;s very simple.\nLet\u0026rsquo;s take any test and tag it with :pending.\ndefmodule SomeTest do use ExUnit.Case, async: false @tag :pending test \u0026#34;always true\u0026#34; do assert 1 == 1 end end We can exclude this \u0026ldquo;pending\u0026rdquo; test by executing our test suite with:\nmix test --exclude pending This will skip any tests that have the :pending tag. Simple as that, we have RSpec\u0026rsquo;s pending functionality just by excluding a tag. If you are wondering if we can make the exclusion of the tag automatic - yes we can. In your test_helper.exs add this line, before the ExUnit.start line:\nExUnit.configure(exclude: [pending: true]) This configuration will tell ExUnit that it should always skip tests that are tagged as :pending. Now, every time you run your tests, the tests tagged with :pending will be excluded.\nDo you have any other interesting configuration trick in your ExUnit suite? Feel free to share them in the comments, I would love to learn more about ExUnit!\nThanks for reading!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/pending-tests-exunit/","summary":"Elixir\u0026rsquo;s built in testing library is called ExUnit. It\u0026rsquo;s a proper testing framework, which, although simple, gives the developers a lot of power and flexibility. If you come from Ruby land, I am sure you\u0026rsquo;ve been in a position where you want to set a certain test to be skipped. For example, RSpec in Ruby does it with the pending method. Let\u0026rsquo;s see how we can customize our test suite so ExUnit can skip over tests in our test suite.","title":"How to set tests as pending in your ExUnit suite"},{"content":"As some of you have heard lately, Elixir is the new hotness. Is it just hype? Well, I thought so at first, but I told myself \u0026ldquo;heck, even if it\u0026rsquo;s a waste of time, at least I\u0026rsquo;ll broaden my horizons\u0026rdquo;. Which, if you think about it, it not really is a waste of time.\nLong story short, after couple of weeks of fiddling with the language, mostly by playing with it\u0026rsquo;s web framework I am delighted to say that it\u0026rsquo;s a really cool language that you should try out and also, I published a really small API wrapper for Elixir.\nSo today, I am going to walk you through writing a simple Elixir library and publishing it to Hex.pm, so it will be available for the whole world to use.\nGot a yes/no question? I am very sure all of you have heard about the Magic 8 Ball. It\u0026rsquo;s this toy that looks like a black and white 8 ball (hence the name). When you ask it a yes/no question it will (magically) answer the question.\nWhy don\u0026rsquo;t we create a small Elixir library that one can ask questions to and get the question answered? We\u0026rsquo;ll call it eight_ball, paying our respect to the Magic 8 Ball.\nLet\u0026rsquo;s mix it up! Mix is Elixir\u0026rsquo;s build tool, that allows you to easily create projects, manage tasks, run tests and much more. Mix also can manage dependencies and integrates very nicely with Hex. Hex is a package manager that provides dependency resolution and the ability to remotely fetch packages. We will publish our project to Hex.pm at the end of this tutorial.\nBut first, let\u0026rsquo;s create a new Elixir project. Project skeletons are created with the command:\nmix new \u0026lt;project-name-here\u0026gt; Or, in our case:\nmix new eight_ball When you run the command, you will get an output like this:\n➜ mix new eight_ball * creating README.md * creating .gitignore * creating mix.exs * creating config * creating config/config.exs * creating lib * creating lib/eight_ball.ex * creating test * creating test/test_helper.exs * creating test/eight_ball_test.exs Your mix project was created successfully. You can use mix to compile it, test it, and more: cd eight_ball mix test Run `mix help` for more commands. If you open the project directory with your favourite text editor, you can see all of the files that were generated. If you have seen any other Elixir projects, the file structure is pretty much the same.\nWhat is what? Just in case anyone gets confused by all of the generated files, let\u0026rsquo;s see what is what here:\n README.md -\u0026gt; This is just the README of the project .gitignore -\u0026gt; .gitignore file mix.exs -\u0026gt; the Mixfile. It\u0026rsquo;s basically the project definition. If you have any experience with Ruby, this is simillar to the .gemspec file config -\u0026gt; configuration files directory config/config.exs -\u0026gt; Application and it\u0026rsquo;s dependencies configuration lib -\u0026gt; Where the code of our library will live lib/eight_ball.ex -\u0026gt; The EightBall module test -\u0026gt; Tests directory test/test_helper.exs -\u0026gt; Test helper file test/eight_ball_test.exs -\u0026gt; The test file for the EightBall module  The answers According to the Wikipedia page for the Magic 8 Ball, the 20 answers inside a standard Magic 8 Ball are:\nLet\u0026rsquo;s make a list from these answers and add them as a module variable in the EightBall module.\ndefmodule EightBall do # Found at https://en.wikipedia.org/wiki/Magic_8-Ball#Possible_answers @answers [ \u0026#34;It is certain\u0026#34;, \u0026#34;It is decidedly so\u0026#34;, \u0026#34;Without a doubt\u0026#34;, \u0026#34;Yes, definitely\u0026#34;, \u0026#34;You may rely on it\u0026#34;, \u0026#34;As I see it, yes\u0026#34;, \u0026#34;Most likely\u0026#34;, \u0026#34;Outlook good\u0026#34;, \u0026#34;Yes\u0026#34;, \u0026#34;Signs point to yes\u0026#34;, \u0026#34;Reply hazy try again\u0026#34;, \u0026#34;Ask again later\u0026#34;, \u0026#34;Better not tell you now\u0026#34;, \u0026#34;Cannot predict now\u0026#34;, \u0026#34;Concentrate and ask again\u0026#34;, \u0026#34;Don\u0026#39;t count on it\u0026#34;, \u0026#34;My reply is no\u0026#34;, \u0026#34;My sources say no\u0026#34;, \u0026#34;Outlook not so good\u0026#34;, \u0026#34;Very doubtful\u0026#34; ] end Our next step will be to introduce a ask/1 function to our module. It will receive the question as a argument and return an answer. Now, we are faced with a problem. The Magic 8 Ball magically answers questions, because, it\u0026rsquo;s a magic ball. But, although programming often looks like magic to other people, we know that you can\u0026rsquo;t program \u0026ldquo;magic\u0026rdquo;. So, we\u0026rsquo;ll go with a random answer to a question.\nWe will know it\u0026rsquo;s not magic, but atleast, it will look like it is!\ndefmodule EightBall do def ask(_question) do @answers |\u0026gt; Enum.shuffle |\u0026gt; List.first end end Note: The @answers list is intentionally omitted.The function takes the @answers list, shuffles it using Enum.shuffle/1 (docs) and pipes it into List.first/1 (docs) which will take the first item from the shuffled list and return it.\nStarting Elixir v1.1, the core team added the Enum.take_random/2 (docs) function, that takes n random items from a list.\nIf you prefer to use v1.1 with Enum.take_random/2:\ndefmodule EightBall do def ask(_question) do @answers |\u0026gt; Enum.take_random(1) |\u0026gt; List.first end end What about the question? In the EightBall.ask/1 function, we don\u0026rsquo;t use the actual question. As you can see, we ignore the question argument by prepending the argument name with an underscore, or _question.\nWhy don\u0026rsquo;t we do something with the question? For example, let\u0026rsquo;s validate it? Every question is compiled of words and every question ends with e a question mark. So, we want a string as an argument, which ends with a question mark. Any other type of argument should be ignored. Or, rather, inform the user of our library that it expects a question.\nLet\u0026rsquo;s add some validation to our little ask/1 function. I will wish the interface of the validator first and we\u0026rsquo;ll write the implementation after that.\ndefmodule EightBall do def ask(question) do EightBall.QuestionValidator.validate!(question) @answers |\u0026gt; Enum.shuffle |\u0026gt; List.first end end Now, the EightBall.QuestionValidator.validate!/1 function will take the question as an argument and throw an error if the question does not have the format we expect.\nQuestionValidator Let\u0026rsquo;s write our simple validator.\ndefmodule EightBall.QuestionValidator do # Question must end with a \u0026#39;?\u0026#39; @validation_regex ~r/\\?$/ def validate!(question) when is_binary(question) do unless String.strip(question) =~ @validation_regex, do: throw_validation_error end def validate!(question) do throw_validation_error end defp throw_validation_error do throw \u0026#34;Question must be a string, ending with a question mark.\u0026#34; end end Looking at the code, top to bottom, there are couple of key points. First, the @validation_regex variable, is a regular expression. It will match any strings that end with a question mark.\nSecond, the validate!/1 function. The first function clause will match when the question is a binary. Why binary? Well, Elixir uses UTF8 encoding for string, which basically makes strings UTF8 encoded binaries. If the first function clause matches, it will strip the unnecessary whitespace using String.strip/1 and match the @validation_regex. If it does not match, it will throw an error.\nAlso, if the first function clause does not match, it will throw a validation error.\nTesting with IEx Let\u0026rsquo;s see how our library works in IEx (Interactive EliXir). In the project directory, run:\niex -S mix IEx will compile and load our library in the IEx session, so we can start using it right away. Try running:\niex(1)\u0026gt; EightBall.ask(\u0026#34;Can I fly?\u0026#34;) \u0026#34;Without a doubt\u0026#34; When I asked a question, the library returned \u0026ldquo;Without a doubt\u0026rdquo;. Nice! Let\u0026rsquo;s check our validation:\niex(2)\u0026gt; EightBall.ask(\u0026#34;This should fail.\u0026#34;) ** (throw) \u0026#34;Question must be a string, ending with a question mark.\u0026#34; (eight_ball) lib/eight_ball/question_validator.ex:14: EightBall.QuestionValidator.throw_validation_error/0 (eight_ball) lib/eight_ball.ex:27: EightBall.ask/1 When we sent a statement instead of a question, the library threw an error. Good. Another (and better) way to test this is by writing actual tests, but, we\u0026rsquo;ll leave that for another day.\nPublishing EightBall to Hex Hex has a very good documentation on publishing packages. If you want to read and understand the details, head over to the documentation. Here, we\u0026rsquo;ll just cover the basic steps needed to publish this libraty to Hex.pm.\nRegistration If you do not have a user registered, you can do it via the command line:\nmix hex.user register Hex will prompt for your username, email and password and then it will create an API key that will be stored in the ~/.hex directory.\nDefining the package The package is configured in the project function in the project\u0026rsquo;s mix.exs file. Let\u0026rsquo;s create a private function in our EightBall.Mixfile module and call it package:\ndefp package do [ files: [\u0026#34;lib\u0026#34;, \u0026#34;mix.exs\u0026#34;, \u0026#34;README\u0026#34;, \u0026#34;LICENSE*\u0026#34;], maintainers: [\u0026#34;Ilija Eftimov\u0026#34;], licenses: [\u0026#34;Apache 2.0\u0026#34;], links: %{\u0026#34;GitHub\u0026#34; =\u0026gt; \u0026#34;https://github.com/fteem/eight_ball\u0026#34;} ] end These properties will define the files of the package and some metadata like maintainers' name and licences. Then, in the EightBall.Mixfile.project/0 function, we need to include the package definiton:\ndefmodule EightBall.Mixfile do use Mix.Project def project do [app: :eight_ball, version: \u0026#34;0.0.1\u0026#34;, elixir: \u0026#34;~\u0026gt; 1.0\u0026#34;, build_embedded: Mix.env == :prod, start_permanent: Mix.env == :prod, deps: deps, package: package ] end *snip* end Also, make sure the version is set properly. In our case, we can leave it as 0.0.1. The last step after you are happy with the package definition is the publish step itself. Publishing a package is done by running:\n➜ eight_ball git:(master) mix hex.publish Publishing eight_ball v0.0.1 Dependencies: Files: lib/eight_ball.ex lib/eight_ball/question_validator.ex mix.exs README.md LICENSE App: eight_ball Name: eight_ball Version: 0.0.1 Build tools: mix Description: Library that acts like a real life Magic 8 Ball. Licenses: Apache 2.0 Maintainers: Ilija Eftimov Links: GitHub: https://github.com/fteem/eight_ball Elixir: ~\u0026gt; 1.0 Before publishing, please read Hex Code of Conduct: https://hex.pm/docs/codeofconduct Proceed? [Yn] y [#########################] 100% Published at https://hex.pm/packages/eight_ball/0.0.1 Don\u0026#39;t forget to upload your documentation with `mix hex.docs` Easy as that. After publishing your package, it\u0026rsquo;s available at it\u0026rsquo;s Hex.pm page.\nOutro That\u0026rsquo;s it. As you can see, publishing the library to Hex.pm is quite straight forward. Also, generating the project skeleton is really easy with Mix. All it takes is one command and the project is set up.\nIf you are looking for more challenge, you can add some tests for the validator module. Also, adding documentation is quite important, so if you feel like writing some documentation - do it! But, whatever you decide to do, go and share your library with the world. Push it to Hex.pm and make it available for everyone to download and use.\nDid you follow along this tutorial? Did you have any hiccups or did it all go smooth? Let me know in the comments below!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/writing-elixir-library/","summary":"As some of you have heard lately, Elixir is the new hotness. Is it just hype? Well, I thought so at first, but I told myself \u0026ldquo;heck, even if it\u0026rsquo;s a waste of time, at least I\u0026rsquo;ll broaden my horizons\u0026rdquo;. Which, if you think about it, it not really is a waste of time.\nLong story short, after couple of weeks of fiddling with the language, mostly by playing with it\u0026rsquo;s web framework I am delighted to say that it\u0026rsquo;s a really cool language that you should try out and also, I published a really small API wrapper for Elixir.","title":"Write and publish your first Elixir library"},{"content":"Have you ever heard of hoisting? Well, regardless if you have or you have not, Ruby has an interesting hositing mechanism built-in. Let\u0026rsquo;s take a dive and see how it creates variables and do some experiments with it.\nHoisting What is hoisting? Well, according to Google \u0026ldquo;hoist\u0026rdquo; means to raise something. Apparently, with with ropes and pulleys. At least, back in the day.\nWell, when it comes to variable hoisting, it\u0026rsquo;s basically a mechanism by which the language, in our context - Ruby, declares and defines variables. Okay, that sounds cool. Well, there are couple of quirks in Ruby that you should be aware of.\nBit of weirdness Take this code for example, and run it in console:\n# weird_1.rb puts x We will get an error, obviously. x is not defined therefore you get an error:\nNameError: undefined local variable or method `x\u0026#39; for main:Object That is normal. Next, try this:\n# weird_2.rb if true x = 1 end puts x This will output 1, which is expected. Now, let\u0026rsquo;s try something else:\n# weird_3.rb if false x = 1 end puts x What should this output? An error? Or nil? Or maybe 1, if somehow we live in a parallel universe? If we try to run this code, we will get a nil. You don\u0026rsquo;t believe me?\nTry adding this to the bottom of the script:\n# weird_4.rb puts x.class #=\u0026gt; NilClass You see, if we try to call an undefined variable we will get a NameError. But, if we define the variable in a part of the code that will not be run at all we will get a nil.\nWhat on Earth is going on here, right? Right?!\nHoisting Well, it\u0026rsquo;s not that complicated really. But, it\u0026rsquo;s a quirk that most of us have not ran across. The \u0026ldquo;magic\u0026rdquo; here is done by Ruby\u0026rsquo;s parser.\nBasically, when the parser runs over the if-clause (look in weird_3.rb example file) it first declares the variable, regardless of whether it will actually be executed. This means that when the parser sees x=1, it will actually declare the variable, by assigning it to nil and let the interpreter than figure out if the x = 1 line will ever get executed.\nDon\u0026rsquo;t confuse the parser with the interpreter. The parser does not care whether x ever gets a value. The job of the parser is just to go over the code, find any local variables and allocate \u0026ldquo;space\u0026rdquo; for those variables. More specifically, set them to nil.\nOn the other hand, it\u0026rsquo;s the interpreter that will follow the logical path of the program and see if/when x will get a value and act on it.\nLast but not least, if you know about hoisting in JavaScript, it\u0026rsquo;s worth mentioning that Ruby\u0026rsquo;s hoisting is much different. In Ruby every variable is available only after the line where the variable has been assigned, regardless if that line will be executed or not.\nUpdate #1 - 21 Aug 2015: Article updated with Pablo Herrero\u0026rsquo;s point on Ruby\u0026rsquo;s v.s. JavaScript\u0026rsquo;s hoisting. Liked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/variable-hoisting-ruby/","summary":"Have you ever heard of hoisting? Well, regardless if you have or you have not, Ruby has an interesting hositing mechanism built-in. Let\u0026rsquo;s take a dive and see how it creates variables and do some experiments with it.\nHoisting What is hoisting? Well, according to Google \u0026ldquo;hoist\u0026rdquo; means to raise something. Apparently, with with ropes and pulleys. At least, back in the day.\nWell, when it comes to variable hoisting, it\u0026rsquo;s basically a mechanism by which the language, in our context - Ruby, declares and defines variables.","title":"Variable hoisting in Ruby"},{"content":"We all know that there are different design patterns. They are all quite trivial to learn, but, the trick lies in applying them. When should we use this or that pattern and will that help in making our code better and cleaner. Well, tests are code as well and, you guessed it, there are some testing patterns that are around for a while.\nToday, we will take a look at one of them. It is a useful one and also it has an interesting name - the Humble Object Pattern.\nThe problem Think about this. You are building an API client/wrapper. You read the documentation, you understand the model and the intent of the API and how everything is composed. You start writing your code, keeping it in small chunks (i.e. classes). You are a responsible programmer, you want to have your code well documented and tested. All of this is nice. And then, you get to this part where you start mocking your HTTP calls and stuff easily gets messy.\nHow can we avoid this? Is there a better way?\nHumble Object Let us take a detour. A bit of history first. I think that Uncle Bob has a really good definition of the Humble Object pattern in Episode 23 of his Clean Code videos:\nIn case you find the definition confusing, let\u0026rsquo;s tear it apart. First, the boundaries. When one says boundaries, it means that the person is referring to the part of the system that communicates with other software that is not written by you, but your software is dependent on it. For example, let\u0026rsquo;s say your software creates cron jobs. The boundary lies beween the software that will call the cronjob system command and the operating system.\nSo, this means when using the Humble Object pattern, we extract as much logic as we can from the boundary class(es), thus making them humble. The extracted logic will be moved to another class, which will be easily testable. On the other hand, the humble code will be dependant on the extracted class, but testing it won\u0026rsquo;t be necessary, because it doesn\u0026rsquo;t hold any business logic.\nUsually, when explaining the humble object, people use GUIs or async code as examples. We won\u0026rsquo;t go down that path today. Let\u0026rsquo;s try finding an example which we might run into more frequently.\nBack to the problem Now, that we undestand the motivation and the theory behind this pattern, let\u0026rsquo;s continue with aforementioned design problem.\nTackling any programming problem, in my opinion, is best understood via some code. Here\u0026rsquo;s an example. We will make a tiny API wrapper of the REST Countries API, more specifically, the World Capitals API.\nrequire \u0026#39;net/http\u0026#39; require \u0026#39;json\u0026#39; class CapitalsClient API_ENDPOINT = \u0026#34;https://restcountries.eu/rest/v1/capital/\u0026#34; def self.find(capital_name) uri = URI(API_ENDPOINT + capital_name) response = Net::HTTP.get(uri) result = JSON.parse(response).first currencies = result[\u0026#39;currencies\u0026#39;].map {|currency| Currency.new(currency) } Country.new({ name: result[\u0026#34;name\u0026#34;], capital: result[\u0026#34;capital\u0026#34;], region: result[\u0026#34;region\u0026#34;], population: result[\u0026#34;population\u0026#34;], latitude: result[\u0026#34;latlng\u0026#34;][0], longitude: result[\u0026#34;latlng\u0026#34;][1], native_name: result[\u0026#34;nativeName\u0026#34;], currencies: currencies }) end end The CapitalsClient will issue a GET request to the API endpoint, get the result and build a Country object from the results. This is what the JSON result looks like for London, UK:\n[ { \u0026#34;name\u0026#34;: \u0026#34;United Kingdom\u0026#34;, \u0026#34;capital\u0026#34;: \u0026#34;London\u0026#34;, \u0026#34;altSpellings\u0026#34;: [ \u0026#34;GB\u0026#34;, \u0026#34;UK\u0026#34;, \u0026#34;Great Britain\u0026#34; ], \u0026#34;relevance\u0026#34;: \u0026#34;2.5\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;Europe\u0026#34;, \u0026#34;subregion\u0026#34;: \u0026#34;Northern Europe\u0026#34;, \u0026#34;translations\u0026#34;: { \u0026#34;de\u0026#34;: \u0026#34;Vereinigtes Königreich\u0026#34;, \u0026#34;es\u0026#34;: \u0026#34;Reino Unido\u0026#34;, \u0026#34;fr\u0026#34;: \u0026#34;Royaume-Uni\u0026#34;, \u0026#34;ja\u0026#34;: \u0026#34;イギリス\u0026#34;, \u0026#34;it\u0026#34;: \u0026#34;Regno Unito\u0026#34; }, \u0026#34;population\u0026#34;: 64105654, \u0026#34;latlng\u0026#34;: [ 54, -2 ], \u0026#34;demonym\u0026#34;: \u0026#34;British\u0026#34;, \u0026#34;area\u0026#34;: 242900, \u0026#34;gini\u0026#34;: 34, \u0026#34;timezones\u0026#34;: [ \u0026#34;UTC−08:00\u0026#34;, \u0026#34;UTC−05:00\u0026#34;, \u0026#34;UTC−04:00\u0026#34;, \u0026#34;UTC−03:00\u0026#34;, \u0026#34;UTC−02:00\u0026#34;, \u0026#34;UTC\u0026#34;, \u0026#34;UTC+01:00\u0026#34;, \u0026#34;UTC+02:00\u0026#34;, \u0026#34;UTC+06:00\u0026#34; ], \u0026#34;borders\u0026#34;: [ \u0026#34;IRL\u0026#34; ], \u0026#34;nativeName\u0026#34;: \u0026#34;United Kingdom\u0026#34;, \u0026#34;callingCodes\u0026#34;: [ \u0026#34;44\u0026#34; ], \u0026#34;topLevelDomain\u0026#34;: [ \u0026#34;.uk\u0026#34; ], \u0026#34;alpha2Code\u0026#34;: \u0026#34;GB\u0026#34;, \u0026#34;alpha3Code\u0026#34;: \u0026#34;GBR\u0026#34;, \u0026#34;currencies\u0026#34;: [ \u0026#34;GBP\u0026#34; ], \u0026#34;languages\u0026#34;: [ \u0026#34;en\u0026#34; ] } ] For completeness sake, let\u0026rsquo;s see the Currency and Country classes.\nclass Currency def initialize code @code = code end def to_s @code end end class Country attr_reader :name, :capital, :region, :population, :latitude, :longitude, :native_name, :currencies def initialize attrs @name = attrs.fetch(\u0026#34;name\u0026#34;,nil) @capital = attrs.fetch(\u0026#34;capital\u0026#34;,nil) @region = attrs.fetch(\u0026#34;region\u0026#34;,nil) @population = attrs.fetch(\u0026#34;population\u0026#34;,nil) @latitude = attrs.fetch(\u0026#34;latlng\u0026#34;,[]).first @longitude = attrs.fetch(\u0026#34;latlng\u0026#34;,[]).last @native_name = attrs.fetch(\u0026#34;nativeName\u0026#34;,nil) @currencies = attrs.fetch(\u0026#34;currencies\u0026#34;, []) end end Now, let\u0026rsquo;s revisit the CountryClient class. We\u0026rsquo;ve all done this - we fetch the JSON, parse it and build the currencies and country object(s). Now, testing is interesting.\nFirst, we\u0026rsquo;ll need to stub the GET request using Webmock and assert on the Country object that we receive as a result of the CapitalsClient::find method. Another approach is to use VCR and record the request going out and replay it whenever needed.\nrequire \u0026#39;minitest/autorun\u0026#39; require \u0026#39;webmock/minitest\u0026#39; class CountryClientTest \u0026lt; Minitest::Test def test_client_fetches_countries response = %Q{ [ { \u0026#34;name\u0026#34;: \u0026#34;United Kingdom\u0026#34;, \u0026#34;capital\u0026#34;: \u0026#34;London\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;Europe\u0026#34;, \u0026#34;population\u0026#34;: 64105654, \u0026#34;latlng\u0026#34;: [54, -2], \u0026#34;nativeName\u0026#34;: \u0026#34;United Kingdom\u0026#34; } ] } stub_request(:get, CountryClient::API_ENDPOINT + \u0026#34;London\u0026#34;).to_return(body: response) country = CapitalsClient.find(\u0026#34;London\u0026#34;) assert_equal \u0026#34;London\u0026#34;, country.name assert_equal \u0026#34;United Kingdom\u0026#34;, country.name assert_equal \u0026#34;Europe\u0026#34;, country.region end end Now, this works, it\u0026rsquo;s fine. But, what exactly are we testing here? I am sure we have all done this multiple times. Look at the test class name - CountryClientTest. We should be testing the client, not setting assertions on the country object. The CountryClient acts like a factory, not like an API client.\nAlso, think about this - stubbing, although it looks fine, it\u0026rsquo;s basically isolation. While we cannot completely rely on pulling real data from the API for each of our tests, we shouldn\u0026rsquo;t also go overboard with it.\nWhile one can argue that stubbing external services is all good, what would the case be if you used a library that was actually fetching the data and building it for you? What would you test if the wrapper was made by someone else and you are using it in a Rails app? You could go on and stub the library, but you have no idea if the API and/or the wrapper had any changes made to them.\nBut, let\u0026rsquo;s take a step back. How can we apply the humble object pattern here?\nApplying the pattern If you remember, the pattern states that we need to extract most of the logic near the boundaries of the system, so the code on the boundary itself is so humble, it doesn\u0026rsquo;t need to be tested. But, the humble object should be dependent on the extracted code.\nLet\u0026rsquo;s try to refactor our code by doing exactly that.\nFirst, the CountryClient. It sure does more than it should. Let\u0026rsquo;s make it humble. The first step would be to make it an API client. Exactly that, nothing more or less. This means that it will only issue HTTP GET to the API. Hint: think of the Single-responsibility principle.\nrequire \u0026#39;net/http\u0026#39; class CapitalsClient API_ENDPOINT = \u0026#34;https://restcountries.eu/rest/v1/capital/\u0026#34; def self.find(capital_name) uri = URI(API_ENDPOINT + capital_name) Net::HTTP.get(uri) end end That\u0026rsquo;s it. Again, CapitalsClient just sends the request and it returns it\u0026rsquo;s response. Now, the extracted logic.\nSince the code that we extracted was actually building the Country object, we can create a CountryBuilder class out of it:\nrequire \u0026#39;json\u0026#39; class CountryBuilder def self.build json result = JSON.parse(response).first currencies = result[\u0026#39;currencies\u0026#39;].map {|currency| Currency.new(currency) } Country.new({ name: result[\u0026#34;name\u0026#34;], capital: result[\u0026#34;capital\u0026#34;], region: result[\u0026#34;region\u0026#34;], population: result[\u0026#34;population\u0026#34;], latitude: result[\u0026#34;latlng\u0026#34;][0], longitude: result[\u0026#34;latlng\u0026#34;][1], native_name: result[\u0026#34;nativeName\u0026#34;], currencies: currencies }) end end The CountryBuilder.build method will receive the JSON and build the Country object on it\u0026rsquo;s own. The next, obvious step, is to test this class. If you look at the test we wrote earlier, you can notice that the test is 90% done, it just needs some tweaking.\nrequire \u0026#39;minitest/autorun\u0026#39; class CountryBuilderTest \u0026lt; Minitest::Test def test_build_builds_the_country response = %Q{ [ { \u0026#34;name\u0026#34;: \u0026#34;United Kingdom\u0026#34;, \u0026#34;capital\u0026#34;: \u0026#34;London\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;Europe\u0026#34;, \u0026#34;population\u0026#34;: 64105654, \u0026#34;latlng\u0026#34;: [54, -2], \u0026#34;nativeName\u0026#34;: \u0026#34;United Kingdom\u0026#34; } ] } country = CountryBuilder.build(response) # Sanity check assert_equal Country, country.class # Useful assertions assert_equal \u0026#34;London\u0026#34;, country.name assert_equal \u0026#34;United Kingdom\u0026#34;, country.name assert_equal \u0026#34;Europe\u0026#34;, country.region end end The key differences in the new and old test is that the new one is missing the Webmock request stub. Also, we are testing the builder class, which does what it should - receives the response as a JSON, builds an object of a class and returns it. But, what happens now to the CapitalsClient? Well, nothing too complicated. If you remember, the pattern states that the humble object should depend on the extracted code.\nIf you look at the code below, it should all make sense:\nrequire \u0026#39;net/http\u0026#39; class CapitalsClient API_ENDPOINT = \u0026#34;https://restcountries.eu/rest/v1/capital/\u0026#34; def self.find(capital_name) uri = URI(API_ENDPOINT + capital_name) response = Net::HTTP.get(uri) CountryBuilder.build(response) end end So, we add the dependency, making CapitalsClient use CountryBuilder to create the country out of the JSON payload.\nAnd, what about testing CapitalsClient? Well, we don\u0026rsquo;t really need to test it. Even if we wanted to test it, we could only write a test with a test spy that would expect CountryBuilder.build to be called. But, how useful is that test? If we wrote it, we would tie our test to the implementation of the production code. This means that if the implementation of this method changes in the future, but it\u0026rsquo;s output does not, our tests will fail although we haven\u0026rsquo;t broken our code.\nOutro As you can see, although very simple, this humble pattern can make a difference when we want to leave out heavy stubbing to external services, APIs or interfaces and just focus on our code where \u0026ldquo;the magic\u0026rdquo; happens. Also, at least for me, this type of refactor comes very natural in these situations. But, knowing the pattern guides us towards making only one entry point to our code (or, dependency).\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/tdd-humble-object/","summary":"We all know that there are different design patterns. They are all quite trivial to learn, but, the trick lies in applying them. When should we use this or that pattern and will that help in making our code better and cleaner. Well, tests are code as well and, you guessed it, there are some testing patterns that are around for a while.\nToday, we will take a look at one of them.","title":"TDD Patterns: Humble Object"},{"content":"Those of us that do Test Driven Development have heard about doubles, mocks, stubs, fakes and spies multiple times. Unfortunately there is a ton of confusion about all these words and their meaning. Let\u0026rsquo;s see what each an every one of these really mean, where we should use them and how the popular testing frameworks for Ruby implement these.\nTest Doubles So, first things first. One of the biggest misconceptions is that doubles are types of objects that are used in testing.\nDummies, mocks, stubs, fakes and spies are test doubles. Test double is the category of these test objects. I think that the confusion around this concept arises from the naming that the popular testing frameworks use for these objects.\nSo remember - dummies, mocks, stubs, fakes and spies are test doubles. Also, another thing to keep in mind is the word mock. The words mock and doubles were used interchangeably in the past and their definitions got skewed.\nDummy Now, that we got this right, what is a dummy?\nThe simplest type of test double is test dummy. Basically, the dummy is dumb, hence the naming. This means that the object is just a placeholder for another object, but it\u0026rsquo;s interfaces (or methods) do not return anything.\nConfusing? Let\u0026rsquo;s see an example.\nWe have this class Blog that has a publish! method.\nclass Post attr_reader :published def publish! @published = true end end class Blog attr_reader :published_posts def initialize author @author = author @published_posts = [] end def publish! post published_posts \u0026lt;\u0026lt; post post.publish! end # Moar methods... end Now, we need to test the publish! method. How do we go about this? We obviously need to create a Post object first, then create a Blog object and pass the author as an argument to the initializer. Afterwards, we need to assert that the publish! method will add the post to the published_posts array.\nMinitest Let\u0026rsquo;s test our method with Minitest:\nrequire \u0026#39;minitest/autorun\u0026#39; class BlogTest \u0026lt; Minitest::Test def test_publish_adds_post_to_published_posts blog = Blog.new(author) post = Post.new blog.publish!(post) assert_includes(blog.published_posts, post) end end If we run the test, it will fail. Why? Well, what is author? As you can see if we exclude author when creating the Blog object it will complain with an exception, ArgumentError. But, in the code that we are testing, author has no role to play. It basically does nothing. It is important to the class, but it\u0026rsquo;s not important to the method under test.\nThis is a great place to use a dummy. Let\u0026rsquo;s add the author using a dummy. Minitest and RSpec do not have the concept of a pure dummy, although RSpec has a trick that you can use.\nIf you need a dummy in Minitest, you can just use an Object. Or nil. Or an empty Hash. Or.. whatever.\nrequire \u0026#39;minitest/autorun\u0026#39; class BlogTest \u0026lt; Minitest::Test def test_publish_adds_post_to_published_posts author = Object.new blog = Blog.new(author) post = Post.new blog.publish!(post) assert_includes(blog.published_posts, post) end end RSpec The same test, but using RSpec:\nrequire \u0026#39;rspec/autorun\u0026#39; describe Post do describe \u0026#34;#publish!\u0026#34; do it \u0026#39;adds the post to the published_posts array\u0026#39; do author = Object.new blog = Blog.new(author) post = Post.new blog.publish!(post) expect(blog.published_posts).to include(post) end end end Also, another trick in RSpec is to use a double. A double that doesn\u0026rsquo;t to anything is a dummy. Remember that this only applies to RSpec:\nrequire \u0026#39;rspec/autorun\u0026#39; describe Post do describe \u0026#34;#publish!\u0026#34; do it \u0026#39;adds the post to the published_posts array\u0026#39; do author = double blog = Blog.new(author) post = Post.new blog.publish!(post) expect(blog.published_posts).to include(post) end end end Do not get confused by the double keyword. For now, just pretend that it\u0026rsquo;s an object that does nothing. Just like Object.new or nil.\nStub Stubs are dummies, with one notable difference. Stubs have methods that they respond to. But, their methods do not do anything except they return a predefined value. This means that their methods do not have an effect, they just return a value which will drive the test through the production code.\nLet\u0026rsquo;s see some examples. We have the Blog class which has the publish! method.\nclass Blog attr_reader :published_posts def initialize user @user = user end def publish! post published_posts \u0026lt;\u0026lt; post if @user.author? end # Moar methods... end How can we test the publish! method? Due to the check that occurs in the publish! method, we need a stub User object, which will return true when the author? method is called on it.\nMinitest Creating a stub in Minitest is dead easy. Let\u0026rsquo;s write the test for the publish method:\nrequire \u0026#39;minitest/autorun\u0026#39; class BlogTest \u0026lt; Minitest::Test def test_publish post = Post.new user = User.new blog = Blog.new(user) user.stub :author?, true do blog.publish!(post) assert_includes blog.published_posts, post end end end Stubbing in Minitest is done by calling .stub on the object/class that you want to stub a method on, with three arguments: the method name, the return value of the stub and a block. The block is basically the scope of the stub, or in other words, the stub will work only in the provided block.\nAnother way to achieve the same, which is a bit weird, is to avoid creating a new User object, create a dummy and declare a stub method on it.\nrequire \u0026#39;minitest/autorun\u0026#39; class BlogTest \u0026lt; Minitest::Test def test_publish post = Post.new user = Object.new # Tha stub def user.author? true end blog = Blog.new(user) blog.publish!(post) assert_includes blog.published_posts, post end end Using this way, we define the author? method on the singleton class of the user object, which will return true.\nRSpec The same test, or spec if you will, in RSpec is quite easy to write as well.\nrequire \u0026#39;rspec/autorun\u0026#39; describe Blog do describe \u0026#39;#publish\u0026#39; do it \u0026#39;adds the published post to the published_posts collection\u0026#39; do post = Post.new user = double(:author? =\u0026gt; true) blog = Blog.new(user) blog.publish!(post) expect(blog.published_posts).to include(post) end end end As you can see, the RSpec syntax is easy to understand as well. We create a double, which is basically a dummy (makes sense, right?) and we declare a stub on it. The stub is the author? which will return a predefined value, or in our case true.\nSpy I hope you guessed it - a spy is a stub. It\u0026rsquo;s just an object whose methods do nothing and return a predefined values to drive the test. However the spy remembers certain things about the way and occurance of it\u0026rsquo;s methods being called. For example, sometimes you want to assert that a certain method has been called. Another time, you might want to test how many times a method has been called.\nThat\u0026rsquo;s where spies are used.\nAgain, let\u0026rsquo;s see some code. Take these classes and methods for example:\nclass Blog attr_reader :published_posts def initialize user @user = user end def publish! post if @user.author? published_posts \u0026lt;\u0026lt; post NotificationService.notify_subscribers(post) end end end Now, the NotificationService.notify_subscribers method will send a notification email to all the subscribers of the blog when a new post is published.\nWhen testing this method, we are interested in two things:\n The post will be added to the published_posts array, and The subscribers will be notified of the new post.  Since we already tested the first case in the example before, we\u0026rsquo;ll just focus on no. 2. Let\u0026rsquo;s test this method.\nMinitest Minitest does not support spies by default, but as always, we can use another gem that plays nice with Minitest.\nSpy is a really simple gem that does exactly that - spies.\nLet\u0026rsquo;s add some spies using Spy.\nclass BlogTest \u0026lt; Minitest::Test def test_notification_is_sent_when_publishing notification_service_spy = Spy.on(NotificationService, :notify_subscribers) post = Post.new user = User.new blog = Blog.new(user) blog.publish!(post) assert notificaion_service_spy.has_been_called? end end Quite self-explanatory, isn\u0026rsquo;t it?\nRSpec The RSpec syntactic sugar is really nice and human. This is how we can create spies in RSpec and use them appropriately.\ndescribe Blog do describe \u0026#39;#publish!\u0026#39; do it \u0026#34;sends notification when new post is published\u0026#34; do notification_spy = class_spy(\u0026#34;Invitation\u0026#34;) post = Post.new user = User.new blog = Blog.new(user) # If you want to set the expectation before the action is done: expect(notification_spy).to receive(:notify_subscribers).with(post) blog.publish!(post) # If you want to assert after the action is done: expect(NotificationService).to have_received(:notify_subscribers).with(post) end end end Also, keep in mind that since spy has the functionality of a stub, it can return fixed/predefined values. If you need your spy to return a value, you can do this in RSpec very easily, by chaining the and_return method to the spy:\ndescribe Blog do describe \u0026#39;#publish!\u0026#39; do it \u0026#34;sends notification when new post is published\u0026#34; do notification_spy = class_spy(\u0026#34;Invitation\u0026#34;) post = Post.new user = User.new blog = Blog.new(user) expect(notification_spy).to receive(:notify_subscribers).with(post).and_return(true) blog.publish!(post) end end end (True) Mock Before we go over the true mock, we have to make sure we understand the difference between \u0026ldquo;mocking\u0026rdquo;, \u0026ldquo;the RSpec mock\u0026rdquo; and a \u0026ldquo;True Mock\u0026rdquo;.\nThe whole issue behind the word mock is that in the beginning people started using it for simillar (but not the same) things and the word got left hanging in the air without a proper defnition.\nSo, \u0026ldquo;mocking\u0026rdquo; is usually used when thinking about creating objects that simulate the behavior of real objects or units.\nOn the other hand, RSpec also has the concept of a mock. From RSpec\u0026rsquo;s documentation:\nAs you can see, there\u0026rsquo;s some nomenclature overlapping and/or disagreement.\nNow, throw away any knowledge you have about the word mock. The True Mock is a very interesting type of test object. Of course, it has all the functionalities that a dummy, a stub and a spy have. And, a bit more.\nThe True Mock is an object that knows the flow of the method under test, and the test can ask the mock if everything went well, usually called \u0026ldquo;verifying\u0026rdquo;. This means that the test will rely on the True Mock to track what are the effects of the method under test and what methods have been called.\nLet\u0026rsquo;s see an example. The code under test:\nclass Blog attr_reader :published_posts def initialize user @user = user end def publish! post published_posts \u0026lt;\u0026lt; post if @user.can?(:publish) end def delete post post.delete! if @user.can?(:delete) end end Minitest Minitest has this type of testing object - it\u0026rsquo;s called (believe it or not) Mock.\nclass BlogTest \u0026lt; Minitest::Test def test_post_deletion user = Minitest::Mock.new post = Minitest::Mock.new blog = Blog.new(user) user.expect :can?, true post.expect :delete!, true blog.delete(post) user.verify post.verify end end We create new Minitest::Mock objects and we set an expectation that it should receive the can? and delete! method, respectively. These will return true. Although this seems like a stub (setting a return value), the last line is what it differentiates it from a stub. The test asks the mocks to verify that the expected method was called, which will result in the test passing/failing.\nRSpec With RSpec, it\u0026rsquo;s a bit different. RSpec does not have a Mock object, but it\u0026rsquo;s jack-of-all-trades double can do the same trick.\ndescribe Blog do it \u0026#39;can remove a post\u0026#39; do user = double post = double blog = Blog.new(user) expect(user).to receive(:can?).with(:publish) expect(user).to receive(:can?).with(:delete) expect(post).to receive(:delete!) blog.publish(post) blog.delete(post) end end This is a bit ambigous, since it\u0026rsquo;s half-way between spies and a true mock objects. But if you look in all the examples above, RSpec\u0026rsquo;s double can morph into anything. It all depends on the programmer what (s)he want\u0026rsquo;s to use it as. I guess that\u0026rsquo;s why it\u0026rsquo;s called double, because it can be any type of a test double you want.\nFake Last but not least, the fake. The fake is basically a half-baked, half-working implementation of the test object. It is not production ready, but, it\u0026rsquo;s enough functional for the test to use it.\nThe popular testing frameworks do not have the concept of a fake. This is due to that writing the (needed) implementation for the fake is left for the programmer to do.\nYou should avoid fakes because fakes are standalone objects which are not used in the production code, but, they will grow linearly as the system grows. This means that in the long run they can turn into code that will be very hard to maintain. Also, pretty much every test can be written with one of the aforementioned testing objects. So, if you are ever using fakes, make sure you know what you are getting into.\nConclusion Now, that we got to the end, I hope that this article helped you understand the theory behind test doubles and their implementations in Ruby. Be careful where and how you use these test objects. If you go overboard you can create isolation between your tests and your production code, which can render your test suite useless.\nWow, you got to the very end. Thanks so much for reading!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/test-doubles-theory-minitest-rspec/","summary":"Those of us that do Test Driven Development have heard about doubles, mocks, stubs, fakes and spies multiple times. Unfortunately there is a ton of confusion about all these words and their meaning. Let\u0026rsquo;s see what each an every one of these really mean, where we should use them and how the popular testing frameworks for Ruby implement these.\nTest Doubles So, first things first. One of the biggest misconceptions is that doubles are types of objects that are used in testing.","title":"Test Doubles: in theory, in Minitest and in RSpec"},{"content":"When testing our code, we usually go for the happy path (TM). We are awesome developers, we test our code, we are careful and there\u0026rsquo;s no way our code might crash. Or not really? I often try to think of software as a live being. It thinks, it does stuff and sometimes it gets some things wrong. Just like us. We sometimes trip up while walking, we drop our keys or forget them on our desk at the office. It\u0026rsquo;s normal. So, how can we test our code for these rare occurances?\nWhat is what? Errors, exceptions and failures. It\u0026rsquo;s really hard to tell them apart. More so, it\u0026rsquo;s harder to know when to use what. Avdi Grimm in his book \u0026ldquo;Exceptional Ruby\u0026rdquo; uses Bertrand Meyer\u0026rsquo;s definition of these words:\n An exception is the occurrence of an abnormal condition during the execution of a software element. A failure is the inability of a software element to satisfy its purpose. An error is the presence in the software of some element not satisfying its specification.  Also, he mentions:\nGive yourself time for this to sink in. I think that these definitions very much explain the difference between errors, exceptions and failures.\nWhy testing them? Let\u0026rsquo;s start this with a hypotetical example. Say you are building a gem, that\u0026rsquo;s basically an API wrapper. The code has nice coverage percentage and you are confident that it works as it should. I guess you know where I am heading with this example. The obvious question is - what happens if for whatever reason, the API is not responsive? Maybe a switch in the datacentre died and they need couple of minutes to re-route the network. Or, maybe the API server crashed for whatever reason. What do we do than?\nThe problem with errors (which cause failures, whose product is exceptions) is that they are very often hard to think about. But they are real. Just like us, we never think about forgetting our keys on our desk, but, it happens. While in real life we can pretty much always go back and get the keys from our desk, software isn\u0026rsquo;t that intelligent by default. It\u0026rsquo;s our duty to make it intelligent, or in other words, we have to handle exceptions in our code.\nSo, why test them? Well, if you have error handling code, you should have tests. You should always aim for 100% code coverage. Simple as that.\nAdd error handling I am the author of this tiny gem called Forecastr. Given that the gem doesn\u0026rsquo;t know how to handle errors, let\u0026rsquo;s add the code so it can handle errors and test it.\nrequire \u0026#39;net/http\u0026#39; require \u0026#39;json\u0026#39; module Forecastr class Client class \u0026lt;\u0026lt; self def search_by_city(city_name) uri = UriBuilder.by_city(city_name) response = Net::HTTP.get(uri) json = JSON.parse(response) Forecastr::DataContainer.new(json) end def search_by_coordinates(latitude, longitude) uri = UriBuilder.by_coordinates(latitude, longitude) response = Net::HTTP.get(uri) json = JSON.parse(response) Forecastr::DataContainer.new(json) end end end end This is the code that actually does the API calls. The first method, search_by_city accepts a city name as argument and issues the API call with the city name. The second method, search_by_coordinates accepts the coordinates of the location that we want to get the weather for. Just like the first method, it issues the API call and parses the JSON response.\n(As I sidenote - yes, I am aware that these methods are not as DRY as they should be, but lets stick to this code, at least for the purpose of this post.)\nNow, after seeing this code, there\u0026rsquo;s an obvious question - when it issues the GET request to the API, what would happen if the API is down? Or, if our internet connection dies?\nI guess you can notice that there\u0026rsquo;s a clear gap here. There\u0026rsquo;s no code that can handle a HTTP timeout, or any other type of failure.\nThere are couple of ways that we can do this.\nMake some noise When an exception happens, one option is to let it make noise. What I mean by that is just to let it explode.\nclient.rb:12:in `search_by_coordinates\u0026#39;: execution expired (Timeout::Error) Boom! And this is fine, but you want to have this covered by tests.\ndef test_raises_timeout_error stub_get(\u0026#34;http://api.openweathermap.org/data/2.5/weather?lat=42.0\u0026amp;lon=21.4333\u0026#34;).to_timeout assert_raises TimeoutError do Forecastr::Client.search_by_coordinates(42.0, 21.4333) end end As you can see it the test above, the syntax to do this in Minitest is to use the assert_raises method. It accepts an exception class as it\u0026rsquo;s first parameter. Also, it expects that it\u0026rsquo;s block will raise the exception specified as argument.\nMake some noise, your way Another option is to create your own exception classes. You can do this by subclassing an stdlib error, like TimeoutError.\nmodule Forecastr class RequestTimeout \u0026lt; ::TimeoutError; end class Client class \u0026lt;\u0026lt; self def search_by_coordinates(lat, lon) uri = UriBuilder.by_coordinates(lat, lon) begin response = Net::HTTP.get(uri) rescue TimeoutError raise Forecastr::RequestTimeout.new(\u0026#34;Request timeout.\u0026#34;) end json = JSON.parse(response) Forecastr::DataContainer.new(json) end end end end Here, we rescue the TimeoutError that the GET request returns and we raise our own custom error.\nAgain, we can test this out by using the assert_raises assertion.\ndef test_raises_timeout_error stub_get(\u0026#34;http://api.openweathermap.org/data/2.5/weather?lat=42.0\u0026amp;lon=21.4333\u0026#34;).to_timeout assert_raises Forecastr::RequestTimeout do Forecastr::Client.search_by_coordinates(42.0, 21.4333) end end This is particularly useful because when you know how the API works, you can customize your errors to mimick the errors that the API can produce.\nBenign values This is also a very interesting approach to exception handling. Benign values mean that the program won\u0026rsquo;t bomb out, but, it will return a meaningless value of some sort.\nWhat do I mean? Let\u0026rsquo;s see an example:\ndef search_by_city(city_name) uri = UriBuilder.by_city(city_name) begin response = Net::HTTP.get(uri) rescue TimeoutError response = \u0026#34;\u0026#34; end json = JSON.parse(response) Forecastr::DataContainer.new(json) end You see, instead of bombing out, we set the response to blank string. This will not make the program stop, but, it will be obvious that the values we got back are not right.\nTesting this is pretty trivial:\nclass Forecastr::ClientTest \u0026lt; Minitest::Test def test_handling_exceptions_with_benign_values stub_get(\u0026#34;http://api.openweathermap.org/data/2.5/weather?lat=42.0\u0026amp;lon=21.4333\u0026#34;).to_timeout result = Forecastr::Client.search_by_coordinates(42.0, 21.4333) assert_equal nil, result.temeprature end end Basically, our program didn\u0026rsquo;t bomb out, but the forecast object got created without any real data in it. Usually, when doing this, it\u0026rsquo;s best to log these events so there\u0026rsquo;s a written record that this occurred.\nConclusion While there are more tactics to handling exceptions in Ruby, it\u0026rsquo;s very crucial we test them. If we are not testing how our applications respond to errors, eventually, we will find out. The problem is that the experience will not be a pleasant one. Whichever way you prefer, it\u0026rsquo;s best to know how our application will handle the exceptions and (possibly) recover from them.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/exception-handling-and-testing/","summary":"When testing our code, we usually go for the happy path (TM). We are awesome developers, we test our code, we are careful and there\u0026rsquo;s no way our code might crash. Or not really? I often try to think of software as a live being. It thinks, it does stuff and sometimes it gets some things wrong. Just like us. We sometimes trip up while walking, we drop our keys or forget them on our desk at the office.","title":"Exception handling and testing it with Minitest"},{"content":"Float precision in Ruby is a well known quirk. But when testing floats, not many of us bother to remember this and make their tests respectful to this quirk. In this post we will see how the popular Ruby testing frameworks help us test floats properly.\nBackground story Last week I published a post about migrating a test suite from RSpec to Minitest. What was very interesting is that I got a mention on Twitter from Ryan Davis with an offer for a code review of the migration. Here\u0026rsquo;s the convo:\nRyan did the review for me, and one of his comments was:\nLets see why\u0026hellip;\nRuby Float (im)precision Float numbers cannot store decimal numbers properly. The reason is that Float is a binary number format. What do I mean? Well, Ruby always converts Floats from decimal to binary and vice versa.\nThink about this very simple example. Whats the result of 1 divided by 3? Yup, 0.33333333333\u0026hellip; The result of this calculation is 0.333(3), with 3 repeating until infinity.\nThis same rule, or quirk, applies to binary numbers. When a decimal number is converted to binary, the resulting binary number can be endless. Mathematically this is all fine. But in practice, my MacBook Air doesn\u0026rsquo;t have endless memory. I am running just on 4GBs of RAM, so Ruby must cut off the endless number at some point. Or it will fill up the whole memory of the computer and it will become useless. This mechanism of rounding numbers produces a rounding error and that\u0026rsquo;s exactly what we have to deal with here.\nSo, the base rule about this is: do not represent currency (or, money) with Float.\nIn practice Take this for an example. Simple calculation. We want to add 0.1 to 0.05, which should return 0.15. Right? Lets give it a try:\n\u0026gt;\u0026gt; 0.1 + 0.05 == 0.15 =\u0026gt; false Okay, what? Let\u0026rsquo;s see what\u0026rsquo;s the result of the addition:\n\u0026gt;\u0026gt; 0.1 + 0.05 =\u0026gt; 0.15000000000000002 You can see that Ruby rounds off the number at the end. Lets print this number with 50 decimal points:\n\u0026gt;\u0026gt; sprintf(\u0026#34;%0.50f\u0026#34;, 0.10 + 0.05) =\u0026gt; \u0026#34;0.15000000000000002220446049250313080847263336181641\u0026#34; Whoa! You can see that the actual result of this addition is quite different from 0.15. Ruby here rounds off the numbers, because the difference is so \u0026ldquo;microscopic\u0026rdquo;.\nIf you are curious, here\u0026rsquo;s how the numbers 0.10 and 0.05 actually look like with 50 decimal points in Ruby:\n\u0026gt;\u0026gt; sprintf(\u0026#34;%0.50f\u0026#34;, 0.10) =\u0026gt; \u0026#34;0.10000000000000000555111512312578270211815834045410\u0026#34; \u0026gt;\u0026gt; sprintf(\u0026#34;%0.50f\u0026#34;, 0.05) =\u0026gt; \u0026#34;0.05000000000000000277555756156289135105907917022705\u0026#34; Testing it Okay, so now when the problem is obvious, how can we test it? The best way to test this is to use a delta number. You can think of this delta number as a number showing the margin of rounding error.\nFor example, the delta for the 0.10 + 0.05 operation is approximately 0.0000000000000001.\nWith Minitest Minitest provides us the assert_in_delta and assert_in_epsilon methods.\nassert_in_delta It fails unless the expected and the actual values are within delta of each other.\ndef test_precision assert_in_delta(0.15, 0.10 + 0.05, 0.0000000000000001) end This means that, while we will expect to get 0.15 as a result, the rounding-off error can be as big as 0.0000000000000001.\nIf you see the source of this method, it\u0026rsquo;s quite easy to understand:\n# File minitest/unit.rb, line 122 def assert_in_delta exp, act, delta = 0.001, msg = nil n = (exp - act).abs msg = message(msg) { \u0026#34;Expected #{exp}- #{act}(#{n}) to be \u0026lt; #{delta}\u0026#34; } assert delta \u0026gt;= n, msg end The delta must be larger or equal than the absolute value of the result of subtraction of the expected and the actual values.\nassert_in_epsilon This method behaves in a different matter than assert_in_delta. For example, if we use the delta as an epsilon, this test will fail:\ndef test_precision assert_in_epsilon(0.15, 0.10 + 0.05, 0.0000000000000001) end # Running: F Finished in 0.001584s, 1262.6263 runs/s, 1262.6263 assertions/s. 1) Failure: SomeTest#test_with_epsilon [test.rb:5]: Expected |0.15 - 0.15000000000000002| (2.7755575615628914e-17) to be \u0026lt;= 1.5e-17. Why this happens is easier to see in the source of the assert_in_epsilon method:\n# File minitest/unit.rb, line 132 def assert_in_epsilon a, b, epsilon = 0.001, msg = nil assert_in_delta a, b, [a, b].min * epsilon, msg end So, assert_in_epsilon is a wrapper for assert_in_delta with a small but important difference. The delta here is subject to \u0026ldquo;auto-scaling\u0026rdquo;. This means that it will increase for the product of the smaller number from the expected value/actual value pair and the epsilon.\nAlso, I guess, it\u0026rsquo;s called \u0026ldquo;epsilon\u0026rdquo; because the greek letter Epsilon is usually used to denote a small quantity (like a margin of error) or perhaps a number which will be turned into a zero within some limit.\nWith RSpec RSpec provides us the be_within matcher. The same rules apply here as the Minitest assert_in_delta method. The format is:\nexpect(\u0026lt;actual\u0026gt;).to be_within(\u0026lt;delta\u0026gt;).of(\u0026lt;expected\u0026gt;) Or, in our case:\nit \u0026#34;should match within a delta\u0026#34; do expect(0.10 + 0.05).to be_within(0.0000000000000001).of(0.15) end Conclusion Since the people behind RSpec and Minitest are awesome, they have provided us these methods where we can easily smooth out the edges of testing floats. What\u0026rsquo;s very important to understand here is that while testing this is pretty easy, it\u0026rsquo;s extremely important to know what to use when.\nWhen it comes to money/currency, every sane developer out there will use BigDecimal. It provides arbitrary-precision floating point decimal arithmetic, which means that it will always get a correct result for any calculation involving floating point numbers.\nAs an outro, I\u0026rsquo;ll leave you with this tweet:\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/testing-floats-in-ruby/","summary":"Float precision in Ruby is a well known quirk. But when testing floats, not many of us bother to remember this and make their tests respectful to this quirk. In this post we will see how the popular Ruby testing frameworks help us test floats properly.\nBackground story Last week I published a post about migrating a test suite from RSpec to Minitest. What was very interesting is that I got a mention on Twitter from Ryan Davis with an offer for a code review of the migration.","title":"Testing Ruby's floats precision"},{"content":"I have always wanted to have some fun with Minitest but until this weekend I never got the chance to do it. For those of you that don\u0026rsquo;t know, Minitest is a suite of testing facilities, that support TDD, BDD, mocking and benchmarking. Having wanted to play with Minitest, this weekend I decided that I will migrate the test suite of a gem of mine, from RSpec to Minitest. Read on to see how it all went.\nThe gem that I worked with is called Forecastr. It is a very minimal gem that serves as a wrapper for the Open Weather Map API. It supports only current forecast: temperature, pressure, humidity, min/max temperatures and wind (speed and direction).\nThe setup After checking out to a new Git branch (duh!) I first went to the gemspec and changed the RSpec dependency to Minitest.\nspec.add_development_dependency \u0026#34;minitest\u0026#34; Setup-wise, the first difference that I noticed is that while RSpec\u0026rsquo;s specs live in spec/forecastr, Minitest\u0026rsquo;s tests live in test/forecastr. Although this is the default, it\u0026rsquo;s not the only way to do it. When creating the new Rake task for running the Minitest tests, which I\u0026rsquo;ll get to shortly, one can specify the path where she/he wants the tests to live.\nIn the newly created test/forecastr path, I had to add the test_helper.rb. The purpose of the file is the same as spec_helper.rb in RSpec. Instead of requiring RSpec, now I had to require:\nrequire \u0026#39;minitest/autorun\u0026#39; # the test runner require \u0026#39;minitest/pride\u0026#39; # adds some formatting to the test output The last important thing was the Rake task. To run all the tests one needs to add a built-in Rake task to the Rakefile:\nrequire \u0026#34;rake/testtask\u0026#34; Rake::TestTask.new do |t| t.libs \u0026lt;\u0026lt; \u0026#39;test\u0026#39; t.pattern = \u0026#34;test/**/*_test.rb\u0026#34; t.warning = true end task default: :test The Rake::TestTask object is the task that will be called when running rake test in command line. As you can see, it takes a small configuration block. In it, one can set the path of the tests (what I mentioned before). On the last line, I made this task to be the default one, because it\u0026rsquo;s more convenient for me and I don\u0026rsquo;t need to run any other tasks.\nThe first test I started by migrating one test at a time from the spec directory to the test directory. What was interesting to me is that every test file in Minitest is a class that inherits from Minitest::Test. Also, every test case is a method, which of course makes sense since the test file is a class. In contrast to RSpec, Minitest is very verbose, while RSpec hides a lot of complexity for you with it\u0026rsquo;s huge collection of helper methods.\nAt the beginning I had a bit of problem with naming the methods because I was used to the \u0026ldquo;free text\u0026rdquo; way of describing test cases in RSpec. I eventually got the first one:\nrequire \u0026#39;test_helper\u0026#39; class Forecastr::WindTest \u0026lt; Minitest::Test def setup @wind = Forecastr::Wind.new(2.5, -37) end def test_speed_in_ms assert_equal @wind.speed, \u0026#34;2.5 m/s\u0026#34; end def test_direction assert_equal @wind.direction, \u0026#34;NNW\u0026#34; end end What was interesting to me is that I got really cool warnings when running the tests:\n/Users/ie/dev/forecastr/lib/forecastr/wind.rb:12: warning: method redefined; discarding old speed /Users/ie/dev/forecastr/lib/forecastr/wind.rb:16: warning: method redefined; discarding old direction The reason behind these errors is that, back in the day when I was writing the Wind class, I had added attr_reader for speed and direction. Although I had these in place, I had overridden the methods, so the warning was spot on.\nmodule Forecastr class Wind DIRECTIONS = [\u0026#34;N\u0026#34;,\u0026#34;NNE\u0026#34;,\u0026#34;NE\u0026#34;,\u0026#34;ENE\u0026#34;,\u0026#34;E\u0026#34;,\u0026#34;ESE\u0026#34;, \u0026#34;SE\u0026#34;, \u0026#34;SSE\u0026#34;,\u0026#34;S\u0026#34;,\u0026#34;SSW\u0026#34;,\u0026#34;SW\u0026#34;,\u0026#34;WSW\u0026#34;,\u0026#34;W\u0026#34;,\u0026#34;WNW\u0026#34;,\u0026#34;NW\u0026#34;,\u0026#34;NNW\u0026#34;] attr_reader :speed, :direction # \u0026lt;--- useless... def initialize(speed, angle) @speed = speed @angle = angle end def speed \u0026#34;#{@speed}m/s\u0026#34; end def direction val = ((@angle/22.5) + 0.5).to_i DIRECTIONS[val % 16] end def to_s \u0026#34;#{speed}#{direction}\u0026#34; end end end After removing the unneeded attr_readers the warnings went away.\nmodule Forecastr class Wind DIRECTIONS = [\u0026#34;N\u0026#34;,\u0026#34;NNE\u0026#34;,\u0026#34;NE\u0026#34;,\u0026#34;ENE\u0026#34;,\u0026#34;E\u0026#34;,\u0026#34;ESE\u0026#34;, \u0026#34;SE\u0026#34;, \u0026#34;SSE\u0026#34;,\u0026#34;S\u0026#34;,\u0026#34;SSW\u0026#34;,\u0026#34;SW\u0026#34;,\u0026#34;WSW\u0026#34;,\u0026#34;W\u0026#34;,\u0026#34;WNW\u0026#34;,\u0026#34;NW\u0026#34;,\u0026#34;NNW\u0026#34;] def initialize(speed, angle) @speed = speed @angle = angle end def speed \u0026#34;#{@speed}m/s\u0026#34; end def direction val = ((@angle/22.5) + 0.5).to_i DIRECTIONS[val % 16] end def to_s \u0026#34;#{speed}#{direction}\u0026#34; end end end Although this is a nice feature of Minitest, I ended up turning it off because it started reporting warnings for libraries that weren\u0026rsquo;t under my control:\n/Users/ie/.rbenv/versions/2.2.2/lib/ruby/gems/2.2.0/gems/webmock-1.15.0/lib/webmock/http_lib_adapters/net_http.rb:100: warning: assigned but unused variable - response After some fun with the test, I got it passing:\nFabulous!\nThe flow After migrating two classes from RSpec to Minitest, I noticed a change in my workflow. I was running rake, which runs the complete suite, to run just one test. The only way I could find to run a single test seems a bit too verbose for me. Since I am very used to RSpec, running a test with the line number is one of my most used features of RSpec.\nIn this sense, Minitest gave me a tiny disappointment. Running a huge command with four arguments every time I want to run a single test is a flow-killer. True, I could use Guard to run the test when it gets changed. But also, I often want to run tests by hand without any hassle.\nThanks to Nick Quaranto who wrote the m gem. The gem is quite simple - just a Test::Unit runner that can run tests by line number. Although simple, it is exactly what I needed!\nThis means that, instead of running a single test with:\nruby -Itest test/lib/test.rb --name /some_test/ m allowes one to do the same with:\nm test/lib/test.rb:12 Fabulous!\nMinitest::Spec::DSL After getting all my tests green, I took a look at Minitest\u0026rsquo;s Spec DSL. Mintest::Spec is a functionally complete spec engine. It turns the test assertions into spec expectations. This basically allows the developers to use Minitest just as RSpec. The syntax is pretty much the same, so migrating RSpec suite to Minitest is much much easier with Minitest::Spec in the mix.\nMy personal preference in this case was to stay away from spec expectations and think more in a test assertions way. Although they are basically the same, this experience was much more joyful for me. Or maybe I just needed to have fun with something new.\nOutput Formatting The basic output, or the one that comes with minitest/pride wasn\u0026rsquo;t really cutting it for me. When looking for other formatting options, I ran into minitest-reporters - a gem for creating customizable Minitest output formats.\nThe setup is quite easy - just require the library in the test_helper.rb and call Minitest::Reporters.use!:\nrequire \u0026#34;forecastr\u0026#34; require \u0026#34;minitest/autorun\u0026#34; require \u0026#34;minitest/reporters\u0026#34; Minitest::Reporters.use! Minitest::Reporters::SpecReporter.new The gem has couple of built-in reporters, and I went for the Minitest::Reporters::SpecReporter. With this gem one can also create his own reporters and formatting.\nSo, what\u0026rsquo;s next? Although Forecastr\u0026rsquo;s codebase might not be big with lots of challenges in it, this was defnitely a really nice exercise for a hot Saturday afternoon. I just wish I had the chance to work with Fixtures and some fake objects.\nAll in all, what I can say now is that using Minitest was a real joy. It seems to be very simple to setup, extend and use. But, although simple, in my opinion it is as powerful as the other alternatives.\nYou can see the whole RSpec to Minitest migration on this commit.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/migrate-rspec-to-minitest/","summary":"I have always wanted to have some fun with Minitest but until this weekend I never got the chance to do it. For those of you that don\u0026rsquo;t know, Minitest is a suite of testing facilities, that support TDD, BDD, mocking and benchmarking. Having wanted to play with Minitest, this weekend I decided that I will migrate the test suite of a gem of mine, from RSpec to Minitest. Read on to see how it all went.","title":"Migrating a test suite from RSpec to Minitest"},{"content":"In my last two posts about Rack, I wrote about the basics of Rack and how to write middleware. If you have no idea what this is about, I recommend reading the last two posts (in the order above). For the rest of you, carry on - today we will see how to write awesome Rails middleware and how to use it in any Rails application. Rails and Rack play together really nice, so keep on reading!\nRails on Rack Rails by default has bunch of middleware loaded that is crucial to Rails' working. If you want to see what middleware your Rails app is using, open it up in command line and run:\nrake middleware You will see a big list of middleware classes that your current Rails app is using. This is a sample output on a app that I am working on. Keep in mind that your output may vary.\nuse ActionDispatch::Static use Rack::Lock use #\u0026lt;ActiveSupport::Cache::Strategy::LocalCache::Middleware:0x007f93ff6810d8\u0026gt; use Rack::Runtime use Rack::MethodOverride use ActionDispatch::RequestId use Rails::Rack::Logger use ActionDispatch::ShowExceptions use ActionDispatch::DebugExceptions use BetterErrors::Middleware use ActionDispatch::RemoteIp use ActionDispatch::Reloader use ActionDispatch::Callbacks use ActiveRecord::ConnectionAdapters::ConnectionManagement use ActiveRecord::QueryCache use ActionDispatch::Cookies use ActionDispatch::Session::CookieStore use ActionDispatch::Flash use ActionDispatch::ParamsParser use ActionDispatch::Head use Rack::ConditionalGet use Rack::ETag use ActionDispatch::BestStandardsSupport use Warden::Manager run MyApplication::Application.routes The list of middleware is quite big. If you are curious what any of these middleware classes do, check this list out. Cool stuff, right? Lets see what rules and conventions apply to writing Rails middleware and how we can leverage those to write our own middleware.\nSetting up a middleware class Just like any Rack middleware that we wrote before, we will need to write a middleware class. Since v3.2, Rails gave us the ability to add middleware classes to lib/middleware. So, lets add that class.\n# lib/middleware/my_middleware.rb class MyMiddleware end As always, there are some conventions of how Rails middleware should be created. Like any other middleware class, the class needs an initialize method and a call method. Also, the first argument of the initialize method is the application itself, and the first argument of the call method is the request environment.\n# lib/middleware/my_middleware.rb class MyMiddleware def initialize app @app = app end def call env # do something... end end Using our middleware Rails allows us to mount this middleware class in the middleware stack so the application can use it in runtime. Again, you can see the middleware stack by running\nrake middleware in your command line.\nMounting Mounting middleware is usually done in the config/application.rb file. But, Rails also allows us to mount different middleware for different environment. This means that you can mount middleware in any of the config/environments files. Mounting a middleware class is done with the command:\nmodule MyRailsApplication class Application \u0026lt; Rails::Application *snip* config.middleware.use \u0026lt;class-name\u0026gt;, \u0026lt;first-argument\u0026gt;, \u0026lt;nth-argument\u0026gt; *snip* end end Or, in our case:\n# config/application.rb module MyRailsApplication class Application \u0026lt; Rails::Application *snip* config.middleware.use \u0026#34;MyMiddleware\u0026#34; *snip* end end There is this tiny caveat when mounting middleware - note that the class name is written as a string, not as a constant. If you mount a middleware class in the config/application.rb file the class name has to be a string. But, if you load the middleware class in the environment files (i.e. config/environment/development.rb) you can mount is as a constant:\n# config/environment/development.rb module MyRailsApplication class Application \u0026lt; Rails::Application *snip* config.middleware.use MyMiddleware *snip* end end As far as I can tell, the reason for this tiny caveat is when Rails is loading all the required files on server boot, when config/application.rb is loaded not all constants are loaded. But, due to the nature of the envronment files, they seem to be autoloaded at the end, when all of the constants are present in memory.\nMounting the middleware in the stack Adding our middleware at a certain point of the middleware stack is done via the insert_before and insert_after commands.\nFor example, if we, for whatever reason, want to add our MyMiddleware class just before the Rails::Rack::Logger middleware, we can use this line:\nmodule MyRailsApplication class Application \u0026lt; Rails::Application *snip* config.middleware.insert_before \u0026#34;Rails::Rack::Logger\u0026#34;, \u0026#34;MyMiddleware\u0026#34; *snip* end end On the flipside, if we want to add our MyMiddleware class after the Rails::Rack::Logger middleware, we can use this line:\nconfig.middleware.insert_after \u0026#34;Rails::Rack::Logger\u0026#34;, \u0026#34;MyMiddleware\u0026#34; Another convenience method that Rails provides us is swap, as in swapping middleware. For example, if you wrote your own params parser middleware, that will substitute ActionDispatch::ParamsParser, you can swap it using:\nconfig.middleware.swap \u0026#34;ActionDispatch::ParamsParser\u0026#34;, \u0026#34;MyParamsParser\u0026#34; This will swap the middleware classes, as in, it will use MyParamsParser instead of ActionDispatch::ParamsParser.\nJust to give you an idea, this can be useful when debugging - you can extend the existing middleware, add some logging so you can see how the data mutates in the params parsers and continue with the normal execution of parsing the params. One can enable that middleware just in development mode, so the middleware is swapped only in development environment.\nThat being said, lets see how we can write our own tiny middleware and mount it to an existing Rails application.\nDeltaLogger We will write a tiny middleware class that will calculate the delta time of the request and log it to the Rails console. You can open any Rails application that you have laying in your computer and play with it. I promise we won\u0026rsquo;t do anything malicious. :-)\nFirst, we need a middleware class. Lets add it to the lib/middleware directory. It\u0026rsquo;s worth mentioning that the directory does not exist by default. So, if it is missing - feel free to create it.\nNext, we\u0026rsquo;ll need to add the initialize and the call method. Remember, the first argument of the initialize method is the application, and the first argument of the call method is the request environment.\n# lib/middleware/delta_logger.rb class DeltaLogger def initialize app @app = app end def call env # do something... end end Next, we\u0026rsquo;ll need to calculate the total time that the applicaiton took to process the request and log it:\n# lib/middleware/delta_logger.rb class DeltaLogger def initialize app @app = app end def call env request_started_on = Time.now @status, @headers, @response = @app.call(env) request_ended_on = Time.now Rails.logger.debug \u0026#34;=\u0026#34; * 50 Rails.logger.debug \u0026#34;Request delta time: #{request_ended_on - request_started_on}seconds.\u0026#34; Rails.logger.debug \u0026#34;=\u0026#34; * 50 [@status, @headers, @response] end end As you can see, this is quite trivial. We save the time before the request has been passed onto the rest of the middleware stack and the time after the middleware has finished with the request. Then, we subtract the start time from the end time and we get a number of seconds that the request processing took.\nWhat\u0026rsquo;s cool in Rails middleware is that we have the Rails application available to us in the scope of the middleware. This allows us to use to Rails logger and log the delta time.\nIf you managed to add your middleware to the Rails app, go ahead and boot it. When the server boots, issue any request to it. In the logs you will see something like:\n================================================== Request delta time: 1.40877 seconds. ================================================== This is our DeltaLogger logging the delta time.\nFormatting the output In one of the examples in the introduction of this post, I mentioned the option of passing arguments to the middleware class. Lets see how we can use this feature to improve the formatting of the DeltaLogger.\nPassing arguments is done by adding the arguments after the class name in the mounting command:\nconfig.middleware.use \u0026#34;MyMiddleware\u0026#34;, \u0026#34;First Argument\u0026#34;, { second: \u0026#34;argument\u0026#34; }, [\u0026#34;nth-argument\u0026#34;] In our tiny example, we can send through the character that we want the output to be formatted with. Currently, our default formatting is done with the equals sign. Making this customizable is easily done by sending this character as the first argument:\n# lib/middleware/delta_logger.rb class DeltaLogger def initialize app, formatting_char = \u0026#39;=\u0026#39; @app = app @formatting_char = formatting_char end def call env request_started_on = Time.now @status, @headers, @response = @app.call(env) request_ended_on = Time.now Rails.logger.debug @formatting_char * 50 Rails.logger.debug \u0026#34;Request delta time: #{request_ended_on - request_started_on}seconds.\u0026#34; Rails.logger.debug @formatting_char * 50 [@status, @headers, @response] end end Now, we can change the output when adding the DeltaLogger to the middleware stack:\nconfig.middleware.use \u0026#34;DeltaLogger\u0026#34;, \u0026#34;*\u0026#34; It\u0026rsquo;s worth mentioning that if your Rails application is running, when changing a middleware class you will have to reboot the application so the new changes in the middleware can be picked up. This happens because Rails loads the middleware only once - on boot.\nNow, when we send a request in the logs we can see that the DeltaLogger output changed:\n************************************************** Request delta time: 1.40877 seconds. ************************************************** Logging levels Another way to leverage arguments is to make the logging level customizable. For example, you might want to change the logging level. In Rails, there are six different logging levels: :debug, :info, :warn, :error, :fatal, and :unknown. Lets make the logging level customizable.\n# lib/middleware/delta_logger.rb VALID_LOG_LEVELS = [:debug, :info, :warn, :error, :fatal, :unknown] class DeltaLogger def initialize app, log_level @app = app # Default to :info log level if the user sets an invalid log level. @log_level = VALID_LOG_LEVELS.include?(log_level) ? log_level : :info end def call env request_started_on = Time.now @status, @headers, @response = @app.call(env) request_ended_on = Time.now Rails.logger.send(@log_level, \u0026#39;=\u0026#39; * 50) Rails.logger.send(@log_level, \u0026#34;Request delta time: #{request_ended_on - request_started_on}seconds.\u0026#34;) Rails.logger.send(@log_level, \u0026#39;=\u0026#39; * 50) [@status, @headers, @response] end end Now, in our application.rb (or environment.rb) file, we can set the logger to use the desired loging level:\nconfig.middleware.use \u0026#34;DeltaLogger\u0026#34;, :warn If we reboot the Rails app and send a new request, the logs will show:\n[WARN] ================================================== [WARN] Request delta time: 0.270595 seconds. [WARN] ================================================== Be aware that your output may vary because logging output relies on the logger formatter that your application is using.\nIf you are not seeing the exact output, you can plug this logging formatter in your app:\n# lib/delta_formatter.rb class DeltaFormatter \u0026lt; Logger::Formatter def call(severity, time, program_name, msg) \u0026#34;[#{severity}] #{String === msg ? msg : msg.inspect}\\n\u0026#34; end end You can use this formatter by including it into application.rb:\n*snipped* require \u0026#34;./lib/delta_formatter\u0026#34; module MyApplication class Application \u0026lt; Rails::Application config.autoload_paths += %W( #{config.root}/lib/**/*) *snipped* config.middleware.use \u0026#34;DeltaLogger\u0026#34;, :warn config.log_formatter = DeltaFormatter.new end end After adding this, you\u0026rsquo;ll need to reboot your server and you should see the output with the severity tag.\nThread safety Last of the important topics about Rails middleware is thread-safety. When using Puma or Unicorn web servers, one of the strong sides of these servers is that they are threaded. Since our middleware runs on these servers, it has to be thread-safe, meaning, it should easily spawn multiple duplicates of it so different threads can use different objects of the same middleware.\nThe easiest and most efficient way to do this is to dup the middleware object that is created in runtime.\n# lib/middleware/delta_logger.rb VALID_LOG_LEVELS = [:debug, :info, :warn, :error, :fatal, :unknown] class DeltaLogger def initialize app, log_level @app = app # Default to :info log level if the user sets an invalid log level. @log_level = VALID_LOG_LEVELS.include?(log_level) ? log_level : :info end def call env dup._call env end def _call env request_started_on = Time.now @status, @headers, @response = @app.call(env) request_ended_on = Time.now Rails.logger.send(@log_level, \u0026#39;=\u0026#39; * 50) Rails.logger.send(@log_level, \u0026#34;Request delta time: #{request_ended_on - request_started_on}seconds.\u0026#34;) Rails.logger.send(@log_level, \u0026#39;=\u0026#39; * 50) [@status, @headers, @response] end end By adding the _call method and duplicating the object we make sure that any instance variables we set in _call will be set on the duped instance, not the original. This allows the web server to use a separate (duped) object for each thread which will contain different data, based on it\u0026rsquo;s execution.\nOutro As you can see, there\u0026rsquo;s quite a bit that needed to be covered in this post. I hope that this explained how you can write your own Rails middleware and mount it in the middleware stack. It\u0026rsquo;s very easy to get creative with Rails middleware as it iss highly customizable, quite low-level(ish) while you have the whole app available in runtime. Next time, we will work together on building and testing a real-life example of Rails middleware.\nUntil then, feel free to drop a comment, I would love to hear your opinions, problems and code that you\u0026rsquo;ve come up with.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/writing-rails-middleware/","summary":"In my last two posts about Rack, I wrote about the basics of Rack and how to write middleware. If you have no idea what this is about, I recommend reading the last two posts (in the order above). For the rest of you, carry on - today we will see how to write awesome Rails middleware and how to use it in any Rails application. Rails and Rack play together really nice, so keep on reading!","title":"How to write Rails middleware"},{"content":"Last time I wrote about the basics of Rack and writing a tiny Rack application. If you are unsure what Rack is and what is it\u0026rsquo;s purpose, I recommend you read the other post, famirialize yourself with Rack and get back to this post. If you think you know enough about Rack, please, carry on reading.\nEnter: Middleware So, middleware. Lets take it from the basics. What is middleware? Remember that Rack \u0026ldquo;wraps\u0026rdquo; HTTP requests and responses? Also, remember that it has this interface (or API) which allows you to play with the request and the responses?\nWell, middleware is a term that is used when speaking for a piece of software which is somehow related to the execution of the web application, but is not directly involved with the execution of the requested task.\nConfusing? Okay, lets put it in another way.\nThink of logging. You request a resource from an API, and the API responds with your results. Although you did not request the API to log your request (why would you?), the API has a logger which records everything that goes in and out of the application. So you see, although the logger is not directly involved with handling your request, the logger is middleware that writes down what you requested and what the API responded with.\nHow it works Every Rack application is a class. The same applies to Rack middleware. Lets write the class and see some basic rules that apply to writing middleware classes.\nclass MyMiddleware def initialize(app) @app = app end end When writing a Rack middleware class, the first argument of the initialize method is the application, or the request handler. If that\u0026rsquo;s confusing, think of it in this way\n the request handler has to be passed in the middleware class, so the middleware can wrap the execution of the application and do something to the request and the response of the application.  Another rule that applies to a middleware class is the call method. The call method executes the application which returns the status, the headers and the body of the response.\nTake this for an example:\n# test_handler.ru class MiddlewareTwo def initialize(app) @app = app end def call(env) puts \u0026#34;MiddlewareTwo reporting in!\u0026#34; puts \u0026#34;The app is: #{@app}\u0026#34; puts \u0026#34;The has the methods: #{@app.methods - Object.methods}\u0026#34; status, headers, body = @app.call(env) [status, headers, body] end end class MiddlewareOne def initialize(app) @app = app end def call(env) puts \u0026#34;MiddlewareOne reporting in!\u0026#34; puts \u0026#34;The app is: #{@app}\u0026#34; puts \u0026#34;The has the methods: #{@app.methods - Object.methods}\u0026#34; status, headers, body = @app.call(env) [status, headers, body] end end class HandlerClass def self.call(env) puts \u0026#39;Handling the request...\u0026#39; [200, { \u0026#34;Content-Type\u0026#34; =\u0026gt; \u0026#34;text/html\u0026#34; }, [\u0026#34;\u0026lt;b\u0026gt;Request handled.\u0026lt;/b\u0026gt;\u0026#34;]] end end use MiddlewareTwo use MiddlewareOne run HandlerClass When we run this file with rackup test_handler.ru, the WEBrick server will boot and our request handler will be served (your output may vary):\n➜ rackup ~/Desktop/test.ru \u0026gt;\u0026gt; Thin web server (v1.5.1 codename Straight Razor) \u0026gt;\u0026gt; Maximum connections set to 1024 \u0026gt;\u0026gt; Listening on localhost:9292, CTRL+C to stop When you visit localhost:9292 in your browser (or cURL it), you will see the \u0026ldquo;Request handled.\u0026rdquo; message. But the server logs are what we are interested in:\nMiddlewareTwo reporting in! The app is: #\u0026lt;MiddlewareOne:0x007fbcdb111f08\u0026gt; The has the methods: [:call] MiddlewareOne reporting in! The app is: HandlerClass The has the methods: [:call] Handling the request... As you can see, the app is actually the handler, or, the HandlerClass. It only has one method, the call method. But, what\u0026rsquo;s really interesting is the order in which the statements are executed. First, MiddlewareTwo wraps the request and prints the app and it\u0026rsquo;s methods. After, it executes the @app.call(env) line, which is the MiddlewareOne class. When it calls the call method, it actually executes the MiddlewareOne call method. Then, that method prints out the app and it\u0026rsquo;s methods. Here, the app is the RequestHandler. After it calls the call method, the response is served.\nThis is what the wrapping looks like:\nMiddlewareTwo[ MiddlewareOne [ RequestHandler ] ] This means that MiddlewareTwo executes MiddlewareOne which executes RequestHandler.\nLoggster Let\u0026rsquo;s take it to the next level and write our own logging middleware. We\u0026rsquo;ll call the class Loggster! :-) What we are aiming for is middleware, that will wrap our Rack application and will log the requests that come in to a logfile. Sounds simple? Lets see\u0026hellip;\n# loggster.ru class Loggster def initialize app @app = app end def call env start_time = Time.now status, headers, body = @app.call env end_time = Time.now Dir.mkdir(\u0026#39;logs\u0026#39;) unless File.directory?(\u0026#39;logs\u0026#39;) File.open(\u0026#39;logs/server.log\u0026#39;, \u0026#39;a+\u0026#39;) do |f| f.write(\u0026#34;[#{Time.now}] \\\u0026#34;#{env[\u0026#39;REQUEST_METHOD\u0026#39;]}#{env[\u0026#39;PATH_INFO\u0026#39;]}\\\u0026#34;#{status}Delta: #{end_time - start_time}s \\n\u0026#34;) end [status, headers, body] end end class RackApp def self.call env [200, {\u0026#39;Content-Type\u0026#39; =\u0026gt; \u0026#39;text/html\u0026#39;}, [\u0026#39;Hi!\u0026#39;]] end end use Loggster run RackApp The Rack application, or, the RackApp class just returns a HTTP 200 with a \u0026ldquo;Hi!\u0026rdquo; message. Simple stuff. So, what does Loggster do? When we add the use Loggster line in the file, we tell Rack to wrap the request handler a.k.a. RackApp with Loggster. This means that Loggster#call will call RackApp.call, it will write to the log file and return the full response that RackApp returned. The \u0026ldquo;magic\u0026rdquo; call method, is really simple. It checks if there\u0026rsquo;s a directory called \u0026ldquo;logs\u0026rdquo; and creates it if it does not exist. After, it creates a server.log file and inside, it writes the current time, the request method (i.e. GET), the URL that the web client requested and the response HTTP status.\nIf we run this file with rackup loggster.ru and visit the URL, we\u0026rsquo;ll see that a directory called \u0026ldquo;logs\u0026rdquo; and a file \u0026ldquo;server.log\u0026rdquo; inside, have been created. So, how does the output of our simple logger looks?\n➜ cat logs/server.log [2015-06-27 01:24:37 +0200] \u0026#34;GET /something\u0026#34; 200 Delta: 1.3s [2015-06-27 01:24:37 +0200] \u0026#34;GET /favicon.ico\u0026#34; 200 Delta: 0.3s [2015-06-27 01:24:37 +0200] \u0026#34;GET /favicon.ico\u0026#34; 200 Delta: 0.2s As you can see, I requested localhost:\u0026lt;port-number\u0026gt;/something via my browser. The browser requested the path and it also requested the favicon twice.\nOutro As you can see, writing Rack middleware can be pretty simple. Of course, it all depends on what functionality you would like the middleware to have. That being said, the rules (or constraints) that Rack imposes when writing middleware are tiny and very clear. In the next post, we will see how we can implement Rack middleware and mount it in a Rails application. In the mean time, did you implement any Rack middleware yourself?\nFeel free to share your stuff (or ask for help, if needed) with me and my readers in the comments.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/writing-rack-middleware/","summary":"Last time I wrote about the basics of Rack and writing a tiny Rack application. If you are unsure what Rack is and what is it\u0026rsquo;s purpose, I recommend you read the other post, famirialize yourself with Rack and get back to this post. If you think you know enough about Rack, please, carry on reading.\nEnter: Middleware So, middleware. Lets take it from the basics. What is middleware? Remember that Rack \u0026ldquo;wraps\u0026rdquo; HTTP requests and responses?","title":"Rack: Writing middleware"},{"content":"About three years ago, when I started working with Ruby and Rails, I noticed that the term \u0026ldquo;Rack\u0026rdquo; always came up in my Google searches. Overwhelmed with all of the stuff I needed to learn combined with the awesomeness of Rails, which shields the new Rails devs from it\u0026rsquo;s internals, I never really understood Rack or writing Rack apps. Although I used to see people mentioning \u0026ldquo;middleware\u0026rdquo; or \u0026ldquo;Rack middleware\u0026rdquo; I never really wrote (or tried to write) any middleware. But, you know what\u0026rsquo;s really funny?\nAs a Rails developer you use Rack every single day, it\u0026rsquo;s just that you\u0026rsquo;re not aware of it. So, for anyone that is wondering what Rack does and how you can leverage it\u0026rsquo;s awesomeness, lets take a look at Rack from first principles.\nWhat is Rack? Wait, isn\u0026rsquo;t it Rake, not Rack? Nope, Rake is \u0026ldquo;Make for Ruby\u0026rdquo; and it\u0026rsquo;s basically a task runner. On the other hand Rack is something else.\nTaken from Rack\u0026rsquo;s documentation:\n Rack provides a minimal, modular, and adaptable interface for developing web applications in Ruby. By wrapping HTTP requests and responses in the simplest way possible, it unifies and distills the API for web servers, web frameworks, and software in between (the so-called middleware) into a single method call.\n What does this tell us? It wraps HTTP requests and responses. Okay, so you can actually use the request (as an object) and write/create the response which the Rack app will return. Cool? Next, has an API for servers, frameworks and middleware into a single method call.\nA single method call? Yes, a Rack application is an object that responds to a method called call.\nTaken from Rack\u0026rsquo;s specification:\n A Rack application is a Ruby object (not a class) that responds to call. It takes exactly one argument, the environment and returns an Array of exactly three values: The status, the headers, and the body.\n What\u0026rsquo;s the environment? Well basically, it\u0026rsquo;s the environment of the server, because Rack is an interface (or an API) for web servers. More specifically, it\u0026rsquo;s a Hash that has a lot of headers (key-value pairs). Also, it contains some Rack specific variables. You can explore the environment here.\nWhy does it return exactly three values? That\u0026rsquo;s what always the web clients are interested in when receiving the response from the server:\n the status - did the request fail, or was it ok the headers - HTTP headers. Rarely mentioned, but they are great! the body - the useful stuff that the server returns (usually a HTTP page or JSON payload)  Makes sense, right?\nRack application Let\u0026rsquo;s see how we can create a simple Rack application.\nFirst, we need to install Rack. Believe it or not (sarcasm sign!) Rack is a gem and we can install it by running this command in our command line:\ngem install rack After you have Rack installed, you can use Rack in two ways. What\u0026rsquo;s interesting is that a Proc can be a Rack application. But why Proc? Well, if you remember, a Rack application is an object that responds to the call method. ;-)\n# rack_app.rb require \u0026#39;rack\u0026#39; rack_app = Proc.new do |env| [200, {\u0026#39;Content-Type\u0026#39; =\u0026gt; \u0026#39;application/json\u0026#39;}, [\u0026#34;{\u0026#39;response\u0026#39;:\u0026#39;OK\u0026#39;}\u0026#34;]] end Rack::Handler::WEBrick.run rack_app If we run this app in our command line:\nruby rack_app.rb we can see that a webserver booted and it ran the Rack application. This is the output of my webserver (the output of yours will vary):\n[2015-06-16 21:26:38] INFO WEBrick 1.3.1 [2015-06-16 21:26:38] INFO ruby 2.0.0 (2014-09-19) [x86_64-darwin13.4.0] [2015-06-16 21:26:38] INFO WEBrick::HTTPServer#start: pid=12649 port=8080 As you can see, Rack started a WEBrick webserver that is running the Rack application we wrote. This happens because WEBrick is built in into Rack, as a Handler, therefore the last line in the Ruby file is:\n*** snip *** Rack::Handler::WEBrick.run rack_app Another way to run this application is using the rackup command. To use this command we\u0026rsquo;ll need to modify the application a bit:\n# rack_app.ru app = Proc.new do |env| [200, {\u0026#39;Content-Type\u0026#39; =\u0026gt; \u0026#39;application/json\u0026#39;}, [\u0026#34;{\u0026#39;response\u0026#39;:\u0026#39;OK\u0026#39;}\u0026#34;]] end run app Much simpler, but what happened? Well, the Proc object still stands in, but the rest of the stuff is gone. As you can see also the filename changed. Why?\nFirst and foremost, when using the rackup command we need a \u0026ldquo;rackup\u0026rdquo; file, whose extension is .ru. Yes, just like Russia\u0026rsquo;s TLD! Also, we use the run method which basically tells rackup to call call on the object that run takes as a parameter (or, the app).\nBooting the server and running the app is trivial, just like before:\nrackup rack_app.ru The output, again, is very similar:\n[2015-06-16 21:37:09] INFO WEBrick 1.3.1 [2015-06-16 21:37:09] INFO ruby 2.0.0 (2014-09-19) [x86_64-darwin13.4.0] [2015-06-16 21:37:09] INFO WEBrick::HTTPServer#start: pid=14930 port=9292 Oh, and did I mention you can cURL the app or view the app running in the browser? WEBrick is a server, which means your Rack application is running on a webserver. In fact, notice the last line of the log above - it says that the server is running on port 9292. To see your Rack application in action, you can visit http://localhost:9292 in the browser. Or, you can curl 127.0.0.1:9292!\nThis is what I got when i cURLed to localhost:9292:\n{\u0026#39;response\u0026#39;:\u0026#39;OK\u0026#39;} That\u0026rsquo;s it. The server returned the response that the Rack application created. There you go - this is a very tiny functioning Rack application.\nOutro I hope this post helped you understand what Rack is and what it\u0026rsquo;s used for. Next time we will take a look at writing Rack middleware and integrating it into a Rails application. Until than, feel free to share your thoughts on Rack with me and the ways you use it. Also, I am looking for suggestions for the middleware example for the next post - what kind of middleware would you like to me to cover?\nEDIT #1 (2015-06-19): Thanks to BlazeBoy for the Rack vs Rake suggestion. Thanks to André for noticing a typo.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/rack-first-principles/","summary":"About three years ago, when I started working with Ruby and Rails, I noticed that the term \u0026ldquo;Rack\u0026rdquo; always came up in my Google searches. Overwhelmed with all of the stuff I needed to learn combined with the awesomeness of Rails, which shields the new Rails devs from it\u0026rsquo;s internals, I never really understood Rack or writing Rack apps. Although I used to see people mentioning \u0026ldquo;middleware\u0026rdquo; or \u0026ldquo;Rack middleware\u0026rdquo; I never really wrote (or tried to write) any middleware.","title":"Rack: First Principles"},{"content":"I am pretty sure everyone of us has been in a situation where you needed to generate a report and/or extract some data from a database and present it in a spreadsheet. In many cases, our clients prefer Excel to handle spreadsheets/reports, because, duh, it\u0026rsquo;s Excel.\nSo, how do you approach this problem? Do you copy and paste data? Or use a RDBMS GUI to generate the report into a spreadsheet? Today, I\u0026rsquo;ll show you a really small but convenient feature of PostgreSQL - COPY.\nHello COPY From the COPY documentation: \u0026ldquo;COPY moves data between PostgreSQL tables and standard file-system files. COPY TO copies the contents of a table to a file, while COPY FROM copies data from a file to a table (appending the data to whatever is in the table already). COPY TO can also copy the results of a SELECT query.\u0026rdquo;\nSo, what does COPY do:\n It can copy the contents of a file (data) to a table, or It can copy the contents of a table (or a SELECT query result) into a file.  If a list of columns is specified, COPY will only copy the data in the specified columns to or from the file. If there are any columns in the table that are not in the column list, COPY FROM will insert the default values for those columns.\nCOPY with a file name instructs the PostgreSQL server to directly read from or write to a file. The file must be accessible to the server and the name must be specified from the viewpoint of the server. When STDIN or STDOUT is specified, data is transmitted via the connection between the client and the server.\nSounds good? Let\u0026rsquo;s give it a try!\nDisclaimer: COPY has the ability to read/write data from/to CSV and Binary files. Although I am sure there are lots of usecases for using binary files, in this blogpost I will only focus on using it for CSV files because, personally for me, they are the most convenient for handing data sets.\nCOPY TO When you want to create a CSV file out of a SELECT query, or dump all of the contents of a table in a CSV file, you can use the \u0026ldquo;COPY \u0026hellip; TO \u0026hellip;\u0026rdquo; command.\nUsing a SELECT query When you want to copy a result set to a CSV file, the format of the COPY command is:\nCOPY (\u0026lt;select-query-here\u0026gt;) TO \u0026lt;file-path\u0026gt;; Or, a more real-life example:\nCOPY (SELECT * FROM people WHERE age \u0026gt; 21) TO \u0026#39;~/Desktop/adults.csv\u0026#39;; As you can see, we use the COPY command which copies the results into a CSV file on the local filesystem. You can take the query a lot further. Here\u0026rsquo;s a real life example of a project that I am currently working on:\nCOPY (SELECT price_rules.* FROM quotes LEFT JOIN price_rules ON quotes.id = price_rules.chargeable_id where quotes.id = 437) TO \u0026#39;~/Desktop/exports/price_rules.csv\u0026#39; CSV; As you can see, you can use any SELECT query that can will return a data result set. But, what\u0026rsquo;s a CSV without headers, right? :-)\nCOPY (SELECT * FROM people WHERE age \u0026gt; 21) TO \u0026#39;~/Desktop/adults.csv\u0026#39; CSV HEADER; Adding the keyword HEADER at the end will include headers in the CSV file, which are the table column names.\nAlso, another key feature of CSV files are the delimiters. Depending on what character delimiter you want the CSV file to have, you can specify the character in the command:\nCOPY (SELECT * FROM people WHERE age \u0026gt; 21) TO \u0026#39;~/Desktop/adults.csv\u0026#39; CSV DELIMITER \u0026#39;,\u0026#39; HEADER; Using a table name When you want a whole table to be dumped into a CSV, the command is really simpler. You just need to specify the table name and the target file:\nCOPY people TO \u0026#39;~/Desktop/people.csv\u0026#39; CSV DELIMITER \u0026#39;,\u0026#39; HEADER; That\u0026rsquo;s it.\nCOPY FROM Now, when you want to inject the data from the CSV file into a table, you can use the \u0026ldquo;COPY \u0026hellip; FROM \u0026hellip;\u0026rdquo; command. The syntax is very simillar, with only one key difference:\nCOPY \u0026lt;table-name\u0026gt; FROM \u0026lt;file-path\u0026gt; DELIMITER \u0026#39;,\u0026#39; CSV HEADER; Or, using a real life example:\nCOPY addresses FROM \u0026#39;~/Desktop/addresses.csv\u0026#39; DELIMITER \u0026#39;,\u0026#39; CSV HEADER; Outro COPY is a really neat and cool feature of Postgres. For brewity, I tried to keep this blogpost short and simple. If you have any thoughts and questions feel free to drop me a comment. Or, if you don\u0026rsquo;t feel chatty, you can head over to the COPY documentation.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/postgresql-copy/","summary":"I am pretty sure everyone of us has been in a situation where you needed to generate a report and/or extract some data from a database and present it in a spreadsheet. In many cases, our clients prefer Excel to handle spreadsheets/reports, because, duh, it\u0026rsquo;s Excel.\nSo, how do you approach this problem? Do you copy and paste data? Or use a RDBMS GUI to generate the report into a spreadsheet?","title":"In and out of PostgreSQL using COPY"},{"content":"In every software, there are some things that have to be unique. For example, a Rails app has only one logger. Also, applications must have configurations, like environment, various API keys and etc. Take the configuration example - we need only one configuration for a runtime of an application. If all of the configuration data is stored into a class, then the whole app will need to use an object of that class. Hence, we use singletons - classes that can only have one object instantiated from them.\nBasically, singleton classes prevent instantiation of more than one object of that class. Some people say that singletons are bad, some don\u0026rsquo;t. But I am pretty sure there are fine use-cases that we need to be aware of.\nThere are couple of ways to implement this pattern in Ruby:\nRuby Singleton Module Ruby\u0026rsquo;s Standard Library has a module that allows the creation of Singleton pattern. Using it is really easy.\nrequire \u0026#39;singleton\u0026#39; class Configuration include Singleton attr_accessor :data def initialize @data = {} end def add key, value @data[key] = value end def version \u0026#39;0.0.1\u0026#39; end end Here, we create a Configuration class - a class that has a hash called \u0026lsquo;data\u0026rsquo; that will contain all the configration data. We added the add method that accepts a key and a value pair as arguments. This method will add the key-value pair to the data hash.\n\u0026gt;\u0026gt; c = Configuration.new NoMethodError: private method `new\u0026#39; called for Configuration:Class from (irb):27 from /Users/ie/.rbenv/versions/2.0.0-p576/bin/irb:12:in `\u0026lt;main\u0026gt;\u0026#39; As you can see, instantiating a new object of this class is prohibited. Accessing the singleton is done using the instance class method.\n\u0026gt;\u0026gt; Configuration.instance =\u0026gt; #\u0026lt;Configuration:0x007fc2799e1568 @data={}\u0026gt; \u0026gt;\u0026gt; Configuration.instance.data =\u0026gt; {} Also, using the add method is done by calling it on the instance: \u0026gt;\u0026gt; Configuration.instance.add \u0026#34;environment\u0026#34;, \u0026#34;development\u0026#34; =\u0026gt; \u0026#34;development\u0026#34; \u0026gt;\u0026gt; Configuration.instance.data =\u0026gt; {\u0026#34;environment\u0026#34;=\u0026gt;\u0026#34;development\u0026#34;}\nInstantiating a single object of a class So, how can we reproduce the same class as a Singleton without mixing in the Singleton module?\nclass Configuration attr_accessor :data def initialize @data = {} end def self.instance @@instance end def add key, value @data[key] = value end @@instance = Configuration.new private_class_method :new end So, where\u0026rsquo;s the magic? The initialize and add methods look pretty usual. We create a class variable @@instance that is an object of the Configuration class. The key thing here is that we \u0026lsquo;protect\u0026rsquo; the Configuration.new method by making it a private class method. Then, Configuration.instance method will just return the @@instance. The use case is very much the same.\n\u0026gt;\u0026gt; Configuration.new NoMethodError: private method `new\u0026#39; called for Configuration:Class from (irb):20 from /Users/ie/.rbenv/versions/2.0.0-p576/bin/irb:12:in `\u0026lt;main\u0026gt;\u0026#39; \u0026gt;\u0026gt; Configuration.instance =\u0026gt; #\u0026lt;Configuration:0x007fd76419ebf8 @data={}\u0026gt; \u0026gt;\u0026gt; Configuration.instance.add \u0026#39;env\u0026#39;, \u0026#39;dev\u0026#39; =\u0026gt; \u0026#34;dev\u0026#34; \u0026gt;\u0026gt; Configuration.instance.data[\u0026#39;env\u0026#39;] =\u0026gt; \u0026#34;dev\u0026#34; \u0026gt;\u0026gt; Configuration.instance =\u0026gt; #\u0026lt;Configuration:0x007fd76419ebf8 @data={\u0026#34;env\u0026#34;=\u0026gt;\u0026#34;dev\u0026#34;}\u0026gt; Constants and global variables The key feature of a Singleton, beside the only-one-available-object is that the Singleton has to be globally acessible. That\u0026rsquo;s why constants and global variables can play well here.\nCONFIGURATION = Configuration.new CONFIGURATION.add \u0026#39;environment\u0026#39;, \u0026#39;development\u0026#39; $configuration = Configuration.new $configuration.add \u0026#39;environment\u0026#39;, \u0026#39;development\u0026#39; One problem that global variables have is that it can get changed in runtime, without you noticing.\nClass Singleton pattern can also be implemented by using class methods and variables. By using class methods we have are sure that we will have a single instance of the class.\nclass Configuration def self.add key, value @@data ||= {} @@data[key] = value end def self.data @@data ||= {} end end Using it is, again, simple:\n\u0026gt;\u0026gt; Configuration.data =\u0026gt; {} \u0026gt;\u0026gt; Configuration.add \u0026#39;environment\u0026#39;, \u0026#39;production\u0026#39; =\u0026gt; \u0026#34;production\u0026#34; \u0026gt;\u0026gt; Configuration.data =\u0026gt; {\u0026#34;environment\u0026#34;=\u0026gt;\u0026#34;production\u0026#34;} Module Simillar to the class implementation, a module can be a Singleton. Also, by default, instantiating an object from a module is impossible, which is a nice thing when it comes to the Singleton pattern.\nmodule Configuration def self.add key, value @@data ||= {} @@data[key] = value end def self.data @@data ||= {} end end Using the module is the same as using the class:\n\u0026gt;\u0026gt; Configuration.data =\u0026gt; {} \u0026gt;\u0026gt; Configuration.add \u0026#39;environment\u0026#39;, \u0026#39;production\u0026#39; =\u0026gt; \u0026#34;production\u0026#34; \u0026gt;\u0026gt; Configuration.data =\u0026gt; {\u0026#34;environment\u0026#34;=\u0026gt;\u0026#34;production\u0026#34;} The good, the bad and the Singleton Pattern There is quite a debate going on the internet about the Singleton pattern. Some are in love with it, others consider it an anti-pattern and despise it. What\u0026rsquo;s very crucial that you must understand is that every pattern has it\u0026rsquo;s use cases. Yes, each and every one of them!\nIn my opinion, the problem with the Singleton pattern is that if you fall \u0026ldquo;in love\u0026rdquo; with it, you might overuse it and then the coupling and the global state might hunt you for years. On the other hand, the best examples where you should use Singletons that come to mind are application Configuration and Loggers. So, like I said, it has it\u0026rsquo;s use cases but you should really think hard about it before using it.\nWhen and where have you used Singletons? Is it that bad, or is it much better? What\u0026rsquo;s your opinion on using the Singleton pattern?\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/singleton-pattern/","summary":"In every software, there are some things that have to be unique. For example, a Rails app has only one logger. Also, applications must have configurations, like environment, various API keys and etc. Take the configuration example - we need only one configuration for a runtime of an application. If all of the configuration data is stored into a class, then the whole app will need to use an object of that class.","title":"Implementing \"the lovely\" Singleton Pattern"},{"content":"Startup - in my opinion it\u0026rsquo;s the most ear-catching word nowadays. It represents growth, energy and, of course, billions of dollars. But yeah, a billion of dollars over a weekend is next to impossible. So, why would you attend a startup weekend? What\u0026rsquo;s the benefit? Or, if you know the answers to these questions, you probably would like to know how to win? Yeah, everybody would like that\u0026hellip;\nThis year, it was my first time to attend a startup weekend and it happened in the city where I live - Skopje, Macedonia. The venue was the Telekom Innovation Center in Skopje - man, working for three days in that place made us feel like rockstars. The interior is awesome. Also, the people were great! The local organizers and volunteers are amazing people. So much energy and love for the community, I just hope they don\u0026rsquo;t get tired one day and stop doing all this. It would be a big loss for our micro startup community and a very very sad day.\nPitching an idea When you arrive on Friday, you\u0026rsquo;ll have the opportunity to pitch an idea. You\u0026rsquo;ll have only 60 seconds to do that and believe me if you miss the opportunity, on Sunday evening you WILL BE SORRY you didn\u0026rsquo;t pitch on Friday! So, get out there and pitch. Relax as much as you can and keep in mind that +85% of the people there are as skilled speakers as you are. There\u0026rsquo;s nothing to be afraid of! When I got out to pitch my idea last Friday, my legs were shaking, my heart was pounding and my hands were sweaty. After those \u0026ldquo;terrible\u0026rdquo; 60 seconds, I felt really good. I got a huge round of applause and went back to my seat. 30 minutes later, I got about 20 votes for my idea which was enough to get it into the next stage.\nFinding a team/team members Having a good team is crucial. I guess it\u0026rsquo;s worth mentioning that more than 65% of the startups fail because of team issues. I was lucky I had my friend Angel, who\u0026rsquo;s a designer, on my team. We found another guy there, Antonio, who helped us with the questionnaires. If you are the founder of the team, at this point you need to step up your game. You need to listen very carefully to your teammates but if there\u0026rsquo;s no teamwork, or someone is sabotaging the team you have to remove him. You don\u0026rsquo;t have the luxury for giving someone a second chance. Also, when you are on a team, if someone\u0026rsquo;s being a dick - you expel him or you switch teams. Although you might consider this as a sign of bad luck or whatever, it actually happened to me, I didn\u0026rsquo;t eliminate the problem quickly and we kind-of lost a whole day arguing with the wrong people instead of doing meaningful work. So, pick your team/teammates wisely and move quick.\nIdea validation This is hard. And it\u0026rsquo;s meant to be. In this phase you will see if your idea, which although got the votes from the voters, is a viable idea that can be turned into a business. Protip: when the coaching sessions start, make sure you have 20 minutes available after two or three coaching sessions, so you can reflect on the feedback you got from the coaches and adapt. But, before the coaching sessions start, make sure your elevator pitch is top-notch. You need to explain the problem and the solution in literally a minute. What\u0026rsquo;s very important is although the mentors/coaches are very experienced, it doesn\u0026rsquo;t mean their opinion is right and that you should take it for granted. That\u0026rsquo;s why it is an opinion. None of them will give you the solution of the problems that your business has. They are there for guidance. Remember that. Ask for (and expect) guidance and make sure you know what\u0026rsquo;s their expertise so you can ask the right questions. Another key point is that you don\u0026rsquo;t have to accept the mentor\u0026rsquo;s suggestions. Or, at least, be selective about it. But make sure you understand their reasoning and why they are saying what they are saying. For example, we were a bit stubborn. We rejected around 80% of the suggestions that we got. It wasn\u0026rsquo;t that they weren\u0026rsquo;t good, it was because the picture Angel and I had for the product was definitive and we held to our guts.\nGet out there Yes, get out there! Make couple of surveys and leave the building. Go talk to people on the street, to nearby businesses or find the people that you need to speak with, regardless of where they are. That\u0026rsquo;s how you will get the best feedback - the one from your potential users/customers. Also, this will tell a lot about your team. If you took the \u0026ldquo;risk\u0026rdquo; to leave the building and expose yourselves to people on the street, it means that you have the guts to do business.\nBusiness and growth Peeps, if there\u0026rsquo;s no business you are unattractive to investors. Actually, if there\u0026rsquo;s no cash coming from the product, it\u0026rsquo;s not a business, but a hobby. And that\u0026rsquo;s it. But, if you figured out the business part, then you need to stick to the plan and move fast. Also, after you figured out where your business is, you need to figure out how you will expand. Every business is meant to take over the world, the limits exist only in your mind.\nThe Final Pitch Oh boy, you are in for a treat! Being anxious, scared or somewhere in between is just fine. No one was born as a fluent public speaker. And like everything else, speaking in front of hundred(s) of people takes practice. But, when you are preparing your pitch you need to make sure it\u0026rsquo;s very concise. You\u0026rsquo;ll have exactly four minutes to present the problem, the solution, the business, growth, marketing and whatnot. So you make sure you don\u0026rsquo;t throw words around. Be very concise. Also, if you are feeling nervous, thinking that everybody in the room is naked wont help. Nope, I tried and it didn\u0026rsquo;t work. Just think that you have nothing to lose, think that even the best public speakers had their first public pitch once and they sucked at it. Also, know that almost everyone there is as good speaker as you.\nAfter your pitch, the judges will ask you questions for three minutes. A key thing that you need to remember - you do not bend. You will not show any type of weakness. Be confident in yourself and in your answers. You should protect your business as it\u0026rsquo;s your own child. They will throw questions at you and you will know the answer, because you worked hard over the weekend and you know every aspect of your business. Also, keep in mind that the time is very short, so again - be very concise.\nYou win, anyway At the end, regardless if you win or you don\u0026rsquo;t, it will be a great experience. I promise you! When you exit the venue on Sunday night you will feel that you learnt a lot and you will want to come back next time. So believe me, you are a winner anyway. When we walked in on Friday night, Angel and I just wanted to meet people, have fun and learn how to start a business. We did have fun, we did meet a lot of people and we definitely learned a lot. But there\u0026rsquo;s one cooler thing we did\u0026hellip; we won!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/my-swsk-xp/","summary":"Startup - in my opinion it\u0026rsquo;s the most ear-catching word nowadays. It represents growth, energy and, of course, billions of dollars. But yeah, a billion of dollars over a weekend is next to impossible. So, why would you attend a startup weekend? What\u0026rsquo;s the benefit? Or, if you know the answers to these questions, you probably would like to know how to win? Yeah, everybody would like that\u0026hellip;\nThis year, it was my first time to attend a startup weekend and it happened in the city where I live - Skopje, Macedonia.","title":"POV: Startup Weekend Skopje"},{"content":"Really cool gems, like Carrierwave for example, have this neat feature of configuring the gem in runtime. It allows you to easily configure how the gem will behave in your app. For example, you can add various authentication keys, how errors should be handled and what not. If you want to add this cool functionality in your gems, read on to find out more.\nPersonally, I love to implement (and use) this way of configuring libraries in runtime. Although people have used and blogged about this \u0026ldquo;pattern\u0026rdquo; so many times, I am writing another how-to because I really like this type of configuring external libs/gems. So, if you\u0026rsquo;ve ever wondered how to implement it, here is another how-to.\nRandomizer Lets build a gem that generates random numbers. We\u0026rsquo;ll call it Randomizer. Basically, every gem is a module, that namespaces bunch of classes and methods. So, say we want our gem to have one method, called generate! that will return our random number. Under the hood, we\u0026rsquo;ll just use the built in rand method.\nmodule Randomizer class \u0026lt;\u0026lt; self def generate! rand end end end This is all good, the rand method will generate a really long Float. But, lets say that we want the generate! method to return a number up to a maximum number? We can change the method to accept a number as an argument and pass that number as an argument to the rand method.\nmodule Randomizer class \u0026lt;\u0026lt; self def generate! max rand max end end end Again, really simple. But, what if we want to set a range for the random number that will be generated? For example, for whatever reason an user might want the method to return random numbers between 50 and 60. How can we do this?\nWell, one approach is to make the generate! method accept two arguments, which is fine. But, instead of passing the arguments every time we make the call, we can add a configuration block so the gem always returns random numbers in a range. This is where we need to introduce the configure block.\nmodule Randomizer class \u0026lt;\u0026lt; self attr_accessor :configuration def configure @config ||= Configuration.new yield(@config) end end class Configuration attr_accessor :from, :to end end How does this work? The configure class method stores a Configuration object inside the Randomizer module. Anything set from the configure block is an attr_accessor on the Configuration class. Now, lets add the generate! method back in and see how we can use the configure block.\nmodule Randomizer class \u0026lt;\u0026lt; self attr_accessor :configuration def configure @configuration ||= Configuration.new yield(@configuration) end def generate! (configuration.from..configuration.to).to_a.sample end end class Configuration attr_accessor :from, :to end end Now, the generate! method takes the from and to attributes from the configuration object and creates an array of it. Then, we use the Array#sample method which picks a random item from an array object. So, say you have a Rails app where you want to use the Randomizer gem. Configuring the gem can be done by adding a randomizer.rb file in the config/initializers folder. Then, we need to use the configure block in the file.\nRandomizer.configure do |config| config.from = 100 config.to = 200 end Now, when we call Randomizer.generate! the method will return a random number between 100 and 200. Hope my explanation was good and you understood how you can use this \u0026ldquo;pattern\u0026rdquo;.\nWhat do you think, how we can adjust the gem so the method returns an array of two random numbers? And how we can adjust the gem so the method will return a custom number of random numbers in an array?\nFeel free to share your solution in the comments. Thanks for reading!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/how-to-yourgem-configure/","summary":"Really cool gems, like Carrierwave for example, have this neat feature of configuring the gem in runtime. It allows you to easily configure how the gem will behave in your app. For example, you can add various authentication keys, how errors should be handled and what not. If you want to add this cool functionality in your gems, read on to find out more.\nPersonally, I love to implement (and use) this way of configuring libraries in runtime.","title":"How to: YourGem.configure"},{"content":"Recently Confreaks uploaded a ton of RailsConf 2015 talks on Youtube. Although I haven\u0026rsquo;t watched all of the talks, these are some of the ones that in my opinion are very worth watching. Keep in mind that this list will grow as I watch more talks over time. So, without further ado\u0026hellip;\nSo You Want to Start Refactoring? by @j3foley In this talk, Jillian Foley talks about refactoring. She shares some techniques about how to approach code that you haven\u0026rsquo;t written and how to easily refactor it.\nNothing is Something by @sandimetz The great Sandi Metz talks about how our code hides concepts/knowledge away from us. Her examples are awesome and her explanation of the NullObject pattern and OOD in general is awesome, as always.\nDon\u0026rsquo;t Be A Hero: Sustainable Open Source by @lilliealbert Lillie Chilen talks about the pain points of maintaining open source projects, how to improve the experience and how to onboard new contributors.\nOpening Keynote by @dhh DHH talks about the motivation behind the built in, slimmed down, API Rails generator, then continues about Turbolinks 3 and the newest addition to Rails - ActionCable.\nKeynote by @tenderlove Man\u0026hellip; he starts off by reading puns from his Twitter timeline. Then goes on to boot his XP machine and opens his slides written with ComicSans. Everything is awesome about Aaron\u0026rsquo;s keynote.\nClosing Keynote by @kentbeck Beautiful talk by Kent Beck about what he learned in his career as a software developer, his habits that he has developed and what he aims for everyday in his day-to-day job.\nYou think I missed an awesome talk in this list? Or maybe, you want to share your favourite talks from RailsConf 2015? Please leave a comment!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/railsconf-2015-talks-that-you-should-watch/","summary":"Recently Confreaks uploaded a ton of RailsConf 2015 talks on Youtube. Although I haven\u0026rsquo;t watched all of the talks, these are some of the ones that in my opinion are very worth watching. Keep in mind that this list will grow as I watch more talks over time. So, without further ado\u0026hellip;\nSo You Want to Start Refactoring? by @j3foley In this talk, Jillian Foley talks about refactoring. She shares some techniques about how to approach code that you haven\u0026rsquo;t written and how to easily refactor it.","title":"RailsConf 2015 talks that you should watch"},{"content":"Recently I did an experiment with RSpec\u0026rsquo;s formatters. Turns out, the output that RSpec returns when you run your specs can be very customized for your own needs. Read on to learn how you can write custom RSpec formatters.\nWriting custom formatters RSpec allows customization of the output by creating your own Formatter class. Yep, it\u0026rsquo;s that easy. You just need to write one class and than require it into RSpec\u0026rsquo;s configuration to use it. Lets explore couple of key concepts about the formatters and it\u0026rsquo;s internals.\nThe Protocol First thing to be aware of is the protocol (the order) that RSpec uses when calling methods from the formatter. Keep in mind that every method receives one argument, which is a Notification object. This is sent by the RSpec reporter which notifies the formatter of the outcome of the example. On the beginning **Formatter#start **is called. This method takes a notification argument of the class StartNotification. On every example group, Formatter#example_group_started is called. This method takes a notification argument of the class GroupNotification. When an example is ran, one of these methods is called, based on the result of the example:\n If the example passes, **Formatter#example_passed **is called. The notification argument is of class ExampleNotification. If the example fails, **Formatter#example_failed **is called. The notification argument is of class FailedExampleNotification. If the example is pending, **Formatter#example_pending **is called. The notification argument is of class ExampleNotification.  At the end of the spec suite, these methods are called in this order:\n Formatter#stop. The notification passed as argument is of class ExamplesNotification. Formatter#start_dump. The notification passed as argument is of class NullNotification. Formatter#dump_pending. The notification passed as argument is of class ExamplesNotification. Formatter#dump_failures. The notification passed as argument is of class ExamplesNotification. Formatter#dump_summary. The notification passed as argument is of class SummaryNotification. Formatter#seed. The notification passed as argument is of class SeedNotification. Formatter#close. The notification passed as argument is of class NullNotification.  I wont go into detail for every of the notification classes. You can dive in the details about each of them in the links that I have attached.\nRegistering your formatter class to RSpec RSpec provides this neat feature of registering a class as a formatter. This is done by creating the class and calling:\nRSpec::Core::Formatters.register \u0026lt;the class name\u0026gt;, \u0026lt;array of symbols representing the methods that this formatter will provide\u0026gt; So, say we want a formatter that shows the progress of the suite, just like the built-in progress formatter, but it will group the failing and the pending specs in the summary of the suite.\nCreating the the GroupingFormatter class class GroupingFormatter RSpec::Core::Formatters.register self, :dump_summary, :close def initialize output @output = output end def dump_summary notification # SummaryNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nFinished in #{notification.duration}.\u0026#34; end def close notification # NullNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34; end end As you can see, the GroupingFormatter is just a class. In it\u0026rsquo;s initializer it takes the output as an argument and sets it as an instance variable. Also, on line 2, you can see the aforementioned RSpec.register call. We pass self as the first argument, because we want to register this class as a formatter. The rest of the arguments are method names that RSpec will call when using this formatter. What this means is that when you define a method for **the protocol, **if you don\u0026rsquo;t register it - it will not be called. Basically, RSpec won\u0026rsquo;t know it exists at all. Next, the dump_summary method calls the duration method on the notification object, which returns a number representing the time of the specs' duration in seconds. So, how can we test if this is working? The command is:\nrspec some_file.rb --require ./grouping_formatter.rb --format GroupingFormatter And the output is:\nFinished in 0.007552. Now, this doesn\u0026rsquo;t tell much. Let\u0026rsquo;s use RSpec\u0026rsquo;s built in helpers to format this number in a meaningful string.\nclass GroupingFormatter RSpec::Core::Formatters.register self, :dump_summary, :close def initialize output @output = output end def dump_summary notification # SummaryNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nFinished in #{RSpec::Core::Formatters::Helpers.format_duration(notification.duration)}.\u0026#34; end def close notification # NullNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34; end end In the dump_summary method we use the RSpec::Core::Formatters::Helpers module which has some methods that can help us turn the duration number into a meaningful string. The output now looks like:\nOkay, great. Now, lets make this formatter mimic the reporting formatter that comes with RSpec. We need the formatter to show a dot for every passing example, F for every failing example and an asterisk for every pending example.\nclass GroupingFormatter RSpec::Core::Formatters.register self, :dump_summary, :close, :example_passed, :example_failed, :example_pending def initialize output @output = output end def example_passed notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;.\u0026#34; end def example_failed notification # FailedExampleNotification @output \u0026lt;\u0026lt; \u0026#34;F\u0026#34; end def example_pending notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;*\u0026#34; end def dump_summary notification # SummaryNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nFinished in #{RSpec::Core::Formatters::Helpers.format_duration(notification.duration)}.\u0026#34; end def close notification # NullNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34; end end So, the reporter (the algorithm that follows the protocol) will call example_failed when an example fails, example_pending when an example is pending and **example_passed **when an example passes. This is really self-explanatory - we add the case specific character to the output for every example. Take note that I added the method names to the RSpec.register call. If I didn\u0026rsquo;t - they\u0026rsquo;d be ignored. The output will now look like:\nLooking good, things are starting to take shape! Now for the more complicated part. How can we group the pending/failing specs? First, lets group the pending specs.\nclass GroupingFormatter RSpec::Core::Formatters.register self, :dump_summary, :close, :example_passed, :example_failed, :example_pending, :dump_pending def initialize output @output = output end def example_passed notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;.\u0026#34; end def example_failed notification # FailedExampleNotification @output \u0026lt;\u0026lt; \u0026#34;F\u0026#34; end def example_pending notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;*\u0026#34; end def dump_pending notification # ExamplesNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nPENDING:\\n\\t\u0026#34; @output \u0026lt;\u0026lt; notification.pending_examples.map {|example| example.full_description + \u0026#34; - \u0026#34; + example.location }.join(\u0026#34;\\n\\t\u0026#34;) end def dump_summary notification # SummaryNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nFinished in #{RSpec::Core::Formatters::Helpers.format_duration(notification.duration)}.\u0026#34; end def close notification # NullNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34; end end Lets look at the dump_pending method now. First, it adds \u0026ldquo;PENDING\u0026rdquo; to the output. Next, it loops through the pending_examples array and creates an array of strings for each of the pending examples. Note that I added the new method to the RSpec.register call, it would be ignored otherwise. Each string in the array will look something like this:\nAt the end, we call _join _on the array of strings to build a single formatted string that we append to the output. Now when we run the specs with the formatter, the output will look like:\nLooking good. Now, for the trickiest part, grouping the failing specs and adding the error underneath every failing spec.\nclass GroupingFormatter RSpec::Core::Formatters.register self, :dump_pending, :dump_failures, :close, :dump_summary, :example_passed, :example_failed, :example_pending def initialize output @output = output end def example_passed notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;.\u0026#34; end def example_failed notification # FailedExampleNotification @output \u0026lt;\u0026lt; \u0026#34;F\u0026#34; end def example_pending notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;*\u0026#34; end def dump_pending notification # ExamplesNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nPENDING:\\n\\t\u0026#34; @output \u0026lt;\u0026lt; notification.pending_examples.map {|example| example.full_description + \u0026#34; - \u0026#34; + example.location }.join(\u0026#34;\\n\\t\u0026#34;) end def dump_failures notification # ExamplesNotification @output \u0026lt;\u0026lt; \u0026#34;\\nFAILING\\n\\t\u0026#34; # For every failed example... @output \u0026lt;\u0026lt; notification.failed_examples.map do |example| # Extract the full description of the example full_description = example.full_description # Extract the example location in the file location = example.location \u0026#34;#{full_description}- #{location}\u0026#34; end.join(\u0026#34;\\n\\n\\t\u0026#34;) end def dump_summary notification # SummaryNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nFinished in #{RSpec::Core::Formatters::Helpers.format_duration(notification.duration)}.\u0026#34; end def close notification # NullNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34; end end In the new dump_failures method we loop through every failed example. Then, we extract the description and the location of the failed example and we build a string that we append to the output. After this change, the output will look like this:\nNext thing, how do we add the error messages underneath every failing spec? Lets expand the **dump_failures **method just a bit.\nclass GroupingFormatter RSpec::Core::Formatters.register self, :dump_pending, :dump_failures, :close, :dump_summary, :example_passed, :example_failed, :example_pending def initialize output @output = output end def example_passed notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;.\u0026#34; end def example_failed notification # FailedExampleNotification @output \u0026lt;\u0026lt; \u0026#34;F\u0026#34; end def example_pending notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;*\u0026#34; end def dump_pending notification # ExamplesNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nPENDING:\\n\\t\u0026#34; @output \u0026lt;\u0026lt; notification.pending_examples.map {|example| example.full_description + \u0026#34; - \u0026#34; + example.location }.join(\u0026#34;\\n\\t\u0026#34;) end def dump_failures notification # ExamplesNotification @output \u0026lt;\u0026lt; \u0026#34;\\nFAILING\\n\\t\u0026#34; # For every failed example... @output \u0026lt;\u0026lt; notification.failed_examples.map do |example| # Extract the full description of the example full_description = example.full_description # Extract the example location in the file location = example.location # Get the Exception message message = example.execution_result.exception.message \u0026#34;#{full_description}- #{location}#{message}\u0026#34; end.join(\u0026#34;\\n\\n\\t\u0026#34;) end def dump_summary notification # SummaryNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nFinished in #{RSpec::Core::Formatters::Helpers.format_duration(notification.duration)}.\u0026#34; end def close notification # NullNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34; end end The only addition is on line 34 - we extract the result of the execution of the example, then we get the message of the exception that RSpec raised when the example failed. Now, lets test it:\nThis is all good, but you can see that the text alignment is broken a bit. If you look at the picture at the beginning, you will notice that the exceptions should appear indented underneath the description of the failing example. Lets fix this.\nclass GroupingFormatter RSpec::Core::Formatters.register self, :dump_pending, :dump_failures, :close, :dump_summary, :example_passed, :example_failed, :example_pending def initialize output @output = output end def example_passed notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;.\u0026#34; end def example_failed notification # FailedExampleNotification @output \u0026lt;\u0026lt; \u0026#34;F\u0026#34; end def example_pending notification # ExampleNotification @output \u0026lt;\u0026lt; \u0026#34;*\u0026#34; end def dump_pending notification # ExamplesNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nPENDING:\\n\\t\u0026#34; @output \u0026lt;\u0026lt; notification.pending_examples.map {|example| example.full_description + \u0026#34; - \u0026#34; + example.location }.join(\u0026#34;\\n\\t\u0026#34;) end def dump_failures notification # ExamplesNotification @output \u0026lt;\u0026lt; \u0026#34;\\nFAILING\\n\\t\u0026#34; @output \u0026lt;\u0026lt; failed_examples_output(notification) end def dump_summary notification # SummaryNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nFinished in #{RSpec::Core::Formatters::Helpers.format_duration(notification.duration)}.\u0026#34; end def close notification # NullNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34; end private # Loops through all of the failed examples and rebuilds the exception message def failed_examples_output notification failed_examples_output = notification.failed_examples.map do |example| failed_example_output example end build_examples_output(failed_examples_output) end # Joins all exception messages def build_examples_output output output.join(\u0026#34;\\n\\n\\t\u0026#34;) end # Extracts the full_description, location and formats the message of each example exception def failed_example_output example full_description = example.full_description location = example.location formatted_message = strip_message_from_whitespace(example.execution_result.exception.message) \u0026#34;#{full_description}- #{location}\\n#{formatted_message}\u0026#34; end # Removes whitespace from each of the exception message lines and reformats it def strip_message_from_whitespace msg msg.split(\u0026#34;\\n\u0026#34;).map(\u0026amp;:strip).join(\u0026#34;\\n#{add_spaces(10)}\u0026#34;) end def add_spaces n \u0026#34; \u0026#34; * n end end In the example above we took the extra step to format the error messages nicely. Basically, we split the exception message on a new-line character, we remove all the whitespace and we rejoin the pieces with a newline between them and add 10 spaces at the beginning of the message (for the indentation). Now, the output will look like this:\nAnd voila, the formatter is working as supposed. Or, is it? :) Lets add some colors! Adding colors is really easy, we just need to require the ConsoleCodes module. The ConsoleCodes module provides helpers for formatting console output with ANSI codes, for example colors and bold. So, the final version of our GroupingFormatter is:\nrequire \u0026#39;rspec/core/formatters/console_codes\u0026#39; class GroupingFormatter RSpec::Core::Formatters.register self, :dump_pending, :dump_failures, :close, :dump_summary, :example_passed, :example_failed, :example_pending def initialize output @output = output end def example_passed notification # ExampleNotification @output \u0026lt;\u0026lt; RSpec::Core::Formatters::ConsoleCodes.wrap(\u0026#34;.\u0026#34;, :success) end def example_failed notification # FailedExampleNotification @output \u0026lt;\u0026lt; RSpec::Core::Formatters::ConsoleCodes.wrap(\u0026#34;F\u0026#34;, :failure) end def example_pending notification # ExampleNotification @output \u0026lt;\u0026lt; RSpec::Core::Formatters::ConsoleCodes.wrap(\u0026#34;*\u0026#34;, :pending) end def dump_pending notification # ExamplesNotification if notification.pending_examples.length \u0026gt; 0 @output \u0026lt;\u0026lt; \u0026#34;\\n\\n#{RSpec::Core::Formatters::ConsoleCodes.wrap(\u0026#34;PENDING:\u0026#34;, :pending)}\\n\\t\u0026#34; @output \u0026lt;\u0026lt; notification.pending_examples.map {|example| example.full_description + \u0026#34; - \u0026#34; + example.location }.join(\u0026#34;\\n\\t\u0026#34;) end end def dump_failures notification # ExamplesNotification if notification.failed_examples.length \u0026gt; 0 @output \u0026lt;\u0026lt; \u0026#34;\\n#{RSpec::Core::Formatters::ConsoleCodes.wrap(\u0026#34;FAILING:\u0026#34;, :failure)}\\n\\t\u0026#34; @output \u0026lt;\u0026lt; failed_examples_output(notification) end end def dump_summary notification # SummaryNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\\nFinished in #{RSpec::Core::Formatters::Helpers.format_duration(notification.duration)}.\u0026#34; end def close notification # NullNotification @output \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34; end private # Loops through all of the failed examples and rebuilds the exception message def failed_examples_output notification failed_examples_output = notification.failed_examples.map do |example| failed_example_output example end build_examples_output(failed_examples_output) end # Joins all exception messages def build_examples_output output output.join(\u0026#34;\\n\\n\\t\u0026#34;) end # Extracts the full_description, location and formats the message of each example exception def failed_example_output example full_description = example.full_description location = example.location formatted_message = strip_message_from_whitespace(example.execution_result.exception.message) \u0026#34;#{full_description}- #{location}\\n#{formatted_message}\u0026#34; end # Removes whitespace from each of the exception message lines and reformats it def strip_message_from_whitespace msg msg.split(\u0026#34;\\n\u0026#34;).map(\u0026amp;:strip).join(\u0026#34;\\n#{add_spaces(10)}\u0026#34;) end def add_spaces n \u0026#34; \u0026#34; * n end end As you can see, we are using the ConsoleCodes.wrap method which wraps a piece of text in ANSI codes with the supplied code in the arguments. You can now test our new colored formatter:\nUsing your new GroupingFormatter Our formatter is now working, but how can we put it to use? One way to use it is by running the specs and requiring the formatter in the RSpec command:\nThis works alright. But, requiring your formatter every time you run your specs is boring.\nMeet .rspec RSpec\u0026rsquo;s documentation says that RSpec reads command line configuration options from files in three different locations:\n Local: ./.rspec-local - This file should exist in the project\u0026rsquo;s root directory. It can contain some private customizations (in the scope of the project) of RSpec and should be ignored by git. Project: ./.rspec - This file should exist in the project\u0026rsquo;s root directory. It usually contains public project-wide customizations of RSpec and is usually checked into the git repo. Global: ~/.rspec - This file exists in the user\u0026rsquo;s home directory. It can contain some personal customizations of your RSpec and is applied to every project where RSpec is used on your machine.  So, we can add a .rspec file in our project\u0026rsquo;s folder with the following contents:\nRSpec will read this file every time we run our specs, so this means that we can run our specs without specifying these options in the rspec command:\nThis will now work with our new formatter.\nUsing it in a Rails app Lets integrate our new formatter in a Rails application. Using the formatter in your Rails application is done in two steps:\n  The formatter class must either be in Rails' autoload path, or manually required in the spec_helper. My personal preference is to require it manually because it\u0026rsquo;s more verbose.\n  In the RSpec.configure block in the spec_helper, you need to register the formatter to RSpec. This is done by:\nconfig.formatter = NameOfTheClass    or, in our case:\nconfig.formatter = GroupingFormatter   That\u0026rsquo;s it. Now when you run your specs the new formatter will be used by RSpec.\nOutro I hope you found this (quite long) post informative and interesting. If any of you wrote your own RSpec formatters, please, share them with me and the others in the comments - I am very curious to see what you\u0026rsquo;ve come up with. Thanks for reading to the very end!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/how-to-write-rspec-formatters-from-scratch/","summary":"Recently I did an experiment with RSpec\u0026rsquo;s formatters. Turns out, the output that RSpec returns when you run your specs can be very customized for your own needs. Read on to learn how you can write custom RSpec formatters.\nWriting custom formatters RSpec allows customization of the output by creating your own Formatter class. Yep, it\u0026rsquo;s that easy. You just need to write one class and than require it into RSpec\u0026rsquo;s configuration to use it.","title":"How to write RSpec formatters from scratch"},{"content":"Recently I wrote about the Template Method pattern and how it\u0026rsquo;s implemented in Ruby. In the comments, one of the readers commented that the Template Method pattern is in fact the Strategy pattern. After thinking hard about how I should answer the question, I thought about writing a post comparing the two patterns. So, here it is - my version of design patterns head to head. Let\u0026rsquo;s see what these two patterns have in common and what are their key differences.\nTemplate Method pattern The most important thing to remember about this pattern is: boilerplate code goes in the parent class while the algorithm-specific methods are implemented (usually overridden) in the child classes. This means, that all of the child classes will share the functionality of the parent class (inheritance, duh!), but the parent class will only be a skeletal class, i.e. one cannot create objects out of it. On the other hand, the child classes will only override the methods that are specific to their domain. You can read more about this in my recent article on Template Method pattern.\nStrategy Pattern In it\u0026rsquo;s core the Strategy Pattern (or SP) is about encapsulating logic into objects, making them interchangeable and using those objects as part of an algorithm. This means that an algorithm (context) can have it\u0026rsquo;s behaviour changed in runtime by an object (strategy).\nImplementing the Strategy pattern Let\u0026rsquo;s see a short example of how we can use the Strategy pattern. Let\u0026rsquo;s create a simple Invoice class.\nclass Invoice attr_accessor :formatter def initialize amount, buyer, seller @amount = amount @buyer = buyer @seller = seller @formatter = JSONFormatter.new end def generate @formatter.format! @amount, @buyer, @seller end end As you can see, the Invoice is consisted of an amount, the name of the buyer and the name of the seller. In it\u0026rsquo;s constructor, a formatter of the Invoice is created. The formatter is an object of a class that has a method format! which takes the buyer, seller and amount as params. When the method is called, it will create the invoice in it\u0026rsquo;s specific format. One very important aspect of the strategy classes is that the context class expects the strategy classes to implement, in our example,** a format! method**. For example, in Java this is achieved by using interfaces, which force a class to implement certain methods. But because Ruby is a dynamic language, there\u0026rsquo;s no such thing as an interface and we must think about this aspect in advance. That being said, lets take a look at the formatter classes - they\u0026rsquo;re all pretty simple.\nclass JSONFormatter def format! amount, buyer_name, seller_name %Q{ { \u0026#34;buyer\u0026#34; =\u0026gt; \u0026#34;#{buyer_name}\u0026#34;, \u0026#34;seller\u0026#34; =\u0026gt; \u0026#34;#{seller_name}\u0026#34;, \u0026#34;amount\u0026#34; =\u0026gt; \u0026#34;#{amount}\u0026#34; } } end end The JSONFormatter creates the invoice in JSON format. As a side note, I am using the percentage string notation because it\u0026rsquo;s a bit more readable this way.\nclass XMLFormatter def format! amount, buyer_name, seller_name %Q{ \u0026lt;invoice\u0026gt; \u0026lt;buyer\u0026gt;#{buyer_name}\u0026lt;/buyer\u0026gt; \u0026lt;seller\u0026gt;#{seller_name}\u0026lt;/seller\u0026gt; \u0026lt;amount\u0026gt;#{amount}\u0026lt;/amount\u0026gt; \u0026lt;/invoice\u0026gt; } end end The XMLFormatter creates the invoice in XML format.\nclass YAMLFormatter def format! amount, buyer_name, seller_name %Q{ --- invoice: buyer: #{buyer_name}seller: #{seller_name}amount: #{amount}} end end And, last but not least, YAMLFormatter creates the invoice in YAML format. The beauty of the Strategy Pattern lies in the context (the Invoice) and the strategies (the formatters). You see, when we first create the Invoice, we can use it to print out a JSON formatted invoice. And it\u0026rsquo;s cool. But the cooler thing is that you can change how the Invoice will behave in runtime, meaning, you can change the formatter object and the behaviour of the invoice will change. Or, said in a more abstract way, the context\u0026rsquo;s behaviour can change with every different strategy you apply to the context. So, how this applies to our code?\ninvoice = Invoice.new 100, \u0026#34;John\u0026#34;, \u0026#34;Jane\u0026#34; puts invoice.generate The first time we generate the Invoice, we use the JSONFormatter and of course we get an invoice back in a JSON format.\n{ \u0026#34;buyer\u0026#34; =\u0026gt; \u0026#34;John\u0026#34;, \u0026#34;cashier\u0026#34; =\u0026gt; \u0026#34;Jane\u0026#34;, \u0026#34;amount\u0026#34; =\u0026gt; \u0026#34;100\u0026#34; } Now, if we change the formatter to that same Invoice object\u0026hellip;\ninvoice.formatter = XMLFormatter.new puts invoice.generate \u0026hellip;we will get the same invoice, formatted in XML.\n\u0026lt;invoice\u0026gt; \u0026lt;buyer\u0026gt;John\u0026lt;/buyer\u0026gt; \u0026lt;cashier\u0026gt;Jane\u0026lt;/cashier\u0026gt; \u0026lt;amount\u0026gt;100\u0026lt;/amount\u0026gt; \u0026lt;/invoice\u0026gt; You see, our formatters change the behaviour of our Invoice.\nStrategy and Template Method So what are the similarities and what are the key differences in these two design patterns? Well, it might be obvious to some of you, confusing to others (as it was for me at the beginning). Both patterns are about encapsulating domain-specific algorithms into objects. But, the key difference is that Strategy Pattern is about modifying a behaviour of a context in runtime using strategies, while Template Method Pattern is about following a skeleton implementation of an algorithm and modifying its behaviour by overriding methods of the skeleton class in the subclasses.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/pattern-to-pattern-template-method-and-strategy/","summary":"Recently I wrote about the Template Method pattern and how it\u0026rsquo;s implemented in Ruby. In the comments, one of the readers commented that the Template Method pattern is in fact the Strategy pattern. After thinking hard about how I should answer the question, I thought about writing a post comparing the two patterns. So, here it is - my version of design patterns head to head. Let\u0026rsquo;s see what these two patterns have in common and what are their key differences.","title":"Pattern to pattern: Template Method \u0026 Strategy"},{"content":"For those late to the Ruby 2.2.0 party like me, aside from the changes (and updates) the core team made under the hood for this version, they introduced couple of new methods to the Enumerable module and to the_ Method, Float, File_ and _String_ classes. Lets take a look at these methods and explore how we can use them in our everyday jobs. Just a heads up, make sure you **use Ruby 2.2.0** when working on the examples.\nEnumerable\u0026rsquo;s #slice_after Enumerable#slice_after is used to chunk an array. When chunks are created, it creates an enumerator for the chunked elements. The end of every chunk is defined by a pattern or a block. This means that, if the pattern returns true for an element, the element that matches the pattern is the end of the chunk. This applies for the block as well - if the block returns true for an element - that element is the end of the chunk. How can we use this? Say you have some an array of page numbers and you want to group them by three. Also, the group should show the first page and last page of the group, with a dash in between.\npages = Array(1..12) # =\u0026gt; [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] enum = pages.slice_after{|n| n % 3 == 0 } enum.to_a # =\u0026gt; [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] enum.map {|chunk| \u0026#34;#{chunk[0]}- #{chunk[2]}\u0026#34; } # =\u0026gt; [\u0026#34;1 - 3\u0026#34;, \u0026#34;4 - 6\u0026#34;, \u0026#34;7 - 9\u0026#34;, \u0026#34;10 - 12\u0026#34;] You can see that we use slice_after to slice the array after every third number. This returns an enumerator, that we can use to loop over it and do something with the chunked elements. In this case, we concatenate the first and the last element with a dash in between them, and we compose a new array of the grouped page numbers by using Enumerable#map. You can read more about the slice_after method in the official Ruby docs.\nEnumerable\u0026rsquo;s #slice_when slice_when works very similarly to slice_after. The difference is that it only accepts a block as an argument, and it will create a chunk when that block returns true. Also, the block accepts two arguments, representing two adjacent elements of the array. How can we use this? Lets say we have an array of numbers and we want to detect all decreasing subsequences in the array.\n# Generates an array of 20 random numbers from 1 to 10K arr = (1..10000).to_a.sample 20 # =\u0026gt; [9000, 4068, 3339, 234, 2861, 2436, 1853, 397, 701, 7072, 6306, 6976, 5736, 4942, 7332, 4941, 6171, 2178, 248, 8473] arr.slice_when {|left, right| left \u0026lt; right }.to_a # =\u0026gt; [[9000, 4068, 3339, 234], [2861, 2436, 1853, 397], [701], [7072, 6306], [6976, 5736, 4942], [7332, 4941], [6171, 2178, 248], [8473]] As you can see, the slice_when method block takes two arguments, the number \u0026ldquo;on the left\u0026rdquo; and the number \u0026ldquo;on the right\u0026rdquo;. I find it easier to think about it that way, but I think it is more correct to use previous and next when naming the block arguments. In the example, the code in the block just looks for a pair of adjacent elements in the array where the first one is smaller than the second one. When the condition returns true a chunk is created. You can read more about this method in the official Ruby docs.\nFloat\u0026rsquo;s #next_float and #prev_float These are pretty much self explanatory. When you call any of these methods on a floating point number, you get the next/previous in line.\nKeep in mind that if you call Float::MAX.next_float you will get back Infinity. For those that haven\u0026rsquo;t seen Float::MAX before, it\u0026rsquo;s the largest floating point number that Ruby can interpret (it\u0026rsquo;s value is 1.7976931348623157e+308). Also, if you call\n(-Float::MAX).prev_float you will get back -Infinity. You can read more about these methods in the official docs for next_float and prev_float.\nFile\u0026rsquo;s .birthtime and #birthtime Also, very self explanatory. It returns the time and date when the file was created.\n# You can use the class method with the path of the file File.birthtime(\u0026#34;/Applications/TextEdit.app\u0026#34;) # =\u0026gt; 2014-09-10 00:05:30 +0200 # Or, open the file... f = File.open(\u0026#34;/Applications/TextEdit.app\u0026#34;) # .. and call #birthtime. f.birthtime # =\u0026gt; 2014-09-10 00:05:30 +0200 # You can also use the class method with a File object. File.birthtime(f) # =\u0026gt; 2014-09-10 00:05:30 +0200 You can read more about this in the official docs for the File class. Important: this does not work on GNU/Linux, because (at the moment of writing this) Linux has no API where Ruby would read that data from. Also, it seems that only Ext4 filesystem is keeping this data, but as said, it doesn\u0026rsquo;t expose it. You can read more about this on this LKML mailing list thread.\nString\u0026rsquo;s #unicode_normalize, #unicode_normalize! \u0026amp; #unicode_normalized? **#unicode_normalize **normalizes the string. The predicate checks if the string is normalized.\n# The Unicode code for the umlaut sign is \\u0308 bad = \u0026#34;making u with an umlaut in Unicode is done with: u\\u0308\u0026#34; # =\u0026gt; \u0026#34;making u with an umlaut in Unicode is done with: ü\u0026#34; bad.unicode_normalized? # =\u0026gt; false bad.unicode_normalize! # =\u0026gt; \u0026#34;making u with an umlaut in Unicode is done with: ü\u0026#34; bad.unicode_normalized? # =\u0026gt; true Method#super_method This method returns a Method of superclass, which would be called if super is used.\nclass Parent def name puts \u0026#34;I\u0026#39;m the parent!\u0026#34; end end class Child \u0026lt; Parent def name puts \u0026#34;I\u0026#39;m the child!\u0026#34; end end parent = Parent.new parent.name # I\u0026#39;m the parent! child = Child.new child.name # I\u0026#39;m the child! # We need to access the Method object, not the result of method... # So, this will not work because the method returns nil, not itself: child.name.super_method # NoMethodError: undefined method `super_method\u0026#39; for nil:NilClass child.name.class # =\u0026gt; NilClass # But if we access the Method object... child.public_method(:name) # =\u0026gt; #\u0026lt;Method: Child#name\u0026gt; # ... we can call the super method of the #name method child.public_method(:name).super_method # =\u0026gt; #\u0026lt;Method: Parent#name\u0026gt; child.public_method(:name).super_method.call # I\u0026#39;m the parent! Outro These are some nice methods that can make our lives easier. I hope this blog post helped you understand (and maybe discover) these new methods that were added to Ruby 2.2.0. What do you think about these new methods? Where can you put them in use? Please, feel free to drop a comment - I would love to read your opinion on this topic.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/exploring-new-methods-in-ruby-two-point-two/","summary":"For those late to the Ruby 2.2.0 party like me, aside from the changes (and updates) the core team made under the hood for this version, they introduced couple of new methods to the Enumerable module and to the_ Method, Float, File_ and _String_ classes. Lets take a look at these methods and explore how we can use them in our everyday jobs. Just a heads up, make sure you **use Ruby 2.","title":"Exploring new methods in Ruby 2.2.0"},{"content":"Gemfiles require at least one gem source, in the form of the URL for a RubyGems server. Although it\u0026rsquo;s not recommended, it\u0026rsquo;s possible as of Bundler 1.7, to add multiple global source lines. Each of these sources has to be a valid Rubygems repository.\nWhen using multiple sources, bundler shows a warning message:\nAlthough, this warning can be disabled by running the\nbundle config disable_multisource true\ncommand, there\u0026rsquo;s a better approach to this.\n:source Just like one can use the :github, to fetch a gem from a Github repo, there\u0026rsquo;s also an option that allows the selection of an alternate Rubygems repository for a gem using the \u0026lsquo;:source\u0026rsquo; option.\ngem \u0026#34;my_gem\u0026#34;, :source =\u0026gt; \u0026#34;https://mygems.com\u0026#34; This forces the gem to be loaded from the specified source and ignores any global sources declared at the top level of the file. If the gem does not exist in this source, it will not be installed.\nSource blocks Just like **group **accepts a name and a block as arguments, there\u0026rsquo;s a git and source blocks that allow one to specify the source of the gems (s)he want\u0026rsquo;s installed.\nsource \u0026#34;https://my.rubygems.server.com\u0026#34; do gem \u0026#34;my_api_gem\u0026#34; gem \u0026#34;my_api_logging_gem\u0026#34; end This tells Bundler to fetch my gems from my Rubygems server. If he can\u0026rsquo;t find them on that server, it does not fall back to any other sources specified in the Gemfile. Also, there\u0026rsquo;s the git block. This is an example from the Bundler documentation.\ngit \u0026#34;https://github.com/rails/rails.git\u0026#34; do gem \u0026#34;activesupport\u0026#34; gem \u0026#34;actionpack\u0026#34; end Since the Rails Github repo contains all of the gems that consist the Ruby on Rails framework, the repo can be used as a kind of a source server. This will tell Bundler to look for these gems in this git repo and install them.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/using-multiple-sources-in-a-gemfile/","summary":"Gemfiles require at least one gem source, in the form of the URL for a RubyGems server. Although it\u0026rsquo;s not recommended, it\u0026rsquo;s possible as of Bundler 1.7, to add multiple global source lines. Each of these sources has to be a valid Rubygems repository.\nWhen using multiple sources, bundler shows a warning message:\nAlthough, this warning can be disabled by running the\nbundle config disable_multisource true\ncommand, there\u0026rsquo;s a better approach to this.","title":"Using multiple sources in a Gemfile"},{"content":"When working as a software developer, knowledge of some design patterns is always welcomed. If you\u0026rsquo;ve never heard about design patterns, they are basically some general reusable patterns for common problems that developers run into. There\u0026rsquo;s a big list of these and knowing all of them is a bit hard. Well, hard might not be the right word, but it takes a lot of practice to master them all. Lets take a look at one of the (in my opinion) easier patterns - the Template Method Pattern and implement it in Ruby.\nTemplate method pattern The Template method pattern (or TMP) is a design pattern that defines the program skeleton, or an algorithm skeleton in a method, and the methods that this algorithm is dependent on. The key thing is that some/all of the methods are deferred to subclasses. If this is a bit confusing, bear with me, I promise the example will clear it up. :-)\nA simple payment system Lets say we are working on an e-commerce web application. Like every e-commerce webapp we need a payment system in place for a great user experience. Usually, the payment process has the same flow regardless of the payment provider used.\nKeep in mind that this is an oversimplified example and payment systems in real web applications have more complexity around them. The flow of our example payment system is:\n Authenticate the merchant (the application) with the provider. Send the user\u0026rsquo;s card data to the provider with the amount of the order. Receive confirmation/error from the provider.  If we want to implement this payment algorithm using Stripe, it would look something like:\nclass StripePayment def initialize card, amount @api_key = ENV[\u0026#39;STRIPE_API_KEY\u0026#39;] @card = card @amount = amount end def process_payment! authenticate_merchant \u0026amp;\u0026amp; make_payment end def authenticate_merchant begin return true if Stripe::Merchant.authenticate @api_key rescue Stripe::MerchantError =\u0026gt; e Rails.logger.error \u0026#34;Cannot establish connection between Merchant and Provider.\u0026#34; return false rescue Stripe::ProviderUnreachable =\u0026gt; e Rails.logger.error \u0026#34;Provider unreachable.\u0026#34; return false end end def make_payment begin return true if Stripe::Payment.process! @api_key, @card, @amount rescue Stripe::PaymentUnprocessable =\u0026gt; e Rails.logger.error \u0026#34;Payment unprocessable, try again.\u0026#34; return false end end end Again, keep in mind, this is just dummy code, not actual Stripe payment gateway implementation. Okay, so this looks all fine. We can instantiate a new StripePayment object, pass the card object and the amount of the order as parameters in the initializer and call the process_payment! method on the object to execute the payment. For a successful payment, we need the Merchant (our web application) to successfully authenticate with the payment provider (Stripe) and then the credit card to be charged the total of the order. If any of these two fail, the payment wont be processed.\nWhat about PayPal? Software is made to grow, not die. Or sometimes, get rewritten. So what if our customers need us to add PayPal as a payment option? Easy, right? We can just add another class called PaypalPayment and add the payment logic in the class. But, hold on for a second! What if we need to add Skrill as a payment too? And what if we need to add simple credit card payment, because we have customers that don\u0026rsquo;t want to register accounts with any of the aforementioned payment providers? You see, we run into a problem. We will have to add separate classes that will share a lot of the functionality. The Template Method Pattern can come into play here. So, how can we leverage TMP? We need to create a BasePayment class that will store the template method**(s)**. Then, we will create subclasses, one for every payment provider we use. In the subclasses we will add the specifics of each payment provider, while on the surface the payment will be done by calling the _process_payment!_ method on the payment object, regardless of its class. Let\u0026rsquo;s create our _BasePayment_ and _StripePayment_ classes and see how we can leverage TMP.\nclass BasePayment def initialize card, amount @card = card @amount = amount end def process_payment! authenticate_merchant \u0026amp;\u0026amp; make_payment end def authenticate_merchant raise NotImplementedError.new \u0026#34;authenticate_merchant\u0026#34; end def make_payment raise NotImplementedError.new \u0026#34;make_payment\u0026#34; end end class StripePayment \u0026lt; BasePayment def authenticate_merchant begin return true if Stripe::Merchant.authenticate ENV[\u0026#39;STRIPE_API_KEY\u0026#39;] rescue Stripe::MerchantError =\u0026gt; e Rails.logger.error \u0026#34;Cannot establish connection between Merchant and Provider.\u0026#34; return false rescue Stripe::ProviderUnreachable =\u0026gt; e Rails.logger.error \u0026#34;Provider unreachable.\u0026#34; return false end end def make_payment begin return true if Stripe::Payment.process! ENV[\u0026#39;STRIPE_API_KEY\u0026#39;], @card, @amount rescue Stripe::PaymentUnprocessable =\u0026gt; e Rails.logger.error \u0026#34;Payment unprocessable, try again.\u0026#34; return false end end end As you can see, the template-method-holding-class, or BasePayment, cannot be used as a standalone class. This is because we want to use the class just as a blueprint for the subclasses, instead of instantiating any objects of it. Also, all of the BasePayment subclasses will have to implement the authenticate_merchant and make_payment methods before they can be usable. Let\u0026rsquo;s add PayPal as a payment option now!\nclass PaypalPayment \u0026lt; BasePayment def authenticate_merchant begin return true if Paypal::Account.authenticate ENV[\u0026#39;PAYPAL_API_KEY\u0026#39;] rescue Paypal::NotAuthenticated =\u0026gt; e Rails.logger.error \u0026#34;Cannot establish connection between Merchant and Provider.\u0026#34; return false rescue Paypal::NotFound =\u0026gt; e Rails.logger.error \u0026#34;Provider unreachable.\u0026#34; return false end end def make_payment begin return true if Paypal::Payment.create! ENV[\u0026#39;PAYPAL_API_KEY\u0026#39;], @card, @amount rescue Paypal::UnprocessablePayment =\u0026gt; e Rails.logger.error \u0026#34;Payment unprocessable, try again.\u0026#34; return false end end end As you can see, although the subclasses look alike, the logic in the template methods is very provider specific. The advantage is that the shared logic is inherited and the interfaces of all the payment classes are the same while the algorithm of the authentication and the payment is different in the subclasses. This is how TMP can be done in our example. Now, adding Skrill, or some other payment provider is really easy. Also, another advantage is that the rest of the web application can easily work with any of the payment classes.\nOutro I hope my examples explained the Template Method design pattern. You can use the TMP when there are multiple invariants of a type in your code, and you leave placeholders in your parent type so you can easily customize the subtypes. Also, this enables the developer to not break the functionality of all the subtypes that they inherit from their super-type. Basically, you should use this pattern when you want to have a varying algorithm in a class. The template method holder class should implement the skeleton, while the subclasses should implement the details of the varying algorithm. Questions for you - in Ruby, which approach to TMP do you use? Are there more ways to achieve TMP? Or maybe you have some feedback for this post? Please share your thoughts in the comments. Thanks for reading! Update: Updated the code to raise NotImplementedError. Thanks to David and serg-kovalev for the suggestion!\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/template-method-pattern-in-ruby/","summary":"When working as a software developer, knowledge of some design patterns is always welcomed. If you\u0026rsquo;ve never heard about design patterns, they are basically some general reusable patterns for common problems that developers run into. There\u0026rsquo;s a big list of these and knowing all of them is a bit hard. Well, hard might not be the right word, but it takes a lot of practice to master them all. Lets take a look at one of the (in my opinion) easier patterns - the Template Method Pattern and implement it in Ruby.","title":"Template Method Pattern in Ruby"},{"content":"So far we saw the magic of creating AngularJS services using Provider, Factory and Service. In this post, we will look at two more types of services - Value and Constant.\nValue The Value service is basically a service that returns a single value, like, string, object, number or an array. For instance:\n(function(){ angular.module(\u0026#39;app\u0026#39;, []) .value(\u0026#34;Number\u0026#34;, 24) .value(\u0026#34;String\u0026#34;, \u0026#34;Hey, how are you?\u0026#34;) .value(\u0026#34;Object\u0026#34;, { prop1: \u0026#39;prop1\u0026#39;, prop2: \u0026#39;prop2\u0026#39; }) .value(\u0026#34;Array\u0026#34;, [1,2,3,4,5]); })(); The Value service is basically like writing a service using Provider, whose $get function returns a plain value (string/object/number/array).\n(function(){ angular.module(\u0026#39;app\u0026#39;, []) .provider(\u0026#34;Value\u0026#34;, function(){ this.$get = function(){ return \u0026#34;I am a value.\u0026#34;; }; }); })(); If you are unfamiliar of the way Provider works, take a look here. One drawback of Value is that it cannot be injected into a module configuration function, unlike Provider. On the other hand, it can be decorated using an Angular decorator.\nConstant The Constant service is really the same like Value, with two key differences:\n It can be injected into a module configuration function, like Provider. A Constant service cannot be decorated using an Angular decorator.  For consistency\u0026rsquo;s sake, lets see how constants are defined:\n(function(){ angular.module(\u0026#39;app\u0026#39;, []) .constant(\u0026#34;Pi\u0026#34;, 3.1415) .constant(\u0026#39;e\u0026#39;, 2.718); })(); One last note - injecting Value and Constant services in controllers is done just like any other services.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/angularjs-services-part-4/","summary":"So far we saw the magic of creating AngularJS services using Provider, Factory and Service. In this post, we will look at two more types of services - Value and Constant.\nValue The Value service is basically a service that returns a single value, like, string, object, number or an array. For instance:\n(function(){ angular.module(\u0026#39;app\u0026#39;, []) .value(\u0026#34;Number\u0026#34;, 24) .value(\u0026#34;String\u0026#34;, \u0026#34;Hey, how are you?\u0026#34;) .value(\u0026#34;Object\u0026#34;, { prop1: \u0026#39;prop1\u0026#39;, prop2: \u0026#39;prop2\u0026#39; }) .","title":"AngularJS Services Part 4: Value and Constant"},{"content":"So, Service is basically the same as Factory, it just has one key difference. Service treats the function as a constructor, meaning, the service will call new on the function and return the resulting object as a service object. Oh, if you haven\u0026rsquo;t yet read about Factory, check out AngularJS Services Part 2: Factory.\nUsing Service Declaring a Service is easy. Lets look at an example.\n(function(){ angular.module(\u0026#39;app\u0026#39;, []) .service(\u0026#34;GreetingService\u0026#34;, GreetingService); function GreetingService(){ this.greet = function(){ console.log(\u0026#34;Hello\u0026#34;); } } })(); As you can see, we create a named function GreetingService and we create a service out of it. One slight difference is that we are treating the function as a constructor. This means that, like I said before, the Service will call new GreetingService() when instantiating the service singleton.\nIn case you are wondering, in the example, we can use the GreetingService prototype too.\n(function(){ angular.module(\u0026#39;app\u0026#39;, []) .service(\u0026#34;GreetingService\u0026#34;, GreetingService); function GreetingService(){ } GreetingService.prototype.greet = function(){ console.log(\u0026#34;Hello\u0026#34;); } })(); These examples are basically the same. One advantage of Prototypes is that it allows us to use prototype-based inheritance.\nService in the wild I will use the same example from my last post about Factory.\n(function(){ angular.module(\u0026#34;app\u0026#34;, []) .service(\u0026#39;TemperatureService\u0026#39;, TemperatureService); function TemperatureService($http){ this.API_URL = \u0026#34;http://api.openweathermap.org/data/2.5/weather?q=London,uk\u0026#34;; this.get = function(){ return $http.get(this.API_URL) .then(function(results){ return results.data.main.temp; }) .catch(function(err){ console.log(err); }); } } })(); We use OpenWeatherMap\u0026rsquo;s API and we\u0026rsquo;ll fetch London\u0026rsquo;s (UK) current temperature using a service.\nAngular\u0026rsquo;s built-in $http service is injected into our service so we can make HTTP calls to a external API.\nThe rest, is simple - we issue an HTTP call, use promises to handle successful or errored requests and we return back the promise itself.\nWhat would injecting the service in a controller look like?\n(function(){ angular.module(\u0026#39;app\u0026#39;) .controller(\u0026#39;TemperaturesController\u0026#39;, TemperaturesController); function TemperaturesController(TemperatureService){ TemperatureService.get().then(function(temperature){ // Use the temperature in whichever way you want... \tconsole.log(temperature); }); } })(); Easy! The service is injected in the controller, get() is called on the service and the returned promise from the service is handled. Then, when we get the temperature in the promise we can do whatever we want with it.\nAs you can see, services are pretty simple compared to Provier or Factory. Although simple, we can use protype-based inheritance. What does that mean?\nInheritance via prototype chains If you are unfamiliar with this topic, I recommend you read MDN\u0026rsquo;s article on this topic before continuing with the example.\nSo, since Service allows us to use prototypes, let\u0026rsquo;s see how we can leverage this.\n(function(){ \u0026#34;use strict\u0026#34;; angular.module(\u0026#34;app\u0026#34;, []) .service(\u0026#39;GreetingService\u0026#39;, GreetingService); function Greeting { this.hello = function(){ console.log(\u0026#34;Hello!\u0026#34;); } } function GreetingService { Greeting.call(this); this.bye = function(){ console.log(\u0026#39;Bye!\u0026#39;); } } GreetingService.prototype = Object.create(Greeting.prototype); })(); You can see in the code above how we can use inheritance to our own benefit here. I am guessing you already know that GreetingService will have both, the hello() and bye() functions. Also, what\u0026rsquo;s cool about this approach is that we can make Greet a service as well. These are some nice ways you can use the Service service in AngularJS. Although it provides a lot of flexibility, can be a bit confusing.\nIn the next post we will look at the last two types of services: Constants and Values.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/angularjs-services-part-3/","summary":"So, Service is basically the same as Factory, it just has one key difference. Service treats the function as a constructor, meaning, the service will call new on the function and return the resulting object as a service object. Oh, if you haven\u0026rsquo;t yet read about Factory, check out AngularJS Services Part 2: Factory.\nUsing Service Declaring a Service is easy. Lets look at an example.\n(function(){ angular.module(\u0026#39;app\u0026#39;, []) .service(\u0026#34;GreetingService\u0026#34;, GreetingService); function GreetingService(){ this.","title":"AngularJS Services Part 3: Service"},{"content":"If you don\u0026rsquo;t know the basics of AngularJS service, I recommend you read the other article I wrote on AngularJS Services Part 1: Provider.\nProvider v.s. Factory Factory is a thin wrapper on top of Provider. While Provider provides us the ability to configure the service provider before injection (creating the service object), Factory lacks that ability.\nAlthough it is short of this functionality, most of the Angular devs use factories because they are, in my opinion, the easiest to use and really cover all the general needs that one might need from a service. This does not mean that Provider is bad - it is definitely great for certain use cases (configurability!).\nThat said, lets take a look at factories.\nUsing Factory Factories are defined very similarly as Providers. They return a value, a function or an object literal. Usually developers go with returning an object, which would result in a nice interface to the function. For example:\n(function(){ angular.module(\u0026#39;app\u0026#39;, []) .factory(\u0026#39;GreetingService\u0026#39;, GreetingService); function GreetingService() { var service = { greet: function() { console.log(\u0026#34;Hey there!\u0026#34;); }, }; return service; } })(); Then, we can inject the GreetingService in a controller:\n(function(){ angular.module(\u0026#39;app\u0026#39;) .controller(\u0026#34;GreetingController\u0026#34;, GreetingController); function GreetingController(GreetingService) { GreetingService.greet(); } })(); As you can see, returning an object from the service creates a nice looking interface to the method.\nFactories in the wild Usually, the practice is to use Factory (or services) when you need a reusable piece of code that you can inject into a controller or another service.\nLets take a look at, a more real-life-like, example:\n(function(){ angular.module(\u0026#34;app\u0026#34;, []) .factory(\u0026#39;TemperatureService\u0026#39;, TemperatureService); function TemperatureService($http){ var API_URL = \u0026#34;http://api.openweathermap.org/data/2.5/weather?q=London,uk\u0026#34;; function get(){ return $http.get(API_URL) .then(function(results){ return results.data.main.temp; }) .catch(function(err){ console.log(err); return 0; }); } return { get: get }; } })(); Here we are using OpenWeatherMap\u0026rsquo;s API which is free to use. We will fetch London\u0026rsquo;s (UK) current temperature using a service.\nAs you can see, Angular\u0026rsquo;s built-in $http service is injected into our service so we can issue HTTP calls to a remote API.\nThe API\u0026rsquo;s url is defined as a variable and there is only one method in the service, get(). The url can also be extracted into another service i.e. constant and injected back into the TemperatureService, but lets keep it simple until we get to constants, in one of the next articles.\nThe rest, is simple - we issue an HTTP call, use promises to handle successful or errored requests and we return back the promise itself.\nWhat would injecting the service into a controller look like? Lets see:\n(function(){ angular.module(\u0026#39;app\u0026#39;) .controller(\u0026#39;TemperaturesController\u0026#39;, TemperaturesController); function TemperaturesController(TemperatureService){ TemperatureService.get().then(function(temperature){ // Use the temperature in whichever way you want... \tconsole.log(temperature); }); } })(); Simple, right? We inject the service in the controller, call get() on the service and handle the returned promise from the service. Then, when we get the temperature in the promise we can do whatever we want with it.\nYou can use these files to play with these services - it should all work well. Just make sure you have an HTML file that loads AngularJS from Google\u0026rsquo;s CDNs and make sure you include these files after Angular is loaded.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/angularjs-services-part-2/","summary":"If you don\u0026rsquo;t know the basics of AngularJS service, I recommend you read the other article I wrote on AngularJS Services Part 1: Provider.\nProvider v.s. Factory Factory is a thin wrapper on top of Provider. While Provider provides us the ability to configure the service provider before injection (creating the service object), Factory lacks that ability.\nAlthough it is short of this functionality, most of the Angular devs use factories because they are, in my opinion, the easiest to use and really cover all the general needs that one might need from a service.","title":"AngularJS Services Part 2: Factory"},{"content":"I started using AngularJS couple of months ago, when we got a new client that wanted us to help with building an app written in Angular.\nAfter couple of months of using it, I found myself struggling with uber-phat controllers and I started thinking of solutions about extracting knowledge out of the controller into separate entities. Also, having the ability to easily inject those entities back into the controller is a must.\nWhen I found out about services it really reminded me of service/utility classes that I was used to write in Ruby. Interestingly, the people at Google added 5 types of services in Angular - to fit all your needs.\n Provider Constant Value Factory Service  Problem is, this was quite confusing to me, and I guess for any dev that just got started with AngularJS. So I am writing this blog post that\u0026rsquo;s part of my learning and understanding of AngularJS services, and also, to help other fellow AngularJS developers to understand services.\nOverview Taken from AngularJS' documentation on services:\nWhen you request a service, the $injector is responsible for finding the correct service provider, instantiating it and then calling its $get service factory function to get the instance of the service.\nMildly confusing. Okay, so, what is important:\n Every service in Angular is a singleton. Every service in Angular has a factory. These factories are functions, that are created by the service providers. A servide provider contains the constructor function of the factory. This constructor function is always called $get.  What happens when you inject your newly created service to (let\u0026rsquo;s say) a controller:\n the AngularJS injector finds the provider and instantiates it then it calls the $get function on the provider instance $get returns a service instance Voila! The service is injected in your controller!  Example (using Provider) Let\u0026rsquo;s take a look at a tiny example. As we all know, the internet is made for cats. So, say we have a Cat provider.\n(function(){ \u0026#34;use strict\u0026#34;; angular.module(\u0026#34;app\u0026#34;, []) .provider(\u0026#39;cat\u0026#39;, function(){ this.$get = function() { var name = \u0026#39;Tom\u0026#39;; var color = \u0026#39;Black\u0026#39;; var age = \u0026#34;1\u0026#34;; return { name: name, color: color }; }; }); })(); As you can see, this provider has a $get function that will return an instance of the service, which will be an object literal, containing two properties - the name and the color of the cat.\nWe can now inject this service in a controller and use it in a template.\n(function(){ angular.module(\u0026#39;app\u0026#39;) .controller(\u0026#39;CatsController\u0026#39;, CatsController); function CatsController(cat){ // here we inject the cat service in our controller \tthis.name = cat.name; this.color = cat.color; } })(); \u0026lt;!-- ...snip.. --\u0026gt; \u0026lt;body ng-app=\u0026#39;app\u0026#39;\u0026gt; \u0026lt;div ng-controller=\u0026#34;CatsController as cats\u0026#34;\u0026gt; The cat\u0026#39;s name is: {{ cats.name }}. The cat\u0026#39;s color is: {{ cats.color }}. \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;!-- ...snip.. --\u0026gt; This is a very simple example of how to create services using the provider built-in service.\nProvider So we saw how we can easily use provider. Let\u0026rsquo;s see what else provider provides (no pun intended!).\nEvery provider we create (i.e. see first code snippet) is a module that we can inject. What\u0026rsquo;s cool about Angular is that we can configure any injectables before they are being injected (i.e. in a controller). Basically, the whole point of provider is to enable the developer to configure the service provider before it creates the service, therefore making services much more flexible.\nTake this for example:\n(function(){ \u0026#34;use strict\u0026#34;; angular.module(\u0026#34;app\u0026#34;, []) .provider(\u0026#39;cat\u0026#39;, function(){ var self = this; var bornOn = new Date(\u0026#34;June 18, 2012 22:03:00\u0026#34;); var today = new Date(); self.age = 1; self.$get = function() { var name = \u0026#39;Tom\u0026#39;; var color = \u0026#39;Black\u0026#39;; return { name: name, color: color, age: self.age, }; }; self.setAge = function(value){ if(typeof value === \u0026#39;undefined\u0026#39;){ self.calculateAge(); } else { self.age = value; } }; self.calculateAge = function(){ var oneDayInMs = 1000*60*60*24; var differenceInMs = today.getTime() - bornOn.getTime(); var daysDifference = Math.round(differenceInMs/oneDayInMs); self.age = Math.round(daysDifference/365); }; }) .config(function(catProvider){ catProvider.setAge(); }); })(); Let me walk you through this (bear with me!).\nThis is a Cat service provider, which contains the $get factory function that will return the actual service object. The object, as you can see on lines 17-21, will contain the name, color and age properties. The name and color are hardcoded, meaning, they never change.\nI mean, who dyes their cat\u0026rsquo;s fur or changes that little cute creature\u0026rsquo;s name? Right?\nBut, like any other cat, it ages. So we have a hardcoded date of birth and a setAge method. Take note that the setAge method, as well as the calculateAge are bound/in the scope of the provider, not the factory function.\nThe cool thing happens on lines 40-42. The .config block is get executed during the provider registrations and configuration phase. This means that we can do any custom configuration to the provider before we actually use the service object that the factory method will return.\nTake note that on line 40, we pass in the catProvider to the config block, because it\u0026rsquo;s the provider that we are configuring, not the service. The service will be an object that the $get function will return.\nIn our example, the config block calls setAge which then calls calculateAge which dynamically calculates the age of the cat.\nIf one wants to set the age of the cat manually, he can pass a number as a parameter to the setAge function.\nAlso, if one completely removes the configuration block, the age of the cat will be set to 1. I know it doesn\u0026rsquo;t really make sense, but for this example\u0026rsquo;s sake lets leave it like that.\nProvider (and config) in the wild Take for example Restangular. For those who haven\u0026rsquo;t heard of it Restnagular is basically a AngularJS service that provides a wrapper on top of $http and is made to handle Restful Resources easily.\nIn the documentation, in the section How to configure them globally the author wrote a very cool snippet showing how one can configure the RestangularProvider before any Restangular service is created.\nFor example:\napp.config(function(RestangularProvider) { RestangularProvider.setBaseUrl(\u0026#39;/api/v1\u0026#39;); }); Here, we tell the RestangularProvider that every remote resource that we try to fetch (i.e. /users ) should have a base URL of /api/v1. So, when Restangular fetches the users, it will hit /api/v1/users.\nThis is just a small and tiny example of the flexibillity that AngularJS Providers gives us the developers.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/angularjs-services-part-1/","summary":"I started using AngularJS couple of months ago, when we got a new client that wanted us to help with building an app written in Angular.\nAfter couple of months of using it, I found myself struggling with uber-phat controllers and I started thinking of solutions about extracting knowledge out of the controller into separate entities. Also, having the ability to easily inject those entities back into the controller is a must.","title":"AngularJS Services Part 1: Provider"},{"content":"Regardless of your knowledge level, as a programmer you love to write awesome code. It\u0026rsquo;s what we do. We like it and we do it every single day. But, we all know that writing awesome code is not easy at all. So, how can we improve the code we produce every day?\nAn awareness (or a reminder!) of SOLID principles is beneficial here. SOLID is a group of five principles that when applied correctly can help us produce better code.\nSo, what are the SOLID principles? SOLID is a mnemonic acronym coined by Uncle Bob back in the early 2000s. It represents a group of five principles:\n Single Responsibility Principle Open/Closed Principle Liskov Substitution Principle Interface Segregation Principle Dependency Inversion Principle  Sounds good? Great. Let\u0026rsquo;s take a look at each of these principles.\nIn my opinion, this is the easiest principle to understand. What SRP says is:\n Every class should have a single responsibility, and that responsibility should be entirely encapsulated by the class.\n What does this mean? Basically, every class in your app must have a single responsibility. Easy as that. The best way to detect if your class obeys this principle is to answer this question:\n What does this class do?\n If your answer contains the word AND, then your class does not obey the SRP.\nLets see a quick example. There\u0026rsquo;s the Student class and every student has grades for different terms.\nclass Student attr_accessor :first_term_home_work, :first_term_test, :first_term_paper attr_accessor :second_term_home_work, :second_term_test, :second_term_paper def first_term_grade (first_term_home_work + first_term_test + first_term_paper) / 3 end def second_term_grade (second_term_home_work + second_term_test + second_term_paper) / 3 end end Some of you may already be thinking \u0026ldquo;that is wrong sir!\u0026rdquo;, some of you may not. Regardless of that, yes, this does not obey the SRP. The reason is that the class Student contains the logic that calculates the average grade for each term. The responsibility of Student is to hold info/logic about the student, not the grades. The logic that calculates the grades should be part of a class Grade, not Student.\nLet\u0026rsquo;s refactor the code.\nclass Student def initialize @terms = [ Grade.new(:first), Grade.new(:second) ] end def first_term_grade term(:first).grade end def second_term_grade term(:second).grade end private def term reference @terms.find {|term| term.name == reference} end end class Grade attr_reader :name, :home_work, :test, :paper def initialize(name) @name = name @home_work = 0 @test = 0 @paper = 0 end def grade (home_work + test + paper) / 3 end end You can see that now Grade holds the logic for calculation of the grade and Student only stores the grades into a collection. Now this complies to the SRP, because, every class has it\u0026rsquo;s own responsibility.\nThe Open/closed principle (OCP) is a principle whose definition is:\n One software entity (class/module) must be open for extension but closed for modification.\n What does this mean? Once a class implements the current scope of requirements, the implementation should not need to change in order to fulfil future requirements.\nIt doesn\u0026rsquo;t make sense? Let\u0026rsquo;s take a look at a quick example.\nclass MyLogger def initialize @format_string = \u0026#34;%s: %s\\n\u0026#34; end def log(msg) STDOUT.write @format_string % [Time.now, msg] end end Simple logger class right? It has a format string and sends the current time and the message to STDOUT. Cool, simple enough. Lets test it:\nirb\u0026gt; MyLogger.new.log(\u0026#39;test!\u0026#39;) =\u0026gt; 2014-04-25 16:16:32 +0200: test! Awesome. But, what would happen if someone in the future needs the logger to prepend the string \u0026ldquo;[LOG]\u0026rdquo; to the log message, so the output would look like:\n[LOG] 2014-04-25 16:16:32 +0200: MyLogger calling! For example, a programmer that does not know about the OCP can possibly do this change:\nclass MyLogger def initialize @format_string = \u0026#34;[LOG] %s: %s\\n\u0026#34; end end And the output of the new MyLogger class would be:\nirb\u0026gt; MyLogger.new.log(\u0026#39;test!\u0026#39;) =\u0026gt; [LOG] 2014-04-25 16:16:32 +0200: test! Everything looks good, right? But, wait a second? Does it?\nThink about this - if this was a core class of an app, the change we introduced to the format_string would break the functionality of that classes that rely on the MyLogger class. There\u0026rsquo;s the possibility that a whole world out there relies on the former funcionality of the class, but now, that we changed it, a lot of things can break. This is a violation of the OCP and it is bad!\nSo, what is the good way to do it? Inheritance! Or object composition!\nLet\u0026rsquo;s see an example that uses inheritance:\nclass NewCoolLogger \u0026lt; MyLogger def initialize @format_string = \u0026#34;[LOG] %s: %s\\n\u0026#34; end end irb\u0026gt; NewCoolLogger.new.log(\u0026#39;test!\u0026#39;) =\u0026gt; [LOG] 2014-04-25 16:16:32 +0200: test! Nice, works as expected! What about the functionality of MyLogger?\nirb\u0026gt; MyLogger.new.log(\u0026#39;test!\u0026#39;) =\u0026gt; 2014-04-25 16:16:32 +0200: test! Great! So, what did we just do? We extended the MyLogger class and created a brand new class called NewCoolLogger that extends the former class. Now the code that relies on the functionality of the old logger will not break due to the changes we introduced. The old logger will work just like it did before and the new one will provide the new functionality that the programmer wanted.\nAlso, I mentioned object composition. Take this refactor in cosideration:\nclass MyLogger def log(msg, formatter: MyLogFormatter.new) STDOUT.write formatter.format(msg) end end You can notice that the log method receives an optional parameter called formatter. The format of the log string is responsibility of the MyLogFormatter class not the logger class itself. This is good because now MyLogger#log can accept different formatter classes that will set the format of the log message. For example, you can create ErrorLogFormatter that will prepend [ERROR] to the log message but MyLogger will not care because all it needs is a string that it will send to STDOUT.\nLiskov substitution principle Barbara Liskov defined the principle within these lines:\n If S is a subtype of T, then objects of type T may be replaced with objects of type S (i.e., objects of type S may substitute objects of type T) without altering any of the desirable properties of that program (correctness, task performed, etc.).\n Honestly, I found this definition pretty hard to understand. So, after some thinking, this is what it boils down to:\nThere is a class Bird. And there are two objects, obj1 and obj2. The class of obj1 is Duck which is a child-class of Bird. Let\u0026rsquo;s say we discover that obj2\u0026rsquo;s class is Pigeon, which is also a child-class of Bird. Liskov substitution principle states that in this situation, when obj2 has a type of Bird sub-class and obj1 which is of class Duck which is also a sub-type of Bird, I should be able to treat obj1 and obj2 in the same way - as Birds.\nStill confusing? Take a look at the example below.\nclass Person def greet puts \u0026#34;Hey there!\u0026#34; end end class Student \u0026lt; Person def years_old(age) return \u0026#34;I\u0026#39;m #{age}years old.\u0026#34; end end person = Person.new student = Student.new # What LSP says is if I know the interface of person, I need to be able to # guess the interface of student because the Student class is a subtype of # the Person class. student.greet # returns \u0026#34;Hey there!\u0026#34; Hope that explained LSP.\nInterface segregation principle The interface-segregation principle (ISP) states that:\n No client should be forced to depend on methods it does not use.\n Simple as that. Lets see some code examples and explain them.\nclass Computer def turn_on # turns on the computer end def type # type on the keyboard end def change_hard_drive # opens the computer body # and changes the hard drive end end class Programmer def use_computer @computer.turn_on @computer.type end end class Technician def fix_computer @computer.change_hard_drive end end In this example, there are Computer, Programmer and Technician classes. Both, Programmer and Technician use the Computer in a different way. The programmer uses the computer for typing, but the technician knows how to change the computer hard drive. What Interface Segregation Principle (ISP) enforces is that one class should not depend on methods it does not use. In our case, Programmer is unnecessarily coupled to the Computer#change_hard_drive method because it does not use it, but the state changes that this method enforces can affect the Programmer. Let\u0026rsquo;s refactor the code to obey the LSP.\nclass Computer def turn_on end def type end end class ComputerInternals def change_hard_drive end end class Programmer def use_computer @computer.turn_on @computer.type end end class Technician def fix_computer @computer_internals.change_hard_drive end end After this refactor the Technician uses a different object from the type ComputerInternals which is isolated from the state of the Computer. The state of the Computer object can be influenced by the Programmer but the changes wont affect the Technician in any way.\nDependency inversion principle refers to a specific form of decoupling software modules. It\u0026rsquo;s definition has two parts:\n  High-level modules should not depend on low-level modules. Both should depend on abstractions.   Abstractions should not depend upon details. Details should depend upon abstractions.  I know that this might be a bit confusing. But, before we jump to a example I want to make sure that you must not mix Dependecy Inversion Principle with Dependency Injection. The later is a technique (or pattern) and the former is the principle.\nHaving that said, lets see the example:\nclass Report def initialize @body = \u0026#34;whatever\u0026#34; end def print XmlFormatter.new.generate @body end end class XmlFormatter def generate(body) # convert the body argument into XML end end The Report class is used to generate an XML report. In it\u0026rsquo;s initializer we setup the report and its body. The print method uses the XmlFormatter class to convert the body of the report to XML. Easy as that.\nLet\u0026rsquo;s think a bit about this class. Look at it\u0026rsquo;s name - Report. It\u0026rsquo;s a generic name and it tells us that it will return a report of some kind, but, it doesnt say much about it\u0026rsquo;s format. In fact, in our example, we can easily rename our class to XmlReport since we know the implementation details. But insead of making it very specific, let\u0026rsquo;s think about abstracting this code.\nRight now, our class is dependant on the XmlFormatter class and it\u0026rsquo;s interface i.e. generate. Report right now is dependent on a detail, not on abstraction. It knows that there must be a class XmlFormatter so it can work. Also, another question - what would happen if we wanted an CSV report? Or a JSON report? We\u0026rsquo;d have to have multiple methods like print_xml, print_csv or print_json. This means that our class right now is very tied to the details, it knows about the formatter class type instead of knowing just how to use it (abstraction).\nLet\u0026rsquo;s refactor it:\nclass Report def initialize @body = \u0026#34;whatever\u0026#34; end def print(formatter) formatter.generate @body end end class XmlFormatter def generate(body) # convert the body argument into XML end end Look at the print method now. It knows that it needs a formatter, but it only cares about it\u0026rsquo;s interface. To be more specific, it only cares that that formatter has a method called generate. How is this better? Well, if we wanted CSV reports, all we would need is to add the following class:\nclass CSVFormatter def generate(body) # convert the body argument into CSV end end The Report#print method would accept a CSVFormatter object as a parameter which would convert the report body into a CSV string.\nThat pretty much sums up all of the five SOLID principles. All of our refactoring examples are very basic and we just scratched the surface. I\u0026rsquo;m sure that in your carreer as a programmer you\u0026rsquo;d come on to much more complex problems. But, be assured that having SOLID foundations can definitely help you to write better code that is easier to maintain.\nLiked this article? Subscribe to my newsletter and get future articles in your inbox. It's a short and sweet read, going out to hundreds of other engineers.\n    ","permalink":"https://ieftimov.com/post/solid-principles-ruby/","summary":"Regardless of your knowledge level, as a programmer you love to write awesome code. It\u0026rsquo;s what we do. We like it and we do it every single day. But, we all know that writing awesome code is not easy at all. So, how can we improve the code we produce every day?\nAn awareness (or a reminder!) of SOLID principles is beneficial here. SOLID is a group of five principles that when applied correctly can help us produce better code.","title":"SOLID Principles in Ruby"},{"content":"I am a senior software engineer based in Amsterdam 🇳🇱, working for a Silicon Valley startup, that is the longest-running independent Y-Combinator alumn (followed by Dropbox and Reddit).\nMy areas of interest are platform engineering, cloud native technologies, distributed systems and DevOps.\nSign up below and get my newsletter, once a month. It is a short but sweet read, and you will become a part of a community of +1000 other subscribers.\n     Your information will only be used to send the newsletter. You can unsubscribe any time.\n","permalink":"https://ieftimov.com/newsletter/","summary":"I am a senior software engineer based in Amsterdam 🇳🇱, working for a Silicon Valley startup, that is the longest-running independent Y-Combinator alumn (followed by Dropbox and Reddit).\nMy areas of interest are platform engineering, cloud native technologies, distributed systems and DevOps.\nSign up below and get my newsletter, once a month. It is a short but sweet read, and you will become a part of a community of +1000 other subscribers.","title":"Newsletter"},{"content":"Table of Contents   Test when there’s a DB connection involved, using an actual database.\nDescription: Learn how to write idiomatic tests that rely on a database connection. Find out how to insert data to the test database, how to clean it up after every test and learn about test isolation. Learn different strategies of automatic test database clean up.\n  Test when there’s a database involved, without relying on an actual database.\nDescription: Learn how to write idiomatic tests that DON\u0026rsquo;T rely on a database connection. Find out different strategies of substituting an connection, understand composition choices and tradeoffs, learn about test isolation.\n  Test when there’s a 3rd party service involved.\nDescription: We live in a connected world, our applications talk to many APIs. Learn how to test the code that talks to 3rd party APIs, what are the different approaches to testing such code, how can you use or avoid mocks, and more.\n  Test when an API client (3rd party library) is involved.\nDescription: Often APIs come with pre-built API clients or SDK. While they make integrations easier, testing your code can become tricky, especially because you rely on a 3rd party library. In this video, we will learn what are the pitfalls to testing such code and how we can use tried and tested approaches to such situations.\n  Test when there’s file I/O involved.\nDescription: Our applications often create files and write to them, in this video we will explore different ways to test code that does I/O.\n  Test when time is involved.\nDescription: Time is essential in almost all applications. You might be checking for an entity to expire, or maybe an event to begin. Regardless, time is a necessity and we have know how to code that utilizes time. In this video we will look at different challenges when testing time, and ways to overcome them.\n  Test when SMTP is involved.\nDescription: Golang\u0026rsquo;s standard library ships with a package for sending emails using SMTP (https://golang.org/pkg/net/smtp). While this is powerful feature of the standard library, it brings certain challenges to testing code that uses it. In this video we will explore ways to do just that, in an efficient and idiomatic way.\n  Test code that uploads to S3.\nDescription: The days of uploading files on your application\u0026rsquo;s web servers are long gone. S3 is a very popular object storage solution, by Amazon Web Services, that solves this problem in the age of the cloud. But it also brings its own challenges, such as properly testing your code that uploads to S3. In this video we will see how to do exactly that.\n  Test code that uses Web Sockets.\nDescription: Web Sockets allow us to open a two-way interactive communication session between the user\u0026rsquo;s browser and a server. There are multiple implementation of the WebSocket standard (https://tools.ietf.org/html/rfc6455) for Golang, but we will focus on the most popular one (https://github.com/gorilla/websocket). We will explore what challenges WebSockets in Golang bring and how we can better test them.\n  Test when OS signal and processes are involved.\nDescription: Go is a popular choice of tool when it comes to writing system processes, daemons, CLIs and generally programs running on servers. To gracefully shut down a Go process, the program must know how to handle incoming OS signals, how to clean up after itself and how to gracefully shut down. All of this essential code must be well tested, which is what we will learn how to do in this video.\n  ","permalink":"https://ieftimov.com/testing-in-go-toc/","summary":"Table of Contents   Test when there’s a DB connection involved, using an actual database.\nDescription: Learn how to write idiomatic tests that rely on a database connection. Find out how to insert data to the test database, how to clean it up after every test and learn about test isolation. Learn different strategies of automatic test database clean up.\n  Test when there’s a database involved, without relying on an actual database.","title":"Testing in Go Course"},{"content":"I am a senior software engineer, working with the fine folks over at Stripe on the Stripe Tax team. Before that I worked with some great people in Scribd, Catawiki and in Siyelo.\nIn my career now spanning ~10 years my roles have varied from a full-stack developer, to technical leader, backend software engineer, and even moonlighting as a product manager.\nI have built large distributed systems, serving millions of requests a day. At Catawiki I built one of the first microservices – breaking ground for an architecture that later grew to over 40 different microservices, hosted on hundreds of nodes, unlocking the growth potential of the product. At Scribd, with my team I am work on laying the foundations for growing a service-oriented architecture and fully embracing the DevOps culture. If that seems interesting - join us!\nThroughout my career I have been fortunate to collaborate and be challenged by invigorating people. I have worked on ambitious projects and have had to set up foundations for others to build upon while solving interesting problems.\nSince 2015, on this blog, I\u0026rsquo;m sharing my learnings and realizations on building software, conquering the vast area of cloud technologies and being a successful engineer.\n","permalink":"https://ieftimov.com/work/","summary":"I am a senior software engineer, working with the fine folks over at Stripe on the Stripe Tax team. Before that I worked with some great people in Scribd, Catawiki and in Siyelo.\nIn my career now spanning ~10 years my roles have varied from a full-stack developer, to technical leader, backend software engineer, and even moonlighting as a product manager.\nI have built large distributed systems, serving millions of requests a day.","title":"Work"},{"content":"I am sorry to see you go.\nIf you change your mind, you can still subscribe back here.\n","permalink":"https://ieftimov.com/unsubscribed/","summary":"I am sorry to see you go.\nIf you change your mind, you can still subscribe back here.","title":"You are now unsubscribed"}]