

<!DOCTYPE html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"
><head>
  <meta charset="utf-8" />
  
    <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>Predict diabetes using k-NN from scratch and scikit-learn &middot; Ilija Eftimov üë®‚ÄçüöÄ</title>
    <meta name="title" content="Predict diabetes using k-NN from scratch and scikit-learn &middot; Ilija Eftimov üë®‚ÄçüöÄ" />
  
  <meta name="description" content="Documenting my experiences and learnings, with the goal of helping other software engineers on their journey" />
  
  
  
  <link rel="canonical" href="https://ieftimov.com/posts/knn-from-scratch-scikit-learn/" />
  
  
  
  
  
  
  
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="/css/main.bundle.min.4801cb831d6359e43865e37733fc89df21983ad1c08157d4e17c36e09cb2501cdbd2e1dcde1db016cfa1554f175134d948555ab487816811cb9e93b19673ce89.css"
    integrity="sha512-SAHLgx1jWeQ4ZeN3M/yJ3yGYOtHAgVfU4Xw24JyyUBzb0uHc3h2wFs&#43;hVU8XUTTZSFVatIeBaBHLnpOxlnPOiQ=="
  />
  
  
  <script type="text/javascript" src="/js/appearance.min.badab316c9287a5a42a843e4eb45da65bb3d194a5a0f5fa4a3e516160e67df0b8c65f4f19a8e146436e29d583699e6cb41d6bbe99e05e1dbaa877763bad9f8e2.js" integrity="sha512-utqzFskoelpCqEPk60XaZbs9GUpaD1&#43;ko&#43;UWFg5n3wuMZfTxmo4UZDbinVg2mebLQda76Z4F4duqh3djutn44g=="></script>
  
    
    
    
  
  
    
    
  
  
  
    
    <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.15ae6e2c9b1ac24a9ccf40003fa689efb1a18db1ee9b73d780b01a6c31b150441415862513e93184f68fe385759e4698b8763cba6a0f79493c1fed99ad5868d4.js" integrity="sha512-Fa5uLJsawkqcz0AAP6aJ77GhjbHum3PXgLAabDGxUEQUFYYlE&#43;kxhPaP44V1nkaYuHY8umoPeUk8H&#43;2ZrVho1A==" data-copy="Copy" data-copied="Copied"></script>
  
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  <meta property="og:title" content="Predict diabetes using k-NN from scratch and scikit-learn" />
<meta property="og:description" content="Learn the k-Nearest Neighbors algorithm with me with a practical application on a dataset with diabetes patients" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ieftimov.com/posts/knn-from-scratch-scikit-learn/" /><meta property="og:image" content="https://ieftimov.com/posts/knn-from-scratch-scikit-learn/index_files/card.jpg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-03-01T00:00:00+00:00" /><meta property="og:site_name" content="Ilija Eftimov üë®‚ÄçüöÄ" />

  <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://ieftimov.com/posts/knn-from-scratch-scikit-learn/index_files/card.jpg"/>

<meta name="twitter:title" content="Predict diabetes using k-NN from scratch and scikit-learn"/>
<meta name="twitter:description" content="Learn the k-Nearest Neighbors algorithm with me with a practical application on a dataset with diabetes patients"/>

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Predict diabetes using k-NN from scratch and scikit-learn",
    "headline": "Predict diabetes using k-NN from scratch and scikit-learn",
    "description": "Learn the k-Nearest Neighbors algorithm with me with a practical application on a dataset with diabetes patients",
    "abstract": "Preface # In the past few months, I\u0026rsquo;ve been learning machine learning via the IBM Data Science specialization on Coursera.",
    "inLanguage": "en",
    "url" : "https:\/\/ieftimov.com\/posts\/knn-from-scratch-scikit-learn\/",
    "author" : {
      "@type": "Person",
      "name": "Ilija Eftimov"
    },
    "copyrightYear": "2023",
    "dateCreated": "2023-03-11T00:00:00\u002b00:00",
    "datePublished": "2023-03-01T00:00:00\u002b00:00",
    
    "dateModified": "2023-03-01T00:00:00\u002b00:00",
    
    
    
    "mainEntityOfPage": "true",
    "wordCount": "4164"
  }]
  </script>


  
  <meta name="author" content="Ilija Eftimov" />
  
    
      <link href="https://twitter.com/ilijaio" rel="me" />
    
      <link href="https://www.linkedin.com/in/ieftimov/" rel="me" />
    
      <link href="mailto:blog@ieftimov.com" rel="me" />
    
      <link href="https://captainscodebook.com" rel="me" />
    
      <link href="https://dev.to/fteem" rel="me" />
    
      <link href="https://github.com/fteem" rel="me" />
    
      <link href="https://t.me/ieftimovcom" rel="me" />
    
  
  
  






  
  <script async defer data-domain="ieftimov.com" src="https://plausible.io/js/plausible.js"></script>

  
  
</head>
<body
    class="flex flex-col h-screen px-6 m-auto text-lg leading-7 bg-neutral text-neutral-900 sm:px-14 md:px-24 lg:px-32 dark:bg-neutral-800 dark:text-neutral max-w-7xl"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 dark:bg-neutral-600 focus:translate-y-0"
        href="#main-content"
        ><span class="font-bold ltr:pr-2 rtl:pl-2 text-primary-600 dark:text-primary-400"
          >&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold sm:py-10 text-neutral-900 dark:text-neutral print:hidden">
  <nav class="flex justify-between">
    
    <div>
      
        <a
          class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
          rel="me"
          href="/"
          >Ilija Eftimov üë®‚ÄçüöÄ</a
        >
      

    </div>
    
    
      <ul class="flex flex-col list-none ltr:text-right rtl:text-left sm:flex-row">
        
          
            <li class="mb-1 sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
              <a
                class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                href="/"
                title=""
                >Home</a
              >
            </li>
          
            <li class="mb-1 sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
              <a
                class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                href="/posts/"
                title="Posts"
                >Essays</a
              >
            </li>
          
            <li class="mb-1 sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
              <a
                class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                href="/work"
                title=""
                >Work</a
              >
            </li>
          
            <li class="mb-1 sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
              <a
                class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                href="https://captainscodebook.com"
                title=""
                >Subscribe</a
              >
            </li>
          
        
        
          <li class="ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
            <button
              id="search-button"
              class="text-base hover:text-primary-600 dark:hover:text-primary-400"
              title="Search (/)"
            >
              

  <span class="relative inline-block align-text-bottom icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
          </li>
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex flex-col grow">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
      <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        Predict diabetes using k-NN from scratch and scikit-learn
      </h1>
      <div class="mt-8 mb-12 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
        





  
  



  

  
  
    
  

  

  

  
    
  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2023-03-11 00:00:00 &#43;0000 UTC">11 March 2023</time><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">20 mins</span>
    

    
    
  </div>

  
  


      </div>
    </header>
    <section class="flex flex-col max-w-full mt-0 prose lg:flex-row dark:prose-invert">
      
        <div class="order-first px-0 lg:max-w-xs ltr:lg:pl-8 rtl:lg:pr-8 lg:order-last">
          <div class="ltr:pl-5 rtl:pr-5 toc lg:sticky lg:top-10 print:hidden">
            <details open class="mt-0 overflow-hidden rounded-lg rtl:pr-5 ltr:pl-5 ltr:-ml-5 rtl:-mr-5">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer rtl:pr-5 ltr:pl-5 ltr:-ml-5 rtl:-mr-5 text-neutral-800 dark:text-neutral-100 lg:hidden bg-neutral-100 dark:bg-neutral-700"
  >
    Table of Contents
  </summary>
  <div
    class="py-2 border-dotted ltr:border-l rtl:border-r rtl:pr-5 ltr:pl-5 ltr:-ml-5 rtl:-mr-5 border-neutral-300 dark:border-neutral-600"
  >
    <nav id="TableOfContents">
  <ul>
    <li><a href="#preface">Preface</a></li>
    <li><a href="#k-nearest-neighbors">k-Nearest Neighbors</a>
      <ul>
        <li><a href="#the-math-behind-k-nn">The math behind k-NN</a></li>
      </ul>
    </li>
    <li><a href="#patients-data--diabetes-outcome">Patients&rsquo; data &amp; diabetes outcome</a>
      <ul>
        <li><a href="#cleaning-zero-values">Cleaning zero values</a></li>
      </ul>
    </li>
    <li><a href="#data-splitting">Data splitting</a></li>
    <li><a href="#scaling-our-data">Scaling our data</a>
      <ul>
        <li><a href="#intro-to-scaling">Intro to scaling</a></li>
        <li><a href="#scaling-the-features">Scaling the features</a></li>
      </ul>
    </li>
    <li><a href="#k-nn-from-scratch">k-NN from scratch</a></li>
    <li><a href="#accuracy-confusion-precision--recall">Accuracy, confusion, precision &amp; recall</a>
      <ul>
        <li><a href="#accuracy">Accuracy</a></li>
        <li><a href="#confusion-matrix">Confusion matrix</a></li>
        <li><a href="#precision--recall">Precision &amp; recall</a></li>
        <li><a href="#f1-score">F1 Score</a></li>
      </ul>
    </li>
    <li><a href="#comparing-to-scikit-learn">Comparing to scikit-learn</a></li>
  </ul>
</nav>
  </div>
</details>

          </div>
        </div>
      
      <div class="min-w-0 min-h-0 max-w-prose">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<h2 id="preface" class="relative group">Preface <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#preface" aria-label="Anchor">#</a></span></h2>
<p>In the past few months, I&rsquo;ve been learning machine learning via the <a href="https://www.coursera.org/professional-certificates/ibm-data-science">IBM Data Science specialization</a> on Coursera. It&rsquo;s been an exciting experience, having learned about many topics I&rsquo;ve never dabbled in before. I could glide through most of the courses in the specialization because I am a software engineer with over a decade of experience. This meant that, for me, the real learning started in the last few courses. Learning some rudimentary machine learning has been exciting, so I decided to document what I know and how I understand things.</p>
<p>Therefore, a fair warning: I am an absolute machine learning newbie. I am writing this primarily for myself and someone in a similar boat. There might be some stuff that&rsquo;s wrong here. If you see any, <strong>please</strong> let me know, so I can fix my understanding.</p>
<p>One of the first classification algorithms I learned was k-Nearest Neighbors (k-NN). When I discovered it, I found it really cool because it can do some legit classification while being an algorithm that fits within 100 lines of code. As an ML newbie, I find this fascinating. With the newfound excitement from learning k-NN, I decided to look deeper into it, find a dataset, do some feature engineering, apply k-NN, and assess its performance.</p>
<p>Before we dive into the dataset, I want to discuss the theory of the k-Nearest Neighbors (k-NN) algorithm and its inner workings.</p>
<h2 id="k-nearest-neighbors" class="relative group">k-Nearest Neighbors <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#k-nearest-neighbors" aria-label="Anchor">#</a></span></h2>
<p>Let&rsquo;s take an imaginary dataset with cars, with three columns where two are features (top speed and horsepower) and the target (class):</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">import</span> <span style="color:#8fbcbb">pandas</span> <span style="color:#81a1c1;font-weight:bold">as</span> <span style="color:#8fbcbb">pd</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data <span style="color:#81a1c1">=</span> <span style="color:#eceff4">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a3be8c">&#39;Top Speed (mph)&#39;</span><span style="color:#eceff4">:</span> <span style="color:#eceff4">[</span><span style="color:#b48ead">205</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">217</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">211</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">186</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">202</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">187</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">183</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">174</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">181</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">155</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">155</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">150</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">149</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">147</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">155</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">126</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">130</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">122</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">90</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">95</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">110</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">112</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">109</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">118</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">121</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">130</span><span style="color:#eceff4">],</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a3be8c">&#39;Horsepower (hp)&#39;</span><span style="color:#eceff4">:</span> <span style="color:#eceff4">[</span><span style="color:#b48ead">600</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">710</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">650</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">460</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">500</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">493</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">420</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">365</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">414</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">227</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">255</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">240</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">335</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">290</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">330</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">240</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">260</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">210</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">150</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">170</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">200</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">180</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">190</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">170</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">220</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">190</span><span style="color:#eceff4">],</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a3be8c">&#39;Class&#39;</span><span style="color:#eceff4">:</span> <span style="color:#eceff4">[</span><span style="color:#a3be8c">&#39;Hypercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Hypercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Hypercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Supercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Supercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Supercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Supercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Supercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Supercar&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Luxury car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Luxury car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Luxury car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Luxury car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Luxury car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Luxury car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Economy car&#39;</span><span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span><span style="color:#eceff4">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cars_df <span style="color:#81a1c1">=</span> pd<span style="color:#81a1c1">.</span>DataFrame<span style="color:#eceff4">(</span>data<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>cars_df
</span></span></code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Top Speed (mph)</th>
      <th>Horsepower (hp)</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>205</td>
      <td>600</td>
      <td>Hypercar</td>
    </tr>
    <tr>
      <th>1</th>
      <td>217</td>
      <td>710</td>
      <td>Hypercar</td>
    </tr>
    <tr>
      <th>2</th>
      <td>211</td>
      <td>650</td>
      <td>Hypercar</td>
    </tr>
    <tr>
      <th>3</th>
      <td>186</td>
      <td>460</td>
      <td>Supercar</td>
    </tr>
    <tr>
      <th>4</th>
      <td>202</td>
      <td>500</td>
      <td>Supercar</td>
    </tr>
    <tr>
      <th>5</th>
      <td>187</td>
      <td>493</td>
      <td>Supercar</td>
    </tr>
    <tr>
      <th>6</th>
      <td>183</td>
      <td>420</td>
      <td>Supercar</td>
    </tr>
    <tr>
      <th>7</th>
      <td>174</td>
      <td>365</td>
      <td>Supercar</td>
    </tr>
    <tr>
      <th>8</th>
      <td>181</td>
      <td>414</td>
      <td>Supercar</td>
    </tr>
    <tr>
      <th>9</th>
      <td>155</td>
      <td>227</td>
      <td>Luxury car</td>
    </tr>
    <tr>
      <th>10</th>
      <td>155</td>
      <td>255</td>
      <td>Luxury car</td>
    </tr>
    <tr>
      <th>11</th>
      <td>150</td>
      <td>240</td>
      <td>Luxury car</td>
    </tr>
    <tr>
      <th>12</th>
      <td>149</td>
      <td>335</td>
      <td>Luxury car</td>
    </tr>
    <tr>
      <th>13</th>
      <td>147</td>
      <td>290</td>
      <td>Luxury car</td>
    </tr>
    <tr>
      <th>14</th>
      <td>155</td>
      <td>330</td>
      <td>Luxury car</td>
    </tr>
    <tr>
      <th>15</th>
      <td>126</td>
      <td>240</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>16</th>
      <td>130</td>
      <td>260</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>17</th>
      <td>122</td>
      <td>210</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>18</th>
      <td>90</td>
      <td>150</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>19</th>
      <td>95</td>
      <td>170</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>20</th>
      <td>110</td>
      <td>200</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>21</th>
      <td>112</td>
      <td>180</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>22</th>
      <td>109</td>
      <td>190</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>23</th>
      <td>118</td>
      <td>170</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>24</th>
      <td>121</td>
      <td>220</td>
      <td>Economy car</td>
    </tr>
    <tr>
      <th>25</th>
      <td>130</td>
      <td>190</td>
      <td>Economy car</td>
    </tr>
  </tbody>
</table>
</div>
<p>We can observe that the speed and horsepower affect the class of the car. If we create a scatterplot of the data we&rsquo;ll see how they&rsquo;re grouped on the plot:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">import</span> <span style="color:#8fbcbb">seaborn</span> <span style="color:#81a1c1;font-weight:bold">as</span> <span style="color:#8fbcbb">sns</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sns<span style="color:#81a1c1">.</span>scatterplot<span style="color:#eceff4">(</span>x<span style="color:#81a1c1">=</span>cars_df<span style="color:#eceff4">[</span><span style="color:#a3be8c">&#39;Top Speed (mph)&#39;</span><span style="color:#eceff4">],</span> y<span style="color:#81a1c1">=</span>cars_df<span style="color:#eceff4">[</span><span style="color:#a3be8c">&#39;Horsepower (hp)&#39;</span><span style="color:#eceff4">],</span> hue<span style="color:#81a1c1">=</span>cars_df<span style="color:#eceff4">[</span><span style="color:#a3be8c">&#39;Class&#39;</span><span style="color:#eceff4">]);</span>
</span></span></code></pre></div><p><img src="index_files/figure-markdown_strict/cell-3-output-1.png" alt=""  />
</p>
<p>There&rsquo;s a correlation between the top speed, the horsepower, and the class of the car. Now, if we get a car whose top speed is 140mph, with 300hp, would that be an economy or luxury car? This is where k-NN can help.</p>
<p>The k-NN algorithm is a voting system where the majority class label determines the class label of a new data point among its nearest &lsquo;k&rsquo; neighbors, where k is an integer in the feature space. Using the above example of a car with a top speed of 140mph and 300hp, k-NN would measure the distance of the newly added point to its nearest neighbors. Once the algorithm finds the K closest points, it takes the prevalent category amongst those nearest points and set it to the newly added point. When setting K, a good starting point is usually the square root of the features used from the dataset. Generally, it&rsquo;s best if the K number is assigned to an odd number, so the algorithm doesn&rsquo;t run into a tie.</p>
<p>Now, you will see that I refer to k-NN as an algorithm and not an ML model. That&rsquo;s because k-NN is a non-parametric and lazy learning algorithm. In machine learning, lazy learning is a method in which the generalization of the training data is delayed until a query is made to the system. As we will see soon, there&rsquo;s no model that we will train with k-NN - it&rsquo;s merely an algorithm that will run on the training data and apply a local function (distance between points) to determine the target class.</p>
<h3 id="the-math-behind-k-nn" class="relative group">The math behind k-NN <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-math-behind-k-nn" aria-label="Anchor">#</a></span></h3>
<p>The distance is the next important aspect: what is actually a distance between two points, or a vector, and other points/vectors? To calculate the distance between points we use what&rsquo;s called an Euclidean distance. If <code>a</code> and <code>b</code> are points on a two-dimensional plane, their Euclidean distance will be:</p>
<p><img src="https://latex.codecogs.com/svg.latex?d%28a%2Cb%29%20%3D%20%5Csqrt%7B%28a_1%20-%20b_1%29%5E2%20%2B%20%28a_2%20-%20b_2%29%5E2%7D" alt="d(a,b) = \sqrt{(a_1 - b_1)^2 &#43; (a_2 - b_2)^2}"  class="d(a,b) = \sqrt{(a_1 - b_1)^2 &#43; (a_2 - b_2)^2}" />
</p>
<p>For those that do not like mathematial notation, this basically means the square root of the squares of the differences between the two points on the plane. In Python, this would be:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">euclidean_distance</span><span style="color:#eceff4">(</span>a<span style="color:#eceff4">,</span>b<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#616e87;font-style:italic"># Two points, with their x and y coordinates</span>
</span></span><span style="display:flex;"><span>    a <span style="color:#81a1c1">=</span> <span style="color:#eceff4">[</span><span style="color:#b48ead">1</span><span style="color:#eceff4">,</span><span style="color:#b48ead">2</span><span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>    b <span style="color:#81a1c1">=</span> <span style="color:#eceff4">[</span><span style="color:#b48ead">3</span><span style="color:#eceff4">,</span><span style="color:#b48ead">4</span><span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#616e87;font-style:italic"># Calculate the squared distance</span>
</span></span><span style="display:flex;"><span>    squared_distance <span style="color:#81a1c1">=</span> <span style="color:#eceff4">(</span>a<span style="color:#eceff4">[</span><span style="color:#b48ead">0</span><span style="color:#eceff4">]</span> <span style="color:#81a1c1">-</span> b<span style="color:#eceff4">[</span><span style="color:#b48ead">0</span><span style="color:#eceff4">])</span><span style="color:#81a1c1">**</span><span style="color:#b48ead">2</span> <span style="color:#81a1c1">+</span> <span style="color:#eceff4">(</span>a<span style="color:#eceff4">[</span><span style="color:#b48ead">1</span><span style="color:#eceff4">]</span> <span style="color:#81a1c1">-</span> b<span style="color:#eceff4">[</span><span style="color:#b48ead">1</span><span style="color:#eceff4">])</span><span style="color:#81a1c1">**</span><span style="color:#b48ead">2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#616e87;font-style:italic"># Return the root of the squared distance</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> math<span style="color:#81a1c1">.</span>sqrt<span style="color:#eceff4">(</span>squared_distance<span style="color:#eceff4">)</span>
</span></span></code></pre></div><p>When I read this the first time, I thought &ldquo;why are we squaring the differences in the points if we&rsquo;re applying the square root later?&rdquo;. The reason is that by applying the square and then the square root them it&rsquo;s like taking the absolute value of each point - in other words, we gracefully handle negative points, so the distance is always a positive number (a negative distance is not really a thing).</p>
<p>And that&rsquo;s all the math that k-NN requires. Let&rsquo;s go back to a real dataset and apply k-NN to it.</p>
<h2 id="patients-data--diabetes-outcome" class="relative group">Patients&rsquo; data &amp; diabetes outcome <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#patients-data--diabetes-outcome" aria-label="Anchor">#</a></span></h2>
<p>The dataset I found is <a href="https://www.kaggle.com/datasets/mathchi/diabetes-data-set">the Diabetes Dataset</a> from Kaggle. It contains fetures regarding the patient&rsquo;s health status, with the diabetes outcome as the dependent variable. The goal is to implement our own k-NN classifier and then use it on the dataset to predict diabetes outcomes in patients. Afterwards, we will evaluate the classifier&rsquo;s performance relative to the one that&rsquo;s shipped with scikit-learn.</p>
<p>First, we will load the data, explore it, do a bit of feature engineering, and then we&rsquo;ll move on to building the solution.</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df <span style="color:#81a1c1">=</span> pd<span style="color:#81a1c1">.</span>read_csv<span style="color:#eceff4">(</span><span style="color:#a3be8c">&#39;diabetes.csv&#39;</span><span style="color:#eceff4">)</span>
</span></span></code></pre></div><p>First, we will load the dataset and check its first columns just to get a feel for it:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df<span style="color:#81a1c1">.</span>head<span style="color:#eceff4">()</span>
</span></span></code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6</td>
      <td>148</td>
      <td>72</td>
      <td>35</td>
      <td>0</td>
      <td>33.6</td>
      <td>0.627</td>
      <td>50</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>85</td>
      <td>66</td>
      <td>29</td>
      <td>0</td>
      <td>26.6</td>
      <td>0.351</td>
      <td>31</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>183</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>23.3</td>
      <td>0.672</td>
      <td>32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>89</td>
      <td>66</td>
      <td>23</td>
      <td>94</td>
      <td>28.1</td>
      <td>0.167</td>
      <td>21</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>137</td>
      <td>40</td>
      <td>35</td>
      <td>168</td>
      <td>43.1</td>
      <td>2.288</td>
      <td>33</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<p>The dataset has different columns, each one of them with continious numerical values. Let&rsquo;s see their types and <code>null</code> counts:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df<span style="color:#81a1c1">.</span>info<span style="color:#eceff4">()</span>
</span></span></code></pre></div><pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 768 entries, 0 to 767
Data columns (total 9 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   Pregnancies               768 non-null    int64  
 1   Glucose                   768 non-null    int64  
 2   BloodPressure             768 non-null    int64  
 3   SkinThickness             768 non-null    int64  
 4   Insulin                   768 non-null    int64  
 5   BMI                       768 non-null    float64
 6   DiabetesPedigreeFunction  768 non-null    float64
 7   Age                       768 non-null    int64  
 8   Outcome                   768 non-null    int64  
dtypes: float64(2), int64(7)
memory usage: 54.1 KB
</code></pre>
<p>The fact that every column has no null values is great. We can also see that each column contains numerical values, where two are <code>float64</code> and the rest are <code>int64</code>.</p>
<p>Let&rsquo;s look at the column statistics:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df<span style="color:#81a1c1">.</span>describe<span style="color:#eceff4">()</span>
</span></span></code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.845052</td>
      <td>120.894531</td>
      <td>69.105469</td>
      <td>20.536458</td>
      <td>79.799479</td>
      <td>31.992578</td>
      <td>0.471876</td>
      <td>33.240885</td>
      <td>0.348958</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.369578</td>
      <td>31.972618</td>
      <td>19.355807</td>
      <td>15.952218</td>
      <td>115.244002</td>
      <td>7.884160</td>
      <td>0.331329</td>
      <td>11.760232</td>
      <td>0.476951</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.078000</td>
      <td>21.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000000</td>
      <td>99.000000</td>
      <td>62.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>27.300000</td>
      <td>0.243750</td>
      <td>24.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>117.000000</td>
      <td>72.000000</td>
      <td>23.000000</td>
      <td>30.500000</td>
      <td>32.000000</td>
      <td>0.372500</td>
      <td>29.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.000000</td>
      <td>140.250000</td>
      <td>80.000000</td>
      <td>32.000000</td>
      <td>127.250000</td>
      <td>36.600000</td>
      <td>0.626250</td>
      <td>41.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>17.000000</td>
      <td>199.000000</td>
      <td>122.000000</td>
      <td>99.000000</td>
      <td>846.000000</td>
      <td>67.100000</td>
      <td>2.420000</td>
      <td>81.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
<h3 id="cleaning-zero-values" class="relative group">Cleaning zero values <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#cleaning-zero-values" aria-label="Anchor">#</a></span></h3>
<p>There are a few interesting bits in the table above:</p>
<ul>
<li>we see patients whose <code>Glucose</code> measurements are zero, which makes no sense and we need to take care of</li>
<li>we can also observe patients whose <code>BloodPressure</code> measurement is zero</li>
<li>we can also observe patients whose <code>SkinThickness</code> measurement is zero</li>
<li>we can also observe patients whose <code>Insulin</code> measurement is zero</li>
<li>we can also observe patients whose <code>BMI</code> is also zero, which is plainly impossible</li>
</ul>
<p>Let&rsquo;s clean up these nonsensical values - we can replace the zeroes with the mean of each column:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>means <span style="color:#81a1c1">=</span> df<span style="color:#81a1c1">.</span>iloc<span style="color:#eceff4">[:,</span> <span style="color:#b48ead">1</span><span style="color:#eceff4">:</span><span style="color:#b48ead">6</span><span style="color:#eceff4">]</span><span style="color:#81a1c1">.</span>mean<span style="color:#eceff4">()</span>
</span></span><span style="display:flex;"><span>means
</span></span></code></pre></div><pre><code>Glucose          120.894531
BloodPressure     69.105469
SkinThickness     20.536458
Insulin           79.799479
BMI               31.992578
dtype: float64
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>nonzeros <span style="color:#81a1c1">=</span> <span style="color:#81a1c1">list</span><span style="color:#eceff4">(</span>df<span style="color:#81a1c1">.</span>columns<span style="color:#eceff4">[</span><span style="color:#b48ead">1</span><span style="color:#eceff4">:</span><span style="color:#b48ead">6</span><span style="color:#eceff4">])</span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">for</span> column <span style="color:#81a1c1;font-weight:bold">in</span> nonzeros<span style="color:#eceff4">:</span>
</span></span><span style="display:flex;"><span>    df<span style="color:#eceff4">[</span>column<span style="color:#eceff4">]</span> <span style="color:#81a1c1">=</span> df<span style="color:#eceff4">[</span>column<span style="color:#eceff4">]</span><span style="color:#81a1c1">.</span>replace<span style="color:#eceff4">(</span><span style="color:#b48ead">0</span><span style="color:#eceff4">,</span> means<span style="color:#eceff4">[</span>column<span style="color:#eceff4">])</span>
</span></span></code></pre></div><p>We can see how the <code>min</code> values now changed:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df<span style="color:#81a1c1">.</span>min<span style="color:#eceff4">()</span>
</span></span></code></pre></div><pre><code>Pregnancies                  0.000
Glucose                     44.000
BloodPressure               24.000
SkinThickness                7.000
Insulin                     14.000
BMI                         18.200
DiabetesPedigreeFunction     0.078
Age                         21.000
Outcome                      0.000
dtype: float64
</code></pre>
<p>Now that we cleaned up the zero values, let&rsquo;s look splitting our data into training and tests sets.</p>
<h2 id="data-splitting" class="relative group">Data splitting <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#data-splitting" aria-label="Anchor">#</a></span></h2>
<p>Splitting the data into test and train data is an essential part of model buildling. Having the training data allows us to train our model, while the test data allows us to check the accuracy of the model. In other words, the test data allows us to see how our model will perform with out-of-sample data.</p>
<p>Out-of-sample data is a fancy way of saying data that is not part of the training dataset.</p>
<p>To split our data into training and test data, we can use <code>scikit-learn</code>&rsquo;s <code>train_test_split</code> method.</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X <span style="color:#81a1c1">=</span> df<span style="color:#81a1c1">.</span>iloc<span style="color:#eceff4">[:,</span> <span style="color:#b48ead">0</span><span style="color:#eceff4">:</span><span style="color:#b48ead">7</span><span style="color:#eceff4">]</span><span style="color:#81a1c1">.</span>to_numpy<span style="color:#eceff4">()</span>
</span></span><span style="display:flex;"><span>y <span style="color:#81a1c1">=</span> df<span style="color:#81a1c1">.</span>iloc<span style="color:#eceff4">[:,</span> <span style="color:#b48ead">8</span><span style="color:#eceff4">]</span><span style="color:#81a1c1">.</span>to_numpy<span style="color:#eceff4">()</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">from</span> <span style="color:#8fbcbb">sklearn.model_selection</span> <span style="color:#81a1c1;font-weight:bold">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train<span style="color:#eceff4">,</span> X_test<span style="color:#eceff4">,</span> y_train<span style="color:#eceff4">,</span> y_test <span style="color:#81a1c1">=</span> train_test_split<span style="color:#eceff4">(</span>X<span style="color:#eceff4">,</span> y<span style="color:#eceff4">,</span> test_size<span style="color:#81a1c1">=</span><span style="color:#b48ead">0.4</span><span style="color:#eceff4">)</span>
</span></span></code></pre></div><p>The <code>train_test_split</code> method takes three immportant arguments:</p>
<ul>
<li>the independent features, stored in the variable <code>X</code></li>
<li>the target values, stored in the variable <code>y</code></li>
<li>the test size as a float, which tells the method how big the test size should be</li>
</ul>
<p>Let&rsquo;s see how <code>train_test_split</code> has split our data here. Remember, the original dataset had 768 rows and 9 columns:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df<span style="color:#81a1c1">.</span>shape
</span></span></code></pre></div><pre><code>(768, 9)
</code></pre>
<p>Let&rsquo;s see the <code>shape</code> of the train and test data:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X_train<span style="color:#81a1c1">.</span>shape
</span></span></code></pre></div><pre><code>(460, 7)
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X_test<span style="color:#81a1c1">.</span>shape
</span></span></code></pre></div><pre><code>(308, 7)
</code></pre>
<p>We can see that the data has been split to 60% training data and 40% test data, which is exactly what the <code>test_size</code> arguent instructed <code>train_test_split</code> to do (with its value 0.4).</p>
<p>Now that our data is split, let&rsquo;s look into the problem of data scaling.</p>
<h2 id="scaling-our-data" class="relative group">Scaling our data <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#scaling-our-data" aria-label="Anchor">#</a></span></h2>
<p>As we already established in the short part on the backing theory, k-NN is an algorithm that calculates distances between points on a plane. Because it calculates distances, the algorithm will be sensitive to the larger range in which some of the features may have.</p>
<p>Let&rsquo;s look at the different ranges of each feature in the dataset:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#81a1c1">.</span>style<span style="color:#81a1c1">.</span>use<span style="color:#eceff4">(</span><span style="color:#a3be8c">&#39;seaborn-v0_8&#39;</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig<span style="color:#eceff4">,</span> axes <span style="color:#81a1c1">=</span> plt<span style="color:#81a1c1">.</span>subplots<span style="color:#eceff4">(</span><span style="color:#b48ead">2</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">4</span><span style="color:#eceff4">,</span> figsize<span style="color:#81a1c1">=</span><span style="color:#eceff4">[</span><span style="color:#b48ead">14</span><span style="color:#eceff4">,</span><span style="color:#b48ead">6</span><span style="color:#eceff4">])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pd<span style="color:#81a1c1">.</span>DataFrame<span style="color:#81a1c1">.</span>hist<span style="color:#eceff4">(</span>df<span style="color:#81a1c1">.</span>drop<span style="color:#eceff4">(</span><span style="color:#a3be8c">&#39;Outcome&#39;</span><span style="color:#eceff4">,</span> axis<span style="color:#81a1c1">=</span><span style="color:#b48ead">1</span><span style="color:#eceff4">),</span> ax<span style="color:#81a1c1">=</span>axes<span style="color:#eceff4">);</span>
</span></span></code></pre></div><p><img src="index_files/figure-markdown_strict/cell-16-output-1.png" alt=""  />
</p>
<p>For example, let&rsquo;s take two 2D planes, where the frist one has <code>Pregnancies</code> as one axis and <code>SkinThickness</code> as the other, and the second plane has <code>Insulin</code> and <code>Glucose</code> as axes. Due to the ranges of the axes in the first plane being smaller than the second plane, k-NN will always give the distances of the second plane more significance. In other words, the values of the distances from the second plane will always have a higher absolute value, which will make k-NN bias towards the distances from the second plane.</p>
<p>To remove this kind of bias, we need to scale our features.</p>
<h3 id="intro-to-scaling" class="relative group">Intro to scaling <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#intro-to-scaling" aria-label="Anchor">#</a></span></h3>
<p>There are different ways to scale features, but I&rsquo;d say exploring them is outside of the scope of this writeup. One has got to draw the line somewhere! To scale our features we will use the <code>preprocessing</code> module from <code>sklearn</code>. From the <code>preprocessing</code> module we will use the <code>StandardScaler</code> class - it&rsquo;s a utility class, which is a quick and easy way to perform standardization on an array-like dataset.</p>
<p>Let&rsquo;s try to standardize all of our features and see their before- and after-standardization:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">from</span> <span style="color:#8fbcbb">sklearn.preprocessing</span> <span style="color:#81a1c1;font-weight:bold">import</span> StandardScaler
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig<span style="color:#eceff4">,</span> ax <span style="color:#81a1c1">=</span> plt<span style="color:#81a1c1">.</span>subplots<span style="color:#eceff4">(</span><span style="color:#b48ead">2</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">4</span><span style="color:#eceff4">,</span> figsize<span style="color:#81a1c1">=</span><span style="color:#eceff4">[</span><span style="color:#b48ead">14</span><span style="color:#eceff4">,</span><span style="color:#b48ead">6</span><span style="color:#eceff4">])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>scaler <span style="color:#81a1c1">=</span> StandardScaler<span style="color:#eceff4">()</span>
</span></span><span style="display:flex;"><span>features <span style="color:#81a1c1">=</span> df<span style="color:#81a1c1">.</span>iloc<span style="color:#eceff4">[:,</span> <span style="color:#b48ead">0</span><span style="color:#eceff4">:</span><span style="color:#b48ead">8</span><span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>scaled_features <span style="color:#81a1c1">=</span> scaler<span style="color:#81a1c1">.</span>fit_transform<span style="color:#eceff4">(</span>features<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>scaled_features_df <span style="color:#81a1c1">=</span> pd<span style="color:#81a1c1">.</span>DataFrame<span style="color:#eceff4">(</span>scaled_features<span style="color:#eceff4">,</span> columns<span style="color:#81a1c1">=</span>df<span style="color:#81a1c1">.</span>columns<span style="color:#eceff4">[</span><span style="color:#b48ead">0</span><span style="color:#eceff4">:</span><span style="color:#b48ead">8</span><span style="color:#eceff4">])</span>
</span></span><span style="display:flex;"><span>scaled_features_df<span style="color:#81a1c1">.</span>hist<span style="color:#eceff4">(</span>ax<span style="color:#81a1c1">=</span>ax<span style="color:#eceff4">);</span>
</span></span></code></pre></div><p><img src="index_files/figure-markdown_strict/cell-17-output-1.png" alt=""  />
</p>
<p>What&rsquo;s interesting is that the histograms of the featuers before and after scaling look the same. This is exactly what we want - the scaled individual features are still distributed identically as before scaling, but all values are scaled down between -4 and 4, with some outliers. By standardizing the features here we make sure that some features won&rsquo;t have a greater effect on the model than others, due to their absolute values being larger than others.</p>
<h3 id="scaling-the-features" class="relative group">Scaling the features <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#scaling-the-features" aria-label="Anchor">#</a></span></h3>
<p>To actually scale our training and test sets, we need to take similar steps as above. First, let&rsquo;s initialize the scaler with the <code>X_train</code> data, and make it fit and transform the <code>X_train</code> data first:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scaler <span style="color:#81a1c1">=</span> StandardScaler<span style="color:#eceff4">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train <span style="color:#81a1c1">=</span> scaler<span style="color:#81a1c1">.</span>fit_transform<span style="color:#eceff4">(</span>X_train<span style="color:#eceff4">)</span>
</span></span></code></pre></div><p>Now, with the scaler fitted to the <code>X_train</code> data, we need to transform the <code>X_test</code> data:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X_test <span style="color:#81a1c1">=</span> scaler<span style="color:#81a1c1">.</span>transform<span style="color:#eceff4">(</span>X_test<span style="color:#eceff4">)</span>
</span></span></code></pre></div><p>Now that the features are scaled, let&rsquo;s use them in our k-Nearest Neighbors algorithm. Which we&rsquo;ll have to first write from scratch before we try it out.</p>
<h2 id="k-nn-from-scratch" class="relative group">k-NN from scratch <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#k-nn-from-scratch" aria-label="Anchor">#</a></span></h2>
<p>Now that we have that out of the way, let&rsquo;s implement our own k-NN. To implement the algorithm, we need two methods:</p>
<ul>
<li><code>fit</code>, which will set the features (X) and labels (y) to the model&rsquo;s memory</li>
<li><code>predict</code>, which will take a vector of out-of-sample data and return a prediction</li>
</ul>
<p>Let&rsquo;s start with the simpler ones:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">class</span> <span style="color:#8fbcbb">KNN</span><span style="color:#eceff4">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#81a1c1;font-weight:bold">def</span> __init__<span style="color:#eceff4">(</span>self<span style="color:#eceff4">,</span> k<span style="color:#81a1c1">=</span><span style="color:#b48ead">5</span><span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    self<span style="color:#81a1c1">.</span>k <span style="color:#81a1c1">=</span> k
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">fit</span><span style="color:#eceff4">(</span>self<span style="color:#eceff4">,</span> X<span style="color:#eceff4">,</span> y<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    self<span style="color:#81a1c1">.</span>X_train <span style="color:#81a1c1">=</span> X
</span></span><span style="display:flex;"><span>    self<span style="color:#81a1c1">.</span>y_train <span style="color:#81a1c1">=</span> y
</span></span></code></pre></div><p>In this case, fitting the X and y just means setting them as the object&rsquo;s attributes.</p>
<p>Let&rsquo;s look at the <code>predict</code> method:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">predict</span><span style="color:#eceff4">(</span>self<span style="color:#eceff4">,</span> X<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    predictions <span style="color:#81a1c1">=</span> <span style="color:#eceff4">[</span>self<span style="color:#81a1c1">.</span>_predict<span style="color:#eceff4">(</span>x<span style="color:#eceff4">)</span> <span style="color:#81a1c1;font-weight:bold">for</span> x <span style="color:#81a1c1;font-weight:bold">in</span> X<span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> predictions
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">_predict</span><span style="color:#eceff4">(</span>self<span style="color:#eceff4">,</span> x<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    distances <span style="color:#81a1c1">=</span> <span style="color:#eceff4">[</span>euclidean_distance<span style="color:#eceff4">(</span>x<span style="color:#eceff4">,</span> x_train<span style="color:#eceff4">)</span> <span style="color:#81a1c1;font-weight:bold">for</span> x_train <span style="color:#81a1c1;font-weight:bold">in</span> self<span style="color:#81a1c1">.</span>X_train<span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    k_indices <span style="color:#81a1c1">=</span> np<span style="color:#81a1c1">.</span>argsort<span style="color:#eceff4">(</span>distances<span style="color:#eceff4">)[:</span>self<span style="color:#81a1c1">.</span>k<span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>    k_labels <span style="color:#81a1c1">=</span> <span style="color:#eceff4">[</span>self<span style="color:#81a1c1">.</span>y_train<span style="color:#eceff4">[</span>i<span style="color:#eceff4">]</span> <span style="color:#81a1c1;font-weight:bold">for</span> i <span style="color:#81a1c1;font-weight:bold">in</span> k_indices<span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    most_common <span style="color:#81a1c1">=</span> Counter<span style="color:#eceff4">(</span>k_labels<span style="color:#eceff4">)</span><span style="color:#81a1c1">.</span>most_common<span style="color:#eceff4">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> most_common<span style="color:#eceff4">[</span><span style="color:#b48ead">0</span><span style="color:#eceff4">][</span><span style="color:#b48ead">0</span><span style="color:#eceff4">]</span>
</span></span></code></pre></div><p>The <code>predict</code> method essentially loops through each of the observations from the X n-dimensional array and calls <code>_predit</code> for every subarray. Within <code>_predict</code> we calculate the Euclidean distances for every array pair: the argument (<code>X</code>) and each array of the training data (<code>X_train</code>). Once we have the distances, we use <code>np.argsort</code> [<a href="https://numpy.org/doc/stable/reference/generated/numpy.argsort.html">docs</a>] to get the indices of the sorted distances. <code>np.argsort</code> will basically perform a sort on the distances, but return the indices of the elements in the sorted array, instead of the array itself.</p>
<p>Using the indices we will take the matching target variables from the <code>y_train</code> - in other words, by having the indices of the closest distances from the <code>X_train</code> set we will use their matching target labels from <code>y_train</code>. This is how the <code>X_train</code> input features become a single target class - by fetching the corresponding <code>y_train</code> label.</p>
<p>Once we have the <code>k_labels</code>, we just find the most common label of the bunch. This is the voting component of the k-NN algorithm. By finding the most common label we basically say: from the K nearest neighbors, the most common is Z, so we return Z as the predicted class.</p>
<p>Here&rsquo;s the whole k-NN algorithm:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">from</span> <span style="color:#8fbcbb">collections</span> <span style="color:#81a1c1;font-weight:bold">import</span> Counter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">euclidean_distance</span><span style="color:#eceff4">(</span>a<span style="color:#eceff4">,</span> b<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>  <span style="color:#81a1c1;font-weight:bold">return</span> np<span style="color:#81a1c1">.</span>sqrt<span style="color:#eceff4">(</span>np<span style="color:#81a1c1">.</span>sum<span style="color:#eceff4">((</span>a<span style="color:#81a1c1">-</span>b<span style="color:#eceff4">)</span><span style="color:#81a1c1">**</span><span style="color:#b48ead">2</span><span style="color:#eceff4">))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">class</span> <span style="color:#8fbcbb">KNN</span><span style="color:#eceff4">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#81a1c1;font-weight:bold">def</span> __init__<span style="color:#eceff4">(</span>self<span style="color:#eceff4">,</span> k<span style="color:#81a1c1">=</span><span style="color:#b48ead">5</span><span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    self<span style="color:#81a1c1">.</span>k <span style="color:#81a1c1">=</span> k
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">fit</span><span style="color:#eceff4">(</span>self<span style="color:#eceff4">,</span> X<span style="color:#eceff4">,</span> y<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    self<span style="color:#81a1c1">.</span>X_train <span style="color:#81a1c1">=</span> X
</span></span><span style="display:flex;"><span>    self<span style="color:#81a1c1">.</span>y_train <span style="color:#81a1c1">=</span> y
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>  <span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">predict</span><span style="color:#eceff4">(</span>self<span style="color:#eceff4">,</span> X<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    predictions <span style="color:#81a1c1">=</span> <span style="color:#eceff4">[</span>self<span style="color:#81a1c1">.</span>_predict<span style="color:#eceff4">(</span>x<span style="color:#eceff4">)</span> <span style="color:#81a1c1;font-weight:bold">for</span> x <span style="color:#81a1c1;font-weight:bold">in</span> X<span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> np<span style="color:#81a1c1">.</span>array<span style="color:#eceff4">(</span>predictions<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">_predict</span><span style="color:#eceff4">(</span>self<span style="color:#eceff4">,</span> x<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    distances <span style="color:#81a1c1">=</span> <span style="color:#eceff4">[</span>euclidean_distance<span style="color:#eceff4">(</span>x<span style="color:#eceff4">,</span> x_train<span style="color:#eceff4">)</span> <span style="color:#81a1c1;font-weight:bold">for</span> x_train <span style="color:#81a1c1;font-weight:bold">in</span> self<span style="color:#81a1c1">.</span>X_train<span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    k_indices <span style="color:#81a1c1">=</span> np<span style="color:#81a1c1">.</span>argsort<span style="color:#eceff4">(</span>distances<span style="color:#eceff4">)[:</span>self<span style="color:#81a1c1">.</span>k<span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>    k_labels <span style="color:#81a1c1">=</span> <span style="color:#eceff4">[</span>self<span style="color:#81a1c1">.</span>y_train<span style="color:#eceff4">[</span>i<span style="color:#eceff4">]</span> <span style="color:#81a1c1;font-weight:bold">for</span> i <span style="color:#81a1c1;font-weight:bold">in</span> k_indices<span style="color:#eceff4">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    most_common <span style="color:#81a1c1">=</span> Counter<span style="color:#eceff4">(</span>k_labels<span style="color:#eceff4">)</span><span style="color:#81a1c1">.</span>most_common<span style="color:#eceff4">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> most_common<span style="color:#eceff4">[</span><span style="color:#b48ead">0</span><span style="color:#eceff4">][</span><span style="color:#b48ead">0</span><span style="color:#eceff4">]</span>
</span></span></code></pre></div><p>Let&rsquo;s put it into use, using the <code>X_train_scaled</code> and <code>X_test_scaled</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>clf <span style="color:#81a1c1">=</span> KNN<span style="color:#eceff4">(</span>k<span style="color:#81a1c1">=</span><span style="color:#b48ead">5</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>clf<span style="color:#81a1c1">.</span>fit<span style="color:#eceff4">(</span>X_train<span style="color:#eceff4">,</span> y_train<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>predictions <span style="color:#81a1c1">=</span> clf<span style="color:#81a1c1">.</span>predict<span style="color:#eceff4">(</span>X_test<span style="color:#eceff4">)</span>
</span></span></code></pre></div><p>Now we have our predictions from the k-NN algorithm, but how do we know how if our model is accurate? This is where we need to evaluate our model&rsquo;s performance.</p>
<h2 id="accuracy-confusion-precision--recall" class="relative group">Accuracy, confusion, precision &amp; recall <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#accuracy-confusion-precision--recall" aria-label="Anchor">#</a></span></h2>
<p>Model evaluation is a really interesting topic - it&rsquo;s basically measuring how accurate the model is against the test data. We will look at a few different techniques here that I&rsquo;d like to explore, but the list is not exhaustive as there are other methods of model evaluation as well.</p>
<p>To evaluate the performance of the algorithm we will look at the accuracy metric and the confusion matrix of the algorithm.</p>
<h3 id="accuracy" class="relative group">Accuracy <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#accuracy" aria-label="Anchor">#</a></span></h3>
<p>Accuracy is the simplest approach of all. The way it works is by finding the number of correct predictions between the predictions and the targets, divided by the number of all targets. The accuracy measurement essentially finds the ratio of correctly predicted labels against all labels.</p>
<p>In Python, the accuracy method would look like:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">calculate_accuracy</span><span style="color:#eceff4">(</span>y_true<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    accuracy <span style="color:#81a1c1">=</span> np<span style="color:#81a1c1">.</span>sum<span style="color:#eceff4">(</span>y_true <span style="color:#81a1c1">==</span> y_pred<span style="color:#eceff4">)</span> <span style="color:#81a1c1">/</span> <span style="color:#81a1c1">len</span><span style="color:#eceff4">(</span>y_true<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> accuracy
</span></span></code></pre></div><p>If we take our <code>predictions</code> from above and run them against our test labels (<code>y_test</code>), we will get the accuracy of the k-NN algorithm against the test data:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>calculate_accuracy<span style="color:#eceff4">(</span>y_test<span style="color:#eceff4">,</span> predictions<span style="color:#eceff4">)</span>
</span></span></code></pre></div><pre><code>0.7045454545454546
</code></pre>
<p>The accuracy is quite a simple measurement, as it doesn&rsquo;t tell us about the potential misclassifications. In the diabetes example, with accuracy of 0.75 it means that we will end up misdiagnosing a quarter of the patients.</p>
<h3 id="confusion-matrix" class="relative group">Confusion matrix <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#confusion-matrix" aria-label="Anchor">#</a></span></h3>
<p>While the accuracy metric speaks loads, for us humans in some cases a visualization goes a longer way instead of a metric. A confusion matrix is a visualization that can give us a better idea of the algorithm&rsquo;s performance. Let&rsquo;s see the confusion matrix of our k-NN algorithm:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">from</span> <span style="color:#8fbcbb">sklearn.metrics</span> <span style="color:#81a1c1;font-weight:bold">import</span> confusion_matrix
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cm <span style="color:#81a1c1">=</span> confusion_matrix<span style="color:#eceff4">(</span>y_test<span style="color:#eceff4">,</span> predictions<span style="color:#eceff4">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">import</span> <span style="color:#8fbcbb">seaborn</span> <span style="color:#81a1c1;font-weight:bold">as</span> <span style="color:#8fbcbb">sns</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#616e87;font-style:italic"># Change figure size and increase dpi for better resolution</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#81a1c1">.</span>figure<span style="color:#eceff4">(</span>figsize<span style="color:#81a1c1">=</span><span style="color:#eceff4">(</span><span style="color:#b48ead">6</span><span style="color:#eceff4">,</span> <span style="color:#b48ead">4</span><span style="color:#eceff4">))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax <span style="color:#81a1c1">=</span> sns<span style="color:#81a1c1">.</span>heatmap<span style="color:#eceff4">(</span>cm<span style="color:#eceff4">,</span> annot<span style="color:#81a1c1">=</span><span style="color:#81a1c1;font-weight:bold">True</span><span style="color:#eceff4">,</span> fmt<span style="color:#81a1c1">=</span><span style="color:#a3be8c">&#39;d&#39;</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#616e87;font-style:italic"># set x-axis label and ticks. </span>
</span></span><span style="display:flex;"><span>ax<span style="color:#81a1c1">.</span>set_xlabel<span style="color:#eceff4">(</span><span style="color:#a3be8c">&#34;Predicted Diagnosis&#34;</span><span style="color:#eceff4">,</span> fontsize<span style="color:#81a1c1">=</span><span style="color:#b48ead">14</span><span style="color:#eceff4">,</span> labelpad<span style="color:#81a1c1">=</span><span style="color:#b48ead">20</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>ax<span style="color:#81a1c1">.</span>xaxis<span style="color:#81a1c1">.</span>set_ticklabels<span style="color:#eceff4">([</span><span style="color:#a3be8c">&#39;Negative&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Positive&#39;</span><span style="color:#eceff4">])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#616e87;font-style:italic"># set y-axis label and ticks</span>
</span></span><span style="display:flex;"><span>ax<span style="color:#81a1c1">.</span>set_ylabel<span style="color:#eceff4">(</span><span style="color:#a3be8c">&#34;Actual Diagnosis&#34;</span><span style="color:#eceff4">,</span> fontsize<span style="color:#81a1c1">=</span><span style="color:#b48ead">14</span><span style="color:#eceff4">,</span> labelpad<span style="color:#81a1c1">=</span><span style="color:#b48ead">20</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>ax<span style="color:#81a1c1">.</span>yaxis<span style="color:#81a1c1">.</span>set_ticklabels<span style="color:#eceff4">([</span><span style="color:#a3be8c">&#39;Negative&#39;</span><span style="color:#eceff4">,</span> <span style="color:#a3be8c">&#39;Positive&#39;</span><span style="color:#eceff4">])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax<span style="color:#81a1c1">.</span>set_title<span style="color:#eceff4">(</span><span style="color:#a3be8c">&#34;Confusion Matrix for the Diabetes k-NN&#34;</span><span style="color:#eceff4">,</span> fontsize<span style="color:#81a1c1">=</span><span style="color:#b48ead">14</span><span style="color:#eceff4">,</span> pad<span style="color:#81a1c1">=</span><span style="color:#b48ead">20</span><span style="color:#eceff4">);</span>
</span></span></code></pre></div><p><img src="index_files/figure-markdown_strict/cell-27-output-1.png" alt=""  />
</p>
<p>We can see in the confusion matrix that the algorithm predicts the Negative outcomes pretty well, but there is a significant misclassification happening in the lower left quadrant. In other words, the algorithm classified 56 patients as &lsquo;Negative&rsquo; (no diabetes), but the diagnosis was &lsquo;Positive&rsquo; (they did get diabetes). These 56 classifications are also called false negatives.</p>
<p>What&rsquo;s tricky about this stark number of false negatives is that if a doctor followed the algorithm&rsquo;s prediction, the correct diagnosis would be set much later with these patients, which can have long-term implications for their health. So what can we do about this? Is this a problem with our algorithm or our setup? Or a bit of both?</p>
<p>Let&rsquo;s look at another few metrics to measure the algorithm&rsquo;s performance: precision, recall &amp; F1 score.</p>
<h3 id="precision--recall" class="relative group">Precision &amp; recall <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#precision--recall" aria-label="Anchor">#</a></span></h3>
<p>These two are exciting metrics because they measure the positive predictive value and the algorithm&rsquo;s sensitivity, respectively. Another way to explain them:</p>
<ul>
<li>Precision is the true positive predictions over the sum of the true positive and false positive predictions. It basically returns the ratio of true positive predictions over all positive predictions. Hence the name &lsquo;positive predictive value.&rsquo;</li>
<li>Recall, on the other hand, is the true positive predictions over the sum of the true predictions and the false negative. The true positive and false negative predictions are, in fact, all the <em>correct</em> predictions. So recall returns the ratio of the true predictions against the <em>correct</em> predictions. Hence the name &lsquo;sensitivity&rsquo; - it measures how many of the correct predictions the algorithm under evaluation will pick up.</li>
</ul>
<p>We can implement precision and recall using Python. But, first, we need to implement four helper functions:</p>
<ul>
<li><code>true_positive</code></li>
<li><code>true_negative</code></li>
<li><code>false_positive</code></li>
<li><code>false_negative</code></li>
</ul>
<p>From there, we can easily implement <code>recall</code> and <code>precision</code>. So let&rsquo;s give it a shot. First, the helpers:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">true_positive</span><span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    tp <span style="color:#81a1c1">=</span> <span style="color:#b48ead">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">for</span> pred<span style="color:#eceff4">,</span> val <span style="color:#81a1c1;font-weight:bold">in</span> <span style="color:#81a1c1">zip</span><span style="color:#eceff4">(</span>y_pred<span style="color:#eceff4">,</span> y_val<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#81a1c1;font-weight:bold">if</span> pred <span style="color:#81a1c1">==</span> <span style="color:#b48ead">1</span> <span style="color:#81a1c1;font-weight:bold">and</span> val <span style="color:#81a1c1">==</span> <span style="color:#b48ead">1</span><span style="color:#eceff4">:</span>
</span></span><span style="display:flex;"><span>            tp <span style="color:#81a1c1">+=</span> <span style="color:#b48ead">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> tp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">true_negative</span><span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    tn <span style="color:#81a1c1">=</span> <span style="color:#b48ead">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">for</span> pred<span style="color:#eceff4">,</span> val <span style="color:#81a1c1;font-weight:bold">in</span> <span style="color:#81a1c1">zip</span><span style="color:#eceff4">(</span>y_pred<span style="color:#eceff4">,</span> y_val<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#81a1c1;font-weight:bold">if</span> pred <span style="color:#81a1c1">==</span> <span style="color:#b48ead">0</span> <span style="color:#81a1c1;font-weight:bold">and</span> val <span style="color:#81a1c1">==</span> <span style="color:#b48ead">0</span><span style="color:#eceff4">:</span>
</span></span><span style="display:flex;"><span>            tn <span style="color:#81a1c1">+=</span> <span style="color:#b48ead">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> tn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">false_positive</span><span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    fp <span style="color:#81a1c1">=</span> <span style="color:#b48ead">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">for</span> pred<span style="color:#eceff4">,</span> val <span style="color:#81a1c1;font-weight:bold">in</span> <span style="color:#81a1c1">zip</span><span style="color:#eceff4">(</span>y_pred<span style="color:#eceff4">,</span> y_val<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#81a1c1;font-weight:bold">if</span> pred <span style="color:#81a1c1">==</span> <span style="color:#b48ead">1</span> <span style="color:#81a1c1;font-weight:bold">and</span> val <span style="color:#81a1c1">==</span> <span style="color:#b48ead">0</span><span style="color:#eceff4">:</span>
</span></span><span style="display:flex;"><span>            fp <span style="color:#81a1c1">+=</span> <span style="color:#b48ead">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> fp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">false_negative</span><span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    fn <span style="color:#81a1c1">=</span> <span style="color:#b48ead">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">for</span> pred<span style="color:#eceff4">,</span> val <span style="color:#81a1c1;font-weight:bold">in</span> <span style="color:#81a1c1">zip</span><span style="color:#eceff4">(</span>y_pred<span style="color:#eceff4">,</span> y_val<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#81a1c1;font-weight:bold">if</span> pred <span style="color:#81a1c1">==</span> <span style="color:#b48ead">0</span> <span style="color:#81a1c1;font-weight:bold">and</span> val <span style="color:#81a1c1">==</span> <span style="color:#b48ead">1</span><span style="color:#eceff4">:</span>
</span></span><span style="display:flex;"><span>            fn <span style="color:#81a1c1">+=</span> <span style="color:#b48ead">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> fn
</span></span></code></pre></div><p>Next, the methods themselves:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">calculate_precision</span><span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    tp <span style="color:#81a1c1">=</span> true_positive<span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>    fp <span style="color:#81a1c1">=</span> false_positive<span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>    prec <span style="color:#81a1c1">=</span> tp <span style="color:#81a1c1">/</span> <span style="color:#eceff4">(</span>tp<span style="color:#81a1c1">+</span>fp<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> prec
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">calculate_recall</span><span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    tp <span style="color:#81a1c1">=</span> true_positive<span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>    fn <span style="color:#81a1c1">=</span> false_negative<span style="color:#eceff4">(</span>y_val<span style="color:#eceff4">,</span> y_pred<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>    rec <span style="color:#81a1c1">=</span> tp <span style="color:#81a1c1">/</span> <span style="color:#eceff4">(</span>tp <span style="color:#81a1c1">+</span> fn<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> rec
</span></span></code></pre></div><p>Let&rsquo;s measure the <code>precision</code> and <code>recall</code> of the predictions:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>precision_scr <span style="color:#81a1c1">=</span> calculate_precision<span style="color:#eceff4">(</span>y_test<span style="color:#eceff4">,</span> predictions<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>recall_scr <span style="color:#81a1c1">=</span> calculate_recall<span style="color:#eceff4">(</span>y_test<span style="color:#eceff4">,</span> predictions<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;Precision: </span><span style="color:#a3be8c">{</span>precision_scr<span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;Recall: </span><span style="color:#a3be8c">{</span>recall_scr<span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span></code></pre></div><pre><code>Precision: 0.5980392156862745
Recall: 0.5495495495495496
</code></pre>
<p>Let&rsquo;s compare our implementation of precision and recall against the one from scikit-learn:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">from</span> <span style="color:#8fbcbb">sklearn.metrics</span> <span style="color:#81a1c1;font-weight:bold">import</span> precision_score<span style="color:#eceff4">,</span> recall_score
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;scikit-learn&#39;s Precision: </span><span style="color:#a3be8c">{</span>precision_score<span style="color:#eceff4">(</span>y_test<span style="color:#eceff4">,</span> predictions<span style="color:#eceff4">)</span><span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;scikit-learn&#39;s Recall: </span><span style="color:#a3be8c">{</span>recall_score<span style="color:#eceff4">(</span>y_test<span style="color:#eceff4">,</span> predictions<span style="color:#eceff4">)</span><span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span></code></pre></div><pre><code>scikit-learn's Precision: 0.5980392156862745
scikit-learn's Recall: 0.5495495495495496
</code></pre>
<p>Nice, we got the same scores. You can see that our precision and recall scores are pretty low (0 is worst, 1 is best). This means that with our feature setup and the algorithm we chose, k Nearest Neighbors is not the best choice for the problem. We can conclude that because the algorithm&rsquo;s ability not to label negative samples as positive (precision) and its ability to find all the positive samples (recall) are quite low.</p>
<p>Now that we have the precision and recall, to wrap up our assessment of the algorithm we can also apply the F1 score.</p>
<h3 id="f1-score" class="relative group">F1 Score <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#f1-score" aria-label="Anchor">#</a></span></h3>
<p>The F1 score measures the model&rsquo;s balanced ability to capture positive cases (recall) <strong>and</strong> be accurate with the cases it does capture (precision). Mathematically explained, it takes the recall and precision metrics and it calculates their harmonic mean:</p>
<pre><code>F1 = 2 * (precision * recall) / (precision + recall)
</code></pre>
<p>When compared to the accuracy score, the F1 score is useful because it has both recall and precision captured into it. For contrast, the accuracy score only looks at the recall, ignoring the precision. This bi-modal nature of the F1 score makes it a popular choice of evaluation metric in the ML community.</p>
<p>As you can see above the formula is quite simple, but let&rsquo;s implement it for ourselves and test it against our precision and recall metrics:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">def</span> <span style="color:#88c0d0">calculate_f1</span><span style="color:#eceff4">(</span>precision<span style="color:#eceff4">,</span> recall<span style="color:#eceff4">):</span>
</span></span><span style="display:flex;"><span>    f1 <span style="color:#81a1c1">=</span> <span style="color:#b48ead">2</span> <span style="color:#81a1c1">*</span> <span style="color:#eceff4">(</span>precision <span style="color:#81a1c1">*</span> recall<span style="color:#eceff4">)</span> <span style="color:#81a1c1">/</span> <span style="color:#eceff4">(</span>precision <span style="color:#81a1c1">+</span> recall<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#81a1c1;font-weight:bold">return</span> f1
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>f1_scr <span style="color:#81a1c1">=</span> calculate_f1<span style="color:#eceff4">(</span>precision_scr<span style="color:#eceff4">,</span> recall_scr<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>f1_scr
</span></span></code></pre></div><pre><code>0.5727699530516432
</code></pre>
<p>Now, 0.59259 doesn&rsquo;t tell us much as we need a good idea of how to interpret it. From what I was able to find online, the best way to interpret F1 is this table:</p>
<table>
<thead>
<tr>
<th>F1 score</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td>&gt; 0.9</td>
<td>Very good</td>
</tr>
<tr>
<td>0.8 - 0.9</td>
<td>Good</td>
</tr>
<tr>
<td>0.5 - 0.8</td>
<td>OK</td>
</tr>
<tr>
<td>&lt; 0.5</td>
<td>Not good</td>
</tr>
</tbody>
</table>
<p>If we&rsquo;d follow the above table, then our k-NN algorithm is doing barely OK. Which means we should probably look into other algorithms or models to predict diabetes in patients using the available dataset.</p>
<h2 id="comparing-to-scikit-learn" class="relative group">Comparing to scikit-learn <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#comparing-to-scikit-learn" aria-label="Anchor">#</a></span></h2>
<p>Out of curiosity, the last thing that I wanted to look at is to compare our implementation of k-NN with the one from scikit-learn. The comparison will only confirm whether our implementation is correct, assuming we get the same metrics. Surely, the scikit-learn implementation is better as it will perform better with larger datasets. Still, for our 700-observations-large dataset both will do the trick.</p>
<p>Back to the comparison:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1;font-weight:bold">from</span> <span style="color:#8fbcbb">sklearn.neighbors</span> <span style="color:#81a1c1;font-weight:bold">import</span> KNeighborsClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>knn <span style="color:#81a1c1">=</span> KNeighborsClassifier<span style="color:#eceff4">(</span>n_neighbors<span style="color:#81a1c1">=</span><span style="color:#b48ead">5</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>knn<span style="color:#81a1c1">.</span>fit<span style="color:#eceff4">(</span>X_train<span style="color:#eceff4">,</span> y_train<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>predictions <span style="color:#81a1c1">=</span> knn<span style="color:#81a1c1">.</span>predict<span style="color:#eceff4">(</span>X_test<span style="color:#eceff4">)</span>
</span></span></code></pre></div><pre><code>/Users/ie/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)
</code></pre>
<p>Now that we have the predictions of the <code>KNeighborsClassifier</code>, let&rsquo;s see the precision, recall and F1 scores:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>sk_precision <span style="color:#81a1c1">=</span> calculate_precision<span style="color:#eceff4">(</span>y_test<span style="color:#eceff4">,</span> predictions<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>sk_recall <span style="color:#81a1c1">=</span> calculate_recall<span style="color:#eceff4">(</span>y_test<span style="color:#eceff4">,</span> predictions<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>sk_f1_score <span style="color:#81a1c1">=</span> calculate_f1<span style="color:#eceff4">(</span>precision<span style="color:#eceff4">,</span> recall<span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;Precision: </span><span style="color:#a3be8c">{</span>sk_precision<span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;Recall: </span><span style="color:#a3be8c">{</span>sk_recall<span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;F1: </span><span style="color:#a3be8c">{</span>sk_f1_score<span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span></code></pre></div><pre><code>Precision: 0.5980392156862745
Recall: 0.5495495495495496
F1: 0.5727699530516432
</code></pre>
<p>Let&rsquo;s compare them to our scores:</p>
<div class="highlight"><pre tabindex="0" style="color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;Precision same? </span><span style="color:#a3be8c">{</span>sk_precision <span style="color:#81a1c1">==</span> precision_scr<span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;Recall same? </span><span style="color:#a3be8c">{</span>sk_recall <span style="color:#81a1c1">==</span> recall_scr<span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span><span style="display:flex;"><span><span style="color:#81a1c1">print</span><span style="color:#eceff4">(</span><span style="color:#a3be8c">f</span><span style="color:#a3be8c">&#34;F1 same? </span><span style="color:#a3be8c">{</span>sk_f1_score <span style="color:#81a1c1">==</span> f1_scr<span style="color:#a3be8c">}</span><span style="color:#a3be8c">&#34;</span><span style="color:#eceff4">)</span>
</span></span></code></pre></div><pre><code>Precision same? True
Recall same? True
F1 same? True
</code></pre>
<p>Voil√†! Our k-NN implementation has the same recall and precision metrics as the one from sklearn. That&rsquo;s pretty cool to see, as it confirms that we have implemented our k-NN well!</p>
<hr>
<p>Some references I used while writing this post:</p>
<ul>
<li><a href="https://www.kaggle.com/code/ajinkyaabhang/implementing-acc-precision-recall-f1-from-scratch">https://www.kaggle.com/code/ajinkyaabhang/implementing-acc-precision-recall-f1-from-scratch</a></li>
<li><a href="https://www.kaggle.com/discussions/questions-and-answers/350350">https://www.kaggle.com/discussions/questions-and-answers/350350</a></li>
<li><a href="https://en.wikipedia.org/wiki/Instance-based_learning">https://en.wikipedia.org/wiki/Instance-based_learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Lazy_learning">https://en.wikipedia.org/wiki/Lazy_learning</a></li>
<li><a href="https://proclusacademy.com/blog/practical/confusion-matrix-accuracy-sklearn-seaborn/">https://proclusacademy.com/blog/practical/confusion-matrix-accuracy-sklearn-seaborn/</a></li>
<li><a href="https://en.wikipedia.org/wiki/Precision_and_recall">https://en.wikipedia.org/wiki/Precision_and_recall</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html</a></li>
<li><a href="https://stephenallwright.com/interpret-f1-score/">https://stephenallwright.com/interpret-f1-score/</a></li>
</ul>

      </div>
    </section>
    <footer class="pt-8 max-w-prose print:hidden">
      
  <div class="flex">
    
      
      
        
        <img
          class="w-24 h-24 !mt-0 !mb-0 ltr:mr-4 rtl:ml-4 rounded-full"
          width="96"
          height="96"
          alt="Ilija Eftimov"
          src="/img/avatar_huae39953c6189b6aa60e47103b358d088_112612_192x192_fill_q75_box_smart1.jpg"
        />
      
    
    <div class="place-self-center">
      
        <div class="text-[0.6rem] leading-3 text-neutral-500 dark:text-neutral-400 uppercase">
          Author
        </div>
        <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
          Ilija Eftimov
        </div>
      
      
      <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://twitter.com/ilijaio"
          target="_blank"
          aria-label="Twitter"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://www.linkedin.com/in/ieftimov/"
          target="_blank"
          aria-label="Linkedin"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="mailto:blog@ieftimov.com"
          target="_blank"
          aria-label="Email"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://captainscodebook.com"
          target="_blank"
          aria-label="Substack"
          rel="me noopener noreferrer"
          >

</a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://dev.to/fteem"
          target="_blank"
          aria-label="Dev"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M120.12 208.29c-3.88-2.9-7.77-4.35-11.65-4.35H91.03v104.47h17.45c3.88 0 7.77-1.45 11.65-4.35 3.88-2.9 5.82-7.25 5.82-13.06v-69.65c-.01-5.8-1.96-10.16-5.83-13.06zM404.1 32H43.9C19.7 32 .06 51.59 0 75.8v360.4C.06 460.41 19.7 480 43.9 480h360.2c24.21 0 43.84-19.59 43.9-43.8V75.8c-.06-24.21-19.7-43.8-43.9-43.8zM154.2 291.19c0 18.81-11.61 47.31-48.36 47.25h-46.4V172.98h47.38c35.44 0 47.36 28.46 47.37 47.28l.01 70.93zm100.68-88.66H201.6v38.42h32.57v29.57H201.6v38.41h53.29v29.57h-62.18c-11.16.29-20.44-8.53-20.72-19.69V193.7c-.27-11.15 8.56-20.41 19.71-20.69h63.19l-.01 29.52zm103.64 115.29c-13.2 30.75-36.85 24.63-47.44 0l-38.53-144.8h32.57l29.71 113.72 29.57-113.72h32.58l-38.46 144.8z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://github.com/fteem"
          target="_blank"
          aria-label="Github"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://t.me/ieftimovcom"
          target="_blank"
          aria-label="Telegram"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M248,8C111.033,8,0,119.033,0,256S111.033,504,248,504,496,392.967,496,256,384.967,8,248,8ZM362.952,176.66c-3.732,39.215-19.881,134.378-28.1,178.3-3.476,18.584-10.322,24.816-16.948,25.425-14.4,1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25,5.342-39.5,3.652-3.793,67.107-61.51,68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608,69.142-14.845,10.194-26.894,9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7,18.45-13.7,108.446-47.248,144.628-62.3c68.872-28.647,83.183-33.623,92.511-33.789,2.052-.034,6.639.474,9.61,2.885a10.452,10.452,0,0,1,3.53,6.716A43.765,43.765,0,0,1,362.952,176.66Z"/></svg>

  </span>

</a
        >
      
    
  </div>

</div>
    </div>
  </div>


      
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
        <a
          class="bg-neutral-300 text-neutral-700 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800 m-1 hover:bg-primary-500 hover:text-neutral rounded min-w-[2.4rem] inline-block text-center p-1"
          href="https://www.facebook.com/sharer/sharer.php?u=https://ieftimov.com/posts/knn-from-scratch-scikit-learn/&amp;quote=Predict%20diabetes%20using%20k-NN%20from%20scratch%20and%20scikit-learn"
          title="Share on Facebook"
          aria-label="Share on Facebook"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="bg-neutral-300 text-neutral-700 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800 m-1 hover:bg-primary-500 hover:text-neutral rounded min-w-[2.4rem] inline-block text-center p-1"
          href="https://twitter.com/intent/tweet/?url=https://ieftimov.com/posts/knn-from-scratch-scikit-learn/&amp;text=Predict%20diabetes%20using%20k-NN%20from%20scratch%20and%20scikit-learn"
          title="Tweet on Twitter"
          aria-label="Tweet on Twitter"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="bg-neutral-300 text-neutral-700 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800 m-1 hover:bg-primary-500 hover:text-neutral rounded min-w-[2.4rem] inline-block text-center p-1"
          href="https://reddit.com/submit/?url=https://ieftimov.com/posts/knn-from-scratch-scikit-learn/&amp;resubmit=true&amp;title=Predict%20diabetes%20using%20k-NN%20from%20scratch%20and%20scikit-learn"
          title="Submit to Reddit"
          aria-label="Submit to Reddit"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="bg-neutral-300 text-neutral-700 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800 m-1 hover:bg-primary-500 hover:text-neutral rounded min-w-[2.4rem] inline-block text-center p-1"
          href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://ieftimov.com/posts/knn-from-scratch-scikit-learn/&amp;title=Predict%20diabetes%20using%20k-NN%20from%20scratch%20and%20scikit-learn"
          title="Share on LinkedIn"
          aria-label="Share on LinkedIn"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="bg-neutral-300 text-neutral-700 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800 m-1 hover:bg-primary-500 hover:text-neutral rounded min-w-[2.4rem] inline-block text-center p-1"
          href="mailto:?body=https://ieftimov.com/posts/knn-from-scratch-scikit-learn/&amp;subject=Predict%20diabetes%20using%20k-NN%20from%20scratch%20and%20scikit-learn"
          title="Send via email"
          aria-label="Send via email"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>

  </span>

</a
        >
      
    
  </section>


      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group" href="/posts/how-to-make-reviewers-love-your-big-pull-requests/">
              <span
                class="mr-3 ltr:inline rtl:hidden text-neutral-700 dark:text-neutral group-hover:text-primary-600 dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 ltr:hidden rtl:inline text-neutral-700 dark:text-neutral group-hover:text-primary-600 dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >How to Make Reviewers Love Your Big Pull Requests</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2022-07-08 00:00:00 &#43;0000 UTC">8 July 2022</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="flex text-right group" href="/posts/classifier-decision-trees/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Predict heart attack outcomes using decision tree classifier from scratch and scikit-learn</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2023-03-29 00:00:00 &#43;0000 UTC">29 March 2023</time>
                  
                </span>
              </span>
              <span
                class="ml-3 ltr:inline rtl:hidden text-neutral-700 dark:text-neutral group-hover:text-primary-600 dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span
                class="mr-3 ltr:hidden rtl:inline text-neutral-700 dark:text-neutral group-hover:text-primary-600 dark:group-hover:text-primary-400"
                >&larr;</span
              >
            </a>
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

        
          <div
            class="absolute top-[100vh] ltr:right-0 rtl:left-0 w-12 pointer-events-none bottom-0"
          >
            <a
              href="#the-top"
              class="w-12 h-12 sticky pointer-events-auto top-[calc(100vh-5.5rem)] bg-neutral/50 dark:bg-neutral-800/50 backdrop-blur rounded-full text-xl flex items-center justify-center text-neutral-700 dark:text-neutral hover:text-primary-600 dark:hover:text-primary-400"
              aria-label="Scroll to top"
              title="Scroll to top"
            >
              &uarr;
            </a>
          </div>
        
      </main><footer class="py-10 print:hidden">
  
  
    <nav class="pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400">
      <ul class="flex flex-col list-none sm:flex-row">
        
          <li
            class="mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"
          >
            <a
              class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
              href="/analytics"
              title=""
              >Analytics</a
            >
          </li>
        
          <li
            class="mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"
          >
            <a
              class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
              href="/index.xml"
              title=""
              >RSS</a
            >
          </li>
        
          <li
            class="mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"
          >
            <a
              class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
              href="https://forms.gle/orfXK5jh1LRaiFzo8"
              title=""
              >Suggest a topic</a
            >
          </li>
        
      </ul>
    </nav>
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            &copy;
            2023
            Ilija Eftimov
        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://git.io/hugo-congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    
    
      <div
        class="text-sm cursor-pointer text-neutral-700 dark:text-neutral hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-14 rtl:ml-14"
      >
        <button
          id="appearance-switcher"
          class="w-12 h-12 "
          type="button"
          title="Switch to dark appearance"
        >
          <span class="inline dark:hidden">

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>

</span>
          <span class="hidden dark:inline">

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>

</span>
        </button>
      </div>
    
  </div>
  
  
</footer>
<div
  id="search-wrapper"
  class="fixed inset-0 z-50 flex flex-col p-4 sm:p-6 md:p-[10vh] lg:p-[12vh] w-screen h-screen cursor-default bg-neutral-500/50 backdrop-blur-sm dark:bg-neutral-900/50 invisible"
  data-url="https://ieftimov.com/"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg border-neutral-200 top-20 bg-neutral dark:bg-neutral-800 dark:border-neutral-700"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative inline-block align-text-bottom icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-transparent focus:outline-2"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 dark:text-neutral hover:text-primary-600 dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
</html>
